# Differential Geometry Packages: Comparison & Positioning

## Existing Python Packages for Differential Geometry

### ğŸ”µ **PyDEC** - Discrete Exterior Calculus
**Repository**: `hirani/pydec` (GitHub)
**Publication**: ACM TOMS 2012

**What it does:**
- Discrete exterior calculus on simplicial complexes
- Exterior derivative (coboundary operator)
- Hodge star operator
- Whitney forms (lowest-order finite elements)

**Scope**: General differential forms, algebraic topology, exterior calculus

**Strengths:**
- Rigorous mathematical framework
- Handles arbitrary simplicial complexes
- Topological correctness

**Limitations for neurospatial:**
- âŒ No spatial autocorrelation
- âŒ Not designed for neuroscience workflows
- âŒ Focus on topology, not spatial analysis
- âŒ Overkill for most neuroscience use cases

---

### ğŸ”µ **PyGSP** - Graph Signal Processing
**Repository**: `epfl-lts2/pygsp` (GitHub)
**Institution**: EPFL LTS2 Laboratory

**What it does:**
```python
G.compute_differential_operator()  # Gradient operator D
G.grad(signal)                     # Gradient: D @ signal
G.div(signal)                      # Divergence
G.compute_laplacian()              # Graph Laplacian L = D^T @ D
```

**Scope**: Signal processing on graphs (spectral methods, filtering)

**Strengths:**
- âœ… Graph-based differential operators
- âœ… Gradient and divergence
- âœ… Spectral graph theory
- âœ… Efficient for large graphs
- âœ… Active maintenance (EPFL)

**Limitations for neurospatial:**
- âŒ **No spatial autocorrelation** (only spectral methods)
- âŒ No trajectory operations
- âŒ No RL primitives
- âŒ Signal processing focus, not spatial analysis
- âŒ No neuroscience-specific features

**Overlap**: **~20%**
- Gradient operator exists but different interface
- Laplacian computation (neurospatial already has via `compute_diffusion_kernels`)

---

### ğŸ”µ **LaPy** - Mesh Differential Geometry
**Repository**: `Deep-MI/LaPy` (GitHub)

**What it does:**
- Gradient, divergence, Laplacian on triangle/tetrahedral meshes
- FEM solvers (Laplace, Poisson, Heat equations)
- Mean-curvature flow
- Geodesics, conformal mappings
- ShapeDNA (Laplace spectra)

**Scope**: Medical imaging, surface analysis, FEM

**Strengths:**
- âœ… Complete differential operators
- âœ… Fast (vectorized Python)
- âœ… Medical imaging focus

**Limitations for neurospatial:**
- âŒ **Triangle/tet meshes only** (not arbitrary graphs)
- âŒ No irregular bin layouts (hexagonal, masked grids)
- âŒ No spatial autocorrelation
- âŒ No trajectory/behavioral analysis
- âŒ No RL primitives

**Overlap**: **~15%**
- Both compute gradient/Laplacian, but on different structures

---

### ğŸ”µ **pcdiff** - Point Cloud Differential Operators
**Repository**: `rubenwiersma/pointcloud-differential`
**Available**: PyPI (`pip install pcdiff`)

**What it does:**
```python
pcdiff.operators.gradient(points, values)
pcdiff.operators.divergence(points, vector_field)
pcdiff.operators.laplacian(points, values)
```

**Scope**: Point clouds, deep learning on 3D data

**Strengths:**
- âœ… Gradient, divergence, Laplacian
- âœ… Works on point clouds

**Limitations for neurospatial:**
- âŒ **Point clouds, not bin-based discretization**
- âŒ No spatial autocorrelation
- âŒ No trajectory operations
- âŒ No RL support
- âŒ 3D graphics/ML focus

**Overlap**: **~10%**
- Similar operators, but different data structure

---

### ğŸ”µ **PyTorch Geometric** - Graph Neural Networks
**Repository**: `pyg-team/pytorch_geometric`

**What it does:**
```python
ChebConv(...)  # Chebyshev spectral graph convolution (uses Laplacian)
GCNConv(...)   # Graph convolutional network
LaplacianLambdaMax()  # Compute max eigenvalue
```

**Scope**: Graph neural networks, deep learning

**Strengths:**
- âœ… Graph Laplacian operations
- âœ… Efficient GPU computation
- âœ… Spectral convolutions

**Limitations for neurospatial:**
- âŒ **Deep learning focus**, not spatial analysis
- âŒ No differential operators as standalone tools
- âŒ No spatial autocorrelation
- âŒ No trajectory/behavioral primitives
- âŒ Requires PyTorch

**Overlap**: **<5%**
- Both use graph Laplacian, but for entirely different purposes

---

### ğŸ”µ **libigl** - Geometry Processing
**C++ library with Python bindings**

**What it does:**
- Gradient operator on triangle meshes
- Cotangent Laplacian
- Mesh processing utilities

**Scope**: 3D geometry, graphics, mesh processing

**Limitations for neurospatial:**
- âŒ Triangle meshes only
- âŒ C++ dependency
- âŒ Graphics/CAD focus
- âŒ No spatial analysis primitives

**Overlap**: **<5%**

---

### ğŸ”µ **NetworkX** - Graph Analysis
**What it has:**
```python
nx.laplacian_matrix(G)          # Laplacian matrix
nx.laplacian_spectrum(G)         # Eigenvalues
```

**What it's missing:**
- âŒ No gradient operator
- âŒ No divergence operator
- âŒ No differential geometry beyond Laplacian
- âŒ Graph analysis focus, not spatial operators

**Status**: Neurospatial already uses NetworkX for connectivity.

---

## ğŸ“Š **Summary Comparison**

| Package | Gradient | Divergence | Laplacian | Autocorr | Trajectories | RL | Neuroscience | Graph Arbitrary Layouts |
|---------|----------|------------|-----------|----------|--------------|----|--------------|----|
| **PyDEC** | âœ… (exterior) | âœ… (exterior) | âœ… | âŒ | âŒ | âŒ | âŒ | âš ï¸ (simplicial) |
| **PyGSP** | âœ… | âœ… | âœ… | âŒ | âŒ | âŒ | âŒ | âœ… |
| **LaPy** | âœ… | âœ… | âœ… | âŒ | âŒ | âŒ | âš ï¸ (medical) | âŒ (meshes only) |
| **pcdiff** | âœ… | âœ… | âœ… | âŒ | âŒ | âŒ | âŒ | âŒ (point clouds) |
| **PyG** | âš ï¸ (implicit) | âŒ | âœ… | âŒ | âŒ | âŒ | âŒ | âœ… |
| **libigl** | âœ… | âŒ | âœ… | âŒ | âŒ | âŒ | âŒ | âŒ (meshes) |
| **NetworkX** | âŒ | âŒ | âœ… | âŒ | âŒ | âŒ | âŒ | âœ… |
| **neurospatial (proposed)** | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |

---

## ğŸ¯ **Key Findings**

### **1. PyGSP is the Closest**

**Overlap**: ~20%
- Has `grad()`, `div()`, Laplacian
- Graph-based (like neurospatial)
- Efficient implementation

**Why not just use PyGSP?**
- âŒ **No spatial autocorrelation** - ESSENTIAL for grid cells
- âŒ No trajectory operations (occupancy, transitions, paths)
- âŒ No RL primitives (Bellman, propagate, accumulate)
- âŒ Signal processing API, not spatial analysis API
- âŒ No integration with neurospatial's Environment/layout system

**Decision**: Could potentially use PyGSP's gradient implementation, but need to wrap it in neurospatial API.

---

### **2. No Package Handles Spatial Autocorrelation**

**Critical for neuroscience:**
```python
# Grid cell analysis - NO EXISTING PACKAGE DOES THIS!
autocorr = spatial_autocorrelation(firing_rate, env, max_lag=20)
grid_score = compute_hexagonal_score(autocorr)
```

**Current state**: Every neuroscience lab implements this themselves
- âŒ Only works on regular grids
- âŒ Breaks on hexagonal/triangular/masked layouts
- âŒ No graph-aware correlation

**Conclusion**: This is a **unique contribution** neurospatial would provide.

---

### **3. No Package Bridges Differential Geometry + Neuroscience**

| Need | Exists In | Missing |
|------|-----------|---------|
| Gradient on graphs | PyGSP, LaPy | âœ… Available |
| Spatial autocorrelation | **NONE** | âŒ Must implement |
| Trajectory primitives | **NONE** | âŒ Must implement |
| RL primitives | **NONE** | âŒ Must implement |
| Neuroscience workflows | opexebo (limited) | âš ï¸ Only basic grids |

**Conclusion**: Neurospatial fills a **unique niche** by combining:
- Differential geometry (gradient, Laplacian)
- Spatial correlation (autocorr, xcorr)
- Trajectory analysis (accumulate_along_path)
- RL primitives (propagate, Bellman)
- All on arbitrary graph layouts

---

## ğŸ’¡ **Implementation Strategy**

### **Option 1: Implement Everything (Recommended)**

**Pros:**
- âœ… Full control over API
- âœ… Integration with Environment class
- âœ… Can optimize for neurospatial's data structures
- âœ… No external dependencies

**Cons:**
- âš ï¸ More implementation work
- âš ï¸ Need to validate correctness

**Recommendation**: **Yes**, because:
- PyGSP's API doesn't match neurospatial's needs
- Need spatial autocorrelation anyway (no existing solution)
- Need trajectory/RL primitives anyway (no existing solution)
- Better integration with existing neurospatial features

---

### **Option 2: Wrap PyGSP for Gradient/Divergence**

**Possible:**
```python
# Internal implementation
def gradient(field, env):
    # Convert to PyGSP graph
    G_gsp = pygsp.graphs.Graph(env.connectivity)
    G_gsp.compute_differential_operator()
    grad = G_gsp.grad(field)
    return grad
```

**Pros:**
- âœ… Reuse validated implementation
- âœ… Less code to maintain

**Cons:**
- âŒ Extra dependency (pygsp)
- âŒ API mismatch (need adapter layer)
- âŒ Still need to implement autocorr, trajectories, RL ourselves
- âŒ Performance overhead (conversion)

**Recommendation**: **Maybe** for gradient/divergence only, but still need to implement:
- `spatial_autocorrelation` (unique)
- `neighbor_reduce` (unique)
- `accumulate_along_path` (unique)
- `propagate` (unique)
- `convolve` (custom kernels)

---

## ğŸ”‘ **Conclusion**

### **What Exists:**
âœ… Differential geometry libraries (PyDEC, LaPy)
âœ… Graph signal processing (PyGSP)
âœ… Mesh operators (libigl, pcdiff)
âœ… Deep learning on graphs (PyTorch Geometric)

### **What's Missing for Neurospatial:**
âŒ **Spatial autocorrelation** on arbitrary graphs
âŒ **Trajectory primitives** (accumulate_along_path)
âŒ **RL primitives** (propagate, Bellman)
âŒ **Integration** with neurospatial's Environment/layouts
âŒ **Neuroscience workflows**

### **Overlap Assessment:**
- **PyGSP**: 20% overlap (gradient, divergence, Laplacian)
- **Others**: <15% overlap (wrong data structures or focus)

### **Recommendation:**

**Implement differential operators natively in neurospatial:**

**Tier 1 - Must Implement (No alternatives):**
1. âœ… `spatial_autocorrelation` - NO package has this for graphs
2. âœ… `neighbor_reduce` - Fundamental primitive, unique
3. âœ… `accumulate_along_path` - Trajectory primitive, unique
4. âœ… `propagate` - RL primitive, unique
5. âœ… `integrate` (weighted) - Need bin size awareness

**Tier 2 - Could Use PyGSP But Better Native:**
6. âš ï¸ `gradient` - PyGSP has it, but API mismatch
7. âš ï¸ `divergence_vector` - PyGSP has it, but API mismatch
8. âš ï¸ `laplacian` - Already have via `compute_diffusion_kernels`

**Tier 3 - Extend from Tier 1:**
9. âœ… `convolve` (custom kernels) - Build from neighbor_reduce
10. âœ… `spatial_cross_correlation` - Similar to autocorr

---

## ğŸ“ **Final Verdict**

**Are we reinventing the wheel?**

**NO for the core value proposition:**
- âŒ No package does spatial autocorrelation on graphs
- âŒ No package has trajectory/RL primitives
- âŒ No package integrates differential geometry + neuroscience

**PARTIALLY for differential operators:**
- âš ï¸ PyGSP has gradient/divergence, but:
  - Different API (signal processing vs spatial analysis)
  - Extra dependency
  - Still need 80% of other functionality anyway

**Decision**: **Implement natively**
- Clean integration with neurospatial
- No external dependencies
- Can optimize for our use cases
- Need to implement spatial autocorr/trajectories/RL anyway

**Validation strategy**: Use PyGSP as reference implementation to validate correctness of our gradient/divergence.

---

## ğŸ“ **Positioning**

**neurospatial = Spatial discretization + Differential geometry + Neuroscience workflows**

Not competing with PyGSP (signal processing) or LaPy (medical meshes).

**Filling a gap**: Graph-based spatial operators specifically designed for neuroscience (place cells, grid cells, navigation, RL).

**Unique contributions:**
1. Spatial autocorrelation on arbitrary graphs â­
2. Trajectory primitives (accumulate, path operations) â­
3. RL primitives (propagate, Bellman) â­
4. Integration with Environment/layouts â­
5. Neuroscience-specific API â­

Plus standard differential operators (gradient, Laplacian) that happen to exist elsewhere but need custom implementation for our API.
