"""
Property-based tests using Hypothesis to verify mathematical invariants.

These tests use randomized inputs to verify that key mathematical properties
hold across a wide range of scenarios. Property-based testing is particularly
valuable for scientific code where mathematical constraints must be maintained.

Priority 3.1: Property-based testing with Hypothesis
- Added neuroscience metrics property tests (sparsity, selectivity, skaggs_information, coherence)
"""

import networkx as nx
import numpy as np
import pytest
from hypothesis import given, settings
from hypothesis import strategies as st
from hypothesis.extra import numpy as hnp
from numpy.typing import NDArray

from neurospatial import Environment
from neurospatial.encoding.place import (
    rate_map_coherence,
    selectivity,
    skaggs_information,
    sparsity,
)
from neurospatial.ops import normalize_field
from neurospatial.ops.alignment import get_2d_rotation_matrix
from neurospatial.ops.transforms import AffineND, from_rotation_matrix


def rotate_2d(angle_radians: float) -> AffineND:
    """
    Helper to create a 2D rotation transform from angle in radians.

    Parameters
    ----------
    angle_radians : float
        Rotation angle in radians

    Returns
    -------
    Affine2D
        2D rotation transformation
    """
    angle_degrees = np.degrees(angle_radians)
    rot_matrix = get_2d_rotation_matrix(angle_degrees)
    return from_rotation_matrix(rot_matrix)


class TestEnvironmentProperties:
    """Property-based tests for Environment mathematical invariants."""

    @given(
        data=hnp.arrays(
            dtype=np.float64,
            shape=hnp.array_shapes(min_dims=2, max_dims=2, min_side=100, max_side=500),
            elements=st.floats(
                min_value=-1000.0,
                max_value=1000.0,
                allow_nan=False,
                allow_infinity=False,
            ),
        ),
        bin_size=st.floats(min_value=1.0, max_value=100.0),
    )
    @settings(max_examples=50, deadline=5000)
    def test_bin_centers_within_data_range(
        self, data: NDArray[np.float64], bin_size: float
    ):
        """
        Property: Bin centers should always be within the input data bounds.

        This is a fundamental spatial discretization invariant - the bins we create
        should cover the data, and bin centers should fall within the data extent.

        Parameters
        ----------
        data : NDArray, shape (n_samples, 2)
            Random 2D point data generated by hypothesis
        bin_size : float
            Random bin size in range [1.0, 100.0]
        """
        # Ensure we have 2D data as required by from_samples
        if data.shape[1] != 2:
            data = data[:, :2]

        # Skip if data is too small or degenerate
        data_range = np.ptp(data, axis=0)
        if np.any(data_range < bin_size) or np.any(data_range < 1e-6):
            pytest.skip("Data range too small for given bin size")

        try:
            env = Environment.from_samples(
                data, bin_size=bin_size, bin_count_threshold=1
            )
        except (ValueError, RuntimeError) as e:
            # Valid to fail if no active bins created
            if "No active bins" in str(e) or "active_mask is all False" in str(e):
                pytest.skip("No active bins created - expected for some random data")
            raise

        # Property: All bin centers should be within data bounds
        # Allow small tolerance (half bin_size) for edge effects
        data_min = np.min(data, axis=0)
        data_max = np.max(data, axis=0)
        tolerance = bin_size / 2.0

        for bin_center in env.bin_centers:
            assert np.all(bin_center >= data_min - tolerance), (
                f"Bin center {bin_center} below data min {data_min}"
            )
            assert np.all(bin_center <= data_max + tolerance), (
                f"Bin center {bin_center} above data max {data_max}"
            )

    @given(
        angle1=st.floats(min_value=-2 * np.pi, max_value=2 * np.pi),
        angle2=st.floats(min_value=-2 * np.pi, max_value=2 * np.pi),
    )
    @settings(max_examples=100, deadline=1000)
    def test_rotation_composition_property(self, angle1: float, angle2: float):
        """
        Property: Composing two rotations should equal a single rotation by the sum.

        Mathematically: R(θ₁) ∘ R(θ₂) = R(θ₁ + θ₂)

        This tests the fundamental group property of rotations and verifies
        our transform composition is mathematically sound.

        Parameters
        ----------
        angle1 : float
            First rotation angle in radians
        angle2 : float
            Second rotation angle in radians
        """
        # Create two rotation transforms
        T1 = rotate_2d(angle1)
        T2 = rotate_2d(angle2)

        # Compose them using @ operator
        T_composed = T1 @ T2

        # Expected: single rotation by sum of angles
        T_expected = rotate_2d(angle1 + angle2)

        # Property: Composed transform should match expected transform
        # Compare the transformation matrices (allowing numerical tolerance)
        np.testing.assert_allclose(
            T_composed.A,
            T_expected.A,
            rtol=1e-10,
            atol=1e-10,
            err_msg=f"Rotation composition failed for angles {angle1}, {angle2}",
        )

    @given(
        n_nodes=st.integers(min_value=5, max_value=30),
        seed=st.integers(min_value=0, max_value=10000),
    )
    @settings(max_examples=50, deadline=5000)
    def test_distance_triangle_inequality(self, n_nodes: int, seed: int):
        """
        Property: Graph distances must satisfy triangle inequality.

        For any three nodes i, j, k: d(i,k) ≤ d(i,j) + d(j,k)

        This is a fundamental property of metric spaces and must hold for
        all shortest path distances in our connectivity graphs.

        Parameters
        ----------
        n_nodes : int
            Number of nodes in the graph
        seed : int
            Random seed for reproducibility
        """
        rng = np.random.default_rng(seed)

        # Create random 2D grid environment
        data = rng.uniform(-50, 50, size=(n_nodes * 5, 2))

        try:
            env = Environment.from_samples(
                data,
                bin_size=10.0,
                bin_count_threshold=1,
                connect_diagonal_neighbors=True,
            )
        except (ValueError, RuntimeError):
            pytest.skip("Could not create valid environment")

        if env.n_bins < 5:
            pytest.skip("Not enough bins for meaningful triangle inequality test")

        # Verify graph is connected (otherwise distances might be infinite)
        if not nx.is_connected(env.connectivity):
            pytest.skip("Graph is not connected")

        # Sample 3 random nodes to test triangle inequality
        # Use at least 3 trials to test different node combinations
        for _ in range(min(3, env.n_bins // 2)):
            # Sample 3 distinct nodes
            node_indices = rng.choice(env.n_bins, size=3, replace=False)
            i, j, k = node_indices

            # Get pairwise distances
            try:
                d_ij = nx.shortest_path_length(
                    env.connectivity, source=i, target=j, weight="distance"
                )
                d_jk = nx.shortest_path_length(
                    env.connectivity, source=j, target=k, weight="distance"
                )
                d_ik = nx.shortest_path_length(
                    env.connectivity, source=i, target=k, weight="distance"
                )
            except nx.NetworkXNoPath:
                # Nodes not connected - skip this combination
                continue

            # Property: Triangle inequality must hold
            # Allow small numerical tolerance for floating point arithmetic
            tolerance = 1e-10
            assert d_ik <= d_ij + d_jk + tolerance, (
                f"Triangle inequality violated: d({i},{k})={d_ik} > d({i},{j})+d({j},{k})={d_ij + d_jk}"
            )

    @given(
        n_bins=st.integers(min_value=20, max_value=100),
        seed=st.integers(min_value=0, max_value=10000),
    )
    @settings(max_examples=50, deadline=5000)
    def test_connectivity_graph_is_undirected(self, n_bins: int, seed: int):
        """
        Property: Connectivity graph must be undirected (symmetric edges).

        For spatial environments, if bin A is a neighbor of bin B,
        then bin B must be a neighbor of bin A. This is a fundamental
        property of spatial adjacency.

        Mathematically: (i, j) ∈ E ⟺ (j, i) ∈ E

        Parameters
        ----------
        n_bins : int
            Target number of bins to generate
        seed : int
            Random seed for reproducibility
        """
        rng = np.random.default_rng(seed)

        # Create environment with known number of bins
        n_samples = n_bins * 10
        data = rng.uniform(-50, 50, size=(n_samples, 2))

        try:
            env = Environment.from_samples(
                data,
                bin_size=5.0,
                bin_count_threshold=1,
                connect_diagonal_neighbors=True,
            )
        except (ValueError, RuntimeError):
            pytest.skip("Could not create valid environment")

        if env.n_bins < 5:
            pytest.skip("Not enough bins for meaningful symmetry test")

        # Property: Graph must be undirected
        # For every edge (i, j), there must exist edge (j, i)
        for edge in env.connectivity.edges():
            i, j = edge
            # Check reverse edge exists
            assert env.connectivity.has_edge(j, i), (
                f"Graph not undirected: edge ({i},{j}) exists but ({j},{i}) doesn't"
            )

            # Check edge attributes match (distance, etc.)
            dist_ij = env.connectivity.edges[i, j]["distance"]
            dist_ji = env.connectivity.edges[j, i]["distance"]
            np.testing.assert_allclose(
                dist_ij,
                dist_ji,
                rtol=1e-10,
                atol=1e-10,
                err_msg=f"Edge distances not symmetric: d({i},{j})={dist_ij} ≠ d({j},{i})={dist_ji}",
            )

    @given(
        field_size=st.integers(min_value=10, max_value=100),
        seed=st.integers(min_value=0, max_value=10000),
    )
    @settings(max_examples=50, deadline=3000)
    def test_normalized_field_sums_to_one(self, field_size: int, seed: int):
        """
        Property: Normalized spatial fields should sum to 1 (probability mass).

        When a spatial field is normalized, it represents a probability distribution
        over space. The total probability must sum to 1.

        This tests both the normalize_field method and the underlying mathematical
        correctness of probability normalization.

        Parameters
        ----------
        field_size : int
            Number of bins in the environment
        seed : int
            Random seed for reproducibility
        """
        rng = np.random.default_rng(seed)

        # Create environment with known number of bins
        n_samples = field_size * 5
        data = rng.uniform(-50, 50, size=(n_samples, 2))

        try:
            env = Environment.from_samples(
                data,
                bin_size=10.0,
                bin_count_threshold=1,
            )
        except (ValueError, RuntimeError):
            pytest.skip("Could not create valid environment")

        if env.n_bins < 5:
            pytest.skip("Not enough bins for meaningful normalization test")

        # Generate random non-negative field (like a firing rate map)
        # Use exponential to ensure non-negative values
        field = rng.exponential(scale=2.0, size=env.n_bins)

        # Normalize the field
        try:
            normalized = normalize_field(field)
        except (ValueError, ZeroDivisionError):
            # Valid to fail if field is all zeros
            if np.all(field == 0):
                pytest.skip("All-zero field cannot be normalized")
            raise

        # Property: Normalized field should sum to 1 (probability mass)
        field_sum = np.sum(normalized)
        np.testing.assert_allclose(
            field_sum,
            1.0,
            rtol=1e-10,
            atol=1e-10,
            err_msg=f"Normalized field sums to {field_sum}, expected 1.0",
        )

        # Additional property: All values should be non-negative (valid probability)
        assert np.all(normalized >= 0), "Normalized field has negative values"


class TestTransformProperties:
    """Property-based tests for transformation mathematical properties."""

    @given(
        angle=st.floats(min_value=-2 * np.pi, max_value=2 * np.pi),
        point_x=st.floats(min_value=-100.0, max_value=100.0),
        point_y=st.floats(min_value=-100.0, max_value=100.0),
    )
    @settings(max_examples=100, deadline=1000)
    def test_rotation_preserves_distance_from_origin(
        self, angle: float, point_x: float, point_y: float
    ):
        """
        Property: Rotation preserves distance from origin.

        Rotations are isometries - they preserve distances. Specifically,
        rotating a point should not change its distance from the origin.

        Mathematically: ||R(p)|| = ||p|| for any rotation R and point p.

        Parameters
        ----------
        angle : float
            Rotation angle in radians
        point_x, point_y : float
            2D point coordinates
        """
        point = np.array([point_x, point_y])

        # Distance before rotation
        dist_before = np.linalg.norm(point)

        # Apply rotation using __call__ (Affine2D is callable)
        T = rotate_2d(angle)
        rotated_point = T(point.reshape(1, 2))[0]

        # Distance after rotation
        dist_after = np.linalg.norm(rotated_point)

        # Property: Distance should be preserved (isometry)
        np.testing.assert_allclose(
            dist_after,
            dist_before,
            rtol=1e-10,
            atol=1e-10,
            err_msg=f"Rotation changed distance: {dist_before} -> {dist_after}",
        )

    @given(
        angle=st.floats(min_value=-2 * np.pi, max_value=2 * np.pi),
    )
    @settings(max_examples=50, deadline=1000)
    def test_rotation_inverse_property(self, angle: float):
        """
        Property: Applying a rotation and its inverse should return to identity.

        Mathematically: R(θ) ∘ R(-θ) = I (identity)

        This tests that our rotation composition and inversion are correct.

        Parameters
        ----------
        angle : float
            Rotation angle in radians
        """
        # Create rotation and its inverse
        T = rotate_2d(angle)
        T_inv = rotate_2d(-angle)

        # Compose them using @ operator
        T_composed = T @ T_inv

        # Expected: Identity transformation (identity has matrix [[1,0,0],[0,1,0],[0,0,1]])
        identity_matrix = np.eye(3)

        # Property: Composition should equal identity
        np.testing.assert_allclose(
            T_composed.A,
            identity_matrix,
            rtol=1e-10,
            atol=1e-10,
            err_msg=f"R({angle}) ∘ R({-angle}) ≠ I",
        )


# =============================================================================
# Hypothesis Strategies for Neuroscience Metrics
# =============================================================================


@st.composite
def valid_firing_rate_and_occupancy(
    draw: st.DrawFn,
    min_bins: int = 10,
    max_bins: int = 100,
) -> tuple[NDArray[np.float64], NDArray[np.float64]]:
    """Generate matching firing rate and occupancy arrays.

    Parameters
    ----------
    draw : st.DrawFn
        Hypothesis draw function.
    min_bins : int, default=10
        Minimum number of bins.
    max_bins : int, default=100
        Maximum number of bins.

    Returns
    -------
    tuple[NDArray[np.float64], NDArray[np.float64]]
        (firing_rate, occupancy) with same shape and valid values.
    """
    n_bins = draw(st.integers(min_value=min_bins, max_value=max_bins))

    # Generate firing rate (non-negative)
    firing_rate = draw(
        hnp.arrays(
            dtype=np.float64,
            shape=n_bins,
            elements=st.floats(
                min_value=0.0,
                max_value=100.0,
                allow_nan=False,
                allow_infinity=False,
            ),
        )
    )

    # Generate occupancy (positive, will be normalized)
    occupancy = draw(
        hnp.arrays(
            dtype=np.float64,
            shape=n_bins,
            elements=st.floats(
                min_value=0.01,
                max_value=100.0,
                allow_nan=False,
                allow_infinity=False,
            ),
        )
    )

    # Sanity check: arrays must have matching shapes
    # This is guaranteed by using n_bins for both, but defensive programming
    assert firing_rate.shape == occupancy.shape == (n_bins,), (
        f"Shape mismatch: firing_rate {firing_rate.shape}, "
        f"occupancy {occupancy.shape}, expected ({n_bins},)"
    )

    return firing_rate, occupancy


# =============================================================================
# Property Tests for Neuroscience Metrics
# =============================================================================


class TestSparsityProperties:
    """Property-based tests for sparsity metric.

    Sparsity measures what fraction of the environment elicits significant firing.
    Formula: sparsity = (sum p_i * r_i)^2 / (sum p_i * r_i^2)

    Mathematical properties:
    - Range: [0, 1]
    - Uniform firing → sparsity ≈ 1.0
    - Single-bin firing → sparsity ≈ 1/n_bins
    """

    @given(valid_firing_rate_and_occupancy())
    @settings(max_examples=100, deadline=None)
    def test_sparsity_range_property(
        self, data: tuple[NDArray[np.float64], NDArray[np.float64]]
    ):
        """Property: sparsity is always in [0, 1] for valid inputs."""
        firing_rate, occupancy = data

        sp = sparsity(firing_rate, occupancy)

        # Property: 0 <= sparsity <= 1 (strict, guaranteed by implementation)
        assert 0.0 <= sp <= 1.0, f"Sparsity {sp} outside valid range [0, 1]"

    @given(
        valid_firing_rate_and_occupancy(min_bins=10, max_bins=100),
        st.floats(min_value=0.1, max_value=100.0),
    )
    @settings(max_examples=50, deadline=None)
    def test_uniform_firing_high_sparsity(
        self,
        data: tuple[NDArray[np.float64], NDArray[np.float64]],
        uniform_rate: float,
    ):
        """Property: uniform firing produces high sparsity (close to 1.0)."""
        _, occupancy = data
        n_bins = len(occupancy)

        # Create uniform firing at the given rate
        firing_rate = np.ones(n_bins, dtype=np.float64) * uniform_rate

        sp = sparsity(firing_rate, occupancy)

        # Property: uniform firing → sparsity very close to 1.0
        # Allow small numerical tolerance
        assert sp >= 0.95, f"Uniform firing sparsity {sp} should be close to 1.0"

    @given(valid_firing_rate_and_occupancy(min_bins=20, max_bins=100))
    @settings(max_examples=50, deadline=None)
    def test_single_peak_low_sparsity(
        self, data: tuple[NDArray[np.float64], NDArray[np.float64]]
    ):
        """Property: firing in single bin produces sparsity equal to occupancy fraction.

        For single-bin firing, sparsity = p_k where p_k is the occupancy probability
        in the firing bin. Sparsity is "low" only when occupancy in that bin is low.
        """
        _, occupancy = data
        n_bins = len(occupancy)

        # Create firing only in one bin
        firing_rate = np.zeros(n_bins, dtype=np.float64)
        peak_idx = n_bins // 2
        firing_rate[peak_idx] = 100.0

        sp = sparsity(firing_rate, occupancy)

        # Property: single-bin firing → sparsity ≈ occupancy fraction in that bin
        # (not always "low" - depends on occupancy distribution)
        expected_sparsity = occupancy[peak_idx] / occupancy.sum()
        assert np.isclose(sp, expected_sparsity, rtol=0.01), (
            f"Single-peak sparsity {sp} should equal occupancy fraction {expected_sparsity}"
        )


class TestSelectivityProperties:
    """Property-based tests for selectivity metric.

    Selectivity measures how spatially selective firing is.
    Formula: selectivity = peak_rate / mean_rate

    Mathematical properties:
    - Range: [1.0, ∞) (always >= 1.0)
    - Uniform firing → selectivity = 1.0
    - Sparse firing → selectivity >> 1.0
    """

    @given(valid_firing_rate_and_occupancy())
    @settings(max_examples=100, deadline=None)
    def test_selectivity_minimum_value(
        self, data: tuple[NDArray[np.float64], NDArray[np.float64]]
    ):
        """Property: selectivity is always >= 1.0."""
        firing_rate, occupancy = data

        # Skip all-zero firing rate (undefined selectivity)
        if np.all(firing_rate == 0):
            pytest.skip("All-zero firing rate")

        sel = selectivity(firing_rate, occupancy)

        # Property: selectivity >= 1.0 always
        # (peak rate is always >= mean rate by definition)
        if not np.isnan(sel) and not np.isinf(sel):
            assert sel >= 1.0, f"Selectivity {sel} should be >= 1.0"

    @given(
        valid_firing_rate_and_occupancy(min_bins=10, max_bins=100),
        st.floats(min_value=0.1, max_value=100.0),
    )
    @settings(max_examples=50, deadline=None)
    def test_uniform_firing_selectivity_one(
        self,
        data: tuple[NDArray[np.float64], NDArray[np.float64]],
        uniform_rate: float,
    ):
        """Property: uniform firing produces selectivity = 1.0."""
        _, occupancy = data
        n_bins = len(occupancy)

        # Create uniform firing
        firing_rate = np.ones(n_bins, dtype=np.float64) * uniform_rate

        sel = selectivity(firing_rate, occupancy)

        # Property: uniform firing → selectivity = 1.0
        # Allow small numerical tolerance
        assert np.abs(sel - 1.0) < 0.01, (
            f"Uniform firing selectivity {sel} should be 1.0"
        )

    @given(valid_firing_rate_and_occupancy(min_bins=20, max_bins=100))
    @settings(max_examples=50, deadline=None)
    def test_sparse_firing_high_selectivity(
        self, data: tuple[NDArray[np.float64], NDArray[np.float64]]
    ):
        """Property: firing in few bins produces high selectivity."""
        _, occupancy = data
        n_bins = len(occupancy)

        # Create firing in only 10% of bins
        firing_rate = np.zeros(n_bins, dtype=np.float64)
        n_active = max(2, n_bins // 10)  # At least 2 bins
        firing_rate[:n_active] = 100.0

        sel = selectivity(firing_rate, occupancy)

        # Property: sparse firing → selectivity > 1.0 (higher than uniform)
        # Note: Exact value depends on occupancy distribution
        # Hypothesis found cases where uneven occupancy reduces selectivity
        assert sel > 1.0, f"Sparse firing selectivity {sel} should be > 1.0"


class TestSkaggsInformationProperties:
    """Property-based tests for Skaggs spatial information metric.

    Skaggs information quantifies how much each spike conveys about location.
    Formula: I = sum p_i * (r_i / mean_r) * log2(r_i / mean_r)

    Mathematical properties:
    - Range: [0, ∞) (always non-negative)
    - Uniform firing → information ≈ 0.0
    - Selective firing → information > 0
    """

    @given(valid_firing_rate_and_occupancy())
    @settings(max_examples=100, deadline=None)
    def test_information_non_negative(
        self, data: tuple[NDArray[np.float64], NDArray[np.float64]]
    ):
        """Property: Skaggs information is always non-negative."""
        firing_rate, occupancy = data

        info = skaggs_information(firing_rate, occupancy)

        # Property: information >= 0.0 always (strict, guaranteed by implementation)
        assert info >= 0.0, f"Information {info} should be >= 0.0"

    @given(
        valid_firing_rate_and_occupancy(min_bins=10, max_bins=100),
        st.floats(min_value=0.1, max_value=100.0),
    )
    @settings(max_examples=50, deadline=None)
    def test_uniform_firing_zero_information(
        self,
        data: tuple[NDArray[np.float64], NDArray[np.float64]],
        uniform_rate: float,
    ):
        """Property: uniform firing produces zero spatial information."""
        _, occupancy = data
        n_bins = len(occupancy)

        # Create uniform firing
        firing_rate = np.ones(n_bins, dtype=np.float64) * uniform_rate

        info = skaggs_information(firing_rate, occupancy)

        # Property: uniform firing → information ≈ 0.0
        assert info < 0.01, f"Uniform firing information {info} should be close to 0.0"

    @given(valid_firing_rate_and_occupancy(min_bins=20, max_bins=100))
    @settings(max_examples=50, deadline=None)
    def test_selective_firing_positive_information(
        self, data: tuple[NDArray[np.float64], NDArray[np.float64]]
    ):
        """Property: selective firing produces positive information."""
        _, occupancy = data
        n_bins = len(occupancy)

        # Create selective firing (Gaussian-like)
        firing_rate = np.zeros(n_bins, dtype=np.float64)
        peak_idx = n_bins // 2
        # Add firing in center bin and neighbors
        firing_rate[max(0, peak_idx - 2) : min(n_bins, peak_idx + 3)] = 10.0
        firing_rate[peak_idx] = 50.0  # Peak

        info = skaggs_information(firing_rate, occupancy)

        # Property: selective firing → information > 0
        # Note: For highly non-uniform occupancy (which Hypothesis can generate),
        # the information can be very small but should be positive
        assert info > 0.0, (
            f"Selective firing information {info} should be positive (> 0)"
        )


class TestRateMapCoherenceProperties:
    """Property-based tests for rate map coherence metric.

    Coherence measures spatial smoothness of firing.
    Formula: correlation between each bin and mean of its neighbors

    Mathematical properties:
    - Range: [-1, 1] (correlation coefficient)
    - Smooth fields → high coherence (> 0.5)
    - Random noise → low coherence (~ 0)
    """

    @given(
        st.integers(min_value=50, max_value=200),
        st.integers(min_value=0, max_value=10000),
    )
    @settings(max_examples=50, deadline=None)
    def test_coherence_range_property(self, n_positions: int, seed: int):
        """Property: coherence is in [-1, 1] for all valid inputs."""
        # Create simple environment
        rng = np.random.default_rng(seed)
        positions = rng.standard_normal((n_positions, 2)) * 10

        try:
            env = Environment.from_samples(
                positions, bin_size=2.0, connect_diagonal_neighbors=False
            )
        except (ValueError, RuntimeError):
            pytest.skip("Could not create valid environment")

        # Create random firing rate
        firing_rate = rng.uniform(0, 10, size=env.n_bins)

        coherence = rate_map_coherence(firing_rate, env)

        # Property: -1 <= coherence <= 1 (correlation coefficient range)
        if not np.isnan(coherence):
            assert -1.0 <= coherence <= 1.0, (
                f"Coherence {coherence} outside valid range [-1, 1]"
            )

    @given(
        st.integers(min_value=100, max_value=300),
        st.integers(min_value=0, max_value=10000),
    )
    @settings(max_examples=30, deadline=None)
    def test_smooth_field_high_coherence(self, n_positions: int, seed: int):
        """Property: smooth Gaussian field produces high coherence."""
        # Create environment
        rng = np.random.default_rng(seed)
        positions = rng.standard_normal((n_positions, 2)) * 20

        try:
            env = Environment.from_samples(
                positions, bin_size=2.0, connect_diagonal_neighbors=False
            )
        except (ValueError, RuntimeError):
            pytest.skip("Could not create valid environment")

        if env.n_bins < 10:
            pytest.skip("Not enough bins for coherence test")

        # Create smooth Gaussian field
        firing_rate = np.zeros(env.n_bins, dtype=np.float64)
        for i in range(env.n_bins):
            dist = np.linalg.norm(env.bin_centers[i])
            firing_rate[i] = 10.0 * np.exp(-(dist**2) / (2 * 5.0**2))

        coherence = rate_map_coherence(firing_rate, env)

        # Property: smooth field → high coherence (> 0.4)
        # Threshold is conservative because random environment topology can reduce
        # correlation between bins and neighbors even for smooth Gaussian fields.
        # Empirically observed range for random 2D environments: [0.4, 0.8]
        if not np.isnan(coherence):
            assert coherence > 0.4, (
                f"Smooth field coherence {coherence} should be > 0.4"
            )


class TestCrossMetricProperties:
    """Property-based tests for relationships between metrics.

    Tests mathematical relationships that should hold between different metrics.
    """

    @given(valid_firing_rate_and_occupancy(min_bins=20, max_bins=100))
    @settings(max_examples=50, deadline=None)
    def test_sparsity_selectivity_inverse_relationship(
        self, data: tuple[NDArray[np.float64], NDArray[np.float64]]
    ):
        """Property: high sparsity (uniform firing) implies low selectivity.

        For uniform-like firing patterns (sparsity > 0.9), selectivity
        should be close to 1.0 since peak rate ≈ mean rate. This tests
        the mathematical relationship between spatial spread (sparsity)
        and peak-to-mean ratio (selectivity).
        """
        firing_rate, occupancy = data

        # Skip all-zero case
        if np.all(firing_rate == 0):
            pytest.skip("All-zero firing rate")

        sp = sparsity(firing_rate, occupancy)
        sel = selectivity(firing_rate, occupancy)

        # For uniform firing (high sparsity ~ 1.0):
        # - sparsity should be high
        # - selectivity should be low (~ 1.0)
        if (
            sp > 0.9 and not np.isnan(sel) and not np.isinf(sel)
        ):  # High sparsity (uniform-like)
            assert sel < 2.0, (
                f"High sparsity ({sp}) should imply low selectivity, got {sel}"
            )

    @given(valid_firing_rate_and_occupancy(min_bins=20, max_bins=100))
    @settings(max_examples=50, deadline=None)
    def test_uniform_firing_implies_zero_information(
        self, data: tuple[NDArray[np.float64], NDArray[np.float64]]
    ):
        """Property: uniform firing → zero information (not vice versa).

        Note: The reverse is NOT true - zero information doesn't imply
        uniform firing (e.g., one high-firing bin with low occupancy).
        """
        _, occupancy = data
        n_bins = len(occupancy)

        # Create uniform firing
        firing_rate = np.ones(n_bins, dtype=np.float64) * 10.0

        info = skaggs_information(firing_rate, occupancy)

        # Property: uniform firing → information ≈ 0.0
        assert info < 0.01, (
            f"Uniform firing should produce zero information, got {info}"
        )


# =============================================================================
# Property Tests for Smoothing Operations
# =============================================================================


class TestSmoothingProperties:
    """Property-based tests for spatial field smoothing operations."""

    @given(
        st.integers(min_value=100, max_value=500),
        st.integers(min_value=0, max_value=10000),
        st.floats(min_value=1.0, max_value=10.0),
    )
    @settings(max_examples=30, deadline=15000)
    def test_smoothing_preserves_non_negativity(
        self, n_positions: int, seed: int, bandwidth: float
    ):
        """Property: Smoothing non-negative field produces non-negative result."""
        rng = np.random.default_rng(seed)

        # Create simple environment
        positions = rng.standard_normal((n_positions, 2)) * 20

        try:
            env = Environment.from_samples(
                positions, bin_size=2.0, connect_diagonal_neighbors=True
            )
        except (ValueError, RuntimeError):
            pytest.skip("Could not create valid environment")

        if env.n_bins < 10:
            pytest.skip("Not enough bins")

        # Create non-negative field
        field = rng.exponential(scale=5.0, size=env.n_bins)

        # Smooth the field
        smoothed = env.smooth(field, bandwidth=bandwidth)

        # Property: smoothing non-negative field should remain non-negative
        assert np.all(smoothed >= -1e-10), (
            f"Smoothing produced negative values: min={smoothed.min()}"
        )

    @given(
        st.integers(min_value=100, max_value=500),
        st.integers(min_value=0, max_value=10000),
        st.floats(min_value=1.0, max_value=10.0),
    )
    @settings(max_examples=30, deadline=15000)
    def test_transition_smoothing_preserves_mass(
        self, n_positions: int, seed: int, bandwidth: float
    ):
        """Property: Transition-mode smoothing preserves total mass."""
        rng = np.random.default_rng(seed)

        # Create simple environment
        positions = rng.standard_normal((n_positions, 2)) * 20

        try:
            env = Environment.from_samples(
                positions, bin_size=2.0, connect_diagonal_neighbors=True
            )
        except (ValueError, RuntimeError):
            pytest.skip("Could not create valid environment")

        if env.n_bins < 10:
            pytest.skip("Not enough bins")

        # Create field with known mass
        field = rng.exponential(scale=5.0, size=env.n_bins)
        original_mass = np.sum(field)

        # Smooth with transition mode (row-normalized kernel)
        smoothed = env.smooth(field, bandwidth=bandwidth, mode="transition")

        # Property: transition smoothing should preserve total mass
        smoothed_mass = np.sum(smoothed)
        np.testing.assert_allclose(
            smoothed_mass,
            original_mass,
            rtol=0.01,
            err_msg=f"Transition smoothing changed mass: {original_mass} -> {smoothed_mass}",
        )

    @given(
        st.integers(min_value=100, max_value=500),
        st.integers(min_value=0, max_value=10000),
    )
    @settings(max_examples=30, deadline=15000)
    def test_large_bandwidth_smooths_towards_mean(self, n_positions: int, seed: int):
        """Property: Large bandwidth smoothing produces values closer to mean."""
        rng = np.random.default_rng(seed)

        # Create simple environment
        positions = rng.standard_normal((n_positions, 2)) * 20

        try:
            env = Environment.from_samples(
                positions, bin_size=2.0, connect_diagonal_neighbors=True
            )
        except (ValueError, RuntimeError):
            pytest.skip("Could not create valid environment")

        if env.n_bins < 10:
            pytest.skip("Not enough bins")

        # Create random field with variation
        field = rng.exponential(scale=5.0, size=env.n_bins)

        # Smooth with large bandwidth
        smoothed = env.smooth(field, bandwidth=50.0, mode="transition")

        # Property: large bandwidth should reduce variance (smooth towards mean)
        original_std = np.std(field)
        smoothed_std = np.std(smoothed)

        # Smoothing should reduce variance
        assert smoothed_std < original_std, (
            f"Large bandwidth should reduce std: {original_std:.3f} -> {smoothed_std:.3f}"
        )


class TestFieldNormalizationProperties:
    """Property-based tests for field normalization."""

    @given(
        st.integers(min_value=10, max_value=100),
        st.integers(min_value=0, max_value=10000),
    )
    @settings(max_examples=50, deadline=5000)
    def test_normalize_field_sum_one(self, n_bins: int, seed: int):
        """Property: Normalized field sums to 1."""
        rng = np.random.default_rng(seed)

        # Create non-negative field
        field = rng.exponential(scale=5.0, size=n_bins)

        # Skip if all zeros
        if np.all(field == 0):
            pytest.skip("All-zero field")

        normalized = normalize_field(field)

        np.testing.assert_allclose(
            np.sum(normalized),
            1.0,
            rtol=1e-10,
            err_msg="Normalized field should sum to 1",
        )

    @given(
        st.integers(min_value=10, max_value=100),
        st.integers(min_value=0, max_value=10000),
        st.floats(min_value=0.1, max_value=100.0),
    )
    @settings(max_examples=50, deadline=5000)
    def test_normalize_scaling_invariant(self, n_bins: int, seed: int, scale: float):
        """Property: Normalization is scale-invariant."""
        rng = np.random.default_rng(seed)

        # Create non-negative field
        field = rng.exponential(scale=5.0, size=n_bins)

        # Skip if all zeros
        if np.all(field == 0):
            pytest.skip("All-zero field")

        # Normalize original and scaled field
        normalized = normalize_field(field)
        scaled_normalized = normalize_field(field * scale)

        # Property: normalization should be scale-invariant
        np.testing.assert_allclose(
            scaled_normalized,
            normalized,
            rtol=1e-10,
            err_msg="Normalization should be scale-invariant",
        )


# =============================================================================
# Property Tests for Place Field Detection
# =============================================================================


class TestPlaceFieldDetectionProperties:
    """Property-based tests for place field detection invariants."""

    @given(
        st.integers(min_value=100, max_value=300),
        st.integers(min_value=0, max_value=10000),
    )
    @settings(max_examples=20, deadline=20000)
    def test_detected_fields_have_valid_indices(self, n_positions: int, seed: int):
        """Property: Detected field bin indices are valid."""
        from neurospatial.encoding.place import detect_place_fields

        rng = np.random.default_rng(seed)

        # Create environment
        positions = rng.standard_normal((n_positions, 2)) * 30

        try:
            env = Environment.from_samples(
                positions, bin_size=3.0, connect_diagonal_neighbors=True
            )
        except (ValueError, RuntimeError):
            pytest.skip("Could not create valid environment")

        if env.n_bins < 20:
            pytest.skip("Not enough bins")

        # Create firing rate with Gaussian peak
        firing_rate = np.zeros(env.n_bins, dtype=np.float64)
        peak_idx = env.n_bins // 2
        for i in range(env.n_bins):
            dist = np.linalg.norm(env.bin_centers[i] - env.bin_centers[peak_idx])
            firing_rate[i] = 10.0 * np.exp(-(dist**2) / (2 * 10.0**2))

        # Detect fields
        try:
            fields = detect_place_fields(firing_rate, env)

            # Property: all field bin indices should be valid
            for field in fields:
                for bin_idx in field:
                    assert 0 <= bin_idx < env.n_bins, (
                        f"Invalid bin index {bin_idx} in detected field"
                    )
        except (ValueError, RuntimeError):
            pass  # Some configurations may not detect fields

    @given(
        st.integers(min_value=100, max_value=300),
        st.integers(min_value=0, max_value=10000),
    )
    @settings(max_examples=20, deadline=20000)
    def test_uniform_rate_produces_no_fields(self, n_positions: int, seed: int):
        """Property: Uniform firing rate should produce no detected fields."""
        from neurospatial.encoding.place import detect_place_fields

        rng = np.random.default_rng(seed)

        # Create environment
        positions = rng.standard_normal((n_positions, 2)) * 30

        try:
            env = Environment.from_samples(
                positions, bin_size=3.0, connect_diagonal_neighbors=True
            )
        except (ValueError, RuntimeError):
            pytest.skip("Could not create valid environment")

        if env.n_bins < 20:
            pytest.skip("Not enough bins")

        # Create uniform firing rate
        firing_rate = np.ones(env.n_bins, dtype=np.float64) * 5.0

        # Detect fields
        try:
            fields = detect_place_fields(
                firing_rate,
                env,
                threshold=0.5,  # Threshold for field detection
            )

            # Property: uniform rate should produce either no fields or one big field
            # (depending on threshold relative to the uniform level)
            # Most importantly, it shouldn't crash or produce invalid results
            for field in fields:
                for bin_idx in field:
                    assert 0 <= bin_idx < env.n_bins
        except (ValueError, RuntimeError):
            pass
