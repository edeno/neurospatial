{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"neurospatial","text":"<p>neurospatial is a Python library for discretizing continuous N-dimensional spatial environments into bins/nodes with connectivity graphs. It provides tools for spatial analysis, particularly for neuroscience applications involving place fields, position tracking, and spatial navigation.</p> <p>Whether you're analyzing animal navigation data, modeling place cells, or working with any spatial discretization problem, neurospatial gives you flexible, powerful tools to represent and analyze spatial environments.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Multiple Layout Engines: Choose from regular grids, hexagonal tessellations, masked regions, polygon-bounded areas, triangular meshes, and 1D linearized tracks</li> <li>Automatic Bin Detection: Infer active bins from data samples with morphological operations (dilation, closing, hole filling)</li> <li>Connectivity Graphs: Built-in NetworkX graphs with mandatory node/edge metadata for spatial queries</li> <li>1D Linearization: Transform complex 2D environments into 1D linearized coordinates for track-based analysis</li> <li>Spatial Queries: Point-to-bin mapping, neighbor finding, shortest paths, geodesic distances</li> <li>Region Support: Define and manage named regions of interest (ROIs) with immutable semantics</li> <li>Environment Composition: Merge multiple environments with automatic bridge inference</li> <li>Alignment Tools: Transform and map probability distributions between environments</li> <li>Type-Safe Protocol Design: Layout engines implement protocols, not inheritance, for maximum flexibility</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import numpy as np\nfrom neurospatial import Environment\n\n# Generate some 2D position data (e.g., from animal tracking)\nposition_data = np.array([\n    [0.0, 0.0],\n    [5.0, 5.0],\n    [10.0, 10.0],\n    [15.0, 5.0],\n    [20.0, 0.0],\n])\n\n# Create an environment with 2 cm bins\nenv = Environment.from_samples(\n    data_samples=position_data,\n    bin_size=2.0,\n    name=\"OpenField\"\n)\n\n# Query the environment\nprint(f\"Environment has {env.n_bins} bins\")\nprint(f\"Dimensions: {env.n_dims}D\")\n\n# Map a point to its bin\npoint = np.array([[10.5, 10.2]])\nbin_idx = env.bin_at(point)\nprint(f\"Point {point[0]} is in bin {bin_idx[0]}\")\n\n# Find neighbors\nneighbors = env.neighbors(bin_idx[0])\nprint(f\"Bin {bin_idx[0]} has {len(neighbors)} neighbors\")\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<p>Install neurospatial using pip:</p> <pre><code>pip install neurospatial\n</code></pre> <p>For development installation with documentation tools:</p> <pre><code>git clone https://github.com/edeno/neurospatial.git\ncd neurospatial\nuv sync --extra docs\n</code></pre> <p>See the Installation Guide for more details.</p>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Getting Started: Installation, quickstart, and core concepts</li> <li>User Guide: Detailed guides on using neurospatial features</li> <li>API Reference: Complete API documentation</li> <li>Examples: Jupyter notebooks with real-world use cases</li> <li>Contributing: Guidelines for contributors</li> </ul>"},{"location":"#use-cases","title":"Use Cases","text":"<p>neurospatial is designed for researchers working with spatial data in neuroscience:</p> <ul> <li>Place Cell Analysis: Discretize environments for computing firing rate maps</li> <li>Position Tracking: Convert continuous trajectories into spatial bins</li> <li>Maze Experiments: Linearize complex track structures for 1D analysis</li> <li>Spatial Navigation: Compute geodesic distances and shortest paths</li> <li>Multi-Environment Studies: Align and compare spatial representations across sessions</li> </ul>"},{"location":"#project-status","title":"Project Status","text":"<p>Status: Alpha (v0.1.0) - API may change. Contributions and feedback welcome!</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use neurospatial in your research, please cite:</p> <pre><code>@software{neurospatial2025,\n  author = {Denovellis, Eric},\n  title = {neurospatial: Spatial environment discretization for neuroscience},\n  year = {2025},\n  url = {https://github.com/edeno/neurospatial},\n  version = {0.1.0}\n}\n</code></pre>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"#contact","title":"Contact","text":"<p>Eric Denovellis</p> <ul> <li>Email: eric.denovellis@ucsf.edu</li> <li>GitHub: @edeno</li> <li>Issues: GitHub Issues</li> </ul>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to neurospatial will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Complete MkDocs documentation with Material theme</li> <li>API reference generated with mkdocstrings</li> <li>User guide with detailed examples</li> <li>Getting started tutorials</li> </ul>"},{"location":"changelog/#010-2024-11-03","title":"0.1.0 - 2024-11-03","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Initial release of neurospatial</li> <li>Core <code>Environment</code> class with factory methods</li> <li>Multiple layout engines (regular grid, hexagonal, triangular, graph-based)</li> <li>Region support for defining ROIs</li> <li>Composite environment functionality</li> <li>Alignment and transformation tools</li> <li>Comprehensive test suite</li> <li>NumPy-style docstrings throughout</li> </ul>"},{"location":"changelog/#features","title":"Features","text":"<ul> <li>Automatic active bin detection from data samples</li> <li>NetworkX-based connectivity graphs</li> <li>1D linearization for track-based experiments</li> <li>Spatial queries (bin_at, neighbors, shortest_path, distance_between)</li> <li>Visualization with matplotlib</li> <li>Morphological operations (dilation, closing, hole filling)</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to neurospatial! This guide will help you get started.</p>"},{"location":"contributing/#getting-started","title":"Getting Started","text":""},{"location":"contributing/#development-setup","title":"Development Setup","text":"<ol> <li>Fork the repository on GitHub</li> <li>Clone your fork locally:</li> </ol> <pre><code>git clone https://github.com/YOUR_USERNAME/neurospatial.git\ncd neurospatial\n</code></pre> <ol> <li>Install development dependencies:</li> </ol> <pre><code>uv sync --extra dev\n</code></pre> <ol> <li>Set up pre-commit hooks:</li> </ol> <pre><code>uv run pre-commit install\n</code></pre>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":"<p>This project uses <code>uv</code> for package management. Always prefix commands with <code>uv run</code>:</p> <pre><code># Run tests\nuv run pytest\n\n# Run specific test\nuv run pytest tests/test_environment.py::test_name -v\n\n# Check code quality\nuv run ruff check .\n\n# Format code\nuv run ruff format .\n\n# Type check (optional)\nuv run mypy src/neurospatial\n</code></pre>"},{"location":"contributing/#code-standards","title":"Code Standards","text":""},{"location":"contributing/#python-style","title":"Python Style","text":"<ul> <li>Follow PEP 8 (enforced by ruff)</li> <li>Use type hints where practical</li> <li>Write descriptive variable names</li> <li>Keep functions focused and small</li> </ul>"},{"location":"contributing/#docstring-format","title":"Docstring Format","text":"<p>CRITICAL: All docstrings MUST follow NumPy docstring format:</p> <pre><code>def function_name(param1, param2):\n    \"\"\"\n    Short one-line summary ending with a period.\n\n    Longer description if needed.\n\n    Parameters\n    ----------\n    param1 : type\n        Description of param1.\n    param2 : type, optional\n        Description of param2. Default is None.\n\n    Returns\n    -------\n    return_type\n        Description of return value.\n\n    Raises\n    ------\n    ValueError\n        When this error occurs.\n\n    Examples\n    --------\n    &gt;&gt;&gt; result = function_name(1, 2)\n    &gt;&gt;&gt; print(result)\n    3\n    \"\"\"\n</code></pre> <p>See NumPy Docstring Guide for details.</p>"},{"location":"contributing/#commit-messages","title":"Commit Messages","text":"<p>Use Conventional Commits:</p> <pre><code>feat(environment): add .info() method\nfix(regions): correct area calculation for polygons\ndocs(quickstart): update installation instructions\ntest(layout): add tests for hexagonal layout\nchore(deps): update numpy to 2.3.4\n</code></pre>"},{"location":"contributing/#testing","title":"Testing","text":""},{"location":"contributing/#writing-tests","title":"Writing Tests","text":"<ul> <li>Place tests in <code>tests/</code> directory</li> <li>Mirror source structure: <code>src/neurospatial/foo.py</code> \u2192 <code>tests/test_foo.py</code></li> <li>Use descriptive test names: <code>test_environment_from_samples_creates_bins()</code></li> <li>Use pytest fixtures from <code>tests/conftest.py</code></li> </ul> <p>Example test:</p> <pre><code>def test_environment_bin_at_maps_points_correctly():\n    \"\"\"Test that bin_at correctly maps points to bin indices.\"\"\"\n    env = Environment.from_samples(sample_data, bin_size=2.0)\n    points = np.array([[10.0, 10.0]])\n    bin_idx = env.bin_at(points)\n    assert bin_idx.shape == (1,)\n    assert 0 &lt;= bin_idx[0] &lt; env.n_bins\n</code></pre>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<pre><code># All tests\nuv run pytest\n\n# Specific test file\nuv run pytest tests/test_environment.py\n\n# With coverage\nuv run pytest --cov=src/neurospatial\n\n# Verbose output\nuv run pytest -v\n\n# Stop at first failure\nuv run pytest -x\n</code></pre>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":""},{"location":"contributing/#before-submitting","title":"Before Submitting","text":"<ol> <li>Run all tests: <code>uv run pytest</code></li> <li>Check code quality: <code>uv run ruff check . &amp;&amp; uv run ruff format .</code></li> <li>Update documentation: Add/update docstrings and docs pages</li> <li>Add tests: Ensure new code has test coverage</li> <li>Update CHANGELOG.md: Add entry under \"Unreleased\"</li> </ol>"},{"location":"contributing/#submitting","title":"Submitting","text":"<ol> <li>Create a feature branch:</li> </ol> <pre><code>git checkout -b feature/amazing-feature\n</code></pre> <ol> <li> <p>Make your changes with clear commit messages</p> </li> <li> <p>Push to your fork:</p> </li> </ol> <pre><code>git push origin feature/amazing-feature\n</code></pre> <ol> <li>Open a Pull Request on GitHub</li> </ol>"},{"location":"contributing/#pr-description","title":"PR Description","text":"<p>Include in your PR description:</p> <ul> <li>Summary: What does this PR do?</li> <li>Motivation: Why is this change needed?</li> <li>Testing: How was this tested?</li> <li>Breaking Changes: Any API changes?</li> <li>Related Issues: Link to related issues</li> </ul> <p>Example:</p> <pre><code>## Summary\nAdds `.info()` method to Environment class for printing summary statistics.\n\n## Motivation\nUsers frequently need to inspect environment properties. This provides\na convenient way to see all key information at once.\n\n## Testing\n- Added tests in `test_environment.py`\n- Manually tested with various environment types\n- All existing tests pass\n\n## Breaking Changes\nNone\n\n## Related Issues\nCloses #42\n</code></pre>"},{"location":"contributing/#documentation","title":"Documentation","text":""},{"location":"contributing/#building-documentation","title":"Building Documentation","text":"<pre><code># Install docs dependencies\nuv sync --extra docs\n\n# Serve locally\nuv run mkdocs serve\n\n# Build static site\nuv run mkdocs build\n</code></pre> <p>Documentation is at https://edeno.github.io/neurospatial/</p>"},{"location":"contributing/#adding-documentation","title":"Adding Documentation","text":"<ul> <li>New features: Update relevant user guide pages</li> <li>API changes: Docstrings are auto-generated</li> <li>Examples: Add Jupyter notebooks to <code>examples/</code></li> </ul>"},{"location":"contributing/#release-process","title":"Release Process","text":"<p>(For maintainers)</p> <ol> <li>Update version in <code>pyproject.toml</code></li> <li>Update <code>CHANGELOG.md</code></li> <li>Create git tag: <code>git tag v0.2.0</code></li> <li>Push tag: <code>git push origin v0.2.0</code></li> <li>GitHub Actions handles PyPI release</li> </ol>"},{"location":"contributing/#getting-help","title":"Getting Help","text":"<ul> <li>Questions: Open a GitHub Discussion</li> <li>Bugs: Open a GitHub Issue</li> <li>Contact: Email eric.denovellis@ucsf.edu</li> </ul>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<ul> <li>Be respectful and inclusive</li> <li>Focus on constructive feedback</li> <li>Help create a welcoming environment</li> </ul>"},{"location":"contributing/#recognition","title":"Recognition","text":"<p>Contributors will be acknowledged in:</p> <ul> <li>CHANGELOG.md</li> <li>GitHub contributors page</li> <li>Future publications using neurospatial</li> </ul> <p>Thank you for contributing to neurospatial!</p>"},{"location":"dimensionality_support/","title":"Dimensionality Support in neurospatial","text":"<p>Last Updated: 2025-11-03 (v0.2.0)</p>"},{"location":"dimensionality_support/#summary","title":"Summary","text":"<p>neurospatial supports 1D and 2D spatial environments. Basic 3D binning works, but some features are 2D-only.</p>"},{"location":"dimensionality_support/#supported-dimensionalities","title":"Supported Dimensionalities","text":""},{"location":"dimensionality_support/#1d-environments-linearized-tracks","title":"1D Environments (Linearized Tracks)","text":"<p>Use case: Linear tracks, mazes with defined paths, sequential spatial trajectories</p> <p>How to create: <pre><code>from neurospatial import Environment\n\n# From position data with track structure\nenv = Environment.from_graph(\n    track_graph=graph,\n    position=position_data,\n    sampling_frequency=30.0\n)\n</code></pre></p> <p>Unique features: - <code>env.to_linear(nd_position)</code> - Convert N-D coordinates to linear position - <code>env.linear_to_nd(linear_position)</code> - Convert linear position to N-D coordinates - <code>env.plot_1d()</code> - 1D visualization - <code>env.is_1d == True</code></p> <p>Typical applications: - Linear tracks (e.g., T-maze arms, figure-8 tracks) - Virtual reality corridors - Sequential navigation analysis</p>"},{"location":"dimensionality_support/#2d-environments-grid-based-layouts","title":"2D Environments (Grid-Based Layouts)","text":"<p>Use case: Open field navigation, arenas, complex 2D environments</p> <p>How to create: <pre><code>from neurospatial import Environment\nimport numpy as np\n\n# From 2D position samples\ndata_2d = np.random.randn(1000, 2) * 50  # shape (n_samples, 2)\nenv = Environment.from_samples(data_2d, bin_size=2.0)\n\n# From polygon boundary\nfrom shapely.geometry import Polygon\npolygon = Polygon([(0, 0), (100, 0), (100, 100), (0, 100)])\nenv = Environment.from_polygon(polygon, bin_size=2.0)\n\n# From image mask\nenv = Environment.from_image(\"arena_mask.png\", bin_size_cm=2.0, pixels_per_cm=10)\n</code></pre></p> <p>Layout engines available: - <code>RegularGridLayout</code> - Standard rectangular grids - <code>HexagonalLayout</code> - Hexagonal tessellations - <code>TriangularMeshLayout</code> - Triangular tessellations - <code>MaskedGridLayout</code> - Grids with arbitrary active/inactive regions - <code>ImageMaskLayout</code> - Binary image-based layouts - <code>ShapelyPolygonLayout</code> - Polygon-bounded grids</p> <p>Full feature support: - \u2705 2D affine transforms (rotation, scaling, translation) - \u2705 Polygon regions - \u2705 Image mask layouts - \u2705 All spatial queries (bin_at, contains, neighbors, shortest_path) - \u2705 Alignment and probability mapping between environments - \u2705 Full visualization suite</p> <p>Typical applications: - Open field experiments - Water maze navigation - Complex 2D arenas with barriers - Multi-room environments</p>"},{"location":"dimensionality_support/#3d-support-status","title":"3D Support Status","text":""},{"location":"dimensionality_support/#what-works-in-3d","title":"What Works in 3D","text":"<p>\u2705 Basic spatial binning: <pre><code>data_3d = np.random.randn(1000, 3) * 50  # shape (n_samples, 3)\nenv_3d = Environment.from_samples(data_3d, bin_size=2.0)\n\n# These all work:\nbins = env_3d.bin_at(points_3d)\nmask = env_3d.contains(points_3d)\nneighbors = env_3d.neighbors(bin_idx)\npath = env_3d.shortest_path(source_bin, target_bin)\ndist = env_3d.distance_between(bin1, bin2)\n</code></pre></p> <p>\u2705 Connectivity graphs - Full 3D graph support</p> <p>\u2705 Distance calculations - Euclidean distances in 3D</p> <p>\u2705 Path finding - Shortest paths through 3D bin connectivity</p> <p>\u2705 Composite environments - Merging 3D environments</p>"},{"location":"dimensionality_support/#what-doesnt-work-in-3d","title":"What Doesn't Work in 3D","text":"<p>\u274c 2D affine transforms <pre><code>from neurospatial.alignment import get_2d_rotation_matrix\n\n# This is 2D only - will not work for 3D environments\nrotation = get_2d_rotation_matrix(angle_degrees=45)  # 2x2 matrix\n</code></pre></p> <p>Alternative for 3D: Use <code>scipy.spatial.transform.Rotation</code> for 3D rotations</p> <p>\u274c Polygon regions <pre><code># Polygon regions are 2D only\npolygon_coords = np.array([[0, 0], [10, 0], [10, 10], [0, 10]])\nenv_3d.regions.add(\"goal\", polygon=polygon_coords)  # Will raise error\n\nbins = env_3d.bins_in_region(\"goal\")  # ValueError: Polygon regions only supported for 2D\n</code></pre></p> <p>\u274c Image mask layouts - Binary images are inherently 2D</p> <p>\u274c Hexagonal and triangular layouts - Currently 2D-only tessellations</p> <p>\u274c 3D-specific visualization - No 3D plotting methods yet</p>"},{"location":"dimensionality_support/#feature-compatibility-matrix","title":"Feature Compatibility Matrix","text":"Feature 1D 2D 3D Notes Core Functionality Spatial binning \u2705 \u2705 \u2705 Connectivity graphs \u2705 \u2705 \u2705 Distance calculations \u2705 \u2705 \u2705 Path finding \u2705 \u2705 \u2705 Composite environments \u2705 \u2705 \u2705 Regions Point regions \u2705 \u2705 \u2705 Polygon regions \u274c \u2705 \u274c 2D only Transforms Affine2D \u274c \u2705 \u274c 2D only Rotation matrices \u274c \u2705 \u274c Use scipy for 3D Scaling \u2705 \u2705 \u2705 Translation \u2705 \u2705 \u2705 Layout Engines RegularGridLayout \u274c \u2705 \u2705 HexagonalLayout \u274c \u2705 \u274c 2D tessellation TriangularMeshLayout \u274c \u2705 \u274c 2D tessellation GraphLayout \u2705 \u274c \u274c 1D linearization MaskedGridLayout \u274c \u2705 \u2705 ImageMaskLayout \u274c \u2705 \u274c Images are 2D ShapelyPolygonLayout \u274c \u2705 \u274c Polygons are 2D Visualization plot() \u2705 \u2705 \u274c plot_1d() \u2705 \u274c \u274c 1D only Alignment Probability mapping \u2705 \u2705 \u2705 2D rotation alignment \u274c \u2705 \u274c"},{"location":"dimensionality_support/#best-practices","title":"Best Practices","text":""},{"location":"dimensionality_support/#choosing-dimensionality","title":"Choosing Dimensionality","text":"<p>Use 1D when: - Your spatial data follows a defined path or track - You need linearized position coordinates - Working with sequential navigation (T-maze, linear track)</p> <p>Use 2D when: - Your spatial data is in an open 2D arena - You need polygon-based regions - Working with standard behavioral experiments (open field, water maze)</p> <p>Use 3D when: - Your spatial data is truly 3D (flight, swimming with depth, climbing) - You only need basic binning and connectivity - You don't need transforms or polygon regions</p>"},{"location":"dimensionality_support/#validation","title":"Validation","text":"<p>Always verify dimensionality before assuming features work:</p> <pre><code>env = Environment.from_samples(data, bin_size=2.0)\n\n# Check dimensionality\nprint(f\"Dimensions: {env.n_dims}\")  # 1, 2, or 3\n\n# Check if 1D (linearized)\nif env.is_1d:\n    linear_pos = env.to_linear(nd_position)\nelse:\n    bin_idx = env.bin_at(nd_position)\n\n# Check before using 2D-only features\nif env.n_dims == 2:\n    # Safe to use polygon regions, 2D transforms, etc.\n    env.regions.add(\"goal\", polygon=polygon_coords)\nelse:\n    # Use point regions instead\n    env.regions.add(\"goal\", point=[10, 20, 30])\n</code></pre>"},{"location":"dimensionality_support/#future-3d-support","title":"Future 3D Support","text":"<p>Full 3D support is planned for future releases (v0.3.0+). Planned features:</p> <ul> <li>3D affine transformations</li> <li>3D polyhedron regions (using <code>trimesh</code> or similar)</li> <li>3D visualization with <code>matplotlib 3D</code> or <code>plotly</code></li> <li>3D-specific layout engines (volumetric tessellations)</li> <li>Full documentation and examples for 3D workflows</li> </ul> <p>Track progress: See GitHub Issues for 3D support roadmap</p>"},{"location":"dimensionality_support/#getting-help","title":"Getting Help","text":"<ul> <li>For 1D/2D questions: See main documentation and examples</li> <li>For 3D questions: Check this guide for current limitations</li> <li>Report issues: https://github.com/user/neurospatial/issues</li> <li>Discussions: https://github.com/user/neurospatial/discussions</li> </ul>"},{"location":"gen_ref_pages/","title":"Gen ref pages","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"Generate the code reference pages automatically.\"\"\"\n</pre> \"\"\"Generate the code reference pages automatically.\"\"\" In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n</pre> from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import mkdocs_gen_files\n</pre> import mkdocs_gen_files In\u00a0[\u00a0]: Copied! <pre>nav = mkdocs_gen_files.Nav()\n</pre> nav = mkdocs_gen_files.Nav() In\u00a0[\u00a0]: Copied! <pre>src_root = Path(__file__).parent.parent / \"src\"\npackage_root = src_root / \"neurospatial\"\n</pre> src_root = Path(__file__).parent.parent / \"src\" package_root = src_root / \"neurospatial\" In\u00a0[\u00a0]: Copied! <pre>for path in sorted(package_root.rglob(\"*.py\")):\n    module_path = path.relative_to(src_root).with_suffix(\"\")\n    doc_path = path.relative_to(src_root).with_suffix(\".md\")\n    full_doc_path = Path(\"api\") / doc_path\n\n    parts = tuple(module_path.parts)\n\n    # Skip __pycache__ and test files\n    if \"__pycache__\" in parts or \"test_\" in path.name:\n        continue\n\n    # Skip __init__ files for navigation (but still generate docs)\n    if parts[-1] == \"__init__\":\n        parts = parts[:-1]\n        doc_path = doc_path.with_name(\"index.md\")\n        full_doc_path = full_doc_path.with_name(\"index.md\")\n    elif parts[-1] == \"__main__\":\n        continue\n\n    # Add to navigation\n    nav[parts] = doc_path.as_posix()\n\n    # Generate the markdown file\n    with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:\n        ident = \".\".join(parts)\n        fd.write(f\"# `{ident}`\\n\\n\")\n        fd.write(f\"::: {ident}\")\n\n    mkdocs_gen_files.set_edit_path(full_doc_path, path.relative_to(src_root.parent))\n</pre> for path in sorted(package_root.rglob(\"*.py\")):     module_path = path.relative_to(src_root).with_suffix(\"\")     doc_path = path.relative_to(src_root).with_suffix(\".md\")     full_doc_path = Path(\"api\") / doc_path      parts = tuple(module_path.parts)      # Skip __pycache__ and test files     if \"__pycache__\" in parts or \"test_\" in path.name:         continue      # Skip __init__ files for navigation (but still generate docs)     if parts[-1] == \"__init__\":         parts = parts[:-1]         doc_path = doc_path.with_name(\"index.md\")         full_doc_path = full_doc_path.with_name(\"index.md\")     elif parts[-1] == \"__main__\":         continue      # Add to navigation     nav[parts] = doc_path.as_posix()      # Generate the markdown file     with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:         ident = \".\".join(parts)         fd.write(f\"# `{ident}`\\n\\n\")         fd.write(f\"::: {ident}\")      mkdocs_gen_files.set_edit_path(full_doc_path, path.relative_to(src_root.parent)) In\u00a0[\u00a0]: Copied! <pre># Write the navigation file\nwith mkdocs_gen_files.open(\"api/SUMMARY.md\", \"w\") as nav_file:\n    nav_file.writelines(nav.build_literate_nav())\n</pre> # Write the navigation file with mkdocs_gen_files.open(\"api/SUMMARY.md\", \"w\") as nav_file:     nav_file.writelines(nav.build_literate_nav())"},{"location":"sync_notebooks/","title":"Sync notebooks","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"Sync example notebooks from examples/ to docs/examples/ for documentation build.\"\"\"\n</pre> \"\"\"Sync example notebooks from examples/ to docs/examples/ for documentation build.\"\"\" In\u00a0[\u00a0]: Copied! <pre>import shutil\nfrom pathlib import Path\n</pre> import shutil from pathlib import Path In\u00a0[\u00a0]: Copied! <pre># Paths\nexamples_dir = Path(__file__).parent.parent / \"examples\"\ndocs_examples_dir = Path(__file__).parent / \"examples\"\n</pre> # Paths examples_dir = Path(__file__).parent.parent / \"examples\" docs_examples_dir = Path(__file__).parent / \"examples\" In\u00a0[\u00a0]: Copied! <pre># Sync all notebooks\nfor notebook in examples_dir.glob(\"*.ipynb\"):\n    dest = docs_examples_dir / notebook.name\n    print(f\"Syncing {notebook.name}...\")\n    shutil.copy2(notebook, dest)\n</pre> # Sync all notebooks for notebook in examples_dir.glob(\"*.ipynb\"):     dest = docs_examples_dir / notebook.name     print(f\"Syncing {notebook.name}...\")     shutil.copy2(notebook, dest) In\u00a0[\u00a0]: Copied! <pre>print(f\"\u2713 Synced {len(list(examples_dir.glob('*.ipynb')))} notebooks\")\n</pre> print(f\"\u2713 Synced {len(list(examples_dir.glob('*.ipynb')))} notebooks\")"},{"location":"api/","title":"API Reference","text":"<p>Complete API documentation for neurospatial, automatically generated from source code docstrings.</p>"},{"location":"api/#core-modules","title":"Core Modules","text":""},{"location":"api/#neurospatialenvironment","title":"neurospatial.environment","text":"<p>The main <code>Environment</code> class and related functionality.</p> <p>Key Classes:</p> <ul> <li><code>Environment</code>: Main class for discretized spatial environments</li> </ul>"},{"location":"api/#neurospatialcomposite","title":"neurospatial.composite","text":"<p>Merge multiple environments into composite structures.</p> <p>Key Classes:</p> <ul> <li><code>CompositeEnvironment</code>: Combine multiple environments with automatic bridge inference</li> </ul>"},{"location":"api/#neurospatialregions","title":"neurospatial.regions","text":"<p>Define and manage named regions of interest (ROIs).</p> <p>Key Classes:</p> <ul> <li><code>Region</code>: Immutable point or polygon region</li> <li><code>Regions</code>: Container for managing multiple regions</li> </ul>"},{"location":"api/#neurospatiallayout","title":"neurospatial.layout","text":"<p>Layout engines for discretizing continuous space.</p> <p>Key Modules:</p> <ul> <li><code>layout.base</code>: <code>LayoutEngine</code> protocol definition</li> <li><code>layout.engines.*</code>: Concrete layout implementations</li> <li><code>layout.factories</code>: Factory functions for creating layouts</li> </ul>"},{"location":"api/#neurospatialalignment","title":"neurospatial.alignment","text":"<p>Transform and align spatial representations.</p> <p>Key Functions:</p> <ul> <li><code>map_probabilities_to_nearest_target_bin()</code>: Align probability distributions between environments</li> <li><code>get_2d_rotation_matrix()</code>: Create 2D rotation matrices</li> </ul>"},{"location":"api/#neurospatialtransforms","title":"neurospatial.transforms","text":"<p>2D affine transformations.</p> <p>Key Classes:</p> <ul> <li><code>Affine2D</code>: Composable 2D affine transformations</li> </ul>"},{"location":"api/#layout-engines","title":"Layout Engines","text":"<p>Detailed documentation for each layout engine:</p> <ul> <li>RegularGridLayout</li> <li>HexagonalLayout</li> <li>GraphLayout</li> <li>MaskedGridLayout</li> <li>ShapelyPolygonLayout</li> <li>TriangularMeshLayout</li> <li>ImageMaskLayout</li> </ul>"},{"location":"api/#navigation","title":"Navigation","text":"<p>Use the sidebar to browse the complete API reference, or search for specific functions, classes, or methods.</p>"},{"location":"api/#docstring-format","title":"Docstring Format","text":"<p>All docstrings follow NumPy docstring conventions for consistency with the scientific Python ecosystem.</p>"},{"location":"api/SUMMARY/","title":"SUMMARY","text":"<ul> <li>neurospatial<ul> <li>_constants</li> <li>_logging</li> <li>alignment</li> <li>calibration</li> <li>composite</li> <li>distance</li> <li>environment</li> <li>io</li> <li>layout<ul> <li>base</li> <li>engines<ul> <li>graph</li> <li>hexagonal</li> <li>image_mask</li> <li>masked_grid</li> <li>regular_grid</li> <li>shapely_polygon</li> <li>triangular_mesh</li> </ul> </li> <li>factories</li> <li>helpers<ul> <li>graph</li> <li>hexagonal</li> <li>regular_grid</li> <li>triangular_mesh</li> <li>utils</li> </ul> </li> <li>mixins</li> <li>validation</li> </ul> </li> <li>regions<ul> <li>core</li> <li>io</li> <li>ops</li> <li>plot</li> </ul> </li> <li>spatial</li> <li>transforms</li> </ul> </li> </ul>"},{"location":"api/neurospatial/","title":"<code>neurospatial</code>","text":""},{"location":"api/neurospatial/#neurospatial","title":"neurospatial","text":""},{"location":"api/neurospatial/#neurospatial-classes","title":"Classes","text":""},{"location":"api/neurospatial/#neurospatial.Environment","title":"Environment  <code>dataclass</code>","text":"<pre><code>Environment(name: str = '', layout: LayoutEngine | None = None, layout_type_used: str | None = None, layout_params_used: dict[str, Any] | None = None, regions: Regions | None = None)\n</code></pre> <p>Represents a discretized N-dimensional space with connectivity.</p> <p>This class serves as a comprehensive model of a spatial environment, discretized into bins or nodes. It stores the geometric properties of these bins (e.g., centers, areas), their connectivity, and provides methods for various spatial queries and operations.</p> <p>Instances are typically created using one of the provided classmethod factories (e.g., <code>Environment.from_samples(...)</code>, <code>Environment.from_graph(...)</code>). These factories handle the underlying <code>LayoutEngine</code> setup.</p> Terminology <p>Active Bins     In neuroscience experiments, an animal typically explores only a subset     of the physical environment. \"Active bins\" are spatial bins that contain     data (e.g., position samples) or meet specified criteria (e.g., minimum     sample count). Only active bins are included in the environment's     <code>bin_centers</code> and <code>connectivity</code> graph.</p> <pre><code>This filtering is scientifically important because:\n\n- **Meaningful analysis**: Neural activity (e.g., place fields) can only\n  be computed in locations the animal actually visited\n- **Computational efficiency**: Excludes empty regions, reducing memory\n  and computation costs\n- **Statistical validity**: Prevents analysis of bins with insufficient\n  data\n\nFor example, in a plus maze experiment, only the maze arms are active;\nthe surrounding room is excluded. In an open field with a circular\nboundary, only bins inside the circle are active.\n\nThe `infer_active_bins` parameter in `Environment.from_samples()` controls\nwhether bins are automatically filtered based on data presence. Additional\nparameters (`bin_count_threshold`, `dilate`, `fill_holes`, `close_gaps`)\nprovide fine-grained control over which bins are considered active.\n</code></pre> Choosing a Factory Method <p>The <code>Environment</code> class provides six factory methods for creating environments. Choose based on your data format and use case:</p> <p>Most Common (ordered by frequency of use)</p> <ol> <li> <p>from_samples - Discretize position data into bins    Use when you have a collection of position samples (e.g., animal tracking    data) and want to automatically infer the spatial extent and active bins.    Supports automatic filtering, morphological operations (dilate, fill_holes,    close_gaps), and flexible bin size specification.    See <code>from_samples()</code>.</p> </li> <li> <p>from_polygon - Create grid masked by a polygon boundary    Use when your environment has a well-defined geometric boundary (e.g.,    circular arena, irregular enclosure) specified as a Shapely polygon. The    grid is automatically clipped to the polygon interior.    See <code>from_polygon()</code>.</p> </li> <li> <p>from_graph - Create 1D linearized track environment    Use when analyzing data on tracks or mazes where 2D position should be    projected onto a 1D linearized representation. Supports automatic    linearization and conversion between 2D and 1D coordinates.    See <code>from_graph()</code>.</p> </li> </ol> <p>Specialized Use Cases</p> <ol> <li> <p>from_mask - Create environment from pre-computed mask    Use when you have already determined which bins should be active (e.g.,    from external analysis) as an N-D boolean array. Requires explicit    specification of grid edges.    See <code>from_mask()</code>.</p> </li> <li> <p>from_image - Create environment from binary image    Use when your environment boundary is defined by a binary image (e.g.,    segmentation mask, overhead camera view). Each white pixel becomes a    potential bin.    See <code>from_image()</code>.</p> </li> </ol> <p>Advanced</p> <ol> <li>from_layout - Create environment from custom LayoutEngine    Use when you need full control over the layout engine (e.g., HexagonalLayout,    TriangularMeshLayout, custom tessellations) or are implementing advanced    spatial discretization schemes. The factory method <code>create_layout()</code> provides    access to all available layout engines.    See <code>from_layout()</code> and <code>neurospatial.layout.factories.create_layout()</code>.</li> </ol> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>A user-defined name for the environment.</p> <code>layout</code> <code>LayoutEngine</code> <p>The layout engine instance that defines the geometry and connectivity of the discretized space.</p> <code>bin_centers</code> <code>NDArray[float64]</code> <p>Coordinates of the center of each active bin/node in the environment. Shape is (n_active_bins, n_dims). Populated by <code>_setup_from_layout</code>.</p> <code>connectivity</code> <code>Graph</code> <p>A NetworkX graph where nodes are integers from <code>0</code> to <code>n_active_bins - 1</code>, directly corresponding to the rows of <code>bin_centers</code>. Edges represent adjacency between bins. Populated by <code>_setup_from_layout</code>.</p> <code>dimension_ranges</code> <code>Optional[Sequence[Tuple[float, float]]]</code> <p>The effective min/max extent <code>[(min_d0, max_d0), ..., (min_dN-1, max_dN-1)]</code> covered by the layout's geometry. Populated by <code>_setup_from_layout</code>.</p> <code>grid_edges</code> <code>Optional[Tuple[NDArray[float64], ...]]</code> <p>For grid-based layouts, a tuple where each element is a 1D array of bin edge positions for that dimension of the original, full grid. <code>None</code> or <code>()</code> for non-grid or point-based layouts. Populated by <code>_setup_from_layout</code>.</p> <code>grid_shape</code> <code>Optional[Tuple[int, ...]]</code> <p>For grid-based layouts, the N-D shape of the original, full grid. For point-based/cell-based layouts without a full grid concept, this may be <code>(n_active_bins,)</code>. Populated by <code>_setup_from_layout</code>.</p> <code>active_mask</code> <code>Optional[NDArray[bool_]]</code> <ul> <li>For grid-based layouts: An N-D boolean mask indicating active bins   on the original, full grid.</li> <li>For point-based/cell-based layouts: A 1D array of <code>True</code> values,   shape <code>(n_active_bins,)</code>, corresponding to <code>bin_centers</code>. Populated by <code>_setup_from_layout</code>.</li> </ul> <code>regions</code> <code>RegionManager</code> <p>Manages symbolic spatial regions defined within this environment.</p> <code>_is_1d_env</code> <code>bool</code> <p>Internal flag indicating if the environment's layout is primarily 1-dimensional. Set based on <code>layout.is_1d</code>.</p> <code>_is_fitted</code> <code>bool</code> <p>Internal flag indicating if the environment has been fully initialized and its layout-dependent attributes are populated.</p> <code>_layout_type_used</code> <code>Optional[str]</code> <p>The string identifier of the <code>LayoutEngine</code> type used to create this environment (e.g., \"RegularGrid\"). For introspection and serialization.</p> <code>_layout_params_used</code> <code>Dict[str, Any]</code> <p>A dictionary of the parameters used to build the <code>LayoutEngine</code> instance. For introspection and serialization.</p> <p>Initialize the Environment.</p> <p>Note: This constructor is primarily intended for internal use by factory methods. Users should typically create Environment instances using classmethods like <code>Environment.from_samples(...)</code>. The provided <code>layout</code> instance is assumed to be already built and configured.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the environment, by default \"\".</p> <code>''</code> <code>layout</code> <code>LayoutEngine</code> <p>A fully built LayoutEngine instance that defines the environment's geometry and connectivity.</p> <code>None</code> <code>layout_type_used</code> <code>Optional[str]</code> <p>The string identifier for the type of layout used. If None, it's inferred from <code>layout._layout_type_tag</code>. Defaults to None.</p> <code>None</code> <code>layout_params_used</code> <code>Optional[Dict[str, Any]]</code> <p>Parameters used to build the layout. If None, inferred from <code>layout._build_params_used</code>. Defaults to None.</p> <code>None</code> Source code in <code>src/neurospatial/environment.py</code> <pre><code>def __init__(\n    self,\n    name: str = \"\",\n    layout: LayoutEngine | None = None,\n    layout_type_used: str | None = None,\n    layout_params_used: dict[str, Any] | None = None,\n    regions: Regions | None = None,\n):\n    \"\"\"Initialize the Environment.\n\n    Note: This constructor is primarily intended for internal use by factory\n    methods. Users should typically create Environment instances using\n    classmethods like `Environment.from_samples(...)`. The provided\n    `layout` instance is assumed to be already built and configured.\n\n    Parameters\n    ----------\n    name : str, optional\n        Name for the environment, by default \"\".\n    layout : LayoutEngine\n        A fully built LayoutEngine instance that defines the environment's\n        geometry and connectivity.\n    layout_type_used : Optional[str], optional\n        The string identifier for the type of layout used. If None, it's\n        inferred from `layout._layout_type_tag`. Defaults to None.\n    layout_params_used : Optional[Dict[str, Any]], optional\n        Parameters used to build the layout. If None, inferred from\n        `layout._build_params_used`. Defaults to None.\n\n    \"\"\"\n    if layout is None:\n        raise ValueError(\"layout parameter is required\")\n\n    self.name = name\n    self.layout = layout\n\n    self._layout_type_used = (\n        layout_type_used\n        if layout_type_used\n        else getattr(layout, \"_layout_type_tag\", None)\n    )\n    self._layout_params_used = (\n        layout_params_used\n        if layout_params_used is not None\n        else getattr(layout, \"_build_params_used\", {})\n    )\n\n    self._is_1d_env = self.layout.is_1d\n\n    # Initialize attributes that will be populated by _setup_from_layout\n    self.bin_centers = np.empty((0, 0))  # Placeholder\n    self.connectivity = nx.Graph()\n    self.dimension_ranges = None\n    self.grid_edges = ()\n    self.grid_shape = None\n    self.active_mask = None\n    self._is_fitted = False  # Will be set by _setup_from_layout\n    if layout_type_used is not None:\n        self._setup_from_layout()  # Populate attributes from the built layout\n    if regions is not None:\n        if not isinstance(regions, Regions):\n            raise TypeError(\n                f\"Expected 'regions' to be a Regions instance, got {type(regions)}.\",\n            )\n        self.regions = regions\n    else:\n        # Initialize with an empty Regions instance if not provided\n        self.regions = Regions()\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment-attributes","title":"Attributes","text":""},{"location":"api/neurospatial/#neurospatial.Environment.is_1d","title":"is_1d  <code>property</code>","text":"<pre><code>is_1d: bool\n</code></pre> <p>Indicate if the environment's layout is primarily 1-dimensional.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the underlying <code>LayoutEngine</code> (<code>self.layout</code>) reports itself as 1-dimensional (e.g., <code>GraphLayout</code>), False otherwise. This is determined by <code>self.layout.is_1d</code>.</p>"},{"location":"api/neurospatial/#neurospatial.Environment.n_dims","title":"n_dims  <code>property</code>","text":"<pre><code>n_dims: int\n</code></pre> <p>Return the number of spatial dimensions of the active bin centers.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of dimensions (e.g., 1 for a line, 2 for a plane). Derived from the shape of <code>self.bin_centers</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted or if <code>bin_centers</code> is not available.</p>"},{"location":"api/neurospatial/#neurospatial.Environment.layout_parameters","title":"layout_parameters  <code>property</code>","text":"<pre><code>layout_parameters: dict[str, Any]\n</code></pre> <p>Return the parameters used to build the layout engine.</p> <p>This includes all parameters that were passed to the <code>build</code> method of the underlying <code>LayoutEngine</code>.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary of parameters used to create the layout. Useful for introspection and serialization.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p>"},{"location":"api/neurospatial/#neurospatial.Environment.layout_type","title":"layout_type  <code>property</code>","text":"<pre><code>layout_type: str\n</code></pre> <p>Return the type of layout used in the environment.</p> <p>Returns:</p> Type Description <code>str</code> <p>The layout type (e.g., \"RegularGrid\", \"Hexagonal\").</p>"},{"location":"api/neurospatial/#neurospatial.Environment.n_bins","title":"n_bins  <code>property</code>","text":"<pre><code>n_bins: int\n</code></pre> <p>Return the number of active bins in the environment.</p> <p>This is determined by the number of rows in <code>self.bin_centers</code>.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of active bins (0 if not fitted).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p>"},{"location":"api/neurospatial/#neurospatial.Environment.bin_sizes","title":"bin_sizes  <code>cached</code> <code>property</code>","text":"<pre><code>bin_sizes: NDArray[float64]\n</code></pre> <p>Calculate the area (for 2D) or volume (for 3D+) of each active bin.</p> <p>This represent the actual size of each bin in the environment, as opposed to the requested <code>bin_size</code> which is the nominal size used during layout creation.</p> <p>For 1D environments, this typically returns the length of each bin. This method delegates to the <code>bin_sizes</code> method of the underlying <code>LayoutEngine</code>.</p> <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_active_bins))</code> <p>An array containing the area/volume/length of each active bin.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p>"},{"location":"api/neurospatial/#neurospatial.Environment.boundary_bins","title":"boundary_bins  <code>cached</code> <code>property</code>","text":"<pre><code>boundary_bins: NDArray[int_]\n</code></pre> <p>Get the boundary bin indices.</p> <p>Returns:</p> Type Description <code>(NDArray[int_], shape(n_boundary_bins))</code> <p>An array of indices of the boundary bins in the environment. These are the bins that are at the edges of the active area.</p>"},{"location":"api/neurospatial/#neurospatial.Environment.linearization_properties","title":"linearization_properties  <code>cached</code> <code>property</code>","text":"<pre><code>linearization_properties: dict[str, Any] | None\n</code></pre> <p>If the environment uses a GraphLayout, returns properties needed for linearization (converting a 2D/3D track to a 1D line) using the <code>track_linearization</code> library.</p> <p>These properties are typically passed to <code>track_linearization.get_linearized_position</code>.</p> <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>A dictionary with keys 'track_graph', 'edge_order', 'edge_spacing' if the layout is <code>GraphLayout</code> and parameters are available. Returns <code>None</code> otherwise.</p>"},{"location":"api/neurospatial/#neurospatial.Environment.bin_attributes","title":"bin_attributes  <code>cached</code> <code>property</code>","text":"<pre><code>bin_attributes: DataFrame\n</code></pre> <p>Build a DataFrame of attributes for each active bin (node) in the environment's graph.</p> <p>Returns:</p> Name Type Description <code>df</code> <code>DataFrame</code> <p>Rows are indexed by <code>active_bin_id</code> (int), matching 0..(n_bins-1). Columns correspond to node attributes. If a 'pos' attribute exists for any node and is non-null, it will be expanded into columns 'pos_dim0', 'pos_dim1', ..., with numeric coordinates.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there are no active bins (graph has zero nodes).</p>"},{"location":"api/neurospatial/#neurospatial.Environment.edge_attributes","title":"edge_attributes  <code>cached</code> <code>property</code>","text":"<pre><code>edge_attributes: DataFrame\n</code></pre> <p>Return a Pandas DataFrame where each row corresponds to one directed edge (u \u2192 v) in the connectivity graph, and columns include all stored edge attributes (e.g. 'distance', 'vector', 'weight', 'angle_2d', etc.).</p> <p>The DataFrame will have a MultiIndex of (source_bin, target_bin). If you prefer flat columns, you can reset the index.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame whose index is a MultiIndex (source_bin, target_bin), and whose columns are the union of all attribute-keys stored on each edge.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there are no edges in the connectivity graph.</p> <code>RuntimeError</code> <p>If called before the environment is fitted.</p>"},{"location":"api/neurospatial/#neurospatial.Environment-functions","title":"Functions","text":""},{"location":"api/neurospatial/#neurospatial.Environment.info","title":"info","text":"<pre><code>info() -&gt; str\n</code></pre> <p>Return a detailed multi-line diagnostic summary of the environment.</p> <p>This method provides comprehensive diagnostic information about the environment, including geometric properties, layout configuration, and spatial characteristics. The output is formatted for readability with clear labels and organized sections.</p> <p>Returns:</p> Type Description <code>str</code> <p>Multi-line formatted string containing detailed environment information.</p> See Also <p>repr : Single-line concise representation for quick inspection. repr_html : Rich HTML representation for Jupyter notebooks.</p> Notes <p>This method is particularly useful for:</p> <ul> <li>Debugging spatial binning issues</li> <li>Verifying environment configuration</li> <li>Understanding the structure of complex environments</li> <li>Documenting environment parameters for reproducibility</li> </ul> <p>The output includes all critical diagnostic information:</p> <ul> <li>Environment name and layout type</li> <li>Spatial dimensionality and bin count</li> <li>Physical extent in each dimension</li> <li>Bin size statistics (uniform or variable)</li> <li>Region of interest count</li> <li>Linearization status (for 1D environments)</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; data = np.random.rand(500, 2) * 100  # 2D data in cm\n&gt;&gt;&gt; env = Environment.from_samples(data, bin_size=5.0, name=\"OpenField\")\n&gt;&gt;&gt; print(env.info())\nEnvironment Information\n=======================\nName: OpenField\nLayout Type: RegularGridLayout\nDimensions: 2\nNumber of Bins: 400\n\nSpatial Extent:\n  Dimension 0: [-2.50, 102.50] (range: 105.00)\n  Dimension 1: [-2.50, 102.50] (range: 105.00)\n\nBin Sizes:\n  Dimension 0: 5.00\n  Dimension 1: 5.00\n\nRegions: 0\n</code></pre> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef info(self) -&gt; str:\n    \"\"\"Return a detailed multi-line diagnostic summary of the environment.\n\n    This method provides comprehensive diagnostic information about the\n    environment, including geometric properties, layout configuration, and\n    spatial characteristics. The output is formatted for readability with\n    clear labels and organized sections.\n\n    Returns\n    -------\n    str\n        Multi-line formatted string containing detailed environment information.\n\n    See Also\n    --------\n    __repr__ : Single-line concise representation for quick inspection.\n    _repr_html_ : Rich HTML representation for Jupyter notebooks.\n\n    Notes\n    -----\n    This method is particularly useful for:\n\n    - Debugging spatial binning issues\n    - Verifying environment configuration\n    - Understanding the structure of complex environments\n    - Documenting environment parameters for reproducibility\n\n    The output includes all critical diagnostic information:\n\n    - Environment name and layout type\n    - Spatial dimensionality and bin count\n    - Physical extent in each dimension\n    - Bin size statistics (uniform or variable)\n    - Region of interest count\n    - Linearization status (for 1D environments)\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; data = np.random.rand(500, 2) * 100  # 2D data in cm\n    &gt;&gt;&gt; env = Environment.from_samples(data, bin_size=5.0, name=\"OpenField\")\n    &gt;&gt;&gt; print(env.info())  # doctest: +SKIP\n    Environment Information\n    =======================\n    Name: OpenField\n    Layout Type: RegularGridLayout\n    Dimensions: 2\n    Number of Bins: 400\n    &lt;BLANKLINE&gt;\n    Spatial Extent:\n      Dimension 0: [-2.50, 102.50] (range: 105.00)\n      Dimension 1: [-2.50, 102.50] (range: 105.00)\n    &lt;BLANKLINE&gt;\n    Bin Sizes:\n      Dimension 0: 5.00\n      Dimension 1: 5.00\n    &lt;BLANKLINE&gt;\n    Regions: 0\n    \"\"\"\n    # Build output line by line\n    lines = []\n\n    # Header\n    lines.append(\"Environment Information\")\n    lines.append(\"=\" * 23)\n    lines.append(\"\")\n\n    # Basic information\n    name_display = self.name if self.name else \"(unnamed)\"\n    lines.append(f\"Name: {name_display}\")\n    lines.append(f\"Layout Type: {self.layout_type}\")\n    lines.append(f\"Dimensions: {self.n_dims}\")\n    lines.append(f\"Number of Bins: {self.n_bins}\")\n    lines.append(\"\")\n\n    # Spatial extent\n    if self.dimension_ranges is not None:\n        lines.append(\"Spatial Extent:\")\n        for dim_idx, (dim_min, dim_max) in enumerate(self.dimension_ranges):\n            dim_range = dim_max - dim_min\n            lines.append(\n                f\"  Dimension {dim_idx}: [{dim_min:.2f}, {dim_max:.2f}] \"\n                f\"(range: {dim_range:.2f})\"\n            )\n        lines.append(\"\")\n    else:\n        lines.append(\"Spatial Extent: Not available\")\n        lines.append(\"\")\n\n    # Bin sizes\n    lines.append(\"Bin Sizes:\")\n    try:\n        bin_sizes_array = self.bin_sizes\n\n        # Check if all bins have the same size (uniform)\n        if np.allclose(bin_sizes_array, bin_sizes_array[0]):\n            # Uniform bin size - for grids, extract per-dimension from grid_edges\n            if self.grid_edges and all(len(e) &gt; 1 for e in self.grid_edges):\n                for dim_idx, edges in enumerate(self.grid_edges):\n                    dim_sizes = np.diff(edges)\n                    if np.allclose(dim_sizes, dim_sizes[0]):\n                        lines.append(f\"  Dimension {dim_idx}: {dim_sizes[0]:.2f}\")\n                    else:\n                        lines.append(\n                            f\"  Dimension {dim_idx}: variable \"\n                            f\"(mean: {np.mean(dim_sizes):.2f}, \"\n                            f\"std: {np.std(dim_sizes):.2f})\"\n                        )\n            else:\n                # Non-grid layout or 1D - show the uniform measure\n                measure_name = (\n                    \"Size\"\n                    if self.n_dims == 1\n                    else \"Area\"\n                    if self.n_dims == 2\n                    else \"Volume\"\n                )\n                lines.append(f\"  {measure_name}: {bin_sizes_array[0]:.2f}\")\n        else:\n            # Variable bin sizes\n            lines.append(\n                f\"  Variable (mean: {np.mean(bin_sizes_array):.2f}, \"\n                f\"std: {np.std(bin_sizes_array):.2f}, \"\n                f\"range: [{np.min(bin_sizes_array):.2f}, {np.max(bin_sizes_array):.2f}])\"\n            )\n    except (AttributeError, RuntimeError, ValueError):\n        lines.append(\"  (not available)\")\n    lines.append(\"\")\n\n    # Regions\n    n_regions = len(self.regions) if self.regions else 0\n    if n_regions &gt; 0:\n        lines.append(f\"Regions: {n_regions} defined\")\n        # Show region names if not too many\n        if n_regions &lt;= 5:\n            for region_name in self.regions:\n                lines.append(f\"  - {region_name}\")\n        else:\n            lines.append(\"  (use env.regions to inspect all regions)\")\n    else:\n        lines.append(\"Regions: None\")\n    lines.append(\"\")\n\n    # 1D-specific information\n    if hasattr(self, \"is_1d\") and self.is_1d:\n        lines.append(\"Linearization: Available (1D environment)\")\n        lines.append(\"\")\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.from_samples","title":"from_samples  <code>classmethod</code>","text":"<pre><code>from_samples(data_samples: NDArray[float64], bin_size: float | Sequence[float], name: str = '', layout_kind: str = 'RegularGrid', infer_active_bins: bool = True, bin_count_threshold: int = 0, dilate: bool = False, fill_holes: bool = False, close_gaps: bool = False, add_boundary_bins: bool = False, connect_diagonal_neighbors: bool = True, **layout_specific_kwargs: Any) -&gt; Environment\n</code></pre> <p>Create an Environment by binning (discretizing) <code>data_samples</code> into a layout grid.</p> <p>Parameters:</p> Name Type Description Default <code>data_samples</code> <code>(array, shape(n_samples, n_dims))</code> <p>Coordinates of sample points used to infer which bins are \"active.\"</p> required <code>bin_size</code> <code>float or sequence of floats</code> <p>Size of each bin in the same units as <code>data_samples</code> coordinates. For RegularGrid: length of each square bin side (or per-dimension if sequence). For Hexagonal: hexagon width (flat-to-flat distance across hexagon). If your data is in centimeters, bin_size=5.0 creates 5cm bins.</p> required <code>name</code> <code>str</code> <p>Optional name for the resulting Environment.</p> <code>\"\"</code> <code>layout_kind</code> <code>str</code> <p>Either \"RegularGrid\" or \"Hexagonal\" (case-insensitive). Determines bin shape. For \"Hexagonal\", <code>bin_size</code> is interpreted as <code>hexagon_width</code>.</p> <code>\"RegularGrid\"</code> <code>infer_active_bins</code> <code>bool</code> <p>If True, only bins containing \u2265 <code>bin_count_threshold</code> samples are \u201cactive.\u201d</p> <code>True</code> <code>bin_count_threshold</code> <code>int</code> <p>Minimum number of data points required for a bin to be considered \u201cactive.\u201d</p> <code>0</code> <code>dilate</code> <code>bool</code> <p>If True, apply morphological dilation to the active-bin mask.</p> <code>False</code> <code>fill_holes</code> <code>bool</code> <p>If True, fill holes in the active-bin mask.</p> <code>False</code> <code>close_gaps</code> <code>bool</code> <p>If True, close small gaps between active bins.</p> <code>False</code> <code>add_boundary_bins</code> <code>bool</code> <p>If True, add peripheral bins around the bounding region of samples.</p> <code>False</code> <code>connect_diagonal_neighbors</code> <code>bool</code> <p>If True, connect grid bins diagonally when building connectivity.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>env</code> <code>Environment</code> <p>A newly created Environment, fitted to the discretized samples.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>data_samples</code> is not 2D or contains invalid coordinates.</p> <code>NotImplementedError</code> <p>If <code>layout_kind</code> is neither \"RegularGrid\" nor \"Hexagonal\".</p> See Also <p>from_polygon : Create environment with polygon-defined boundary. from_mask : Create environment from pre-defined boolean mask. from_image : Create environment from binary image mask. from_graph : Create 1D linearized track environment. from_layout : Create environment with custom LayoutEngine.</p> <p>Examples:</p> <p>Create a simple 2D environment from position data:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; # Simulate animal position data in a 100x100 cm arena\n&gt;&gt;&gt; np.random.seed(42)  # For reproducible examples\n&gt;&gt;&gt; positions = np.random.rand(1000, 2) * 100  # cm\n&gt;&gt;&gt; # Create environment with 5cm x 5cm bins\n&gt;&gt;&gt; env = Environment.from_samples(\n...     data_samples=positions,\n...     bin_size=5.0,\n...     name=\"arena\",  # bin_size in cm\n... )\n&gt;&gt;&gt; env.n_dims\n2\n&gt;&gt;&gt; env.n_bins &gt; 0\nTrue\n</code></pre> <p>Create environment with morphological operations to clean up the active region:</p> <pre><code>&gt;&gt;&gt; env = Environment.from_samples(\n...     data_samples=positions,\n...     bin_size=5.0,  # 5cm bins\n...     bin_count_threshold=5,  # Require 5 samples per bin (lowered from 10)\n...     dilate=True,  # Expand active region\n...     fill_holes=True,  # Fill interior holes\n... )\n</code></pre> <p>Create a hexagonal grid environment:</p> <pre><code>&gt;&gt;&gt; env = Environment.from_samples(\n...     data_samples=positions,\n...     layout_kind=\"Hexagonal\",\n...     bin_size=5.0,  # 5cm hexagon width\n... )\n</code></pre> Common Pitfalls <ol> <li> <p>bin_size too large: If bin_size is too large relative to your data    range, you may end up with very few bins or no active bins at all.    For example, if your data spans 0-100 cm and you use bin_size=200.0,    you'll only get 1 bin. Try reducing bin_size to create more spatial    resolution (e.g., bin_size=5.0 for 5cm bins).</p> </li> <li> <p>bin_count_threshold too high: Setting bin_count_threshold higher    than the number of samples per bin will result in no active bins.    If you have sparse data with only a few samples per location, try    reducing bin_count_threshold to 0 or 1, or use morphological operations    to expand the active region.</p> </li> <li> <p>Mismatched units: Ensure bin_size and data_samples use the same    units. If your data is in centimeters, bin_size should also be in    centimeters. Mixing units (e.g., data in meters, bin_size in centimeters)    will result in incorrect spatial binning. For example, if your data spans    0-1 meters (100 cm) and you set bin_size=5.0 thinking it's centimeters,    you'll get only 1 bin instead of 20 bins.</p> </li> <li> <p>Missing morphological operations with sparse data: If your data is    sparse (animal didn't visit all locations uniformly), the active region    may have holes or gaps. Enable dilate=True, fill_holes=True, or    close_gaps=True to create a more continuous active region. These    operations are particularly useful for connecting isolated bins or    filling small unvisited areas within explored regions.</p> </li> </ol> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef from_samples(\n    cls,\n    data_samples: NDArray[np.float64],\n    bin_size: float | Sequence[float],\n    name: str = \"\",\n    layout_kind: str = \"RegularGrid\",\n    infer_active_bins: bool = True,\n    bin_count_threshold: int = 0,\n    dilate: bool = False,\n    fill_holes: bool = False,\n    close_gaps: bool = False,\n    add_boundary_bins: bool = False,\n    connect_diagonal_neighbors: bool = True,\n    **layout_specific_kwargs: Any,\n) -&gt; Environment:\n    \"\"\"Create an Environment by binning (discretizing) `data_samples` into a layout grid.\n\n    Parameters\n    ----------\n    data_samples : array, shape (n_samples, n_dims)\n        Coordinates of sample points used to infer which bins are \"active.\"\n    bin_size : float or sequence of floats\n        Size of each bin in the same units as `data_samples` coordinates.\n        For RegularGrid: length of each square bin side (or per-dimension if sequence).\n        For Hexagonal: hexagon width (flat-to-flat distance across hexagon).\n        If your data is in centimeters, bin_size=5.0 creates 5cm bins.\n    name : str, default \"\"\n        Optional name for the resulting Environment.\n    layout_kind : str, default \"RegularGrid\"\n        Either \"RegularGrid\" or \"Hexagonal\" (case-insensitive). Determines\n        bin shape. For \"Hexagonal\", `bin_size` is interpreted as `hexagon_width`.\n    infer_active_bins : bool, default True\n        If True, only bins containing \u2265 `bin_count_threshold` samples are \u201cactive.\u201d\n    bin_count_threshold : int, default 0\n        Minimum number of data points required for a bin to be considered \u201cactive.\u201d\n    dilate : bool, default False\n        If True, apply morphological dilation to the active-bin mask.\n    fill_holes : bool, default False\n        If True, fill holes in the active-bin mask.\n    close_gaps : bool, default False\n        If True, close small gaps between active bins.\n    add_boundary_bins : bool, default False\n        If True, add peripheral bins around the bounding region of samples.\n    connect_diagonal_neighbors : bool, default True\n        If True, connect grid bins diagonally when building connectivity.\n\n    Returns\n    -------\n    env : Environment\n        A newly created Environment, fitted to the discretized samples.\n\n    Raises\n    ------\n    ValueError\n        If `data_samples` is not 2D or contains invalid coordinates.\n    NotImplementedError\n        If `layout_kind` is neither \"RegularGrid\" nor \"Hexagonal\".\n\n    See Also\n    --------\n    from_polygon : Create environment with polygon-defined boundary.\n    from_mask : Create environment from pre-defined boolean mask.\n    from_image : Create environment from binary image mask.\n    from_graph : Create 1D linearized track environment.\n    from_layout : Create environment with custom LayoutEngine.\n\n    Examples\n    --------\n    Create a simple 2D environment from position data:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; # Simulate animal position data in a 100x100 cm arena\n    &gt;&gt;&gt; np.random.seed(42)  # For reproducible examples\n    &gt;&gt;&gt; positions = np.random.rand(1000, 2) * 100  # cm\n    &gt;&gt;&gt; # Create environment with 5cm x 5cm bins\n    &gt;&gt;&gt; env = Environment.from_samples(\n    ...     data_samples=positions,\n    ...     bin_size=5.0,\n    ...     name=\"arena\",  # bin_size in cm\n    ... )\n    &gt;&gt;&gt; env.n_dims\n    2\n    &gt;&gt;&gt; env.n_bins &gt; 0\n    True\n\n    Create environment with morphological operations to clean up the active region:\n\n    &gt;&gt;&gt; env = Environment.from_samples(\n    ...     data_samples=positions,\n    ...     bin_size=5.0,  # 5cm bins\n    ...     bin_count_threshold=5,  # Require 5 samples per bin (lowered from 10)\n    ...     dilate=True,  # Expand active region\n    ...     fill_holes=True,  # Fill interior holes\n    ... )\n\n    Create a hexagonal grid environment:\n\n    &gt;&gt;&gt; env = Environment.from_samples(\n    ...     data_samples=positions,\n    ...     layout_kind=\"Hexagonal\",\n    ...     bin_size=5.0,  # 5cm hexagon width\n    ... )\n\n    Common Pitfalls\n    ---------------\n    1. **bin_size too large**: If bin_size is too large relative to your data\n       range, you may end up with very few bins or no active bins at all.\n       For example, if your data spans 0-100 cm and you use bin_size=200.0,\n       you'll only get 1 bin. Try reducing bin_size to create more spatial\n       resolution (e.g., bin_size=5.0 for 5cm bins).\n\n    2. **bin_count_threshold too high**: Setting bin_count_threshold higher\n       than the number of samples per bin will result in no active bins.\n       If you have sparse data with only a few samples per location, try\n       reducing bin_count_threshold to 0 or 1, or use morphological operations\n       to expand the active region.\n\n    3. **Mismatched units**: Ensure bin_size and data_samples use the same\n       units. If your data is in centimeters, bin_size should also be in\n       centimeters. Mixing units (e.g., data in meters, bin_size in centimeters)\n       will result in incorrect spatial binning. For example, if your data spans\n       0-1 meters (100 cm) and you set bin_size=5.0 thinking it's centimeters,\n       you'll get only 1 bin instead of 20 bins.\n\n    4. **Missing morphological operations with sparse data**: If your data is\n       sparse (animal didn't visit all locations uniformly), the active region\n       may have holes or gaps. Enable dilate=True, fill_holes=True, or\n       close_gaps=True to create a more continuous active region. These\n       operations are particularly useful for connecting isolated bins or\n       filling small unvisited areas within explored regions.\n\n    \"\"\"\n    # Convert and validate data_samples array with helpful error messages\n    try:\n        data_samples = np.asarray(data_samples, dtype=float)\n    except (TypeError, ValueError) as e:\n        actual_type = type(data_samples).__name__\n        raise TypeError(\n            f\"data_samples must be a numeric array-like object (e.g., numpy array, \"\n            f\"list of lists, pandas DataFrame). Got {actual_type}: {data_samples!r}\"\n        ) from e\n\n    if data_samples.ndim != 2:\n        raise ValueError(\n            f\"data_samples must be a 2D array of shape (n_points, n_dims), \"\n            f\"got shape {data_samples.shape}.\",\n        )\n\n    # Validate bin_size early to provide helpful error messages\n    if not isinstance(bin_size, (int, float, list, tuple, np.ndarray)):\n        actual_type = type(bin_size).__name__\n        raise TypeError(\n            f\"bin_size must be a numeric value or sequence of numeric values. \"\n            f\"Got {actual_type}: {bin_size!r}\"\n        )\n\n    # Standardize layout_kind to lowercase for comparison\n    kind_lower = layout_kind.lower()\n    if kind_lower not in (\"regulargrid\", \"hexagonal\"):\n        raise NotImplementedError(\n            f\"Layout kind '{layout_kind}' is not supported. \"\n            \"Use 'RegularGrid' or 'Hexagonal'.\",\n        )\n\n    # Build the dict of layout parameters\n    layout_params: dict[str, Any] = {\n        \"data_samples\": data_samples,\n        \"infer_active_bins\": infer_active_bins,\n        \"bin_count_threshold\": bin_count_threshold,\n        **layout_specific_kwargs,\n    }\n\n    if kind_lower == \"regulargrid\":\n        layout_params.update(\n            {\n                \"bin_size\": bin_size,\n                \"add_boundary_bins\": add_boundary_bins,\n                \"dilate\": dilate,\n                \"fill_holes\": fill_holes,\n                \"close_gaps\": close_gaps,\n                \"connect_diagonal_neighbors\": connect_diagonal_neighbors,\n            },\n        )\n    elif kind_lower == \"hexagonal\":\n        layout_params.update(\n            {\n                \"hexagon_width\": bin_size,\n            },\n        )\n    else:\n        raise NotImplementedError(\n            f\"Layout kind '{layout_kind}' is not supported. \"\n            \"Use 'RegularGrid' or 'Hexagonal'.\",\n        )\n\n    return cls.from_layout(kind=layout_kind, layout_params=layout_params, name=name)\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.from_graph","title":"from_graph  <code>classmethod</code>","text":"<pre><code>from_graph(graph: Graph, edge_order: list[tuple[Any, Any]], edge_spacing: float | Sequence[float], bin_size: float, name: str = '') -&gt; Environment\n</code></pre> <p>Create an Environment from a user-defined graph structure.</p> <p>This method is used for 1D environments where the spatial layout is defined by a graph, an ordered list of its edges, and spacing between these edges. The track is then linearized and binned.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>Graph</code> <p>The NetworkX graph defining the track segments. Nodes are expected to have a 'pos' attribute for their N-D coordinates.</p> required <code>edge_order</code> <code>List[Tuple[Any, Any]]</code> <p>An ordered list of edge tuples (node1, node2) from <code>graph</code> that defines the 1D bin ordering.</p> required <code>edge_spacing</code> <code>Union[float, Sequence[float]]</code> <p>The spacing to insert between consecutive edges in <code>edge_order</code> during linearization, in the same units as the graph node coordinates. If a float, applies to all gaps. If a sequence, specifies spacing for each gap.</p> required <code>bin_size</code> <code>float</code> <p>The length of each bin along the linearized track, in the same units as the graph node coordinates. For example, if node positions are in centimeters, bin_size=2.0 creates 2cm bins along the track.</p> required <code>name</code> <code>str</code> <p>A name for the created environment. Defaults to \"\".</p> <code>''</code> <p>Returns:</p> Type Description <code>Environment</code> <p>A new Environment instance with a <code>GraphLayout</code>.</p> See Also <p>from_samples : Create environment by binning position data. from_layout : Create environment with custom LayoutEngine.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef from_graph(\n    cls,\n    graph: nx.Graph,\n    edge_order: list[tuple[Any, Any]],\n    edge_spacing: float | Sequence[float],\n    bin_size: float,\n    name: str = \"\",\n) -&gt; Environment:\n    \"\"\"Create an Environment from a user-defined graph structure.\n\n    This method is used for 1D environments where the spatial layout is\n    defined by a graph, an ordered list of its edges, and spacing between\n    these edges. The track is then linearized and binned.\n\n    Parameters\n    ----------\n    graph : nx.Graph\n        The NetworkX graph defining the track segments. Nodes are expected\n        to have a 'pos' attribute for their N-D coordinates.\n    edge_order : List[Tuple[Any, Any]]\n        An ordered list of edge tuples (node1, node2) from `graph` that\n        defines the 1D bin ordering.\n    edge_spacing : Union[float, Sequence[float]]\n        The spacing to insert between consecutive edges in `edge_order`\n        during linearization, in the same units as the graph node coordinates.\n        If a float, applies to all gaps. If a sequence, specifies spacing for\n        each gap.\n    bin_size : float\n        The length of each bin along the linearized track, in the same units\n        as the graph node coordinates. For example, if node positions are in\n        centimeters, bin_size=2.0 creates 2cm bins along the track.\n    name : str, optional\n        A name for the created environment. Defaults to \"\".\n\n    Returns\n    -------\n    Environment\n        A new Environment instance with a `GraphLayout`.\n\n    See Also\n    --------\n    from_samples : Create environment by binning position data.\n    from_layout : Create environment with custom LayoutEngine.\n\n    \"\"\"\n    layout_params = {\n        \"graph_definition\": graph,\n        \"edge_order\": edge_order,\n        \"edge_spacing\": edge_spacing,\n        \"bin_size\": bin_size,\n    }\n    return cls.from_layout(kind=\"Graph\", layout_params=layout_params, name=name)\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.from_polygon","title":"from_polygon  <code>classmethod</code>","text":"<pre><code>from_polygon(polygon: PolygonType, bin_size: float | Sequence[float], name: str = '', connect_diagonal_neighbors: bool = True) -&gt; Environment\n</code></pre> <p>Create a 2D grid Environment masked by a Shapely Polygon.</p> <p>A regular grid is formed based on the polygon's bounds and <code>bin_size</code>. Only grid cells whose centers are contained within the polygon are considered active.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>The Shapely Polygon object that defines the boundary of the active area.</p> required <code>bin_size</code> <code>float or sequence of floats</code> <p>The side length(s) of the grid cells, in the same units as the polygon coordinates. If a float, creates square bins. If a sequence, specifies bin size per dimension.</p> required <code>name</code> <code>str</code> <p>A name for the created environment. Defaults to \"\".</p> <code>''</code> <code>connect_diagonal_neighbors</code> <code>bool</code> <p>Whether to connect diagonally adjacent active grid cells. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Environment</code> <p>A new Environment instance with a <code>ShapelyPolygonLayout</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the 'shapely' package is not installed.</p> See Also <p>from_samples : Create environment by binning position data. from_mask : Create environment from pre-defined boolean mask. from_image : Create environment from binary image mask.</p> <p>Examples:</p> <p>Create an environment from a rectangular polygon:</p> <pre><code>&gt;&gt;&gt; from shapely.geometry import Polygon\n&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; # Create a simple rectangular arena (100cm x 50cm)\n&gt;&gt;&gt; polygon = Polygon([(0, 0), (100, 0), (100, 50), (0, 50)])  # cm\n&gt;&gt;&gt; env = Environment.from_polygon(\n...     polygon=polygon,\n...     bin_size=5.0,\n...     name=\"rectangular_arena\",  # 5cm bins\n... )\n&gt;&gt;&gt; env.n_dims\n2\n</code></pre> <p>Create an environment from a circular arena:</p> <pre><code>&gt;&gt;&gt; from shapely.geometry import Point\n&gt;&gt;&gt; center = Point(50, 50)  # cm\n&gt;&gt;&gt; circular_polygon = center.buffer(25)  # Circle with radius 25cm\n&gt;&gt;&gt; env = Environment.from_polygon(\n...     polygon=circular_polygon,\n...     bin_size=2.0,  # 2cm bins\n... )\n</code></pre> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef from_polygon(\n    cls,\n    polygon: PolygonType,\n    bin_size: float | Sequence[float],\n    name: str = \"\",\n    connect_diagonal_neighbors: bool = True,\n) -&gt; Environment:\n    \"\"\"Create a 2D grid Environment masked by a Shapely Polygon.\n\n    A regular grid is formed based on the polygon's bounds and `bin_size`.\n    Only grid cells whose centers are contained within the polygon are\n    considered active.\n\n    Parameters\n    ----------\n    polygon : shapely.geometry.Polygon\n        The Shapely Polygon object that defines the boundary of the active area.\n    bin_size : float or sequence of floats\n        The side length(s) of the grid cells, in the same units as the polygon\n        coordinates. If a float, creates square bins. If a sequence, specifies\n        bin size per dimension.\n    name : str, optional\n        A name for the created environment. Defaults to \"\".\n    connect_diagonal_neighbors : bool, optional\n        Whether to connect diagonally adjacent active grid cells.\n        Defaults to True.\n\n    Returns\n    -------\n    Environment\n        A new Environment instance with a `ShapelyPolygonLayout`.\n\n    Raises\n    ------\n    RuntimeError\n        If the 'shapely' package is not installed.\n\n    See Also\n    --------\n    from_samples : Create environment by binning position data.\n    from_mask : Create environment from pre-defined boolean mask.\n    from_image : Create environment from binary image mask.\n\n    Examples\n    --------\n    Create an environment from a rectangular polygon:\n\n    &gt;&gt;&gt; from shapely.geometry import Polygon\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; # Create a simple rectangular arena (100cm x 50cm)\n    &gt;&gt;&gt; polygon = Polygon([(0, 0), (100, 0), (100, 50), (0, 50)])  # cm\n    &gt;&gt;&gt; env = Environment.from_polygon(\n    ...     polygon=polygon,\n    ...     bin_size=5.0,\n    ...     name=\"rectangular_arena\",  # 5cm bins\n    ... )\n    &gt;&gt;&gt; env.n_dims\n    2\n\n    Create an environment from a circular arena:\n\n    &gt;&gt;&gt; from shapely.geometry import Point\n    &gt;&gt;&gt; center = Point(50, 50)  # cm\n    &gt;&gt;&gt; circular_polygon = center.buffer(25)  # Circle with radius 25cm\n    &gt;&gt;&gt; env = Environment.from_polygon(\n    ...     polygon=circular_polygon,\n    ...     bin_size=2.0,  # 2cm bins\n    ... )\n\n    \"\"\"\n    layout_params = {\n        \"polygon\": polygon,\n        \"bin_size\": bin_size,\n        \"connect_diagonal_neighbors\": connect_diagonal_neighbors,\n    }\n    return cls.from_layout(\n        kind=\"ShapelyPolygon\",\n        layout_params=layout_params,\n        name=name,\n    )\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.from_mask","title":"from_mask  <code>classmethod</code>","text":"<pre><code>from_mask(active_mask: NDArray[bool_], grid_edges: tuple[NDArray[float64], ...], name: str = '', connect_diagonal_neighbors: bool = True) -&gt; Environment\n</code></pre> <p>Create an Environment from a pre-defined N-D boolean mask and grid edges.</p> <p>This factory method allows for precise specification of active bins in an N-dimensional grid.</p> <p>Parameters:</p> Name Type Description Default <code>active_mask</code> <code>NDArray[bool_]</code> <p>An N-dimensional boolean array where <code>True</code> indicates an active bin. The shape of this mask must correspond to the number of bins implied by <code>grid_edges</code> (i.e., <code>tuple(len(e)-1 for e in grid_edges)</code>).</p> required <code>grid_edges</code> <code>Tuple[NDArray[float64], ...]</code> <p>A tuple where each element is a 1D NumPy array of bin edge positions for that dimension, in physical units (e.g., cm, meters). The edges define the boundaries of bins along each dimension. For example, edges [0, 10, 20, 30] define three bins: [0-10], [10-20], [20-30].</p> required <code>name</code> <code>str</code> <p>A name for the created environment. Defaults to \"\".</p> <code>''</code> <code>connect_diagonal_neighbors</code> <code>bool</code> <p>Whether to connect diagonally adjacent active grid cells. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Environment</code> <p>A new Environment instance with a <code>MaskedGridLayout</code>.</p> See Also <p>from_samples : Create environment by binning position data. from_polygon : Create environment with polygon-defined boundary. from_image : Create environment from binary image mask.</p> <p>Examples:</p> <p>Create an environment from a custom mask:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; # Create a simple 2D mask (10x10 grid with center region active)\n&gt;&gt;&gt; mask = np.zeros((10, 10), dtype=bool)\n&gt;&gt;&gt; mask[3:7, 3:7] = True  # Center 4x4 region is active\n&gt;&gt;&gt; # Define grid edges (creates 10cm x 10cm bins)\n&gt;&gt;&gt; grid_edges = (\n...     np.linspace(0, 100, 11),  # x edges in cm\n...     np.linspace(0, 100, 11),  # y edges in cm\n... )\n&gt;&gt;&gt; env = Environment.from_mask(\n...     active_mask=mask, grid_edges=grid_edges, name=\"center_region\"\n... )\n&gt;&gt;&gt; env.n_bins\n16\n</code></pre> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef from_mask(\n    cls,\n    active_mask: NDArray[np.bool_],\n    grid_edges: tuple[NDArray[np.float64], ...],\n    name: str = \"\",\n    connect_diagonal_neighbors: bool = True,\n) -&gt; Environment:\n    \"\"\"Create an Environment from a pre-defined N-D boolean mask and grid edges.\n\n    This factory method allows for precise specification of active bins in\n    an N-dimensional grid.\n\n    Parameters\n    ----------\n    active_mask : NDArray[np.bool_]\n        An N-dimensional boolean array where `True` indicates an active bin.\n        The shape of this mask must correspond to the number of bins implied\n        by `grid_edges` (i.e., `tuple(len(e)-1 for e in grid_edges)`).\n    grid_edges : Tuple[NDArray[np.float64], ...]\n        A tuple where each element is a 1D NumPy array of bin edge positions\n        for that dimension, in physical units (e.g., cm, meters). The edges\n        define the boundaries of bins along each dimension. For example, edges\n        [0, 10, 20, 30] define three bins: [0-10], [10-20], [20-30].\n    name : str, optional\n        A name for the created environment. Defaults to \"\".\n    connect_diagonal_neighbors : bool, optional\n        Whether to connect diagonally adjacent active grid cells.\n        Defaults to True.\n\n    Returns\n    -------\n    Environment\n        A new Environment instance with a `MaskedGridLayout`.\n\n    See Also\n    --------\n    from_samples : Create environment by binning position data.\n    from_polygon : Create environment with polygon-defined boundary.\n    from_image : Create environment from binary image mask.\n\n    Examples\n    --------\n    Create an environment from a custom mask:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; # Create a simple 2D mask (10x10 grid with center region active)\n    &gt;&gt;&gt; mask = np.zeros((10, 10), dtype=bool)\n    &gt;&gt;&gt; mask[3:7, 3:7] = True  # Center 4x4 region is active\n    &gt;&gt;&gt; # Define grid edges (creates 10cm x 10cm bins)\n    &gt;&gt;&gt; grid_edges = (\n    ...     np.linspace(0, 100, 11),  # x edges in cm\n    ...     np.linspace(0, 100, 11),  # y edges in cm\n    ... )\n    &gt;&gt;&gt; env = Environment.from_mask(\n    ...     active_mask=mask, grid_edges=grid_edges, name=\"center_region\"\n    ... )\n    &gt;&gt;&gt; env.n_bins\n    16\n\n    \"\"\"\n    layout_params = {\n        \"active_mask\": active_mask,\n        \"grid_edges\": grid_edges,\n        \"connect_diagonal_neighbors\": connect_diagonal_neighbors,\n    }\n\n    return cls.from_layout(\n        kind=\"MaskedGrid\",\n        layout_params=layout_params,\n        name=name,\n    )\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.from_image","title":"from_image  <code>classmethod</code>","text":"<pre><code>from_image(image_mask: NDArray[bool_], bin_size: float | tuple[float, float], connect_diagonal_neighbors: bool = True, name: str = '') -&gt; Environment\n</code></pre> <p>Create a 2D Environment from a binary image mask.</p> <p>Each <code>True</code> pixel in the <code>image_mask</code> becomes an active bin in the environment. The <code>bin_size</code> determines the spatial scale of these pixels.</p> <p>Parameters:</p> Name Type Description Default <code>image_mask</code> <code>(NDArray[bool_], shape(n_rows, n_cols))</code> <p>A 2D boolean array where <code>True</code> pixels define active bins.</p> required <code>bin_size</code> <code>float or tuple of (float, float)</code> <p>The spatial size of each pixel in physical units (e.g., cm, meters). If a float, pixels are square. If a tuple <code>(width, height)</code>, specifies pixel dimensions. For example, if your camera captures images where each pixel represents 0.5cm, use bin_size=0.5.</p> required <code>connect_diagonal_neighbors</code> <code>bool</code> <p>Whether to connect diagonally adjacent active pixel-bins. Defaults to True.</p> <code>True</code> <code>name</code> <code>str</code> <p>A name for the created environment. Defaults to \"\".</p> <code>''</code> <p>Returns:</p> Type Description <code>Environment</code> <p>A new Environment instance with an <code>ImageMaskLayout</code>.</p> See Also <p>from_mask : Create environment from pre-defined boolean mask. from_polygon : Create environment with polygon-defined boundary. from_samples : Create environment by binning position data.</p> <p>Examples:</p> <p>Create an environment from a binary image mask:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; # Create a simple binary image (e.g., from thresholding camera frame)\n&gt;&gt;&gt; image_height, image_width = 480, 640\n&gt;&gt;&gt; mask = np.zeros((image_height, image_width), dtype=bool)\n&gt;&gt;&gt; # Mark a rectangular region as active\n&gt;&gt;&gt; mask[100:400, 150:500] = True\n&gt;&gt;&gt; env = Environment.from_image(\n...     image_mask=mask,\n...     bin_size=0.5,  # Each pixel = 0.5cm\n...     name=\"arena_from_image\",\n... )\n&gt;&gt;&gt; env.n_dims\n2\n</code></pre> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef from_image(\n    cls,\n    image_mask: NDArray[np.bool_],\n    bin_size: float | tuple[float, float],\n    connect_diagonal_neighbors: bool = True,\n    name: str = \"\",\n) -&gt; Environment:\n    \"\"\"Create a 2D Environment from a binary image mask.\n\n    Each `True` pixel in the `image_mask` becomes an active bin in the\n    environment. The `bin_size` determines the spatial scale of these pixels.\n\n    Parameters\n    ----------\n    image_mask : NDArray[np.bool_], shape (n_rows, n_cols)\n        A 2D boolean array where `True` pixels define active bins.\n    bin_size : float or tuple of (float, float)\n        The spatial size of each pixel in physical units (e.g., cm, meters).\n        If a float, pixels are square. If a tuple `(width, height)`, specifies\n        pixel dimensions. For example, if your camera captures images where\n        each pixel represents 0.5cm, use bin_size=0.5.\n    connect_diagonal_neighbors : bool, optional\n        Whether to connect diagonally adjacent active pixel-bins.\n        Defaults to True.\n    name : str, optional\n        A name for the created environment. Defaults to \"\".\n\n    Returns\n    -------\n    Environment\n        A new Environment instance with an `ImageMaskLayout`.\n\n    See Also\n    --------\n    from_mask : Create environment from pre-defined boolean mask.\n    from_polygon : Create environment with polygon-defined boundary.\n    from_samples : Create environment by binning position data.\n\n    Examples\n    --------\n    Create an environment from a binary image mask:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; # Create a simple binary image (e.g., from thresholding camera frame)\n    &gt;&gt;&gt; image_height, image_width = 480, 640\n    &gt;&gt;&gt; mask = np.zeros((image_height, image_width), dtype=bool)\n    &gt;&gt;&gt; # Mark a rectangular region as active\n    &gt;&gt;&gt; mask[100:400, 150:500] = True\n    &gt;&gt;&gt; env = Environment.from_image(\n    ...     image_mask=mask,\n    ...     bin_size=0.5,  # Each pixel = 0.5cm\n    ...     name=\"arena_from_image\",\n    ... )\n    &gt;&gt;&gt; env.n_dims\n    2\n\n    \"\"\"\n    layout_params = {\n        \"image_mask\": image_mask,\n        \"bin_size\": bin_size,\n        \"connect_diagonal_neighbors\": connect_diagonal_neighbors,\n    }\n\n    return cls.from_layout(kind=\"ImageMask\", layout_params=layout_params, name=name)\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.from_layout","title":"from_layout  <code>classmethod</code>","text":"<pre><code>from_layout(kind: str, layout_params: dict[str, Any], name: str = '', regions: Regions | None = None) -&gt; Environment\n</code></pre> <p>Create an Environment with a specified layout type and its build parameters.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str</code> <p>The string identifier of the <code>LayoutEngine</code> to use (e.g., \"RegularGrid\", \"Hexagonal\").</p> required <code>layout_params</code> <code>Dict[str, Any]</code> <p>A dictionary of parameters that will be passed to the <code>build</code> method of the chosen <code>LayoutEngine</code>.</p> required <code>name</code> <code>str</code> <p>A name for the created environment. Defaults to \"\".</p> <code>''</code> <code>regions</code> <code>Optional[Regions]</code> <p>A Regions instance to manage symbolic spatial regions within the environment.</p> <code>None</code> <p>Returns:</p> Type Description <code>Environment</code> <p>A new Environment instance.</p> See Also <p>from_samples : Create environment by binning position data. from_polygon : Create environment with polygon-defined boundary. from_mask : Create environment from pre-defined boolean mask. from_image : Create environment from binary image mask. from_graph : Create 1D linearized track environment.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef from_layout(\n    cls,\n    kind: str,\n    layout_params: dict[str, Any],\n    name: str = \"\",\n    regions: Regions | None = None,\n) -&gt; Environment:\n    \"\"\"Create an Environment with a specified layout type and its build parameters.\n\n    Parameters\n    ----------\n    kind : str\n        The string identifier of the `LayoutEngine` to use\n        (e.g., \"RegularGrid\", \"Hexagonal\").\n    layout_params : Dict[str, Any]\n        A dictionary of parameters that will be passed to the `build`\n        method of the chosen `LayoutEngine`.\n    name : str, optional\n        A name for the created environment. Defaults to \"\".\n    regions : Optional[Regions], optional\n        A Regions instance to manage symbolic spatial regions within the environment.\n\n    Returns\n    -------\n    Environment\n        A new Environment instance.\n\n    See Also\n    --------\n    from_samples : Create environment by binning position data.\n    from_polygon : Create environment with polygon-defined boundary.\n    from_mask : Create environment from pre-defined boolean mask.\n    from_image : Create environment from binary image mask.\n    from_graph : Create 1D linearized track environment.\n\n    \"\"\"\n    layout_instance = create_layout(kind=kind, **layout_params)\n    return cls(name, layout_instance, kind, layout_params, regions=regions)\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.bin_at","title":"bin_at","text":"<pre><code>bin_at(points_nd: NDArray[float64]) -&gt; NDArray[np.int_]\n</code></pre> <p>Map N-dimensional continuous points to discrete active bin indices.</p> <p>This method delegates to the <code>point_to_bin_index</code> method of the underlying <code>LayoutEngine</code>.</p> <p>Parameters:</p> Name Type Description Default <code>points_nd</code> <code>(NDArray[float64], shape(n_points, n_dims))</code> <p>An array of N-dimensional points to map.</p> required <p>Returns:</p> Type Description <code>(NDArray[int_], shape(n_points))</code> <p>An array of active bin indices (0 to <code>n_active_bins - 1</code>). A value of -1 indicates that the corresponding point did not map to any active bin (e.g., it's outside the environment).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef bin_at(self, points_nd: NDArray[np.float64]) -&gt; NDArray[np.int_]:\n    \"\"\"Map N-dimensional continuous points to discrete active bin indices.\n\n    This method delegates to the `point_to_bin_index` method of the\n    underlying `LayoutEngine`.\n\n    Parameters\n    ----------\n    points_nd : NDArray[np.float64], shape (n_points, n_dims)\n        An array of N-dimensional points to map.\n\n    Returns\n    -------\n    NDArray[np.int_], shape (n_points,)\n        An array of active bin indices (0 to `n_active_bins - 1`).\n        A value of -1 indicates that the corresponding point did not map\n        to any active bin (e.g., it's outside the environment).\n\n    Raises\n    ------\n    RuntimeError\n        If called before the environment is fitted.\n\n    \"\"\"\n    return self.layout.point_to_bin_index(points_nd)\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.contains","title":"contains","text":"<pre><code>contains(points_nd: NDArray[float64]) -&gt; NDArray[np.bool_]\n</code></pre> <p>Check if N-dimensional continuous points fall within any active bin.</p> <p>Parameters:</p> Name Type Description Default <code>points_nd</code> <code>(NDArray[float64], shape(n_points, n_dims))</code> <p>An array of N-dimensional points to check.</p> required <p>Returns:</p> Type Description <code>(NDArray[bool_], shape(n_points))</code> <p>A boolean array where <code>True</code> indicates the corresponding point maps to an active bin, and <code>False</code> indicates it does not.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p> Notes <p>This method is optimized to avoid redundant KDTree queries by reusing the bin index computation from <code>bin_at()</code> and checking for the -1 sentinel.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef contains(self, points_nd: NDArray[np.float64]) -&gt; NDArray[np.bool_]:\n    \"\"\"Check if N-dimensional continuous points fall within any active bin.\n\n    Parameters\n    ----------\n    points_nd : NDArray[np.float64], shape (n_points, n_dims)\n        An array of N-dimensional points to check.\n\n    Returns\n    -------\n    NDArray[np.bool_], shape (n_points,)\n        A boolean array where `True` indicates the corresponding point\n        maps to an active bin, and `False` indicates it does not.\n\n    Raises\n    ------\n    RuntimeError\n        If called before the environment is fitted.\n\n    Notes\n    -----\n    This method is optimized to avoid redundant KDTree queries by reusing\n    the bin index computation from `bin_at()` and checking for the -1 sentinel.\n\n    \"\"\"\n    # Optimized: compute indices once and check for -1 sentinel\n    # This avoids redundant KDTree queries compared to calling bin_at() separately\n    indices = self.layout.point_to_bin_index(points_nd)\n    return np.asarray(indices != -1, dtype=np.bool_)\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.bin_center_of","title":"bin_center_of","text":"<pre><code>bin_center_of(bin_indices: int | Sequence[int] | NDArray[int_]) -&gt; NDArray[np.float64]\n</code></pre> <p>Given one or more active-bin indices, return their N-D center coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>bin_indices</code> <code>int or sequence of int</code> <p>Index (or list/array of indices) of active bins (0 &lt;= idx &lt; self.n_bins).</p> required <p>Returns:</p> Name Type Description <code>centers</code> <code>array, shape (len(bin_indices), n_dims) if multiple indices,</code> <pre><code>        (n_dims,) if single index\n</code></pre> <p>The center coordinate(s) of the requested bin(s).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the environment is not fitted.</p> <code>IndexError</code> <p>If any bin index is out of range.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef bin_center_of(\n    self,\n    bin_indices: int | Sequence[int] | NDArray[np.int_],\n) -&gt; NDArray[np.float64]:\n    \"\"\"Given one or more active-bin indices, return their N-D center coordinates.\n\n    Parameters\n    ----------\n    bin_indices : int or sequence of int\n        Index (or list/array of indices) of active bins (0 &lt;= idx &lt; self.n_bins).\n\n    Returns\n    -------\n    centers : array, shape (len(bin_indices), n_dims) if multiple indices,\n                    (n_dims,) if single index\n        The center coordinate(s) of the requested bin(s).\n\n    Raises\n    ------\n    RuntimeError\n        If the environment is not fitted.\n    IndexError\n        If any bin index is out of range.\n\n    \"\"\"\n    return np.asarray(\n        self.bin_centers[np.asarray(bin_indices, dtype=int)], dtype=np.float64\n    )\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.neighbors","title":"neighbors","text":"<pre><code>neighbors(bin_index: int) -&gt; list[int]\n</code></pre> <p>Find indices of neighboring active bins for a given active bin index.</p> <p>This method delegates to the <code>neighbors</code> method of the underlying <code>LayoutEngine</code>, which typically uses the <code>connectivity</code>.</p> <p>Parameters:</p> Name Type Description Default <code>bin_index</code> <code>int</code> <p>The index (0 to <code>n_active_bins - 1</code>) of the active bin for which to find neighbors.</p> required <p>Returns:</p> Type Description <code>List[int]</code> <p>A list of active bin indices that are neighbors to <code>bin_index</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef neighbors(self, bin_index: int) -&gt; list[int]:\n    \"\"\"Find indices of neighboring active bins for a given active bin index.\n\n    This method delegates to the `neighbors` method of the\n    underlying `LayoutEngine`, which typically uses the `connectivity`.\n\n    Parameters\n    ----------\n    bin_index : int\n        The index (0 to `n_active_bins - 1`) of the active bin for which\n        to find neighbors.\n\n    Returns\n    -------\n    List[int]\n        A list of active bin indices that are neighbors to `bin_index`.\n\n    Raises\n    ------\n    RuntimeError\n        If called before the environment is fitted.\n\n    \"\"\"\n    return list(self.connectivity.neighbors(bin_index))\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.distance_between","title":"distance_between","text":"<pre><code>distance_between(point1: NDArray[float64], point2: NDArray[float64], edge_weight: str = 'distance') -&gt; float\n</code></pre> <p>Calculate the geodesic distance between two points in the environment.</p> <p>Points are first mapped to their nearest active bins using <code>self.bin_at()</code>. The geodesic distance (distance along the shortest path through the space) is then the shortest path length in the <code>connectivity</code> graph between these bins, using the specified <code>edge_weight</code>.</p> <p>Parameters:</p> Name Type Description Default <code>point1</code> <code>(PtArr, shape(n_dims) or (1, n_dims))</code> <p>The first N-dimensional point.</p> required <code>point2</code> <code>(PtArr, shape(n_dims) or (1, n_dims))</code> <p>The second N-dimensional point.</p> required <code>edge_weight</code> <code>str</code> <p>The edge attribute to use as weight for path calculation, by default \"distance\". If None, the graph is treated as unweighted.</p> <code>'distance'</code> <p>Returns:</p> Type Description <code>float</code> <p>The geodesic distance. Returns <code>np.inf</code> if points do not map to valid active bins, if bins are disconnected, or if the connectivity graph is not available.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>def distance_between(\n    self,\n    point1: NDArray[np.float64],\n    point2: NDArray[np.float64],\n    edge_weight: str = \"distance\",\n) -&gt; float:\n    \"\"\"Calculate the geodesic distance between two points in the environment.\n\n    Points are first mapped to their nearest active bins using `self.bin_at()`.\n    The geodesic distance (distance along the shortest path through the space)\n    is then the shortest path length in the `connectivity` graph between these\n    bins, using the specified `edge_weight`.\n\n    Parameters\n    ----------\n    point1 : PtArr, shape (n_dims,) or (1, n_dims)\n        The first N-dimensional point.\n    point2 : PtArr, shape (n_dims,) or (1, n_dims)\n        The second N-dimensional point.\n    edge_weight : str, optional\n        The edge attribute to use as weight for path calculation,\n        by default \"distance\". If None, the graph is treated as unweighted.\n\n    Returns\n    -------\n    float\n        The geodesic distance. Returns `np.inf` if points do not map to\n        valid active bins, if bins are disconnected, or if the connectivity\n        graph is not available.\n\n    \"\"\"\n    source_bin = self.bin_at(np.atleast_2d(point1))[0]\n    target_bin = self.bin_at(np.atleast_2d(point2))[0]\n\n    if source_bin == -1 or target_bin == -1:\n        # One or both points didn't map to a valid active bin\n        return np.inf\n\n    try:\n        return float(\n            nx.shortest_path_length(\n                self.connectivity,\n                source=source_bin,\n                target=target_bin,\n                weight=edge_weight,\n            )\n        )\n    except (nx.NetworkXNoPath, nx.NodeNotFound):\n        return np.inf\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.shortest_path","title":"shortest_path","text":"<pre><code>shortest_path(source_active_bin_idx: int, target_active_bin_idx: int) -&gt; list[int]\n</code></pre> <p>Find the shortest path between two active bins.</p> <p>The path is a sequence of active bin indices (0 to n_active_bins - 1) connecting the source to the target. Path calculation uses the 'distance' attribute on the edges of the <code>connectivity</code> as weights.</p> <p>Parameters:</p> Name Type Description Default <code>source_active_bin_idx</code> <code>int</code> <p>The active bin index (0 to n_active_bins - 1) for the start of the path.</p> required <code>target_active_bin_idx</code> <code>int</code> <p>The active bin index (0 to n_active_bins - 1) for the end of the path.</p> required <p>Returns:</p> Type Description <code>List[int]</code> <p>A list of active bin indices representing the shortest path from source to target. The list includes both the source and target indices. Returns an empty list if the source and target are the same, or if no path exists, or if nodes are not found.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p> <code>NodeNotFound</code> <p>If <code>source_active_bin_idx</code> or <code>target_active_bin_idx</code> is not a node in the <code>connectivity</code>.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef shortest_path(\n    self,\n    source_active_bin_idx: int,\n    target_active_bin_idx: int,\n) -&gt; list[int]:\n    \"\"\"Find the shortest path between two active bins.\n\n    The path is a sequence of active bin indices (0 to n_active_bins - 1)\n    connecting the source to the target. Path calculation uses the\n    'distance' attribute on the edges of the `connectivity`\n    as weights.\n\n    Parameters\n    ----------\n    source_active_bin_idx : int\n        The active bin index (0 to n_active_bins - 1) for the start of the path.\n    target_active_bin_idx : int\n        The active bin index (0 to n_active_bins - 1) for the end of the path.\n\n    Returns\n    -------\n    List[int]\n        A list of active bin indices representing the shortest path from\n        source to target. The list includes both the source and target indices.\n        Returns an empty list if the source and target are the same, or if\n        no path exists, or if nodes are not found.\n\n    Raises\n    ------\n    RuntimeError\n        If called before the environment is fitted.\n    nx.NodeNotFound\n        If `source_active_bin_idx` or `target_active_bin_idx` is not\n        a node in the `connectivity`.\n\n    \"\"\"\n    graph = self.connectivity\n\n    if source_active_bin_idx == target_active_bin_idx:\n        return [source_active_bin_idx]\n\n    try:\n        path = nx.shortest_path(\n            graph,\n            source=source_active_bin_idx,\n            target=target_active_bin_idx,\n            weight=\"distance\",\n        )\n        return list(path)\n    except nx.NetworkXNoPath:\n        warnings.warn(\n            f\"No path found between active bin {source_active_bin_idx} \"\n            f\"and {target_active_bin_idx}.\",\n            UserWarning,\n        )\n        return []\n    except nx.NodeNotFound as e:\n        # Re-raise if the user provides an invalid node index for active bins\n        raise nx.NodeNotFound(\n            f\"Node not found in connectivity graph: {e}. \"\n            \"Ensure source/target indices are valid active bin indices.\",\n        ) from e\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.to_linear","title":"to_linear","text":"<pre><code>to_linear(points_nd: NDArray[float64]) -&gt; NDArray[np.float64]\n</code></pre> <p>Convert N-dimensional points to 1D linearized coordinates.</p> <p>This method is only applicable if the environment uses a <code>GraphLayout</code> and <code>is_1d</code> is True. It delegates to the layout's <code>to_linear</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>points_nd</code> <code>(NDArray[float64], shape(n_points, n_dims))</code> <p>N-dimensional points to linearize.</p> required <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_points))</code> <p>1D linearized coordinates corresponding to the input points.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the environment is not 1D or not based on a <code>GraphLayout</code>.</p> <code>RuntimeError</code> <p>If called before the environment is fitted.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef to_linear(self, points_nd: NDArray[np.float64]) -&gt; NDArray[np.float64]:\n    \"\"\"Convert N-dimensional points to 1D linearized coordinates.\n\n    This method is only applicable if the environment uses a `GraphLayout`\n    and `is_1d` is True. It delegates to the layout's\n    `to_linear` method.\n\n    Parameters\n    ----------\n    points_nd : NDArray[np.float64], shape (n_points, n_dims)\n        N-dimensional points to linearize.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_points,)\n        1D linearized coordinates corresponding to the input points.\n\n    Raises\n    ------\n    TypeError\n        If the environment is not 1D or not based on a `GraphLayout`.\n    RuntimeError\n        If called before the environment is fitted.\n\n    \"\"\"\n    # Use hasattr instead of isinstance to avoid Protocol/concrete class conflict\n    if not self.is_1d or not hasattr(self.layout, \"to_linear\"):\n        raise TypeError(\"Linearized coordinate only for GraphLayout environments.\")\n    result = self.layout.to_linear(points_nd)\n    return np.asarray(result, dtype=np.float64)\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.linear_to_nd","title":"linear_to_nd","text":"<pre><code>linear_to_nd(linear_coordinates: NDArray[float64]) -&gt; NDArray[np.float64]\n</code></pre> <p>Convert 1D linearized coordinates back to N-dimensional coordinates.</p> <p>This method is only applicable if the environment uses a <code>GraphLayout</code> and <code>is_1d</code> is True. It delegates to the layout's <code>linear_to_nd</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>linear_coordinates</code> <code>(NDArray[float64], shape(n_points))</code> <p>1D linearized coordinates to map to N-D space.</p> required <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_points, n_dims))</code> <p>N-dimensional coordinates corresponding to the input linear coordinates.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the environment is not 1D or not based on a <code>GraphLayout</code>.</p> <code>RuntimeError</code> <p>If called before the environment is fitted.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef linear_to_nd(\n    self,\n    linear_coordinates: NDArray[np.float64],\n) -&gt; NDArray[np.float64]:\n    \"\"\"Convert 1D linearized coordinates back to N-dimensional coordinates.\n\n    This method is only applicable if the environment uses a `GraphLayout`\n    and `is_1d` is True. It delegates to the layout's\n    `linear_to_nd` method.\n\n    Parameters\n    ----------\n    linear_coordinates : NDArray[np.float64], shape (n_points,)\n        1D linearized coordinates to map to N-D space.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_points, n_dims)\n        N-dimensional coordinates corresponding to the input linear coordinates.\n\n    Raises\n    ------\n    TypeError\n        If the environment is not 1D or not based on a `GraphLayout`.\n    RuntimeError\n        If called before the environment is fitted.\n\n    \"\"\"\n    # Use hasattr instead of isinstance to avoid Protocol/concrete class conflict\n    if not self.is_1d or not hasattr(self.layout, \"linear_to_nd\"):\n        raise TypeError(\"Mapping linear to N-D only for GraphLayout environments.\")\n    result = self.layout.linear_to_nd(linear_coordinates)\n    return np.asarray(result, dtype=np.float64)\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.plot","title":"plot","text":"<pre><code>plot(ax: Axes | None = None, show_regions: bool = False, layout_plot_kwargs: dict[str, Any] | None = None, regions_plot_kwargs: dict[str, Any] | None = None, **kwargs: Any) -&gt; matplotlib.axes.Axes\n</code></pre> <p>Plot the environment's layout and optionally defined regions.</p> <p>This method delegates plotting of the base layout to the <code>plot</code> method of the underlying <code>LayoutEngine</code>. If <code>show_regions</code> is True, it then overlays any defined spatial regions managed by <code>self.regions</code>.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>The Matplotlib axes to plot on. If None, a new figure and axes are created. Defaults to None.</p> <code>None</code> <code>show_regions</code> <code>bool</code> <p>If True, plot defined spatial regions on top of the layout. Defaults to False.</p> <code>False</code> <code>layout_plot_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments to pass to the <code>layout.plot()</code> method. Defaults to None.</p> <code>None</code> <code>regions_plot_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments to pass to the <code>regions.plot_regions()</code> method. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments that are passed to <code>layout.plot()</code>. These can be overridden by <code>layout_plot_kwargs</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the environment was plotted.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef plot(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    show_regions: bool = False,\n    layout_plot_kwargs: dict[str, Any] | None = None,\n    regions_plot_kwargs: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot the environment's layout and optionally defined regions.\n\n    This method delegates plotting of the base layout to the `plot` method\n    of the underlying `LayoutEngine`. If `show_regions` is True, it then\n    overlays any defined spatial regions managed by `self.regions`.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        The Matplotlib axes to plot on. If None, a new figure and axes\n        are created. Defaults to None.\n    show_regions : bool, optional\n        If True, plot defined spatial regions on top of the layout.\n        Defaults to False.\n    layout_plot_kwargs : Optional[Dict[str, Any]], optional\n        Keyword arguments to pass to the `layout.plot()` method.\n        Defaults to None.\n    regions_plot_kwargs : Optional[Dict[str, Any]], optional\n        Keyword arguments to pass to the `regions.plot_regions()` method.\n        Defaults to None.\n    **kwargs : Any\n        Additional keyword arguments that are passed to `layout.plot()`.\n        These can be overridden by `layout_plot_kwargs`.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the environment was plotted.\n\n    Raises\n    ------\n    RuntimeError\n        If called before the environment is fitted.\n\n    \"\"\"\n    l_kwargs = layout_plot_kwargs if layout_plot_kwargs is not None else {}\n    l_kwargs.update(kwargs)  # Allow direct kwargs to override for layout.plot\n\n    ax = self.layout.plot(ax=ax, **l_kwargs)\n\n    if show_regions and hasattr(self, \"regions\") and self.regions is not None:\n        from neurospatial.regions.plot import plot_regions\n\n        r_kwargs = regions_plot_kwargs if regions_plot_kwargs is not None else {}\n        plot_regions(self.regions, ax=ax, **r_kwargs)\n\n    plot_title = self.name\n    if (\n        self.layout\n        and hasattr(self.layout, \"_layout_type_tag\")\n        and self.layout._layout_type_tag\n    ):\n        plot_title += f\" ({self.layout._layout_type_tag})\"\n\n    # Only set title if layout.plot didn't set one or user didn't pass one via kwargs to layout.plot\n    if ax.get_title() == \"\":\n        ax.set_title(plot_title)\n\n    return ax\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.plot_1d","title":"plot_1d","text":"<pre><code>plot_1d(ax: Axes | None = None, layout_plot_kwargs: dict[str, Any] | None = None, **kwargs: Any)\n</code></pre> <p>Plot a 1D representation of the environment, if applicable.</p> <p>This method is primarily for environments where <code>is_1d</code> is True (e.g., using <code>GraphLayout</code>). It calls the <code>plot_linear_layout</code> method of the underlying layout if it exists and the layout is 1D.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>The Matplotlib axes to plot on. If None, a new figure and axes are created. Defaults to None.</p> <code>None</code> <code>layout_plot_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments to pass to the layout's 1D plotting method.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the layout's 1D plotting method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the 1D layout was plotted, or the original <code>ax</code> if plotting was not applicable.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p> <code>AttributeError</code> <p>If <code>self.layout.is_1d</code> is True but the layout does not have a <code>plot_linear_layout</code> method.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>def plot_1d(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    layout_plot_kwargs: dict[str, Any] | None = None,\n    **kwargs: Any,\n):\n    \"\"\"Plot a 1D representation of the environment, if applicable.\n\n    This method is primarily for environments where `is_1d` is True\n    (e.g., using `GraphLayout`). It calls the `plot_linear_layout`\n    method of the underlying layout if it exists and the layout is 1D.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        The Matplotlib axes to plot on. If None, a new figure and axes\n        are created. Defaults to None.\n    layout_plot_kwargs : Optional[Dict[str, Any]], optional\n        Keyword arguments to pass to the layout's 1D plotting method.\n    **kwargs : Any\n        Additional keyword arguments passed to the layout's 1D plotting method.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the 1D layout was plotted, or the original `ax`\n        if plotting was not applicable.\n\n    Raises\n    ------\n    RuntimeError\n        If called before the environment is fitted.\n    AttributeError\n        If `self.layout.is_1d` is True but the layout does not have a\n        `plot_linear_layout` method.\n\n    \"\"\"\n    l_kwargs = layout_plot_kwargs if layout_plot_kwargs is not None else {}\n    l_kwargs.update(kwargs)  # Allow direct kwargs to override for layout.plot\n    if self.layout.is_1d:\n        if hasattr(self.layout, \"plot_linear_layout\"):\n            ax = self.layout.plot_linear_layout(ax=ax, **l_kwargs)\n        else:\n            warnings.warn(\n                f\"Layout '{self._layout_type_used}' is 1D but does not \"\n                \"have a 'plot_linear_layout' method. Skipping 1D plot.\",\n                UserWarning,\n            )\n    else:\n        warnings.warn(\n            \"Environment is not 1D. Skipping 1D plot. Use regular plot() method.\",\n            UserWarning,\n        )\n\n    return ax\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.save","title":"save","text":"<pre><code>save(filename: str = 'environment.pkl') -&gt; None\n</code></pre> <p>Save the Environment object to a file using pickle.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to save the environment to. Defaults to \"environment.pkl\".</p> <code>'environment.pkl'</code> Warnings <p>This method uses pickle for serialization. Pickle files can execute arbitrary code during deserialization. Only share pickle files with trusted users and only load files from trusted sources.</p> See Also <p>load : Load an Environment from a pickle file.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef save(self, filename: str = \"environment.pkl\") -&gt; None:\n    \"\"\"Save the Environment object to a file using pickle.\n\n    Parameters\n    ----------\n    filename : str, optional\n        The name of the file to save the environment to.\n        Defaults to \"environment.pkl\".\n\n    Warnings\n    --------\n    This method uses pickle for serialization. Pickle files can execute\n    arbitrary code during deserialization. Only share pickle files with\n    trusted users and only load files from trusted sources.\n\n    See Also\n    --------\n    load : Load an Environment from a pickle file.\n\n    \"\"\"\n    with Path(filename).open(\"wb\") as fh:\n        pickle.dump(self, fh, protocol=pickle.HIGHEST_PROTOCOL)\n    logger.info(\"Environment saved to %s\", filename)\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(filename: str) -&gt; Environment\n</code></pre> <p>Load an Environment object from a pickled file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to load the environment from.</p> required <p>Returns:</p> Type Description <code>Environment</code> <p>The loaded Environment object.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the loaded object is not an instance of the Environment class.</p> Warnings <p>This method uses pickle for deserialization. Only load files from trusted sources, as pickle can execute arbitrary code during deserialization. Do not load pickle files from untrusted or unknown sources.</p> See Also <p>save : Save an Environment to a pickle file.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef load(cls, filename: str) -&gt; Environment:\n    \"\"\"Load an Environment object from a pickled file.\n\n    Parameters\n    ----------\n    filename : str\n        The name of the file to load the environment from.\n\n    Returns\n    -------\n    Environment\n        The loaded Environment object.\n\n    Raises\n    ------\n    TypeError\n        If the loaded object is not an instance of the Environment class.\n\n    Warnings\n    --------\n    This method uses pickle for deserialization. **Only load files from\n    trusted sources**, as pickle can execute arbitrary code during\n    deserialization. Do not load pickle files from untrusted or\n    unknown sources.\n\n    See Also\n    --------\n    save : Save an Environment to a pickle file.\n\n    \"\"\"\n    with Path(filename).open(\"rb\") as fh:\n        environment = pickle.load(fh)\n    if not isinstance(environment, cls):\n        raise TypeError(f\"Loaded object is not type {cls.__name__}\")\n    return environment\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.to_file","title":"to_file","text":"<pre><code>to_file(path: str | Path) -&gt; None\n</code></pre> <p>Save Environment to versioned JSON + npz files.</p> <p>This method provides stable, reproducible serialization that is safer than pickle and compatible across Python versions. Creates two files: <code>{path}.json</code> (metadata) and <code>{path}.npz</code> (arrays).</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>Base path for output files (without extension). Will create <code>{path}.json</code> and <code>{path}.npz</code>.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; env = Environment.from_samples(data, bin_size=2.0)\n&gt;&gt;&gt; env.to_file(\"my_environment\")\n</code></pre> See Also <p>from_file : Load environment from saved files save : Legacy pickle-based serialization</p> Notes <p>This format is safer than pickle (no arbitrary code execution) and more portable across Python versions and platforms.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>def to_file(self, path: str | Path) -&gt; None:\n    \"\"\"Save Environment to versioned JSON + npz files.\n\n    This method provides stable, reproducible serialization that is safer\n    than pickle and compatible across Python versions. Creates two files:\n    `{path}.json` (metadata) and `{path}.npz` (arrays).\n\n    Parameters\n    ----------\n    path : str or Path\n        Base path for output files (without extension).\n        Will create `{path}.json` and `{path}.npz`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; env = Environment.from_samples(data, bin_size=2.0)\n    &gt;&gt;&gt; env.to_file(\"my_environment\")\n\n    See Also\n    --------\n    from_file : Load environment from saved files\n    save : Legacy pickle-based serialization\n\n    Notes\n    -----\n    This format is safer than pickle (no arbitrary code execution) and\n    more portable across Python versions and platforms.\n\n    \"\"\"\n    from neurospatial.io import to_file as _to_file\n\n    _to_file(self, path)\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.from_file","title":"from_file  <code>classmethod</code>","text":"<pre><code>from_file(path: str | Path) -&gt; Environment\n</code></pre> <p>Load Environment from versioned JSON + npz files.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>Base path to load from (without extension). Will read <code>{path}.json</code> and <code>{path}.npz</code>.</p> required <p>Returns:</p> Type Description <code>Environment</code> <p>Reconstructed Environment instance.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; env = Environment.from_file(\"my_environment\")\n</code></pre> See Also <p>to_file : Save environment to files load : Legacy pickle-based deserialization</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef from_file(cls, path: str | Path) -&gt; Environment:\n    \"\"\"Load Environment from versioned JSON + npz files.\n\n    Parameters\n    ----------\n    path : str or Path\n        Base path to load from (without extension).\n        Will read `{path}.json` and `{path}.npz`.\n\n    Returns\n    -------\n    Environment\n        Reconstructed Environment instance.\n\n    Examples\n    --------\n    &gt;&gt;&gt; env = Environment.from_file(\"my_environment\")\n\n    See Also\n    --------\n    to_file : Save environment to files\n    load : Legacy pickle-based deserialization\n\n    \"\"\"\n    from neurospatial.io import from_file as _from_file\n\n    return _from_file(path)\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert Environment to dictionary for in-memory handoff.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary representation with all arrays as lists.</p> See Also <p>from_dict : Reconstruct from dictionary to_file : Save to disk with efficient binary format</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert Environment to dictionary for in-memory handoff.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary representation with all arrays as lists.\n\n    See Also\n    --------\n    from_dict : Reconstruct from dictionary\n    to_file : Save to disk with efficient binary format\n\n    \"\"\"\n    from neurospatial.io import to_dict as _to_dict\n\n    return _to_dict(self)\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: dict[str, Any]) -&gt; Environment\n</code></pre> <p>Reconstruct Environment from dictionary representation.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[str, Any]</code> <p>Dictionary from <code>to_dict()</code>.</p> required <p>Returns:</p> Type Description <code>Environment</code> <p>Reconstructed instance.</p> See Also <p>to_dict : Convert to dictionary</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; Environment:\n    \"\"\"Reconstruct Environment from dictionary representation.\n\n    Parameters\n    ----------\n    data : dict[str, Any]\n        Dictionary from `to_dict()`.\n\n    Returns\n    -------\n    Environment\n        Reconstructed instance.\n\n    See Also\n    --------\n    to_dict : Convert to dictionary\n\n    \"\"\"\n    from neurospatial.io import from_dict as _from_dict\n\n    return _from_dict(data)\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.bins_in_region","title":"bins_in_region","text":"<pre><code>bins_in_region(region_name: str) -&gt; NDArray[np.int_]\n</code></pre> <p>Get active bin indices that fall within a specified named region.</p> <p>Parameters:</p> Name Type Description Default <code>region_name</code> <code>str</code> <p>The name of a defined region in <code>self.regions</code>.</p> required <p>Returns:</p> Type Description <code>NDArray[int_]</code> <p>Array of active bin indices (0 to n_active_bins - 1) that are part of the region.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If <code>region_name</code> is not found in <code>self.regions</code>.</p> <code>ValueError</code> <p>If region kind is unsupported or mask dimensions mismatch.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef bins_in_region(self, region_name: str) -&gt; NDArray[np.int_]:\n    \"\"\"Get active bin indices that fall within a specified named region.\n\n    Parameters\n    ----------\n    region_name : str\n        The name of a defined region in `self.regions`.\n\n    Returns\n    -------\n    NDArray[np.int_]\n        Array of active bin indices (0 to n_active_bins - 1)\n        that are part of the region.\n\n    Raises\n    ------\n    KeyError\n        If `region_name` is not found in `self.regions`.\n    ValueError\n        If region kind is unsupported or mask dimensions mismatch.\n\n    \"\"\"\n    region = self.regions[region_name]\n\n    if region.kind == \"point\":\n        point_nd = np.asarray(region.data).reshape(1, -1)\n        if point_nd.shape[1] != self.n_dims:\n            raise ValueError(\n                f\"Region point dimension {point_nd.shape[1]} \"\n                f\"does not match environment dimension {self.n_dims}.\",\n            )\n        bin_idx = self.bin_at(point_nd)\n        return np.asarray(bin_idx[bin_idx != -1], dtype=int)\n\n    if region.kind == \"polygon\":\n        if not _HAS_SHAPELY:  # pragma: no cover\n            raise RuntimeError(\"Polygon region queries require 'shapely'.\")\n        if self.n_dims != 2:  # pragma: no cover\n            raise ValueError(\n                \"Polygon regions are only supported for 2D environments.\",\n            )\n\n        import shapely\n\n        polygon = region.data\n        contained_mask = shapely.contains_xy(\n            polygon,\n            self.bin_centers[:, 0],\n            self.bin_centers[:, 1],\n        )\n\n        return np.flatnonzero(contained_mask)\n\n    # pragma: no cover\n    raise ValueError(f\"Unsupported region kind: {region.kind}\")\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.Environment.mask_for_region","title":"mask_for_region","text":"<pre><code>mask_for_region(region_name: str) -&gt; NDArray[np.bool_]\n</code></pre> <p>Get a boolean mask over active bins indicating membership in a region.</p> <p>Parameters:</p> Name Type Description Default <code>region_name</code> <code>str</code> <p>Name of region to query.</p> required <p>Returns:</p> Type Description <code>NDArray[bool_]</code> <p>Boolean array of shape (n_active_bins,). True if an active bin is part of the region.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef mask_for_region(self, region_name: str) -&gt; NDArray[np.bool_]:\n    \"\"\"Get a boolean mask over active bins indicating membership in a region.\n\n    Parameters\n    ----------\n    region_name : str\n        Name of region to query.\n\n    Returns\n    -------\n    NDArray[np.bool_]\n        Boolean array of shape (n_active_bins,). True if an active bin\n        is part of the region.\n\n    \"\"\"\n    active_bins_for_mask = self.bins_in_region(region_name)\n    mask = np.zeros(self.bin_centers.shape[0], dtype=bool)\n    if active_bins_for_mask.size &gt; 0:\n        mask[active_bins_for_mask] = True\n    return mask\n</code></pre>"},{"location":"api/neurospatial/#neurospatial-functions","title":"Functions","text":""},{"location":"api/neurospatial/#neurospatial.get_2d_rotation_matrix","title":"get_2d_rotation_matrix","text":"<pre><code>get_2d_rotation_matrix(angle_degrees: float) -&gt; NDArray[np.float64]\n</code></pre> <p>Creates a 2D counter-clockwise rotation matrix for a given angle.</p> <p>Parameters:</p> Name Type Description Default <code>angle_degrees</code> <code>float</code> <p>The rotation angle in degrees. Positive for counter-clockwise.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The 2x2 rotation matrix.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; rotation_matrix = get_2d_rotation_matrix(90)\n&gt;&gt;&gt; print(rotation_matrix)\n[[ 0. -1.]\n [ 1.  0.]]\n</code></pre> <p>Rotate a point 90 degrees counter-clockwise:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; point = np.array([[1, 0]])\n&gt;&gt;&gt; rotated = point @ rotation_matrix.T\n&gt;&gt;&gt; print(rotated)\n[[0. 1.]]\n</code></pre> Source code in <code>src/neurospatial/alignment.py</code> <pre><code>def get_2d_rotation_matrix(angle_degrees: float) -&gt; NDArray[np.float64]:\n    \"\"\"Creates a 2D counter-clockwise rotation matrix for a given angle.\n\n    Parameters\n    ----------\n    angle_degrees : float\n        The rotation angle in degrees. Positive for counter-clockwise.\n\n    Returns\n    -------\n    NDArray[np.float64]\n        The 2x2 rotation matrix.\n\n    Examples\n    --------\n    &gt;&gt;&gt; rotation_matrix = get_2d_rotation_matrix(90)\n    &gt;&gt;&gt; print(rotation_matrix)  # doctest: +SKIP\n    [[ 0. -1.]\n     [ 1.  0.]]\n\n    Rotate a point 90 degrees counter-clockwise:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; point = np.array([[1, 0]])\n    &gt;&gt;&gt; rotated = point @ rotation_matrix.T\n    &gt;&gt;&gt; print(rotated)  # doctest: +SKIP\n    [[0. 1.]]\n\n    \"\"\"\n    angle_radians = np.deg2rad(angle_degrees)\n    cos_theta = np.cos(angle_radians)\n    sin_theta = np.sin(angle_radians)\n\n    rotation_matrix = np.array([[cos_theta, -sin_theta], [sin_theta, cos_theta]])\n    return rotation_matrix\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.map_probabilities_to_nearest_target_bin","title":"map_probabilities_to_nearest_target_bin","text":"<pre><code>map_probabilities_to_nearest_target_bin(source_env: Environment, target_env: Environment, source_probs: NDArray[float64], *, mode: Literal['nearest', 'inverse-distance-weighted'] = 'nearest', n_neighbors: int = 1, eps: float = IDW_MIN_DISTANCE, source_scale_factor: float = 1.0, source_rotation_matrix: NDArray[float64] | None = None, source_translation_vector: NDArray[float64] | None = None) -&gt; NDArray[np.float64]\n</code></pre> <p>Map probabilities on source_env onto target_env, with optional scaling/translation of the source bin-centers beforehand.</p> <p>Parameters:</p> Name Type Description Default <code>source_env</code> <code>Environment</code> <p>A fitted Environment whose bins currently have centers <code>source_env.bin_centers</code>.</p> required <code>target_env</code> <code>Environment</code> <p>A fitted Environment onto whose bins we want to map probabilities.</p> required <code>source_probs</code> <code>NDArray[float64]</code> <p>1D array of length source_env.n_bins (nonnegative).</p> required <code>mode</code> <code>('nearest', 'inverse-distance-weighted')</code> <ul> <li>\"nearest\": each source bin's mass \u2192 its single nearest target bin.</li> <li>\"inverse-distance-weighted\" : spread each source bin's mass over     its <code>n_neighbors</code> nearest target bins,     weighted by inverse distance, and summing contributions.</li> </ul> <code>'nearest'</code> <code>n_neighbors</code> <code>int</code> <p>Number of neighbors to use when mode=\"inverse-distance-weighted\" (ignored if mode=\"nearest\").</p> <code>1</code> <code>eps</code> <code>float</code> <p>Small constant to avoid division by zero in IDW weights.</p> <code>IDW_MIN_DISTANCE</code> <code>source_scale_factor</code> <code>float</code> <p>Multiply every source bin-center by this scalar before querying.</p> <code>1.0</code> <code>source_rotation_matrix</code> <code>Optional[NDArray[float64]]</code> <p>If not None, must be a 2x2 rotation matrix (shape (2, 2)) for 2D environments. Applied to source bin centers after scaling but before translation.</p> <code>None</code> <code>source_translation_vector</code> <code>Optional[NDArray[float64]]</code> <p>If not None, must be a 1D array of length n_dims. Applied to source bin centers after scaling and rotation.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>target_probabilities</code> <code>(array, shape(n_target_bins))</code> <p>Each entry is the sum of <code>source_probabilities</code> whose (transformed) source bin center is nearest to that target bin center. If <code>n_target_bins == 0</code>, returns an empty array of shape (0,).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If either <code>source_env</code> or <code>target_env</code> is not fitted.</p> <code>ValueError</code> <p>If <code>source_probabilities</code> has incorrect shape, or if dims mismatch.</p> <p>Examples:</p> <p>Map probabilities between two environments with different bin sizes:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; from neurospatial.alignment import map_probabilities_to_nearest_target_bin\n&gt;&gt;&gt; # Create two environments with different bin sizes\n&gt;&gt;&gt; data = np.random.rand(1000, 2) * 100\n&gt;&gt;&gt; source_env = Environment.from_samples(data, bin_size=5.0)\n&gt;&gt;&gt; target_env = Environment.from_samples(data, bin_size=10.0)\n&gt;&gt;&gt; # Create probability distribution for source\n&gt;&gt;&gt; source_probs = np.ones(source_env.n_bins) / source_env.n_bins\n&gt;&gt;&gt; # Map to target environment\n&gt;&gt;&gt; target_probs = map_probabilities_to_nearest_target_bin(\n...     source_env, target_env, source_probs\n... )\n&gt;&gt;&gt; target_probs.shape[0] == target_env.n_bins\nTrue\n&gt;&gt;&gt; np.allclose(target_probs.sum(), 1.0)\nTrue\n</code></pre> <p>Map with rotation and scaling:</p> <pre><code>&gt;&gt;&gt; from neurospatial.alignment import get_2d_rotation_matrix\n&gt;&gt;&gt; rotation = get_2d_rotation_matrix(45)  # 45 degree rotation\n&gt;&gt;&gt; target_probs = map_probabilities_to_nearest_target_bin(\n...     source_env,\n...     target_env,\n...     source_probs,\n...     source_rotation_matrix=rotation,\n...     source_scale_factor=0.9,\n... )\n</code></pre> Source code in <code>src/neurospatial/alignment.py</code> <pre><code>def map_probabilities_to_nearest_target_bin(\n    source_env: Environment,\n    target_env: Environment,\n    source_probs: NDArray[np.float64],\n    *,\n    mode: Literal[\"nearest\", \"inverse-distance-weighted\"] = \"nearest\",\n    n_neighbors: int = 1,\n    eps: float = IDW_MIN_DISTANCE,\n    source_scale_factor: float = 1.0,\n    source_rotation_matrix: NDArray[np.float64] | None = None,\n    source_translation_vector: NDArray[np.float64] | None = None,\n) -&gt; NDArray[np.float64]:\n    \"\"\"Map probabilities on source_env onto target_env, with optional scaling/translation\n    of the source bin-centers beforehand.\n\n    Parameters\n    ----------\n    source_env : Environment\n        A fitted Environment whose bins currently have centers `source_env.bin_centers`.\n    target_env : Environment\n        A fitted Environment onto whose bins we want to map probabilities.\n    source_probs : NDArray[np.float64]\n        1D array of length source_env.n_bins (nonnegative).\n    mode : {'nearest', 'inverse-distance-weighted'}\n        - \"nearest\": each source bin's mass \u2192 its single nearest target bin.\n        - \"inverse-distance-weighted\" : spread each source bin's mass over\n            its `n_neighbors` nearest target bins,\n            weighted by inverse distance, and summing contributions.\n    n_neighbors : int\n        Number of neighbors to use when mode=\"inverse-distance-weighted\"\n        (ignored if mode=\"nearest\").\n    eps : float, default=IDW_MIN_DISTANCE\n        Small constant to avoid division by zero in IDW weights.\n    source_scale_factor : float\n        Multiply every source bin-center by this scalar before querying.\n    source_rotation_matrix : Optional[NDArray[np.float64]]\n        If not None, must be a 2x2 rotation matrix (shape (2, 2)) for 2D environments.\n        Applied to source bin centers after scaling but before translation.\n    source_translation_vector : Optional[NDArray[np.float64]]\n        If not None, must be a 1D array of length n_dims. Applied to source bin centers\n        after scaling and rotation.\n\n    Returns\n    -------\n    target_probabilities : array, shape (n_target_bins,)\n        Each entry is the sum of `source_probabilities` whose (transformed)\n        source bin center is nearest to that target bin center. If `n_target_bins == 0`,\n        returns an empty array of shape (0,).\n\n    Raises\n    ------\n    RuntimeError\n        If either `source_env` or `target_env` is not fitted.\n    ValueError\n        If `source_probabilities` has incorrect shape, or if dims mismatch.\n\n    Examples\n    --------\n    Map probabilities between two environments with different bin sizes:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; from neurospatial.alignment import map_probabilities_to_nearest_target_bin\n    &gt;&gt;&gt; # Create two environments with different bin sizes\n    &gt;&gt;&gt; data = np.random.rand(1000, 2) * 100\n    &gt;&gt;&gt; source_env = Environment.from_samples(data, bin_size=5.0)\n    &gt;&gt;&gt; target_env = Environment.from_samples(data, bin_size=10.0)\n    &gt;&gt;&gt; # Create probability distribution for source\n    &gt;&gt;&gt; source_probs = np.ones(source_env.n_bins) / source_env.n_bins\n    &gt;&gt;&gt; # Map to target environment\n    &gt;&gt;&gt; target_probs = map_probabilities_to_nearest_target_bin(\n    ...     source_env, target_env, source_probs\n    ... )\n    &gt;&gt;&gt; target_probs.shape[0] == target_env.n_bins\n    True\n    &gt;&gt;&gt; np.allclose(target_probs.sum(), 1.0)\n    True\n\n    Map with rotation and scaling:\n\n    &gt;&gt;&gt; from neurospatial.alignment import get_2d_rotation_matrix\n    &gt;&gt;&gt; rotation = get_2d_rotation_matrix(45)  # 45 degree rotation\n    &gt;&gt;&gt; target_probs = map_probabilities_to_nearest_target_bin(\n    ...     source_env,\n    ...     target_env,\n    ...     source_probs,\n    ...     source_rotation_matrix=rotation,\n    ...     source_scale_factor=0.9,\n    ... )\n\n    \"\"\"\n    from scipy.spatial import cKDTree\n\n    # Validate inputs using dataclass\n    params = ProbabilityMappingParams(\n        source_env=source_env,\n        target_env=target_env,\n        source_probs=source_probs,\n        mode=mode,\n        n_neighbors=n_neighbors,\n    )\n    n_src = params.n_source_bins\n    n_tgt = params.n_target_bins\n\n    # Handle empty environments\n    if n_src == 0 or n_tgt == 0:\n        warnings.warn(\n            \"One of the environments has zero bins; returning zeros.\",\n            UserWarning,\n        )\n        return np.zeros(n_tgt, dtype=float)\n\n    # Transform source bin centers\n    src_centers = _transform_source_bin_centers(\n        source_env.bin_centers,\n        source_scale_factor,\n        source_rotation_matrix,\n        source_translation_vector,\n    )\n\n    # Build KDTree on target bin centers\n    try:\n        tree = cKDTree(target_env.bin_centers, leafsize=KDTREE_LEAF_SIZE)\n    except Exception as e:\n        warnings.warn(\n            f\"KDTree construction on target_env failed: {e}. Returning zeros.\",\n            RuntimeWarning,\n        )\n        return np.zeros(n_tgt, dtype=float)\n\n    # Perform the requested mapping\n    if mode == \"nearest\":\n        return _map_nearest_neighbor(tree, src_centers, source_probs, n_tgt)\n    if mode == \"inverse-distance-weighted\":\n        return _map_inverse_distance_weighted(\n            tree,\n            src_centers,\n            source_probs,\n            n_tgt,\n            n_neighbors,\n            eps,\n        )\n    raise ValueError(f\"Unrecognized mode '{mode}'.\")\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.distance_field","title":"distance_field","text":"<pre><code>distance_field(G: Graph, sources: list[int] | NDArray[int_], weight: str = 'distance') -&gt; NDArray[np.float64]\n</code></pre> <p>Compute distance field: distance from each node to nearest source node.</p> <p>This is a common primitive for spatial analysis - compute the distance from every bin to the nearest bin in a set of source bins (e.g., goal locations, reward sites, or boundaries).</p> <p>Parameters:</p> Name Type Description Default <code>G</code> <code>Graph</code> <p>NetworkX graph representing spatial connectivity.</p> required <code>sources</code> <code>list[int] or NDArray[int_]</code> <p>List of source node indices. Distance field measures distance to nearest node in this set.</p> required <code>weight</code> <code>str</code> <p>Edge attribute to use as weight for path length calculation.</p> <code>\"distance\"</code> <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_nodes))</code> <p>For each node i, the distance to the nearest source node. Nodes unreachable from all sources have distance np.inf.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import networkx as nx\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial.distance import distance_field\n&gt;&gt;&gt; # Create a simple graph\n&gt;&gt;&gt; G = nx.Graph()\n&gt;&gt;&gt; G.add_edges_from([(0, 1), (1, 2), (2, 3), (3, 4)])\n&gt;&gt;&gt; for u, v in G.edges:\n...     G.edges[u, v][\"distance\"] = 1.0\n&gt;&gt;&gt; # Compute distance field from node 2\n&gt;&gt;&gt; dists = distance_field(G, sources=[2])\n&gt;&gt;&gt; dists\narray([2., 1., 0., 1., 2.])\n</code></pre> Notes <p>This function uses Dijkstra's algorithm with multiple sources, which is O((V + E) log V) where V is number of nodes and E is number of edges.</p> <p>For large graphs or repeated queries, consider caching the result.</p> See Also <p>geodesic_distance_matrix : Compute all-pairs distances pairwise_distances : Compute distances between specific node pairs</p> Source code in <code>src/neurospatial/distance.py</code> <pre><code>def distance_field(\n    G: nx.Graph,\n    sources: list[int] | NDArray[np.int_],\n    weight: str = \"distance\",\n) -&gt; NDArray[np.float64]:\n    \"\"\"Compute distance field: distance from each node to nearest source node.\n\n    This is a common primitive for spatial analysis - compute the distance\n    from every bin to the nearest bin in a set of source bins (e.g., goal\n    locations, reward sites, or boundaries).\n\n    Parameters\n    ----------\n    G : nx.Graph\n        NetworkX graph representing spatial connectivity.\n    sources : list[int] or NDArray[np.int_]\n        List of source node indices. Distance field measures distance to\n        nearest node in this set.\n    weight : str, default=\"distance\"\n        Edge attribute to use as weight for path length calculation.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_nodes,)\n        For each node i, the distance to the nearest source node.\n        Nodes unreachable from all sources have distance np.inf.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import networkx as nx\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial.distance import distance_field\n    &gt;&gt;&gt; # Create a simple graph\n    &gt;&gt;&gt; G = nx.Graph()\n    &gt;&gt;&gt; G.add_edges_from([(0, 1), (1, 2), (2, 3), (3, 4)])\n    &gt;&gt;&gt; for u, v in G.edges:\n    ...     G.edges[u, v][\"distance\"] = 1.0\n    &gt;&gt;&gt; # Compute distance field from node 2\n    &gt;&gt;&gt; dists = distance_field(G, sources=[2])\n    &gt;&gt;&gt; dists\n    array([2., 1., 0., 1., 2.])\n\n    Notes\n    -----\n    This function uses Dijkstra's algorithm with multiple sources, which is\n    O((V + E) log V) where V is number of nodes and E is number of edges.\n\n    For large graphs or repeated queries, consider caching the result.\n\n    See Also\n    --------\n    geodesic_distance_matrix : Compute all-pairs distances\n    pairwise_distances : Compute distances between specific node pairs\n\n    \"\"\"\n    sources_array = np.asarray(sources, dtype=int)\n\n    n_nodes = G.number_of_nodes()\n    if n_nodes == 0:\n        return np.empty(0, dtype=np.float64)\n\n    if len(sources_array) == 0:\n        raise ValueError(\"sources must contain at least one node\")\n\n    # Initialize distance array\n    distances = np.full(n_nodes, np.inf, dtype=np.float64)\n\n    # Check that all source nodes are valid\n    valid_sources = []\n    for src in sources_array:\n        if src in G.nodes:\n            valid_sources.append(int(src))\n        else:\n            import warnings\n\n            warnings.warn(f\"Source node {src} not in graph, skipping\", stacklevel=2)\n\n    if len(valid_sources) == 0:\n        raise ValueError(\"No valid source nodes found in graph\")\n\n    # Run Dijkstra from each source and keep minimum distance\n    for src in valid_sources:\n        lengths = nx.single_source_dijkstra_path_length(G, src, weight=weight)\n        for node, length in lengths.items():\n            distances[node] = min(distances[node], float(length))\n\n    return distances\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.pairwise_distances","title":"pairwise_distances","text":"<pre><code>pairwise_distances(G: Graph, nodes: list[int] | NDArray[int_], weight: str = 'distance') -&gt; NDArray[np.float64]\n</code></pre> <p>Compute pairwise geodesic distances between specified nodes.</p> <p>This is more efficient than computing the full distance matrix when you only need distances between a subset of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>G</code> <code>Graph</code> <p>NetworkX graph representing spatial connectivity.</p> required <code>nodes</code> <code>list[int] or NDArray[int_]</code> <p>List of node indices to compute distances between.</p> required <code>weight</code> <code>str</code> <p>Edge attribute to use as weight for path length calculation.</p> <code>\"distance\"</code> <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_nodes, n_nodes))</code> <p>Pairwise distance matrix where element (i, j) is the shortest path length between nodes[i] and nodes[j]. Disconnected nodes have distance np.inf.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import networkx as nx\n&gt;&gt;&gt; from neurospatial.distance import pairwise_distances\n&gt;&gt;&gt; G = nx.cycle_graph(10)\n&gt;&gt;&gt; for u, v in G.edges:\n...     G.edges[u, v][\"distance\"] = 1.0\n&gt;&gt;&gt; # Compute distances between nodes 0, 3, 7\n&gt;&gt;&gt; dists = pairwise_distances(G, [0, 3, 7])\n&gt;&gt;&gt; dists.shape\n(3, 3)\n&gt;&gt;&gt; dists[0, 1]  # Distance from node 0 to node 3\n3.0\n</code></pre> See Also <p>geodesic_distance_matrix : Compute all-pairs distances distance_field : Compute distance to nearest source</p> Source code in <code>src/neurospatial/distance.py</code> <pre><code>def pairwise_distances(\n    G: nx.Graph,\n    nodes: list[int] | NDArray[np.int_],\n    weight: str = \"distance\",\n) -&gt; NDArray[np.float64]:\n    \"\"\"Compute pairwise geodesic distances between specified nodes.\n\n    This is more efficient than computing the full distance matrix when you\n    only need distances between a subset of nodes.\n\n    Parameters\n    ----------\n    G : nx.Graph\n        NetworkX graph representing spatial connectivity.\n    nodes : list[int] or NDArray[np.int_]\n        List of node indices to compute distances between.\n    weight : str, default=\"distance\"\n        Edge attribute to use as weight for path length calculation.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_nodes, n_nodes)\n        Pairwise distance matrix where element (i, j) is the shortest path\n        length between nodes[i] and nodes[j]. Disconnected nodes have distance np.inf.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import networkx as nx\n    &gt;&gt;&gt; from neurospatial.distance import pairwise_distances\n    &gt;&gt;&gt; G = nx.cycle_graph(10)\n    &gt;&gt;&gt; for u, v in G.edges:\n    ...     G.edges[u, v][\"distance\"] = 1.0\n    &gt;&gt;&gt; # Compute distances between nodes 0, 3, 7\n    &gt;&gt;&gt; dists = pairwise_distances(G, [0, 3, 7])\n    &gt;&gt;&gt; dists.shape\n    (3, 3)\n    &gt;&gt;&gt; dists[0, 1]  # Distance from node 0 to node 3\n    3.0\n\n    See Also\n    --------\n    geodesic_distance_matrix : Compute all-pairs distances\n    distance_field : Compute distance to nearest source\n\n    \"\"\"\n    nodes_array = np.asarray(nodes, dtype=int)\n    n = len(nodes_array)\n\n    if n == 0:\n        return np.empty((0, 0), dtype=np.float64)\n\n    dist_matrix = np.full((n, n), np.inf, dtype=np.float64)\n\n    # Compute distances\n    for i, src in enumerate(nodes_array):\n        if src not in G.nodes:\n            continue\n\n        # Set self-distance to 0 for valid nodes\n        dist_matrix[i, i] = 0.0\n\n        lengths = nx.single_source_dijkstra_path_length(G, src, weight=weight)\n        for j, dst in enumerate(nodes_array):\n            if dst in lengths:\n                dist_matrix[i, j] = float(lengths[dst])\n\n    return dist_matrix\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.get_layout_parameters","title":"get_layout_parameters","text":"<pre><code>get_layout_parameters(layout_type: str) -&gt; dict[str, dict[str, Any]]\n</code></pre> <p>Retrieve expected build parameters for a specified layout engine type.</p> <p>Inspects the <code>build</code> method signature of the specified <code>LayoutEngine</code> class to determine its required and optional parameters.</p> <p>Parameters:</p> Name Type Description Default <code>layout_type</code> <code>str</code> <p>The string identifier of the layout engine type (case-insensitive, ignores non-alphanumeric characters).</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Any]]</code> <p>A dictionary where keys are parameter names for the <code>build</code> method. Each value is another dictionary containing: - 'annotation': The type annotation of the parameter. - 'default': The default value, or <code>None</code> if no default. - 'kind': The parameter kind (e.g., 'keyword-only').</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>layout_type</code> is unknown.</p> Source code in <code>src/neurospatial/layout/factories.py</code> <pre><code>def get_layout_parameters(layout_type: str) -&gt; dict[str, dict[str, Any]]:\n    \"\"\"Retrieve expected build parameters for a specified layout engine type.\n\n    Inspects the `build` method signature of the specified `LayoutEngine`\n    class to determine its required and optional parameters.\n\n    Parameters\n    ----------\n    layout_type : str\n        The string identifier of the layout engine type (case-insensitive,\n        ignores non-alphanumeric characters).\n\n    Returns\n    -------\n    Dict[str, Dict[str, Any]]\n        A dictionary where keys are parameter names for the `build` method.\n        Each value is another dictionary containing:\n        - 'annotation': The type annotation of the parameter.\n        - 'default': The default value, or `None` if no default.\n        - 'kind': The parameter kind (e.g., 'keyword-only').\n\n    Raises\n    ------\n    ValueError\n        If `layout_type` is unknown.\n\n    \"\"\"\n    normalized_kind_query = _normalize_name(layout_type)\n    found_key = next(\n        (\n            name\n            for name in _LAYOUT_MAP\n            if _normalize_name(name) == normalized_kind_query\n        ),\n        None,\n    )\n    if not found_key:\n        raise ValueError(\n            f\"Unknown engine kind '{layout_type}'. Available: {list_available_layouts()}\",\n        )\n    engine_class = _LAYOUT_MAP[found_key]\n    sig = inspect.signature(engine_class.build)\n    params_info: dict[str, dict[str, Any]] = {}\n    for name, param in sig.parameters.items():\n        if name == \"self\":\n            continue\n        params_info[name] = {\n            \"annotation\": (\n                param.annotation\n                if param.annotation is not inspect.Parameter.empty\n                else None\n            ),\n            \"default\": (\n                param.default if param.default is not inspect.Parameter.empty else None\n            ),\n            \"kind\": param.kind.description,\n        }\n    return params_info\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.list_available_layouts","title":"list_available_layouts","text":"<pre><code>list_available_layouts() -&gt; list[str]\n</code></pre> <p>List user-friendly type strings for all available layout engines.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>A sorted list of unique string identifiers for available <code>LayoutEngine</code> types (e.g., \"RegularGrid\", \"Hexagonal\").</p> Source code in <code>src/neurospatial/layout/factories.py</code> <pre><code>def list_available_layouts() -&gt; list[str]:\n    \"\"\"List user-friendly type strings for all available layout engines.\n\n    Returns\n    -------\n    List[str]\n        A sorted list of unique string identifiers for available\n        `LayoutEngine` types (e.g., \"RegularGrid\", \"Hexagonal\").\n\n    \"\"\"\n    unique_options: list[str] = []\n    processed_normalized_options: set[str] = set()\n    for opt in _LAYOUT_MAP:\n        norm_opt = _normalize_name(opt)\n        if norm_opt not in processed_normalized_options:\n            unique_options.append(opt)\n            processed_normalized_options.add(norm_opt)\n    return sorted(unique_options)\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.validate_environment","title":"validate_environment","text":"<pre><code>validate_environment(env: Environment, *, strict: bool = True) -&gt; None\n</code></pre> <p>Validate that an Environment satisfies all structural invariants.</p> <p>This function provides a single entry point for validating Environment objects. It checks: - Required node/edge attributes on connectivity graph - Bin geometry consistency (bin_centers matches graph nodes) - Connectivity structure (no duplicate edges, consistent node IDs) - Unit presence (if strict=True, warns about missing units/frame)</p> <p>Downstream packages can use this to verify invariants before processing.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Environment instance to validate.</p> required <code>strict</code> <code>bool</code> <p>If True, performs additional checks like warning about missing units. If False, only validates critical structural requirements.</p> <code>True</code> <p>Raises:</p> Type Description <code>GraphValidationError</code> <p>If connectivity graph is invalid (missing attributes, wrong dimensions).</p> <code>ValueError</code> <p>If bin_centers and connectivity graph are inconsistent.</p> <code>RuntimeError</code> <p>If environment is not fitted (was not created with factory method).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; from neurospatial.layout.validation import validate_environment\n&gt;&gt;&gt; env = Environment.from_samples(data, bin_size=2.0)\n&gt;&gt;&gt; validate_environment(env)  # Passes if environment is valid\n</code></pre> <pre><code>&gt;&gt;&gt; # Catch validation errors\n&gt;&gt;&gt; try:\n...     validate_environment(potentially_invalid_env)\n... except (GraphValidationError, ValueError) as e:\n...     print(f\"Environment is invalid: {e}\")\n</code></pre> See Also <p>validate_connectivity_graph : Lower-level graph validation Environment._setup_from_layout : Calls validation during creation</p> Notes <p>This validator is fail-fast with standardized error messages. It is designed to catch layout engine bugs and data corruption early.</p> <p>Downstream packages that rely on neurospatial environments should call this at their entry points to ensure invariants hold, avoiding the need for duplicate defensive checks.</p> Source code in <code>src/neurospatial/layout/validation.py</code> <pre><code>def validate_environment(env: Environment, *, strict: bool = True) -&gt; None:\n    \"\"\"Validate that an Environment satisfies all structural invariants.\n\n    This function provides a single entry point for validating Environment\n    objects. It checks:\n    - Required node/edge attributes on connectivity graph\n    - Bin geometry consistency (bin_centers matches graph nodes)\n    - Connectivity structure (no duplicate edges, consistent node IDs)\n    - Unit presence (if strict=True, warns about missing units/frame)\n\n    Downstream packages can use this to verify invariants before processing.\n\n    Parameters\n    ----------\n    env : Environment\n        Environment instance to validate.\n    strict : bool, default=True\n        If True, performs additional checks like warning about missing units.\n        If False, only validates critical structural requirements.\n\n    Raises\n    ------\n    GraphValidationError\n        If connectivity graph is invalid (missing attributes, wrong dimensions).\n    ValueError\n        If bin_centers and connectivity graph are inconsistent.\n    RuntimeError\n        If environment is not fitted (was not created with factory method).\n\n    Examples\n    --------\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; from neurospatial.layout.validation import validate_environment\n    &gt;&gt;&gt; env = Environment.from_samples(data, bin_size=2.0)\n    &gt;&gt;&gt; validate_environment(env)  # Passes if environment is valid\n\n    &gt;&gt;&gt; # Catch validation errors\n    &gt;&gt;&gt; try:\n    ...     validate_environment(potentially_invalid_env)\n    ... except (GraphValidationError, ValueError) as e:\n    ...     print(f\"Environment is invalid: {e}\")\n\n    See Also\n    --------\n    validate_connectivity_graph : Lower-level graph validation\n    Environment._setup_from_layout : Calls validation during creation\n\n    Notes\n    -----\n    This validator is fail-fast with standardized error messages. It is\n    designed to catch layout engine bugs and data corruption early.\n\n    Downstream packages that rely on neurospatial environments should call\n    this at their entry points to ensure invariants hold, avoiding the need\n    for duplicate defensive checks.\n\n    \"\"\"\n    import warnings\n\n    # Check fitted status\n    if not getattr(env, \"_is_fitted\", False):\n        raise RuntimeError(\n            f\"Environment '{env.name}' is not fitted. \"\n            f\"Environments must be created with factory methods \"\n            f\"(e.g., Environment.from_samples()) before validation.\"\n        )\n\n    # Validate connectivity graph\n    n_dims = env.n_dims\n    validate_connectivity_graph(\n        env.connectivity, n_dims=n_dims, check_node_attrs=True, check_edge_attrs=True\n    )\n\n    # Validate bin_centers consistency with graph\n    n_bins_from_centers = env.bin_centers.shape[0]\n    n_nodes_from_graph = len(env.connectivity.nodes)\n\n    if n_bins_from_centers != n_nodes_from_graph:\n        raise ValueError(\n            f\"bin_centers and connectivity graph are inconsistent.\\n\"\n            f\"  bin_centers has {n_bins_from_centers} rows\\n\"\n            f\"  connectivity graph has {n_nodes_from_graph} nodes\\n\"\n            f\"These must match. This indicates a layout engine bug.\"\n        )\n\n    # Validate node IDs are sequential from 0 to n_bins-1\n    node_ids = sorted(env.connectivity.nodes)\n    expected_ids = list(range(n_bins_from_centers))\n    if node_ids != expected_ids:\n        raise ValueError(\n            f\"connectivity graph node IDs are not sequential.\\n\"\n            f\"  Expected: [0, 1, ..., {n_bins_from_centers - 1}]\\n\"\n            f\"  Got: {node_ids[:10]}{'...' if len(node_ids) &gt; 10 else ''}\\n\"\n            f\"This indicates a layout engine bug.\"\n        )\n\n    # Validate bin_centers has correct shape\n    if env.bin_centers.ndim != 2:\n        raise ValueError(\n            f\"bin_centers must be 2D array (n_bins, n_dims), \"\n            f\"got shape {env.bin_centers.shape}\"\n        )\n\n    if env.bin_centers.shape[1] != n_dims:\n        raise ValueError(\n            f\"bin_centers has {env.bin_centers.shape[1]} columns, \"\n            f\"expected {n_dims} dimensions\"\n        )\n\n    # Check for duplicate edges (undirected graph should have only one edge per pair)\n    edges_set = set()\n    for u, v in env.connectivity.edges:\n        edge_tuple = tuple(sorted([u, v]))\n        if edge_tuple in edges_set:\n            raise ValueError(\n                f\"Duplicate edge found: {edge_tuple}. \"\n                f\"This indicates a layout engine bug.\"\n            )\n        edges_set.add(edge_tuple)\n\n    # Strict mode checks\n    if strict:\n        # Warn about missing units\n        if not hasattr(env, \"units\") or env.units is None:\n            warnings.warn(\n                f\"Environment '{env.name}' has no units specified. \"\n                f\"Consider setting env.units (e.g., 'cm', 'px', 'm') \"\n                f\"to prevent unit confusion in downstream analysis.\",\n                stacklevel=2,\n            )\n\n        # Warn about missing coordinate frame\n        if not hasattr(env, \"frame\") or env.frame is None:\n            warnings.warn(\n                f\"Environment '{env.name}' has no coordinate frame specified. \"\n                f\"Consider setting env.frame (e.g., 'world', 'camera_1') \"\n                f\"to prevent confusion when aligning multiple sessions.\",\n                stacklevel=2,\n            )\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.map_points_to_bins","title":"map_points_to_bins","text":"<pre><code>map_points_to_bins(points: NDArray[float64], env: Environment, *, tie_break: Literal['lowest_index', 'closest_center'] = 'lowest_index', return_dist: bool = False) -&gt; NDArray[np.int64] | tuple[NDArray[np.int64], NDArray[np.float64]]\n</code></pre> <p>Map points to bin indices with deterministic tie-breaking.</p> <p>This function provides fast, batch mapping of continuous coordinates to discrete bin indices using KD-tree queries. It handles edge cases like boundary points consistently through configurable tie-breaking rules.</p> <p>Internally caches a KD-tree on first call for O(log N) lookups.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>(NDArray[float64], shape(n_points, n_dims))</code> <p>Continuous coordinates to map to bins.</p> required <code>env</code> <code>Environment</code> <p>Environment containing the bin discretization.</p> required <code>tie_break</code> <code>('lowest_index', 'closest_center')</code> <p>Strategy for resolving ties when a point is equidistant from multiple bin centers:</p> <ul> <li>\"lowest_index\": Choose the bin with smallest index (deterministic)</li> <li>\"closest_center\": Return the actual closest (may be non-deterministic   for exact ties, but faster)</li> </ul> <code>\"lowest_index\"</code> <code>return_dist</code> <code>bool</code> <p>If True, also return the distance from each point to its assigned bin center.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bin_indices</code> <code>(NDArray[int_], shape(n_points))</code> <p>Bin index for each point. Value of -1 indicates point is outside all bins.</p> <code>distances</code> <code>(NDArray[float64], shape(n_points), optional)</code> <p>Distance from each point to its assigned bin center. Only returned if <code>return_dist=True</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; from neurospatial.spatial import map_points_to_bins\n&gt;&gt;&gt; data = np.random.randn(1000, 2) * 10\n&gt;&gt;&gt; env = Environment.from_samples(data, bin_size=2.0)\n&gt;&gt;&gt; points = np.array([[0.0, 0.0], [10.0, 10.0], [50.0, 50.0]])\n&gt;&gt;&gt; bins = map_points_to_bins(points, env)\n&gt;&gt;&gt; bins\narray([ 42,  89,  -1])\n</code></pre> <pre><code>&gt;&gt;&gt; # Get distances too\n&gt;&gt;&gt; bins, dists = map_points_to_bins(points, env, return_dist=True)\n&gt;&gt;&gt; dists\narray([0.23, 0.45, inf])\n</code></pre> Notes <p>This function builds and caches a KD-tree on the environment's bin_centers on first call. Subsequent calls reuse the cached tree for O(log N) performance.</p> <p>The cache is stored as a private attribute on the Environment object. If bin_centers are modified after creation (not recommended), the cache will become stale.</p> See Also <p>Environment.bin_at : Basic point-to-bin mapping (delegates to layout engine) Environment.contains : Check if points are within environment bounds</p> Source code in <code>src/neurospatial/spatial.py</code> <pre><code>def map_points_to_bins(\n    points: NDArray[np.float64],\n    env: Environment,\n    *,\n    tie_break: Literal[\"lowest_index\", \"closest_center\"] = \"lowest_index\",\n    return_dist: bool = False,\n) -&gt; NDArray[np.int64] | tuple[NDArray[np.int64], NDArray[np.float64]]:\n    \"\"\"Map points to bin indices with deterministic tie-breaking.\n\n    This function provides fast, batch mapping of continuous coordinates to\n    discrete bin indices using KD-tree queries. It handles edge cases like\n    boundary points consistently through configurable tie-breaking rules.\n\n    Internally caches a KD-tree on first call for O(log N) lookups.\n\n    Parameters\n    ----------\n    points : NDArray[np.float64], shape (n_points, n_dims)\n        Continuous coordinates to map to bins.\n    env : Environment\n        Environment containing the bin discretization.\n    tie_break : {\"lowest_index\", \"closest_center\"}, default=\"lowest_index\"\n        Strategy for resolving ties when a point is equidistant from multiple\n        bin centers:\n\n        - \"lowest_index\": Choose the bin with smallest index (deterministic)\n        - \"closest_center\": Return the actual closest (may be non-deterministic\n          for exact ties, but faster)\n\n    return_dist : bool, default=False\n        If True, also return the distance from each point to its assigned bin center.\n\n    Returns\n    -------\n    bin_indices : NDArray[np.int_], shape (n_points,)\n        Bin index for each point. Value of -1 indicates point is outside all bins.\n    distances : NDArray[np.float64], shape (n_points,), optional\n        Distance from each point to its assigned bin center.\n        Only returned if `return_dist=True`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; from neurospatial.spatial import map_points_to_bins\n    &gt;&gt;&gt; data = np.random.randn(1000, 2) * 10\n    &gt;&gt;&gt; env = Environment.from_samples(data, bin_size=2.0)\n    &gt;&gt;&gt; points = np.array([[0.0, 0.0], [10.0, 10.0], [50.0, 50.0]])\n    &gt;&gt;&gt; bins = map_points_to_bins(points, env)\n    &gt;&gt;&gt; bins\n    array([ 42,  89,  -1])\n\n    &gt;&gt;&gt; # Get distances too\n    &gt;&gt;&gt; bins, dists = map_points_to_bins(points, env, return_dist=True)\n    &gt;&gt;&gt; dists\n    array([0.23, 0.45, inf])\n\n    Notes\n    -----\n    This function builds and caches a KD-tree on the environment's bin_centers\n    on first call. Subsequent calls reuse the cached tree for O(log N) performance.\n\n    The cache is stored as a private attribute on the Environment object. If\n    bin_centers are modified after creation (not recommended), the cache will\n    become stale.\n\n    See Also\n    --------\n    Environment.bin_at : Basic point-to-bin mapping (delegates to layout engine)\n    Environment.contains : Check if points are within environment bounds\n\n    \"\"\"\n    # Build or retrieve cached KD-tree\n    if not hasattr(env, \"_kdtree_cache\") or env._kdtree_cache is None:\n        env._kdtree_cache = cKDTree(env.bin_centers)\n\n    kdtree: cKDTree = env._kdtree_cache\n\n    # Query KD-tree\n    if tie_break == \"closest_center\":\n        # Fast path: just use nearest neighbor\n        distances, indices = kdtree.query(points, k=1, workers=-1)\n        bin_indices: NDArray[np.int64] = indices.astype(np.int64)\n\n    elif tie_break == \"lowest_index\":\n        # Deterministic path: find all ties and pick lowest index\n        # Query for nearest neighbor\n        distances, indices = kdtree.query(points, k=1, workers=-1)\n\n        # For boundary points, we need to check if there are multiple\n        # equidistant bins. Query for k=2 to detect ties.\n        distances_k2, _ = kdtree.query(points, k=2, workers=-1)\n\n        # Check where distance to 2nd nearest equals 1st nearest (within tolerance)\n        has_tie = np.abs(distances_k2[:, 0] - distances_k2[:, 1]) &lt; 1e-10\n\n        if np.any(has_tie):\n            # For tied points, query more neighbors and pick lowest index\n            # Adaptive: query enough neighbors to find all at same distance\n            max_neighbors = min(10, len(env.bin_centers))\n            distances_kn, indices_kn = kdtree.query(\n                points[has_tie], k=max_neighbors, workers=-1\n            )\n\n            # For each tied point, find all neighbors at same distance and pick min index\n            for i, (dists, idxs) in enumerate(\n                zip(distances_kn, indices_kn, strict=False)\n            ):\n                min_dist = dists[0]\n                tied_indices = idxs[np.abs(dists - min_dist) &lt; 1e-10]\n                indices[has_tie][i] = tied_indices.min()\n\n        bin_indices = indices.astype(np.int64)\n\n    else:\n        raise ValueError(\n            f\"Invalid tie_break mode: {tie_break!r}. \"\n            f\"Must be 'lowest_index' or 'closest_center'.\"\n        )\n\n    # Check if any points are outside the environment\n    # Points far from any bin center should be marked as -1\n    # Use a heuristic: if distance &gt; 10 * mean_bin_size, mark as outside\n    if len(env.bin_centers) &gt; 1:\n        # Estimate typical bin spacing from nearest-neighbor distances\n        sample_size = min(100, len(env.bin_centers))\n        sample_indices = np.random.choice(\n            len(env.bin_centers), size=sample_size, replace=False\n        )\n        sample_centers = env.bin_centers[sample_indices]\n        nn_dists, _ = kdtree.query(sample_centers, k=2, workers=-1)\n        typical_bin_spacing = np.median(nn_dists[:, 1])\n\n        # Mark points that are suspiciously far as outside\n        threshold = 10 * typical_bin_spacing\n        bin_indices[distances &gt; threshold] = -1\n\n    if return_dist:\n        # Set distance to inf for points outside environment\n        distances_out = distances.copy()\n        distances_out[bin_indices == -1] = np.inf\n        return (bin_indices, distances_out)\n\n    return bin_indices\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.apply_transform_to_environment","title":"apply_transform_to_environment","text":"<pre><code>apply_transform_to_environment(env: Environment, transform: Affine2D, *, name: str | None = None) -&gt; Environment\n</code></pre> <p>Apply 2D affine transformation to an Environment, returning a new instance.</p> <p>This function creates a new Environment with transformed bin_centers and updated connectivity graph. All other properties (regions, metadata) are copied from the source environment.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Source environment to transform (must be 2D).</p> required <code>transform</code> <code>Affine2D</code> <p>Transformation to apply.</p> required <code>name</code> <code>str</code> <p>Name for the new environment. If None, appends \"_transformed\" to original name.</p> <code>None</code> <p>Returns:</p> Type Description <code>Environment</code> <p>New Environment instance with transformed coordinates.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If environment is not 2D (transforms only support 2D currently).</p> <code>RuntimeError</code> <p>If environment is not fitted.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; from neurospatial.transforms import (\n...     estimate_transform,\n...     apply_transform_to_environment,\n... )\n&gt;&gt;&gt; # Create environment from session 1\n&gt;&gt;&gt; env1 = Environment.from_samples(data1, bin_size=2.0)\n&gt;&gt;&gt; # Estimate transform from landmarks\n&gt;&gt;&gt; T = estimate_transform(landmarks_session1, landmarks_session2, kind=\"rigid\")\n&gt;&gt;&gt; # Transform environment to session 2 coordinates\n&gt;&gt;&gt; env1_aligned = apply_transform_to_environment(env1, T, name=\"session1_aligned\")\n</code></pre> See Also <p>estimate_transform : Estimate transformation from point pairs Affine2D : 2D affine transformation class</p> Notes <p>This function is pure: it does not modify the source environment.</p> <p>The transformation is applied to: - bin_centers - graph node 'pos' attributes - regions (points and polygons)</p> <p>Edge distances and vectors are recomputed after transformation.</p> Source code in <code>src/neurospatial/transforms.py</code> <pre><code>def apply_transform_to_environment(\n    env: Environment,\n    transform: Affine2D,\n    *,\n    name: str | None = None,\n) -&gt; Environment:\n    \"\"\"Apply 2D affine transformation to an Environment, returning a new instance.\n\n    This function creates a new Environment with transformed bin_centers and\n    updated connectivity graph. All other properties (regions, metadata) are\n    copied from the source environment.\n\n    Parameters\n    ----------\n    env : Environment\n        Source environment to transform (must be 2D).\n    transform : Affine2D\n        Transformation to apply.\n    name : str, optional\n        Name for the new environment. If None, appends \"_transformed\" to original name.\n\n    Returns\n    -------\n    Environment\n        New Environment instance with transformed coordinates.\n\n    Raises\n    ------\n    ValueError\n        If environment is not 2D (transforms only support 2D currently).\n    RuntimeError\n        If environment is not fitted.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; from neurospatial.transforms import (\n    ...     estimate_transform,\n    ...     apply_transform_to_environment,\n    ... )\n    &gt;&gt;&gt; # Create environment from session 1\n    &gt;&gt;&gt; env1 = Environment.from_samples(data1, bin_size=2.0)\n    &gt;&gt;&gt; # Estimate transform from landmarks\n    &gt;&gt;&gt; T = estimate_transform(landmarks_session1, landmarks_session2, kind=\"rigid\")\n    &gt;&gt;&gt; # Transform environment to session 2 coordinates\n    &gt;&gt;&gt; env1_aligned = apply_transform_to_environment(env1, T, name=\"session1_aligned\")\n\n    See Also\n    --------\n    estimate_transform : Estimate transformation from point pairs\n    Affine2D : 2D affine transformation class\n\n    Notes\n    -----\n    This function is pure: it does not modify the source environment.\n\n    The transformation is applied to:\n    - bin_centers\n    - graph node 'pos' attributes\n    - regions (points and polygons)\n\n    Edge distances and vectors are recomputed after transformation.\n\n    \"\"\"\n    from neurospatial.environment import Environment\n    from neurospatial.regions import Region, Regions\n\n    # Validate\n    if not getattr(env, \"_is_fitted\", False):\n        raise RuntimeError(\n            \"Environment must be fitted before applying transforms. \"\n            \"Use a factory method like Environment.from_samples().\"\n        )\n\n    if env.n_dims != 2:\n        raise ValueError(\n            f\"apply_transform_to_environment only supports 2D environments, \"\n            f\"got {env.n_dims}D. For 3D, use scipy.spatial.transform.Rotation.\"\n        )\n\n    # Transform bin centers\n    transformed_centers = transform(env.bin_centers)\n\n    # Create new connectivity graph with updated node positions\n\n    new_graph = env.connectivity.copy()\n    for node_id in new_graph.nodes:\n        old_pos = new_graph.nodes[node_id][\"pos\"]\n        new_pos = transform(np.array([old_pos]))[0]\n        new_graph.nodes[node_id][\"pos\"] = tuple(new_pos)\n\n    # Recompute edge attributes (distance, vector, angle_2d)\n    for u, v in new_graph.edges:\n        pos_u = np.array(new_graph.nodes[u][\"pos\"])\n        pos_v = np.array(new_graph.nodes[v][\"pos\"])\n        vec = pos_v - pos_u\n        dist = float(np.linalg.norm(vec))\n\n        new_graph.edges[u, v][\"vector\"] = tuple(vec)\n        new_graph.edges[u, v][\"distance\"] = dist\n\n        # Recompute angle_2d if present\n        if \"angle_2d\" in new_graph.edges[u, v]:\n            angle = float(np.arctan2(vec[1], vec[0]))\n            new_graph.edges[u, v][\"angle_2d\"] = angle\n\n    # Transform dimension_ranges\n    transformed_dim_ranges = None\n    if env.dimension_ranges is not None:\n        # Transform corner points\n        lo_x, hi_x = env.dimension_ranges[0]\n        lo_y, hi_y = env.dimension_ranges[1]\n        corners = np.array([[lo_x, lo_y], [hi_x, lo_y], [hi_x, hi_y], [lo_x, hi_y]])\n        transformed_corners = transform(corners)\n\n        # New bounding box\n        new_lo_x, new_hi_x = (\n            transformed_corners[:, 0].min(),\n            transformed_corners[:, 0].max(),\n        )\n        new_lo_y, new_hi_y = (\n            transformed_corners[:, 1].min(),\n            transformed_corners[:, 1].max(),\n        )\n        transformed_dim_ranges = [(new_lo_x, new_hi_x), (new_lo_y, new_hi_y)]\n\n    # Create new Environment using from_layout pattern\n    # We'll create a minimal layout wrapper\n\n    class TransformedLayout:\n        \"\"\"Minimal layout wrapper for transformed environment.\"\"\"\n\n        def __init__(self, centers, graph, dim_ranges, original_layout):\n            self.bin_centers = centers\n            self.connectivity = graph\n            self.dimension_ranges = dim_ranges\n            self.is_1d = original_layout.is_1d\n            self._layout_type_tag = f\"{original_layout._layout_type_tag}_transformed\"\n            self._build_params_used = {\n                **getattr(original_layout, \"_build_params_used\", {}),\n                \"transformed\": True,\n            }\n\n            # Copy grid attributes if present\n            for attr in (\"grid_edges\", \"grid_shape\", \"active_mask\"):\n                if hasattr(original_layout, attr):\n                    setattr(self, attr, getattr(original_layout, attr))\n\n        def build(self):\n            pass  # Already built\n\n        def point_to_bin_index(self, points):\n            # Use KD-tree on transformed centers\n            from scipy.spatial import cKDTree\n\n            kdtree = cKDTree(self.bin_centers)\n            _, indices = kdtree.query(points)\n            return indices\n\n        def bin_sizes(self):\n            # Approximate from nearest neighbors\n            from scipy.spatial import cKDTree\n\n            if len(self.bin_centers) &lt; 2:\n                return np.array([1.0] * len(self.bin_centers))\n            kdtree = cKDTree(self.bin_centers)\n            dists, _ = kdtree.query(self.bin_centers, k=2)\n            return dists[:, 1] ** 2  # Approximate area\n\n        def plot(self, *args, **kwargs):\n            raise NotImplementedError(\n                \"Plotting not implemented for transformed layouts\"\n            )\n\n    transformed_layout = TransformedLayout(\n        transformed_centers, new_graph, transformed_dim_ranges, env.layout\n    )\n\n    # Create new environment\n    new_name = name if name is not None else f\"{env.name}_transformed\"\n    # Cast to LayoutEngine since TransformedLayout satisfies the protocol structurally\n    new_env = Environment(\n        name=new_name, layout=cast(\"LayoutEngine\", transformed_layout)\n    )\n    new_env._setup_from_layout()\n\n    # Transform and copy regions\n    if env.regions and len(env.regions) &gt; 0:\n        transformed_regions = []\n        for region in env.regions.values():\n            if region.kind == \"point\":\n                # Transform point\n                old_point = np.array(region.data)\n                new_point = transform(old_point.reshape(1, -1))[0]\n                new_region = Region(\n                    name=region.name,\n                    kind=\"point\",\n                    data=new_point,\n                    metadata={**region.metadata, \"transformed\": True},\n                )\n            elif region.kind == \"polygon\":\n                # Transform polygon\n                import shapely.geometry as shp\n                from shapely.geometry import Polygon\n\n                # Type narrowing: region.data is a Polygon when kind == \"polygon\"\n                if not isinstance(region.data, Polygon):\n                    raise TypeError(\n                        f\"Region '{region.name}' has kind='polygon' but data is not a Polygon\"\n                    )\n                old_coords = np.array(region.data.exterior.coords)\n                new_coords = transform(old_coords)\n                new_poly = shp.Polygon(new_coords)\n                new_region = Region(\n                    name=region.name,\n                    kind=\"polygon\",\n                    data=new_poly,\n                    metadata={**region.metadata, \"transformed\": True},\n                )\n\n            transformed_regions.append(new_region)\n\n        new_env.regions = Regions(transformed_regions)\n\n    # Copy units and frame\n    if hasattr(env, \"units\"):\n        new_env.units = env.units\n    if hasattr(env, \"frame\"):\n        new_env.frame = f\"{env.frame}_transformed\" if env.frame else \"transformed\"\n\n    return new_env\n</code></pre>"},{"location":"api/neurospatial/#neurospatial.estimate_transform","title":"estimate_transform","text":"<pre><code>estimate_transform(src: NDArray[float64], dst: NDArray[float64], kind: str = 'rigid') -&gt; Affine2D\n</code></pre> <p>Estimate 2D transformation from point correspondences.</p> <p>Given pairs of corresponding points in source and destination coordinate systems, compute the best-fit transformation (rigid, similarity, or affine).</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>(NDArray[float64], shape(N, 2))</code> <p>Source points (N &gt;= 2 for rigid/similarity, N &gt;= 3 for affine).</p> required <code>dst</code> <code>(NDArray[float64], shape(N, 2))</code> <p>Destination points corresponding to src.</p> required <code>kind</code> <code>('rigid', 'similarity', 'affine')</code> <p>Type of transformation to estimate:</p> <ul> <li>\"rigid\": Rotation + translation (preserves distances and angles)</li> <li>\"similarity\": Rotation + uniform scaling + translation   (preserves angles, scales distances uniformly)</li> <li>\"affine\": Full affine (rotation, scaling, shear, translation)</li> </ul> <code>\"rigid\"</code> <p>Returns:</p> Type Description <code>Affine2D</code> <p>Estimated transformation that maps src \u2192 dst.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If insufficient points for the requested transformation type, or if points are degenerate (collinear, etc.).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial.transforms import estimate_transform\n&gt;&gt;&gt; # Define corresponding points (e.g., landmarks in two sessions)\n&gt;&gt;&gt; src_pts = np.array([[0, 0], [10, 0], [10, 10], [0, 10]])\n&gt;&gt;&gt; # Rotated 45 degrees and translated\n&gt;&gt;&gt; angle = np.pi / 4\n&gt;&gt;&gt; dst_pts = src_pts @ [\n...     [np.cos(angle), -np.sin(angle)],\n...     [np.sin(angle), np.cos(angle)],\n... ] + [5, 5]\n&gt;&gt;&gt; T = estimate_transform(src_pts, dst_pts, kind=\"rigid\")\n&gt;&gt;&gt; transformed = T(src_pts)\n&gt;&gt;&gt; np.allclose(transformed, dst_pts)\nTrue\n</code></pre> Notes <p>Uses Procrustes analysis for rigid and similarity transforms, and least-squares for affine transforms.</p> <p>For cross-session alignment, collect 3-4 landmark points (e.g., corners of arena) in both sessions and use this function to compute the alignment.</p> See Also <p>Affine2D : 2D affine transformation class apply_transform_to_environment : Apply transform to Environment</p> Source code in <code>src/neurospatial/transforms.py</code> <pre><code>def estimate_transform(\n    src: NDArray[np.float64],\n    dst: NDArray[np.float64],\n    kind: str = \"rigid\",\n) -&gt; Affine2D:\n    \"\"\"Estimate 2D transformation from point correspondences.\n\n    Given pairs of corresponding points in source and destination coordinate\n    systems, compute the best-fit transformation (rigid, similarity, or affine).\n\n    Parameters\n    ----------\n    src : NDArray[np.float64], shape (N, 2)\n        Source points (N &gt;= 2 for rigid/similarity, N &gt;= 3 for affine).\n    dst : NDArray[np.float64], shape (N, 2)\n        Destination points corresponding to src.\n    kind : {\"rigid\", \"similarity\", \"affine\"}, default=\"rigid\"\n        Type of transformation to estimate:\n\n        - \"rigid\": Rotation + translation (preserves distances and angles)\n        - \"similarity\": Rotation + uniform scaling + translation\n          (preserves angles, scales distances uniformly)\n        - \"affine\": Full affine (rotation, scaling, shear, translation)\n\n    Returns\n    -------\n    Affine2D\n        Estimated transformation that maps src \u2192 dst.\n\n    Raises\n    ------\n    ValueError\n        If insufficient points for the requested transformation type,\n        or if points are degenerate (collinear, etc.).\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial.transforms import estimate_transform\n    &gt;&gt;&gt; # Define corresponding points (e.g., landmarks in two sessions)\n    &gt;&gt;&gt; src_pts = np.array([[0, 0], [10, 0], [10, 10], [0, 10]])\n    &gt;&gt;&gt; # Rotated 45 degrees and translated\n    &gt;&gt;&gt; angle = np.pi / 4\n    &gt;&gt;&gt; dst_pts = src_pts @ [\n    ...     [np.cos(angle), -np.sin(angle)],\n    ...     [np.sin(angle), np.cos(angle)],\n    ... ] + [5, 5]\n    &gt;&gt;&gt; T = estimate_transform(src_pts, dst_pts, kind=\"rigid\")\n    &gt;&gt;&gt; transformed = T(src_pts)\n    &gt;&gt;&gt; np.allclose(transformed, dst_pts)\n    True\n\n    Notes\n    -----\n    Uses Procrustes analysis for rigid and similarity transforms, and\n    least-squares for affine transforms.\n\n    For cross-session alignment, collect 3-4 landmark points (e.g., corners\n    of arena) in both sessions and use this function to compute the alignment.\n\n    See Also\n    --------\n    Affine2D : 2D affine transformation class\n    apply_transform_to_environment : Apply transform to Environment\n\n    \"\"\"\n    from scipy.linalg import orthogonal_procrustes\n\n    src = np.asanyarray(src, dtype=float)\n    dst = np.asanyarray(dst, dtype=float)\n\n    if src.shape != dst.shape:\n        raise ValueError(\n            f\"src and dst must have same shape, got {src.shape} and {dst.shape}\"\n        )\n\n    if src.ndim != 2 or src.shape[1] != 2:\n        raise ValueError(\n            f\"src and dst must be (N, 2) arrays for 2D transforms, got shape {src.shape}\"\n        )\n\n    n_points = src.shape[0]\n\n    if kind in (\"rigid\", \"similarity\"):\n        if n_points &lt; 2:\n            raise ValueError(\n                f\"{kind} transform requires at least 2 point pairs, got {n_points}\"\n            )\n\n        # Center the points\n        src_mean = src.mean(axis=0)\n        dst_mean = dst.mean(axis=0)\n        src_centered = src - src_mean\n        dst_centered = dst - dst_mean\n\n        # Estimate rotation using Procrustes\n        # Note: orthogonal_procrustes finds R such that ||src @ R - dst|| is minimized\n        # But we want transformation T(x) = x @ R_transform^T\n        # So R_transform = R^T\n        R_proc, _ = orthogonal_procrustes(src_centered, dst_centered)\n        R = R_proc.T\n\n        # Ensure R is a proper rotation (det(R) = +1, not -1)\n        # If det(R) &lt; 0, we have a reflection; flip one axis to get rotation\n        if np.linalg.det(R) &lt; 0:\n            # Flip the second column to convert reflection to rotation\n            R[:, 1] = -R[:, 1]\n\n        if kind == \"rigid\":\n            # Rigid: rotation + translation\n            # T(x) = R @ x + t\n            # Solve for t: dst_mean = R @ src_mean + t\n            t = dst_mean - R @ src_mean\n\n            # Build homogeneous matrix\n            A = np.eye(3)\n            A[:2, :2] = R\n            A[:2, 2] = t\n\n            return Affine2D(A)\n\n        else:  # similarity\n            # Similarity: rotation + uniform scale + translation\n            # Estimate scale: ratio of RMS distances from centroid\n            src_rms = np.sqrt(np.mean(np.sum(src_centered**2, axis=1)))\n            dst_rms = np.sqrt(np.mean(np.sum(dst_centered**2, axis=1)))\n\n            if src_rms &lt; 1e-10:\n                raise ValueError(\"Source points are degenerate (all at same location)\")\n\n            scale = dst_rms / src_rms\n\n            # Build transformation: T(x) = scale * R @ x + t\n            # where t = dst_mean - scale * R @ src_mean\n            t = dst_mean - scale * (R @ src_mean)\n\n            A = np.eye(3)\n            A[:2, :2] = scale * R\n            A[:2, 2] = t\n\n            return Affine2D(A)\n\n    elif kind == \"affine\":\n        if n_points &lt; 3:\n            raise ValueError(\n                f\"affine transform requires at least 3 point pairs, got {n_points}\"\n            )\n\n        # Solve affine transform using least squares\n        # T(x, y) = [a, b, tx] @ [x, y, 1]^T  for x-coordinate\n        #           [c, d, ty] @ [x, y, 1]^T  for y-coordinate\n\n        # Build design matrix: [x, y, 1] for each point\n        X = np.c_[src, np.ones(n_points)]  # (N, 3)\n\n        # Solve for each row of transformation matrix independently\n        # For x: [a, b, tx] = argmin ||X @ [a, b, tx]^T - dst_x||^2\n        # For y: [c, d, ty] = argmin ||X @ [c, d, ty]^T - dst_y||^2\n        params_x = np.linalg.lstsq(X, dst[:, 0], rcond=None)[0]  # [a, b, tx]\n        params_y = np.linalg.lstsq(X, dst[:, 1], rcond=None)[0]  # [c, d, ty]\n\n        # Build homogeneous matrix\n        A = np.eye(3)\n        A[0, :] = params_x  # [a, b, tx]\n        A[1, :] = params_y  # [c, d, ty]\n\n        return Affine2D(A)\n\n    else:\n        raise ValueError(\n            f\"Invalid kind: {kind!r}. Must be 'rigid', 'similarity', or 'affine'.\"\n        )\n</code></pre>"},{"location":"api/neurospatial/_constants/","title":"<code>neurospatial._constants</code>","text":""},{"location":"api/neurospatial/_constants/#neurospatial._constants","title":"_constants","text":"<p>Numerical constants and tolerances for neurospatial.</p> <p>This module defines all numerical tolerances used throughout the package for consistent behavior across geometric operations, equality checks, and numerical stability.</p> <p>All magic numbers should be imported from this module to ensure consistency and make it easier to tune parameters globally.</p>"},{"location":"api/neurospatial/_logging/","title":"<code>neurospatial._logging</code>","text":""},{"location":"api/neurospatial/_logging/#neurospatial._logging","title":"_logging","text":"<p>Structured logging infrastructure for neurospatial.</p> <p>This module provides a centralized logging system for the neurospatial package. By default, logging is disabled (NullHandler), but users can enable it by configuring the root logger.</p> <p>Examples:</p> <p>Enable logging to console::</p> <pre><code>import logging\n\nlogging.basicConfig(level=logging.INFO)\n\nfrom neurospatial import Environment\n\nenv = Environment.from_samples(data, bin_size=2.0)\n# INFO:neurospatial:Building layout: regular_grid\n# INFO:neurospatial:Environment created: 245 bins, 2 dims\n</code></pre> <p>Enable logging with more detail::</p> <pre><code>import logging\n\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n)\n</code></pre> <p>Filter to only neurospatial logs::</p> <pre><code>import logging\n\nneurospatial_logger = logging.getLogger(\"neurospatial\")\nneurospatial_logger.setLevel(logging.INFO)\nhandler = logging.StreamHandler()\nhandler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\nneurospatial_logger.addHandler(handler)\n</code></pre>"},{"location":"api/neurospatial/_logging/#neurospatial._logging-functions","title":"Functions","text":""},{"location":"api/neurospatial/_logging/#neurospatial._logging.log_layout_build","title":"log_layout_build","text":"<pre><code>log_layout_build(layout_type: str, params: dict[str, Any]) -&gt; None\n</code></pre> <p>Log layout engine build operation.</p> <p>Parameters:</p> Name Type Description Default <code>layout_type</code> <code>str</code> <p>Type of layout being built (e.g., 'regular_grid', 'hexagonal').</p> required <code>params</code> <code>dict</code> <p>Parameters used to build the layout.</p> required Source code in <code>src/neurospatial/_logging.py</code> <pre><code>def log_layout_build(layout_type: str, params: dict[str, Any]) -&gt; None:\n    \"\"\"Log layout engine build operation.\n\n    Parameters\n    ----------\n    layout_type : str\n        Type of layout being built (e.g., 'regular_grid', 'hexagonal').\n    params : dict\n        Parameters used to build the layout.\n    \"\"\"\n    logger.info(\n        f\"Building layout: {layout_type}\",\n        extra={\"layout_type\": layout_type, \"params\": params},\n    )\n</code></pre>"},{"location":"api/neurospatial/_logging/#neurospatial._logging.log_graph_validation","title":"log_graph_validation","text":"<pre><code>log_graph_validation(n_nodes: int, n_edges: int, n_dims: int) -&gt; None\n</code></pre> <p>Log graph validation operation.</p> <p>Parameters:</p> Name Type Description Default <code>n_nodes</code> <code>int</code> <p>Number of nodes in the connectivity graph.</p> required <code>n_edges</code> <code>int</code> <p>Number of edges in the connectivity graph.</p> required <code>n_dims</code> <code>int</code> <p>Number of spatial dimensions.</p> required Source code in <code>src/neurospatial/_logging.py</code> <pre><code>def log_graph_validation(n_nodes: int, n_edges: int, n_dims: int) -&gt; None:\n    \"\"\"Log graph validation operation.\n\n    Parameters\n    ----------\n    n_nodes : int\n        Number of nodes in the connectivity graph.\n    n_edges : int\n        Number of edges in the connectivity graph.\n    n_dims : int\n        Number of spatial dimensions.\n    \"\"\"\n    logger.debug(\n        f\"Validating connectivity graph: {n_nodes} nodes, {n_edges} edges, {n_dims}D\",\n        extra={\"n_nodes\": n_nodes, \"n_edges\": n_edges, \"n_dims\": n_dims},\n    )\n</code></pre>"},{"location":"api/neurospatial/_logging/#neurospatial._logging.log_environment_created","title":"log_environment_created","text":"<pre><code>log_environment_created(env_type: str, n_bins: int, n_dims: int, env_name: str | None = None) -&gt; None\n</code></pre> <p>Log environment creation.</p> <p>Parameters:</p> Name Type Description Default <code>env_type</code> <code>str</code> <p>Type of environment (layout type tag).</p> required <code>n_bins</code> <code>int</code> <p>Number of bins in the environment.</p> required <code>n_dims</code> <code>int</code> <p>Number of spatial dimensions.</p> required <code>env_name</code> <code>str or None</code> <p>Optional name of the environment.</p> <code>None</code> Source code in <code>src/neurospatial/_logging.py</code> <pre><code>def log_environment_created(\n    env_type: str, n_bins: int, n_dims: int, env_name: str | None = None\n) -&gt; None:\n    \"\"\"Log environment creation.\n\n    Parameters\n    ----------\n    env_type : str\n        Type of environment (layout type tag).\n    n_bins : int\n        Number of bins in the environment.\n    n_dims : int\n        Number of spatial dimensions.\n    env_name : str or None\n        Optional name of the environment.\n    \"\"\"\n    name_str = f\" '{env_name}'\" if env_name else \"\"\n    logger.info(\n        f\"Environment created{name_str}: {n_bins} bins, {n_dims}D\",\n        extra={\n            \"type\": env_type,\n            \"n_bins\": n_bins,\n            \"n_dims\": n_dims,\n            \"env_name\": env_name,\n        },\n    )\n</code></pre>"},{"location":"api/neurospatial/_logging/#neurospatial._logging.log_composite_build","title":"log_composite_build","text":"<pre><code>log_composite_build(n_subenvs: int, total_bins: int, n_bridges: int) -&gt; None\n</code></pre> <p>Log composite environment construction.</p> <p>Parameters:</p> Name Type Description Default <code>n_subenvs</code> <code>int</code> <p>Number of sub-environments merged.</p> required <code>total_bins</code> <code>int</code> <p>Total number of bins in composite.</p> required <code>n_bridges</code> <code>int</code> <p>Number of bridge edges created.</p> required Source code in <code>src/neurospatial/_logging.py</code> <pre><code>def log_composite_build(n_subenvs: int, total_bins: int, n_bridges: int) -&gt; None:\n    \"\"\"Log composite environment construction.\n\n    Parameters\n    ----------\n    n_subenvs : int\n        Number of sub-environments merged.\n    total_bins : int\n        Total number of bins in composite.\n    n_bridges : int\n        Number of bridge edges created.\n    \"\"\"\n    logger.info(\n        f\"CompositeEnvironment created: {n_subenvs} sub-envs, \"\n        f\"{total_bins} total bins, {n_bridges} bridges\",\n        extra={\n            \"n_subenvs\": n_subenvs,\n            \"total_bins\": total_bins,\n            \"n_bridges\": n_bridges,\n        },\n    )\n</code></pre>"},{"location":"api/neurospatial/_logging/#neurospatial._logging.log_region_added","title":"log_region_added","text":"<pre><code>log_region_added(region_name: str, region_kind: str, env_name: str | None = None) -&gt; None\n</code></pre> <p>Log region addition to environment.</p> <p>Parameters:</p> Name Type Description Default <code>region_name</code> <code>str</code> <p>Name of the region added.</p> required <code>region_kind</code> <code>str</code> <p>Type of region ('point' or 'polygon').</p> required <code>env_name</code> <code>str or None</code> <p>Optional name of the environment.</p> <code>None</code> Source code in <code>src/neurospatial/_logging.py</code> <pre><code>def log_region_added(\n    region_name: str, region_kind: str, env_name: str | None = None\n) -&gt; None:\n    \"\"\"Log region addition to environment.\n\n    Parameters\n    ----------\n    region_name : str\n        Name of the region added.\n    region_kind : str\n        Type of region ('point' or 'polygon').\n    env_name : str or None\n        Optional name of the environment.\n    \"\"\"\n    env_str = f\" to '{env_name}'\" if env_name else \"\"\n    logger.debug(\n        f\"Region '{region_name}' ({region_kind}) added{env_str}\",\n        extra={\n            \"region_name\": region_name,\n            \"region_kind\": region_kind,\n            \"env_name\": env_name,\n        },\n    )\n</code></pre>"},{"location":"api/neurospatial/_logging/#neurospatial._logging.log_spatial_query","title":"log_spatial_query","text":"<pre><code>log_spatial_query(query_type: str, n_points: int, n_results: int) -&gt; None\n</code></pre> <p>Log spatial query operation.</p> <p>Parameters:</p> Name Type Description Default <code>query_type</code> <code>str</code> <p>Type of query ('bin_at', 'contains', 'neighbors', etc.).</p> required <code>n_points</code> <code>int</code> <p>Number of points queried.</p> required <code>n_results</code> <code>int</code> <p>Number of results returned.</p> required Source code in <code>src/neurospatial/_logging.py</code> <pre><code>def log_spatial_query(query_type: str, n_points: int, n_results: int) -&gt; None:\n    \"\"\"Log spatial query operation.\n\n    Parameters\n    ----------\n    query_type : str\n        Type of query ('bin_at', 'contains', 'neighbors', etc.).\n    n_points : int\n        Number of points queried.\n    n_results : int\n        Number of results returned.\n    \"\"\"\n    logger.debug(\n        f\"Spatial query '{query_type}': {n_points} points -&gt; {n_results} results\",\n        extra={\"query_type\": query_type, \"n_points\": n_points, \"n_results\": n_results},\n    )\n</code></pre>"},{"location":"api/neurospatial/_logging/#neurospatial._logging.log_performance_warning","title":"log_performance_warning","text":"<pre><code>log_performance_warning(operation: str, duration_ms: float, threshold_ms: float) -&gt; None\n</code></pre> <p>Log performance warning when operation exceeds threshold.</p> <p>Parameters:</p> Name Type Description Default <code>operation</code> <code>str</code> <p>Name of the operation.</p> required <code>duration_ms</code> <code>float</code> <p>Actual duration in milliseconds.</p> required <code>threshold_ms</code> <code>float</code> <p>Expected threshold in milliseconds.</p> required Source code in <code>src/neurospatial/_logging.py</code> <pre><code>def log_performance_warning(\n    operation: str, duration_ms: float, threshold_ms: float\n) -&gt; None:\n    \"\"\"Log performance warning when operation exceeds threshold.\n\n    Parameters\n    ----------\n    operation : str\n        Name of the operation.\n    duration_ms : float\n        Actual duration in milliseconds.\n    threshold_ms : float\n        Expected threshold in milliseconds.\n    \"\"\"\n    logger.warning(\n        f\"Performance warning: {operation} took {duration_ms:.1f}ms \"\n        f\"(expected &lt;{threshold_ms:.1f}ms)\",\n        extra={\n            \"operation\": operation,\n            \"duration_ms\": duration_ms,\n            \"threshold_ms\": threshold_ms,\n        },\n    )\n</code></pre>"},{"location":"api/neurospatial/alignment/","title":"<code>neurospatial.alignment</code>","text":""},{"location":"api/neurospatial/alignment/#neurospatial.alignment","title":"alignment","text":"<p>Alignment and Probability Mapping Between Spatial Environments.</p> <p>This module provides functionalities to align and map data, particularly probability distributions, between different spatial <code>Environment</code> instances defined in the <code>neurospatial</code> package.</p> <p>Core capabilities include:</p> <ol> <li> <p>Geometric Transformations:</p> <ul> <li>Applying similarity transformations (rotation, scaling, and translation)     to sets of points, typically the bin centers of a source <code>Environment</code>,     to align them with a target <code>Environment</code>'s coordinate space.</li> <li>Helper functions to create 2D rotation matrices from angles or for     common rotations (e.g., 90 degrees).</li> </ul> </li> <li> <p>Probability Mapping:</p> <ul> <li>The primary method, <code>map_probabilities_to_nearest_target_bin</code>,     transfers probabilities from a source environment to a target environment.     For each bin in the (optionally transformed) source environment, its     probability is assigned to the spatially nearest bin in the target     environment. If multiple source bins map to the same target bin,     their probabilities are summed. This is useful when comparing or     aggregating data from slightly different discretizations or     experimental setups of the same underlying space.</li> </ul> </li> </ol> <p>This module is designed to assist in scenarios such as:     * Comparing probability distributions (e.g., place fields (spatial firing         patterns of neurons), occupancy maps) from experiments where the recording         environment might have undergone slight shifts, rotations, or scaling.     * Mapping data from one type of spatial discretization (e.g., a fine grid)         to another (e.g., a coarser grid or a different layout type), while         attempting to preserve the spatial correspondence of the data.</p> <p>The functions generally expect <code>Environment</code> objects that have been \"fitted\" (i.e., their <code>bin_centers</code> attribute is populated) and probability arrays that correspond to the active bins of these environments.</p>"},{"location":"api/neurospatial/alignment/#neurospatial.alignment-classes","title":"Classes","text":""},{"location":"api/neurospatial/alignment/#neurospatial.alignment.ProbabilityMappingParams","title":"ProbabilityMappingParams  <code>dataclass</code>","text":"<pre><code>ProbabilityMappingParams(source_env: Environment, target_env: Environment, source_probs: NDArray[float64], mode: Literal['nearest', 'inverse-distance-weighted'] = 'nearest', n_neighbors: int = 1)\n</code></pre> <p>Validated parameters for probability mapping between environments.</p> <p>This dataclass encapsulates and validates all parameters required for mapping probabilities from a source environment to a target environment. Validation occurs automatically in post_init.</p> <p>Parameters:</p> Name Type Description Default <code>source_env</code> <code>Environment</code> <p>Source environment (must be fitted).</p> required <code>target_env</code> <code>Environment</code> <p>Target environment (must be fitted).</p> required <code>source_probs</code> <code>NDArray[float64]</code> <p>Source probability array, shape (n_source_bins,).</p> required <code>mode</code> <code>Literal['nearest', 'inverse-distance-weighted']</code> <p>Mapping mode.</p> <code>'nearest'</code> <code>n_neighbors</code> <code>int</code> <p>Number of neighbors for inverse-distance-weighted mode.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any validation check fails.</p>"},{"location":"api/neurospatial/alignment/#neurospatial.alignment.ProbabilityMappingParams-attributes","title":"Attributes","text":""},{"location":"api/neurospatial/alignment/#neurospatial.alignment.ProbabilityMappingParams.n_source_bins","title":"n_source_bins  <code>property</code>","text":"<pre><code>n_source_bins: int\n</code></pre> <p>Number of bins in source environment.</p>"},{"location":"api/neurospatial/alignment/#neurospatial.alignment.ProbabilityMappingParams.n_target_bins","title":"n_target_bins  <code>property</code>","text":"<pre><code>n_target_bins: int\n</code></pre> <p>Number of bins in target environment.</p>"},{"location":"api/neurospatial/alignment/#neurospatial.alignment-functions","title":"Functions","text":""},{"location":"api/neurospatial/alignment/#neurospatial.alignment.get_2d_rotation_matrix","title":"get_2d_rotation_matrix","text":"<pre><code>get_2d_rotation_matrix(angle_degrees: float) -&gt; NDArray[np.float64]\n</code></pre> <p>Creates a 2D counter-clockwise rotation matrix for a given angle.</p> <p>Parameters:</p> Name Type Description Default <code>angle_degrees</code> <code>float</code> <p>The rotation angle in degrees. Positive for counter-clockwise.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The 2x2 rotation matrix.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; rotation_matrix = get_2d_rotation_matrix(90)\n&gt;&gt;&gt; print(rotation_matrix)\n[[ 0. -1.]\n [ 1.  0.]]\n</code></pre> <p>Rotate a point 90 degrees counter-clockwise:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; point = np.array([[1, 0]])\n&gt;&gt;&gt; rotated = point @ rotation_matrix.T\n&gt;&gt;&gt; print(rotated)\n[[0. 1.]]\n</code></pre> Source code in <code>src/neurospatial/alignment.py</code> <pre><code>def get_2d_rotation_matrix(angle_degrees: float) -&gt; NDArray[np.float64]:\n    \"\"\"Creates a 2D counter-clockwise rotation matrix for a given angle.\n\n    Parameters\n    ----------\n    angle_degrees : float\n        The rotation angle in degrees. Positive for counter-clockwise.\n\n    Returns\n    -------\n    NDArray[np.float64]\n        The 2x2 rotation matrix.\n\n    Examples\n    --------\n    &gt;&gt;&gt; rotation_matrix = get_2d_rotation_matrix(90)\n    &gt;&gt;&gt; print(rotation_matrix)  # doctest: +SKIP\n    [[ 0. -1.]\n     [ 1.  0.]]\n\n    Rotate a point 90 degrees counter-clockwise:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; point = np.array([[1, 0]])\n    &gt;&gt;&gt; rotated = point @ rotation_matrix.T\n    &gt;&gt;&gt; print(rotated)  # doctest: +SKIP\n    [[0. 1.]]\n\n    \"\"\"\n    angle_radians = np.deg2rad(angle_degrees)\n    cos_theta = np.cos(angle_radians)\n    sin_theta = np.sin(angle_radians)\n\n    rotation_matrix = np.array([[cos_theta, -sin_theta], [sin_theta, cos_theta]])\n    return rotation_matrix\n</code></pre>"},{"location":"api/neurospatial/alignment/#neurospatial.alignment.apply_similarity_transform","title":"apply_similarity_transform","text":"<pre><code>apply_similarity_transform(points: NDArray[float64], rotation_matrix: NDArray[float64], scale_factor: float, translation_vector: NDArray[float64]) -&gt; NDArray[np.float64]\n</code></pre> <p>Applies a similarity transformation (rotation, scaling, translation) to a set of points. The transformation is applied as: P_transformed = scale * (R @ P.T).T + t</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>NDArray[float64]</code> <p>Points to transform, shape (n_points, n_dims).</p> required <code>rotation_matrix</code> <code>NDArray[float64]</code> <p>Rotation matrix, shape (n_dims, n_dims).</p> required <code>scale_factor</code> <code>float</code> <p>Uniform scaling factor.</p> required <code>translation_vector</code> <code>NDArray[float64]</code> <p>Translation vector, shape (n_dims,).</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>Transformed points, shape (n_points, n_dims). If <code>points</code> is empty, returns an empty array of shape (0, n_dims).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If dimensionality mismatches occur or rotation matrix is not square.</p> <p>Examples:</p> <p>Apply a combined rotation, scale, and translation:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial.alignment import (\n...     apply_similarity_transform,\n...     get_2d_rotation_matrix,\n... )\n&gt;&gt;&gt; # Define points\n&gt;&gt;&gt; points = np.array([[1, 0], [0, 1], [1, 1]])\n&gt;&gt;&gt; # Rotate 90 degrees\n&gt;&gt;&gt; rotation = get_2d_rotation_matrix(90)\n&gt;&gt;&gt; # Scale by 2\n&gt;&gt;&gt; scale = 2.0\n&gt;&gt;&gt; # Translate by (10, 20)\n&gt;&gt;&gt; translation = np.array([10, 20])\n&gt;&gt;&gt; transformed = apply_similarity_transform(points, rotation, scale, translation)\n&gt;&gt;&gt; print(transformed)\n[[10. 22.]\n [ 8. 20.]\n [ 8. 22.]]\n</code></pre> Source code in <code>src/neurospatial/alignment.py</code> <pre><code>def apply_similarity_transform(\n    points: NDArray[np.float64],\n    rotation_matrix: NDArray[np.float64],\n    scale_factor: float,\n    translation_vector: NDArray[np.float64],\n) -&gt; NDArray[np.float64]:\n    \"\"\"Applies a similarity transformation (rotation, scaling, translation)\n    to a set of points.\n    The transformation is applied as: P_transformed = scale * (R @ P.T).T + t\n\n    Parameters\n    ----------\n    points : NDArray[np.float64]\n        Points to transform, shape (n_points, n_dims).\n    rotation_matrix : NDArray[np.float64]\n        Rotation matrix, shape (n_dims, n_dims).\n    scale_factor : float\n        Uniform scaling factor.\n    translation_vector : NDArray[np.float64]\n        Translation vector, shape (n_dims,).\n\n    Returns\n    -------\n    NDArray[np.float64]\n        Transformed points, shape (n_points, n_dims).\n        If `points` is empty, returns an empty array of shape (0, n_dims).\n\n    Raises\n    ------\n    ValueError\n        If dimensionality mismatches occur or rotation matrix is not square.\n\n    Examples\n    --------\n    Apply a combined rotation, scale, and translation:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial.alignment import (\n    ...     apply_similarity_transform,\n    ...     get_2d_rotation_matrix,\n    ... )\n    &gt;&gt;&gt; # Define points\n    &gt;&gt;&gt; points = np.array([[1, 0], [0, 1], [1, 1]])\n    &gt;&gt;&gt; # Rotate 90 degrees\n    &gt;&gt;&gt; rotation = get_2d_rotation_matrix(90)\n    &gt;&gt;&gt; # Scale by 2\n    &gt;&gt;&gt; scale = 2.0\n    &gt;&gt;&gt; # Translate by (10, 20)\n    &gt;&gt;&gt; translation = np.array([10, 20])\n    &gt;&gt;&gt; transformed = apply_similarity_transform(points, rotation, scale, translation)\n    &gt;&gt;&gt; print(transformed)\n    [[10. 22.]\n     [ 8. 20.]\n     [ 8. 22.]]\n\n    \"\"\"\n    n_dims = points.shape[1]\n    if points.ndim != 2:\n        raise ValueError(f\"Points must be a 2D array, got shape {points.shape}\")\n\n    if points.shape[0] == 0:\n        return np.zeros((0, n_dims), dtype=points.dtype)\n\n    if rotation_matrix.shape != (n_dims, n_dims):\n        raise ValueError(\n            f\"Rotation matrix shape {rotation_matrix.shape} \"\n            f\"is not compatible with points_dims {n_dims}.\",\n        )\n    if not np.isscalar(scale_factor):\n        raise ValueError(\"Scale factor must be a scalar.\")\n    if translation_vector.shape != (n_dims,):\n        raise ValueError(\n            f\"Translation vector shape {translation_vector.shape} \"\n            f\"is not compatible with points_dims {n_dims}.\",\n        )\n\n    # 1. Rotate\n    rotated_points = (rotation_matrix @ points.T).T\n    # 2. Scale\n    scaled_points = scale_factor * rotated_points\n    # 3. Translate\n    transformed_points = scaled_points + translation_vector\n    return np.asarray(transformed_points, dtype=np.float64)\n</code></pre>"},{"location":"api/neurospatial/alignment/#neurospatial.alignment.map_probabilities_to_nearest_target_bin","title":"map_probabilities_to_nearest_target_bin","text":"<pre><code>map_probabilities_to_nearest_target_bin(source_env: Environment, target_env: Environment, source_probs: NDArray[float64], *, mode: Literal['nearest', 'inverse-distance-weighted'] = 'nearest', n_neighbors: int = 1, eps: float = IDW_MIN_DISTANCE, source_scale_factor: float = 1.0, source_rotation_matrix: NDArray[float64] | None = None, source_translation_vector: NDArray[float64] | None = None) -&gt; NDArray[np.float64]\n</code></pre> <p>Map probabilities on source_env onto target_env, with optional scaling/translation of the source bin-centers beforehand.</p> <p>Parameters:</p> Name Type Description Default <code>source_env</code> <code>Environment</code> <p>A fitted Environment whose bins currently have centers <code>source_env.bin_centers</code>.</p> required <code>target_env</code> <code>Environment</code> <p>A fitted Environment onto whose bins we want to map probabilities.</p> required <code>source_probs</code> <code>NDArray[float64]</code> <p>1D array of length source_env.n_bins (nonnegative).</p> required <code>mode</code> <code>('nearest', 'inverse-distance-weighted')</code> <ul> <li>\"nearest\": each source bin's mass \u2192 its single nearest target bin.</li> <li>\"inverse-distance-weighted\" : spread each source bin's mass over     its <code>n_neighbors</code> nearest target bins,     weighted by inverse distance, and summing contributions.</li> </ul> <code>'nearest'</code> <code>n_neighbors</code> <code>int</code> <p>Number of neighbors to use when mode=\"inverse-distance-weighted\" (ignored if mode=\"nearest\").</p> <code>1</code> <code>eps</code> <code>float</code> <p>Small constant to avoid division by zero in IDW weights.</p> <code>IDW_MIN_DISTANCE</code> <code>source_scale_factor</code> <code>float</code> <p>Multiply every source bin-center by this scalar before querying.</p> <code>1.0</code> <code>source_rotation_matrix</code> <code>Optional[NDArray[float64]]</code> <p>If not None, must be a 2x2 rotation matrix (shape (2, 2)) for 2D environments. Applied to source bin centers after scaling but before translation.</p> <code>None</code> <code>source_translation_vector</code> <code>Optional[NDArray[float64]]</code> <p>If not None, must be a 1D array of length n_dims. Applied to source bin centers after scaling and rotation.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>target_probabilities</code> <code>(array, shape(n_target_bins))</code> <p>Each entry is the sum of <code>source_probabilities</code> whose (transformed) source bin center is nearest to that target bin center. If <code>n_target_bins == 0</code>, returns an empty array of shape (0,).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If either <code>source_env</code> or <code>target_env</code> is not fitted.</p> <code>ValueError</code> <p>If <code>source_probabilities</code> has incorrect shape, or if dims mismatch.</p> <p>Examples:</p> <p>Map probabilities between two environments with different bin sizes:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; from neurospatial.alignment import map_probabilities_to_nearest_target_bin\n&gt;&gt;&gt; # Create two environments with different bin sizes\n&gt;&gt;&gt; data = np.random.rand(1000, 2) * 100\n&gt;&gt;&gt; source_env = Environment.from_samples(data, bin_size=5.0)\n&gt;&gt;&gt; target_env = Environment.from_samples(data, bin_size=10.0)\n&gt;&gt;&gt; # Create probability distribution for source\n&gt;&gt;&gt; source_probs = np.ones(source_env.n_bins) / source_env.n_bins\n&gt;&gt;&gt; # Map to target environment\n&gt;&gt;&gt; target_probs = map_probabilities_to_nearest_target_bin(\n...     source_env, target_env, source_probs\n... )\n&gt;&gt;&gt; target_probs.shape[0] == target_env.n_bins\nTrue\n&gt;&gt;&gt; np.allclose(target_probs.sum(), 1.0)\nTrue\n</code></pre> <p>Map with rotation and scaling:</p> <pre><code>&gt;&gt;&gt; from neurospatial.alignment import get_2d_rotation_matrix\n&gt;&gt;&gt; rotation = get_2d_rotation_matrix(45)  # 45 degree rotation\n&gt;&gt;&gt; target_probs = map_probabilities_to_nearest_target_bin(\n...     source_env,\n...     target_env,\n...     source_probs,\n...     source_rotation_matrix=rotation,\n...     source_scale_factor=0.9,\n... )\n</code></pre> Source code in <code>src/neurospatial/alignment.py</code> <pre><code>def map_probabilities_to_nearest_target_bin(\n    source_env: Environment,\n    target_env: Environment,\n    source_probs: NDArray[np.float64],\n    *,\n    mode: Literal[\"nearest\", \"inverse-distance-weighted\"] = \"nearest\",\n    n_neighbors: int = 1,\n    eps: float = IDW_MIN_DISTANCE,\n    source_scale_factor: float = 1.0,\n    source_rotation_matrix: NDArray[np.float64] | None = None,\n    source_translation_vector: NDArray[np.float64] | None = None,\n) -&gt; NDArray[np.float64]:\n    \"\"\"Map probabilities on source_env onto target_env, with optional scaling/translation\n    of the source bin-centers beforehand.\n\n    Parameters\n    ----------\n    source_env : Environment\n        A fitted Environment whose bins currently have centers `source_env.bin_centers`.\n    target_env : Environment\n        A fitted Environment onto whose bins we want to map probabilities.\n    source_probs : NDArray[np.float64]\n        1D array of length source_env.n_bins (nonnegative).\n    mode : {'nearest', 'inverse-distance-weighted'}\n        - \"nearest\": each source bin's mass \u2192 its single nearest target bin.\n        - \"inverse-distance-weighted\" : spread each source bin's mass over\n            its `n_neighbors` nearest target bins,\n            weighted by inverse distance, and summing contributions.\n    n_neighbors : int\n        Number of neighbors to use when mode=\"inverse-distance-weighted\"\n        (ignored if mode=\"nearest\").\n    eps : float, default=IDW_MIN_DISTANCE\n        Small constant to avoid division by zero in IDW weights.\n    source_scale_factor : float\n        Multiply every source bin-center by this scalar before querying.\n    source_rotation_matrix : Optional[NDArray[np.float64]]\n        If not None, must be a 2x2 rotation matrix (shape (2, 2)) for 2D environments.\n        Applied to source bin centers after scaling but before translation.\n    source_translation_vector : Optional[NDArray[np.float64]]\n        If not None, must be a 1D array of length n_dims. Applied to source bin centers\n        after scaling and rotation.\n\n    Returns\n    -------\n    target_probabilities : array, shape (n_target_bins,)\n        Each entry is the sum of `source_probabilities` whose (transformed)\n        source bin center is nearest to that target bin center. If `n_target_bins == 0`,\n        returns an empty array of shape (0,).\n\n    Raises\n    ------\n    RuntimeError\n        If either `source_env` or `target_env` is not fitted.\n    ValueError\n        If `source_probabilities` has incorrect shape, or if dims mismatch.\n\n    Examples\n    --------\n    Map probabilities between two environments with different bin sizes:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; from neurospatial.alignment import map_probabilities_to_nearest_target_bin\n    &gt;&gt;&gt; # Create two environments with different bin sizes\n    &gt;&gt;&gt; data = np.random.rand(1000, 2) * 100\n    &gt;&gt;&gt; source_env = Environment.from_samples(data, bin_size=5.0)\n    &gt;&gt;&gt; target_env = Environment.from_samples(data, bin_size=10.0)\n    &gt;&gt;&gt; # Create probability distribution for source\n    &gt;&gt;&gt; source_probs = np.ones(source_env.n_bins) / source_env.n_bins\n    &gt;&gt;&gt; # Map to target environment\n    &gt;&gt;&gt; target_probs = map_probabilities_to_nearest_target_bin(\n    ...     source_env, target_env, source_probs\n    ... )\n    &gt;&gt;&gt; target_probs.shape[0] == target_env.n_bins\n    True\n    &gt;&gt;&gt; np.allclose(target_probs.sum(), 1.0)\n    True\n\n    Map with rotation and scaling:\n\n    &gt;&gt;&gt; from neurospatial.alignment import get_2d_rotation_matrix\n    &gt;&gt;&gt; rotation = get_2d_rotation_matrix(45)  # 45 degree rotation\n    &gt;&gt;&gt; target_probs = map_probabilities_to_nearest_target_bin(\n    ...     source_env,\n    ...     target_env,\n    ...     source_probs,\n    ...     source_rotation_matrix=rotation,\n    ...     source_scale_factor=0.9,\n    ... )\n\n    \"\"\"\n    from scipy.spatial import cKDTree\n\n    # Validate inputs using dataclass\n    params = ProbabilityMappingParams(\n        source_env=source_env,\n        target_env=target_env,\n        source_probs=source_probs,\n        mode=mode,\n        n_neighbors=n_neighbors,\n    )\n    n_src = params.n_source_bins\n    n_tgt = params.n_target_bins\n\n    # Handle empty environments\n    if n_src == 0 or n_tgt == 0:\n        warnings.warn(\n            \"One of the environments has zero bins; returning zeros.\",\n            UserWarning,\n        )\n        return np.zeros(n_tgt, dtype=float)\n\n    # Transform source bin centers\n    src_centers = _transform_source_bin_centers(\n        source_env.bin_centers,\n        source_scale_factor,\n        source_rotation_matrix,\n        source_translation_vector,\n    )\n\n    # Build KDTree on target bin centers\n    try:\n        tree = cKDTree(target_env.bin_centers, leafsize=KDTREE_LEAF_SIZE)\n    except Exception as e:\n        warnings.warn(\n            f\"KDTree construction on target_env failed: {e}. Returning zeros.\",\n            RuntimeWarning,\n        )\n        return np.zeros(n_tgt, dtype=float)\n\n    # Perform the requested mapping\n    if mode == \"nearest\":\n        return _map_nearest_neighbor(tree, src_centers, source_probs, n_tgt)\n    if mode == \"inverse-distance-weighted\":\n        return _map_inverse_distance_weighted(\n            tree,\n            src_centers,\n            source_probs,\n            n_tgt,\n            n_neighbors,\n            eps,\n        )\n    raise ValueError(f\"Unrecognized mode '{mode}'.\")\n</code></pre>"},{"location":"api/neurospatial/calibration/","title":"<code>neurospatial.calibration</code>","text":""},{"location":"api/neurospatial/calibration/#neurospatial.calibration","title":"calibration","text":""},{"location":"api/neurospatial/calibration/#neurospatial.calibration-classes","title":"Classes","text":""},{"location":"api/neurospatial/calibration/#neurospatial.calibration-functions","title":"Functions","text":""},{"location":"api/neurospatial/calibration/#neurospatial.calibration.simple_scale","title":"simple_scale","text":"<pre><code>simple_scale(px_per_cm: float, offset_px: tuple[float, float] = (0.0, 0.0)) -&gt; Affine2D\n</code></pre> <p>Create a simple Affine2D transform that converts pixel units to centimeters.</p> <p>This returns an Affine2D matrix which, when applied to [x_px, y_px, 1]^T, yields coordinates in centimeters.</p> <p>Parameters:</p> Name Type Description Default <code>px_per_cm</code> <code>float</code> <p>Number of pixels per centimeter. Must be nonzero.</p> required <code>offset_px</code> <code>tuple of two floats, optional (default: (0.0, 0.0))</code> <p>A pixel offset (x_offset, y_offset). The returned transform first subtracts this offset (in pixels) before scaling.</p> <code>(0.0, 0.0)</code> <p>Returns:</p> Type Description <code>Affine2D</code> <p>An affine transformation that converts pixel coordinates to centimeters.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>px_per_cm</code> is zero.</p> Notes <p>The returned transformation represents the following matrix operation::</p> <pre><code>[x_cm]   [1/px_per_cm      0       -offset_px[0]/px_per_cm]   [x_px]\n[y_cm] = [     0       1/px_per_cm  -offset_px[1]/px_per_cm] * [y_px]\n[ 1  ]   [     0            0                  1            ]   [ 1  ]\n</code></pre> Source code in <code>src/neurospatial/calibration.py</code> <pre><code>def simple_scale(\n    px_per_cm: float,\n    offset_px: tuple[float, float] = (0.0, 0.0),\n) -&gt; Affine2D:\n    \"\"\"Create a simple Affine2D transform that converts pixel units to centimeters.\n\n    This returns an Affine2D matrix which, when applied to [x_px, y_px, 1]^T,\n    yields coordinates in centimeters.\n\n    Parameters\n    ----------\n    px_per_cm : float\n        Number of pixels per centimeter. Must be nonzero.\n    offset_px : tuple of two floats, optional (default: (0.0, 0.0))\n        A pixel offset (x_offset, y_offset). The returned transform first\n        subtracts this offset (in pixels) before scaling.\n\n    Returns\n    -------\n    Affine2D\n        An affine transformation that converts pixel coordinates to centimeters.\n\n    Raises\n    ------\n    ValueError\n        If `px_per_cm` is zero.\n\n    Notes\n    -----\n    The returned transformation represents the following matrix operation::\n\n        [x_cm]   [1/px_per_cm      0       -offset_px[0]/px_per_cm]   [x_px]\n        [y_cm] = [     0       1/px_per_cm  -offset_px[1]/px_per_cm] * [y_px]\n        [ 1  ]   [     0            0                  1            ]   [ 1  ]\n\n    \"\"\"\n    if px_per_cm == 0:\n        raise ValueError(\"px_per_cm must be nonzero to avoid division by zero.\")\n\n    # Compute scale factors\n    sx = sy = 1.0 / px_per_cm\n\n    # Ensure offset_px has exactly two values\n    try:\n        ox, oy = float(offset_px[0]), float(offset_px[1])\n    except (TypeError, IndexError, ValueError) as e:\n        raise ValueError(\n            f\"offset_px must be a tuple of two numeric values (x, y), got {type(offset_px).__name__} with value {offset_px}.\",\n        ) from e\n\n    # Build a 3\u00d73 affine matrix: scale then translate\n    tx = -ox * sx\n    ty = -oy * sy\n    A = np.array(\n        [\n            [sx, 0.0, tx],\n            [0.0, sy, ty],\n            [0.0, 0.0, 1.0],\n        ],\n        dtype=float,\n    )\n    return Affine2D(A)\n</code></pre>"},{"location":"api/neurospatial/composite/","title":"<code>neurospatial.composite</code>","text":""},{"location":"api/neurospatial/composite/#neurospatial.composite","title":"composite","text":"<p>CompositeEnvironment: merges multiple Environment instances into a single unified Environment-like API. Bridge edges between sub-environments are inferred automatically via mutual-nearest-neighbor (MNN).</p> <p>This class exposes the same public interface as the base <code>Environment</code> class:   - Properties: n_dims, n_bins, bin_centers, connectivity, is_1d, dimension_ranges,                 grid_edges, grid_shape, active_mask, regions   - Methods:    bin_at, contains, neighbors, distance_between, bin_center_of,                 bins_in_region, mask_for_region, shortest_path, info,                 save, load, bin_attributes, edge_attributes, plot</p> <p>(Note: factory methods like from_layout are not included, since CompositeEnvironment wraps pre-fitted sub-environments. plot_1d is not applicable for composite environments.)</p>"},{"location":"api/neurospatial/composite/#neurospatial.composite-classes","title":"Classes","text":""},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment","title":"CompositeEnvironment","text":"<pre><code>CompositeEnvironment(subenvs: list[Environment], auto_bridge: bool = True, max_mnn_distance: float | None = None, use_kdtree_query: bool = True)\n</code></pre> <p>A composite environment that merges multiple child Environment instances into one.</p> <p>It automatically infers \"bridge\" edges between every pair of sub-environments by finding mutually nearest neighbor bin-centers (MNN). It then presents the same interface as the base <code>Environment</code> class.</p> <p>Attributes:</p> Name Type Description <code>environments</code> <code>List[Environment]</code> <p>List of constituent Environment instances that make up the composite.</p> <code>name</code> <code>str</code> <p>Name for the composite environment.</p> <code>layout</code> <code>None</code> <p>Not applicable for composite environments (set to None).</p> <code>bin_centers</code> <code>NDArray[float64]</code> <p>Combined bin centers from all sub-environments, shape (n_total_bins, n_dims).</p> <code>connectivity</code> <code>Graph</code> <p>Combined connectivity graph with bridge edges between sub-environments.</p> <code>bridges</code> <code>List[Tuple[int, int, Dict[str, Any]]]</code> <p>List of bridge edges connecting different sub-environments. Each tuple is (source_bin, target_bin, edge_attributes).</p> <code>dimension_ranges</code> <code>Sequence[Tuple[float, float]]</code> <p>Combined dimension ranges across all sub-environments.</p> <code>grid_edges</code> <code>Tuple[NDArray[float64], ...] | None</code> <p>Not applicable for composite environments (set to None).</p> <code>grid_shape</code> <code>Tuple[int, ...] | None</code> <p>Not applicable for composite environments (set to None).</p> <code>active_mask</code> <code>NDArray[bool_] | None</code> <p>Not applicable for composite environments (set to None).</p> <code>regions</code> <code>Regions</code> <p>Manages symbolic spatial regions defined within this composite environment.</p> <code>is_1d</code> <code>bool</code> <p>True if all sub-environments are 1D, False otherwise.</p> <code>_environment_bin_ranges</code> <code>Dict[str, Tuple[int, int]]</code> <p>Mapping of sub-environment names to their bin index ranges in the composite.</p> <code>_layout_type_used</code> <code>str</code> <p>Always \"Composite\" for composite environments.</p> <code>_layout_params_used</code> <code>Dict[str, Any]</code> <p>Parameters used to construct the composite.</p> <p>Build a CompositeEnvironment from a list of pre-fitted Environment instances.</p> <p>Parameters:</p> Name Type Description Default <code>subenvs</code> <code>List[Environment]</code> <p>A list of fitted Environment objects. All must share the same n_dims.</p> required <code>auto_bridge</code> <code>bool</code> <p>If True, automatically infer \"bridge edges\" between each pair of sub-environments using a mutual nearest-neighbor heuristic on their bin_centers.</p> <code>True</code> <code>max_mnn_distance</code> <code>Optional[float]</code> <p>If provided, any automatically inferred bridge whose Euclidean distance exceeds this threshold is discarded. If None, no distance filtering is applied.</p> <code>None</code> <code>use_kdtree_query</code> <code>bool</code> <p>If True, use KDTree-based bin_at() for O(M log N) performance. If False, use sequential query through each sub-environment (original O(N\u00d7M) behavior).</p> <code>True</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If subenvs is not a list or tuple, or if any element is not an Environment instance.</p> <code>ValueError</code> <p>If subenvs is empty, if any environment is not fitted, or if environments have different dimensionalities.</p> Common Pitfalls <ol> <li> <p>Dimension mismatch: All sub-environments must have the same number of    dimensions (n_dims). Mixing 2D and 3D environments will raise an error.    Before creating the composite, verify that all environments have the same    n_dims property (e.g., check env1.n_dims == env2.n_dims). This typically    occurs when combining data from different recording modalities.</p> </li> <li> <p>No bridge edges found: If auto_bridge=True but the sub-environments    are very far apart, no bridge edges may be created, leaving the composite    disconnected. Try increasing max_mnn_distance to allow bridges over longer    distances, or set auto_bridge=False if you intend to work with disconnected    components. Use the bridges property to verify that bridge edges were created.</p> </li> <li> <p>Overlapping bins: If sub-environments have bins at the same or very    similar spatial locations, the composite will have duplicate bins at those    locations. This can lead to unexpected behavior in spatial queries. Ensure    that sub-environments represent distinct, non-overlapping spatial regions    (e.g., different arms of a maze, different rooms). Check bin_centers to    verify that bin locations are spatially separated.</p> </li> </ol> Source code in <code>src/neurospatial/composite.py</code> <pre><code>def __init__(\n    self,\n    subenvs: list[Environment],\n    auto_bridge: bool = True,\n    max_mnn_distance: float | None = None,\n    use_kdtree_query: bool = True,\n):\n    \"\"\"Build a CompositeEnvironment from a list of pre-fitted Environment instances.\n\n    Parameters\n    ----------\n    subenvs : List[Environment]\n        A list of fitted Environment objects. All must share the same n_dims.\n    auto_bridge : bool, default=True\n        If True, automatically infer \"bridge edges\" between each pair of sub-environments\n        using a mutual nearest-neighbor heuristic on their bin_centers.\n    max_mnn_distance : Optional[float]\n        If provided, any automatically inferred bridge whose Euclidean distance exceeds\n        this threshold is discarded. If None, no distance filtering is applied.\n    use_kdtree_query : bool, default=True\n        If True, use KDTree-based bin_at() for O(M log N) performance. If False,\n        use sequential query through each sub-environment (original O(N\u00d7M) behavior).\n\n    Raises\n    ------\n    TypeError\n        If subenvs is not a list or tuple, or if any element is not an Environment instance.\n    ValueError\n        If subenvs is empty, if any environment is not fitted, or if environments\n        have different dimensionalities.\n\n    Common Pitfalls\n    ---------------\n    1. **Dimension mismatch**: All sub-environments must have the same number of\n       dimensions (n_dims). Mixing 2D and 3D environments will raise an error.\n       Before creating the composite, verify that all environments have the same\n       n_dims property (e.g., check env1.n_dims == env2.n_dims). This typically\n       occurs when combining data from different recording modalities.\n\n    2. **No bridge edges found**: If auto_bridge=True but the sub-environments\n       are very far apart, no bridge edges may be created, leaving the composite\n       disconnected. Try increasing max_mnn_distance to allow bridges over longer\n       distances, or set auto_bridge=False if you intend to work with disconnected\n       components. Use the bridges property to verify that bridge edges were created.\n\n    3. **Overlapping bins**: If sub-environments have bins at the same or very\n       similar spatial locations, the composite will have duplicate bins at those\n       locations. This can lead to unexpected behavior in spatial queries. Ensure\n       that sub-environments represent distinct, non-overlapping spatial regions\n       (e.g., different arms of a maze, different rooms). Check bin_centers to\n       verify that bin locations are spatially separated.\n\n    \"\"\"\n    # Validate container type\n    if not isinstance(subenvs, (list, tuple)):\n        raise TypeError(\n            f\"subenvs must be a list or tuple of Environment instances, \"\n            f\"got {type(subenvs).__name__}. \"\n            f\"Did you pass a single Environment instead of a list? \"\n            f\"Use [env] to wrap it in a list.\"\n        )\n\n    # Validate not empty\n    if len(subenvs) == 0:\n        raise ValueError(\n            \"At least one sub-environment is required. Received empty list.\"\n        )\n\n    # Validate each element is Environment instance\n    for i, env in enumerate(subenvs):\n        if not isinstance(env, Environment):\n            raise TypeError(\n                f\"subenvs[{i}] must be an Environment instance, \"\n                f\"got {type(env).__name__}. \"\n                f\"All elements of subenvs must be Environment objects.\"\n            )\n\n    self._use_kdtree_query = use_kdtree_query\n\n    # Validate that all sub-environments share the same n_dims and are fitted\n    self._n_dims = subenvs[0].n_dims\n    if not subenvs[0]._is_fitted:\n        raise ValueError(\"Sub-environment 0 is not fitted.\")\n\n    for i, e in enumerate(subenvs[1:], 1):\n        if not e._is_fitted:\n            raise ValueError(f\"Sub-environment {i} is not fitted.\")\n        if e.n_dims != self._n_dims:\n            raise ValueError(\n                f\"All sub-environments must share the same n_dims. \"\n                f\"Env 0 has {self._n_dims}, Env {i} has {e.n_dims}.\\n\"\n                \"\\n\"\n                \"Common cause:\\n\"\n                \"  This typically occurs when mixing environments created from data with \"\n                \"different dimensionalities (e.g., 2D position tracking data and 3D spatial data).\\n\"\n                \"\\n\"\n                \"To fix:\\n\"\n                \"  1. Check that all data_samples arrays used to create environments have the same \"\n                \"number of columns (n_dims)\\n\"\n                \"  2. Ensure all environments represent the same spatial dimensionality \"\n                \"(all 2D or all 3D)\\n\"\n                \"  3. Verify each environment's n_dims property before creating the composite\"\n            )\n\n    # Build index offsets for each sub-environment\n    self._subenvs_info = []\n    offset = 0\n    for env in subenvs:\n        n_bins = env.bin_centers.shape[0]\n        self._subenvs_info.append(\n            {\"env\": env, \"start_idx\": offset, \"end_idx\": offset + n_bins - 1},\n        )\n        offset += n_bins\n    self._total_bins = offset\n\n    # Stack all bin_centers into one array of shape (N_total, n_dims)\n    self.bin_centers = np.vstack([env.bin_centers for env in subenvs])\n\n    # Build the composite connectivity graph (nodes only for now)\n    self.connectivity = nx.Graph()\n    self.connectivity.add_nodes_from(range(self._total_bins))\n\n    # Add each sub-environment\u2019s edges, reindexed by offset\n    for block in self._subenvs_info:\n        env_i = block[\"env\"]\n        base = block[\"start_idx\"]\n        for u, v, data in env_i.connectivity.edges(data=True):\n            self.connectivity.add_edge(u + base, v + base, **data)\n\n    # Infer MNN-based bridges if requested\n    self._bridge_list: list[tuple[tuple[int, int], tuple[int, int], float]] = []\n    if auto_bridge:\n        self._infer_mnn_bridges(max_mnn_distance)\n\n    # Build KDTree for optimized bin_at() if requested\n    self._kdtree: KDTree | None = None\n    if self._use_kdtree_query and self.bin_centers.shape[0] &gt; 0:\n        self._kdtree = KDTree(\n            self.bin_centers, leaf_size=KDTREE_COMPOSITE_LEAF_SIZE\n        )\n\n    # Properties to match Environment interface\n    self.is_1d = False\n    if self.bin_centers.shape[0] &gt; 0:\n        min_coords = np.min(self.bin_centers, axis=0)\n        max_coords = np.max(self.bin_centers, axis=0)\n        self.dimension_ranges = tuple(\n            (min_coords[i], max_coords[i]) for i in range(self._n_dims)\n        )\n    else:\n        self.dimension_ranges = (\n            tuple(\n                (np.nan, np.nan)\n                for _ in range(self._n_dims)  # Or None, as per Environment\n            )\n            if self._n_dims &gt; 0\n            else None\n        )\n    self.grid_edges = None\n    self.grid_shape = None\n    self.active_mask = None\n    # \u201call_regions\u201d will hold every Region from every sub\u2010environment\n    all_regions: list[Region] = []\n    for child in subenvs:\n        # child.regions is itself a Regions (mapping name \u2192 Region).\n        # We want to pull out each Region object\n        for reg in child.regions.values():\n            # If you suspect two children might have regions with the same name,\n            # you can either rename here (e.g. prefix with child.name) or let\n            # Regions(...) raise a KeyError. Below we simply re\u2010use the original name,\n            # assuming no collisions.\n            all_regions.append(reg)\n\n    # Now create a single Regions object containing every Region from every child\n    self.regions = Regions(all_regions)\n\n    self._layout_type_used = \"Composite\"\n    self._layout_params_used = {\n        \"num_sub_environments\": len(subenvs),\n        \"auto_bridge\": auto_bridge,\n        \"max_mnn_distance\": max_mnn_distance,\n        \"sub_environment_types\": [sub_env.layout_type for sub_env in subenvs],\n    }\n    self._is_fitted = (\n        True  # Composite environment is considered 'fitted' upon construction\n    )\n\n    # Log composite environment creation\n    n_bridges = len(self.bridges) if hasattr(self, \"bridges\") else 0\n    log_composite_build(\n        n_subenvs=len(subenvs),\n        total_bins=self._total_bins,\n        n_bridges=n_bridges,\n    )\n</code></pre>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment-attributes","title":"Attributes","text":""},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.n_dims","title":"n_dims  <code>property</code>","text":"<pre><code>n_dims: int\n</code></pre> <p>Number of spatial dimensions (same as each sub-environment).</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of spatial dimensions.</p>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.n_bins","title":"n_bins  <code>property</code>","text":"<pre><code>n_bins: int\n</code></pre> <p>Total number of active bins in the composite environment.</p> <p>Returns:</p> Type Description <code>int</code> <p>Total number of bins across all sub-environments.</p>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.layout_type","title":"layout_type  <code>property</code>","text":"<pre><code>layout_type: str\n</code></pre> <p>Returns the layout type, which is 'Composite'.</p>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.layout_parameters","title":"layout_parameters  <code>property</code>","text":"<pre><code>layout_parameters: dict[str, Any]\n</code></pre> <p>Returns parameters used to construct the CompositeEnvironment.</p>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment-functions","title":"Functions","text":""},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.bin_at","title":"bin_at","text":"<pre><code>bin_at(points_nd: NDArray[float64]) -&gt; NDArray[np.int_]\n</code></pre> <p>Map points to composite bin indices.</p> <p>Parameters:</p> Name Type Description Default <code>points_nd</code> <code>(NDArray[float64], shape(M, n_dims))</code> <p>Array of M points in n_dims-dimensional space.</p> required <p>Returns:</p> Type Description <code>(NDArray[int_], shape(M))</code> <p>Composite bin indices for each point. Returns -1 for points outside all sub-environments.</p> Notes <p>If use_kdtree_query=True (default), uses KDTree for O(M log N) performance. Otherwise, sequentially queries each sub-environment for O(N\u00d7M) performance.</p> <p>The KDTree approach finds nearest bin centers globally, then verifies each point is actually contained by that bin using the sub-environment's contains() method. This is much faster for large numbers of sub-environments.</p> Source code in <code>src/neurospatial/composite.py</code> <pre><code>def bin_at(self, points_nd: NDArray[np.float64]) -&gt; NDArray[np.int_]:\n    \"\"\"Map points to composite bin indices.\n\n    Parameters\n    ----------\n    points_nd : NDArray[np.float64], shape (M, n_dims)\n        Array of M points in n_dims-dimensional space.\n\n    Returns\n    -------\n    NDArray[np.int_], shape (M,)\n        Composite bin indices for each point. Returns -1 for points\n        outside all sub-environments.\n\n    Notes\n    -----\n    If use_kdtree_query=True (default), uses KDTree for O(M log N) performance.\n    Otherwise, sequentially queries each sub-environment for O(N\u00d7M) performance.\n\n    The KDTree approach finds nearest bin centers globally, then verifies each\n    point is actually contained by that bin using the sub-environment's contains()\n    method. This is much faster for large numbers of sub-environments.\n\n    \"\"\"\n    if points_nd.ndim != 2 or points_nd.shape[1] != self.n_dims:\n        raise ValueError(\n            f\"Expected points_nd of shape (M, {self.n_dims}), got {points_nd.shape}\",\n        )\n\n    M = points_nd.shape[0]\n\n    # Use KDTree-based approach if available\n    # Note: Still respects sub-environment order (earlier in list wins)\n    if self._kdtree is not None:\n        out = np.full((M,), -1, dtype=int)\n\n        # Process each sub-environment in order (maintain first-match semantics)\n        for block in self._subenvs_info:\n            env_i = block[\"env\"]\n            base = block[\"start_idx\"]\n\n            # Only query points that haven't been matched yet\n            unmapped_mask = out == -1\n            if not np.any(unmapped_mask):\n                break  # All points mapped\n\n            unmapped_points = points_nd[unmapped_mask]\n            sub_idxs = env_i.bin_at(unmapped_points)\n\n            # Update output for matches\n            matched_in_subenv = sub_idxs &gt;= 0\n            if np.any(matched_in_subenv):\n                # Map back to full array indices\n                unmapped_indices = np.where(unmapped_mask)[0]\n                matched_indices = unmapped_indices[matched_in_subenv]\n                out[matched_indices] = sub_idxs[matched_in_subenv] + base\n\n        return out\n\n    # Fall back to sequential query (original behavior)\n    out = np.full((M,), -1, dtype=int)\n    for block in self._subenvs_info:\n        env_i = block[\"env\"]\n        base = block[\"start_idx\"]\n        sub_idxs = env_i.bin_at(points_nd)  # expects shape (M,)\n        if sub_idxs.dtype not in (np.int32, np.int64):\n            sub_idxs = sub_idxs.astype(int)\n        mask = (sub_idxs &gt;= 0) &amp; (out == -1)\n        out[mask] = sub_idxs[mask] + base\n\n    return out\n</code></pre>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.contains","title":"contains","text":"<pre><code>contains(points_nd: NDArray[float64]) -&gt; NDArray[np.bool_]\n</code></pre> <p>Check if points are contained in any bin of the composite environment.</p> <p>Parameters:</p> Name Type Description Default <code>points_nd</code> <code>(NDArray[float64], shape(M, n_dims))</code> <p>Array of M points in n_dims-dimensional space.</p> required <p>Returns:</p> Type Description <code>(NDArray[bool_], shape(M))</code> <p>Boolean array where True indicates point is within any bin. Equivalent to self.bin_at(points_nd) != -1.</p> Source code in <code>src/neurospatial/composite.py</code> <pre><code>def contains(self, points_nd: NDArray[np.float64]) -&gt; NDArray[np.bool_]:\n    \"\"\"Check if points are contained in any bin of the composite environment.\n\n    Parameters\n    ----------\n    points_nd : NDArray[np.float64], shape (M, n_dims)\n        Array of M points in n_dims-dimensional space.\n\n    Returns\n    -------\n    NDArray[np.bool_], shape (M,)\n        Boolean array where True indicates point is within any bin.\n        Equivalent to self.bin_at(points_nd) != -1.\n\n    \"\"\"\n    return np.asarray(self.bin_at(points_nd) != -1, dtype=np.bool_)\n</code></pre>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.neighbors","title":"neighbors","text":"<pre><code>neighbors(bin_index: int) -&gt; list[int]\n</code></pre> <p>Get neighboring bins in the merged connectivity graph.</p> <p>Parameters:</p> Name Type Description Default <code>bin_index</code> <code>int</code> <p>Composite bin index to query.</p> required <p>Returns:</p> Type Description <code>list[int]</code> <p>List of composite bin indices that are neighbors of bin_index.</p> Source code in <code>src/neurospatial/composite.py</code> <pre><code>def neighbors(self, bin_index: int) -&gt; list[int]:\n    \"\"\"Get neighboring bins in the merged connectivity graph.\n\n    Parameters\n    ----------\n    bin_index : int\n        Composite bin index to query.\n\n    Returns\n    -------\n    list[int]\n        List of composite bin indices that are neighbors of bin_index.\n\n    \"\"\"\n    if not (0 &lt;= bin_index &lt; self._total_bins):\n        raise KeyError(\n            f\"Bin index {bin_index} is out of range [0..{self._total_bins - 1}]\",\n        )\n    return list(self.connectivity.neighbors(bin_index))\n</code></pre>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.distance_between","title":"distance_between","text":"<pre><code>distance_between(point1: ndarray | list[float] | tuple[float, ...], point2: ndarray | list[float] | tuple[float, ...], edge_weight: str = 'distance') -&gt; float\n</code></pre> <p>Compute shortest-path distance between two points.</p> <p>Parameters:</p> Name Type Description Default <code>point1</code> <code>ndarray or list or tuple</code> <p>First point coordinates (length n_dims).</p> required <code>point2</code> <code>ndarray or list or tuple</code> <p>Second point coordinates (length n_dims).</p> required <code>edge_weight</code> <code>str</code> <p>Edge attribute to use as weight for path computation.</p> <code>\"distance\"</code> <p>Returns:</p> Type Description <code>float</code> <p>Shortest path distance between the two points. Returns np.inf if either point is outside all sub-environments.</p> Notes <p>Maps each point to a bin index via bin_at, then computes the shortest path length in the connectivity graph.</p> Source code in <code>src/neurospatial/composite.py</code> <pre><code>def distance_between(\n    self,\n    point1: np.ndarray | list[float] | tuple[float, ...],\n    point2: np.ndarray | list[float] | tuple[float, ...],\n    edge_weight: str = \"distance\",\n) -&gt; float:\n    \"\"\"Compute shortest-path distance between two points.\n\n    Parameters\n    ----------\n    point1 : np.ndarray or list or tuple\n        First point coordinates (length n_dims).\n    point2 : np.ndarray or list or tuple\n        Second point coordinates (length n_dims).\n    edge_weight : str, default=\"distance\"\n        Edge attribute to use as weight for path computation.\n\n    Returns\n    -------\n    float\n        Shortest path distance between the two points. Returns np.inf\n        if either point is outside all sub-environments.\n\n    Notes\n    -----\n    Maps each point to a bin index via bin_at, then computes the\n    shortest path length in the connectivity graph.\n\n    \"\"\"\n\n    def _to_array(pt):\n        arr = np.asarray(pt, dtype=float)\n        if arr.ndim == 1:\n            arr = arr.reshape(1, self.n_dims)\n        if arr.ndim != 2 or arr.shape[1] != self.n_dims:\n            raise ValueError(\n                f\"Expected a point of length {self.n_dims} or shape (1, {self.n_dims}), got {arr.shape}\",\n            )\n        return arr\n\n    arr1 = _to_array(point1)\n    arr2 = _to_array(point2)\n\n    bin1 = self.bin_at(arr1)[0]\n    bin2 = self.bin_at(arr2)[0]\n    if bin1 &lt; 0 or bin2 &lt; 0:\n        return float(np.inf)\n    return float(\n        nx.shortest_path_length(\n            self.connectivity,\n            source=bin1,\n            target=bin2,\n            weight=edge_weight,\n        ),\n    )\n</code></pre>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.bin_center_of","title":"bin_center_of","text":"<pre><code>bin_center_of(bin_indices: int | NDArray[int_]) -&gt; NDArray[np.float64]\n</code></pre> <p>Get bin center coordinates for specified bin indices.</p> <p>Parameters:</p> Name Type Description Default <code>bin_indices</code> <code>int or NDArray[int_]</code> <p>Single composite bin index or 1-D array of bin indices.</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>N-D coordinate(s) of the specified bin(s). Shape (n_dims,) for a single index, or (M, n_dims) for M indices.</p> Source code in <code>src/neurospatial/composite.py</code> <pre><code>def bin_center_of(self, bin_indices: int | NDArray[np.int_]) -&gt; NDArray[np.float64]:\n    \"\"\"Get bin center coordinates for specified bin indices.\n\n    Parameters\n    ----------\n    bin_indices : int or NDArray[np.int_]\n        Single composite bin index or 1-D array of bin indices.\n\n    Returns\n    -------\n    NDArray[np.float64]\n        N-D coordinate(s) of the specified bin(s). Shape (n_dims,) for\n        a single index, or (M, n_dims) for M indices.\n\n    \"\"\"\n    return np.asarray(self.bin_centers)[bin_indices]\n</code></pre>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.bin_attributes","title":"bin_attributes","text":"<pre><code>bin_attributes() -&gt; pd.DataFrame\n</code></pre> <p>Get concatenated DataFrame of per-bin attributes from all sub-environments.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Concatenated bin attributes with columns 'child_active_bin_id' and 'composite_bin_id' added to track mapping from sub-environment bins to composite bins.</p> Source code in <code>src/neurospatial/composite.py</code> <pre><code>def bin_attributes(self) -&gt; pd.DataFrame:\n    \"\"\"Get concatenated DataFrame of per-bin attributes from all sub-environments.\n\n    Returns\n    -------\n    pd.DataFrame\n        Concatenated bin attributes with columns 'child_active_bin_id'\n        and 'composite_bin_id' added to track mapping from sub-environment\n        bins to composite bins.\n\n    \"\"\"\n    dfs = []\n    for block in self._subenvs_info:\n        env_i = block[\"env\"]\n        base = block[\"start_idx\"]\n        df = env_i.bin_attributes.copy()\n        df[\"child_active_bin_id\"] = df.index\n        df[\"composite_bin_id\"] = df.index + base\n        dfs.append(df)\n    composite_df = pd.concat(dfs, ignore_index=True)\n    return composite_df\n</code></pre>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.edge_attributes","title":"edge_attributes","text":"<pre><code>edge_attributes() -&gt; pd.DataFrame\n</code></pre> <p>Get concatenated DataFrame of per-edge attributes from all sub-environments.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Concatenated edge attributes with 'u_idx' and 'v_idx' shifted to composite bin indices. Includes MNN-inferred bridge edges connecting sub-environments.</p> Source code in <code>src/neurospatial/composite.py</code> <pre><code>def edge_attributes(self) -&gt; pd.DataFrame:\n    \"\"\"Get concatenated DataFrame of per-edge attributes from all sub-environments.\n\n    Returns\n    -------\n    pd.DataFrame\n        Concatenated edge attributes with 'u_idx' and 'v_idx' shifted\n        to composite bin indices. Includes MNN-inferred bridge edges\n        connecting sub-environments.\n\n    \"\"\"\n    dfs = []\n    for block in self._subenvs_info:\n        env_i = block[\"env\"]\n        base = block[\"start_idx\"]\n        df = env_i.edge_attributes.copy()\n        df[\"composite_source_bin\"] = df[\"source_bin\"] + base\n        df[\"composite_target_bin\"] = df[\"target_bin\"] + base\n        dfs.append(df)\n\n    if self._bridge_list:\n        bridge_rows = []\n        for (i_env, i_bin), (j_env, j_bin), w in self._bridge_list:\n            block_i = self._subenvs_info[i_env]\n            block_j = self._subenvs_info[j_env]\n            source_composite_bin = block_i[\"start_idx\"] + i_bin\n            target_composite_bin = block_j[\"start_idx\"] + j_bin\n            bridge_rows.append(\n                {\n                    \"composite_source_bin\": source_composite_bin,\n                    \"composite_target_bin\": target_composite_bin,\n                    \"distance\": w,\n                    \"weight\": 1 / w,\n                },\n            )\n        bridge_df = pd.DataFrame(bridge_rows)\n        dfs.append(bridge_df)\n\n    composite_edges_df = pd.concat(dfs, ignore_index=True)\n    return composite_edges_df\n</code></pre>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.bins_in_region","title":"bins_in_region","text":"<pre><code>bins_in_region(region_name: str) -&gt; NDArray[np.int_]\n</code></pre> <p>Get composite bin indices that fall within a specified named region.</p> <p>Parameters:</p> Name Type Description Default <code>region_name</code> <code>str</code> <p>Name of a defined region in <code>self.regions</code>.</p> required <p>Returns:</p> Type Description <code>NDArray[int_]</code> <p>Array of composite bin indices (0 to n_bins - 1) that fall within the specified region.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If <code>region_name</code> is not found in <code>self.regions</code>.</p> <code>ValueError</code> <p>If region type is unsupported or dimensions mismatch.</p> Notes <p>This method queries the region against all bin centers in the composite environment. For point regions, returns bins containing that point. For polygon regions (requires shapely), returns all bins whose centers fall within the polygon.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; comp = CompositeEnvironment([env1, env2])\n&gt;&gt;&gt; comp.regions.add(\"goal\", point=[10.0, 5.0])\n&gt;&gt;&gt; goal_bins = comp.bins_in_region(\"goal\")\n&gt;&gt;&gt; print(f\"Goal region contains {len(goal_bins)} bins\")\n</code></pre> Source code in <code>src/neurospatial/composite.py</code> <pre><code>def bins_in_region(self, region_name: str) -&gt; NDArray[np.int_]:\n    \"\"\"Get composite bin indices that fall within a specified named region.\n\n    Parameters\n    ----------\n    region_name : str\n        Name of a defined region in `self.regions`.\n\n    Returns\n    -------\n    NDArray[np.int_]\n        Array of composite bin indices (0 to n_bins - 1) that fall within\n        the specified region.\n\n    Raises\n    ------\n    KeyError\n        If `region_name` is not found in `self.regions`.\n    ValueError\n        If region type is unsupported or dimensions mismatch.\n\n    Notes\n    -----\n    This method queries the region against all bin centers in the composite\n    environment. For point regions, returns bins containing that point.\n    For polygon regions (requires shapely), returns all bins whose centers\n    fall within the polygon.\n\n    Examples\n    --------\n    &gt;&gt;&gt; comp = CompositeEnvironment([env1, env2])\n    &gt;&gt;&gt; comp.regions.add(\"goal\", point=[10.0, 5.0])\n    &gt;&gt;&gt; goal_bins = comp.bins_in_region(\"goal\")\n    &gt;&gt;&gt; print(f\"Goal region contains {len(goal_bins)} bins\")\n\n    \"\"\"\n    region = self.regions[region_name]\n\n    if region.kind == \"point\":\n        # Point region - find bin at that point\n        point_nd = np.asarray(region.data).reshape(1, -1)\n        if point_nd.shape[1] != self.n_dims:\n            raise ValueError(\n                f\"Region point dimension {point_nd.shape[1]} \"\n                f\"does not match environment dimension {self.n_dims}.\",\n            )\n        bin_idx = self.bin_at(point_nd)\n        return np.asarray(bin_idx[bin_idx != -1], dtype=int)\n\n    if region.kind == \"polygon\":\n        # Polygon region - check which bin centers are inside\n        try:\n            import shapely\n        except ImportError as e:\n            raise RuntimeError(\n                \"Polygon region queries require 'shapely'. \"\n                \"Install it with: pip install shapely\"\n            ) from e\n\n        if self.n_dims != 2:\n            raise ValueError(\n                f\"Polygon regions are only supported for 2D environments. \"\n                f\"This composite environment has {self.n_dims} dimensions.\"\n            )\n\n        polygon = region.data\n        x_coords = self.bin_centers[:, 0]\n        y_coords = self.bin_centers[:, 1]\n        contained_mask = shapely.contains_xy(polygon, x_coords, y_coords)\n        return np.where(contained_mask)[0].astype(int)\n\n    raise ValueError(\n        f\"Unsupported region kind: '{region.kind}'. \"\n        f\"Supported kinds: 'point', 'polygon'.\"\n    )\n</code></pre>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.mask_for_region","title":"mask_for_region","text":"<pre><code>mask_for_region(region_name: str) -&gt; NDArray[np.bool_]\n</code></pre> <p>Get boolean mask for bins in a specified region.</p> <p>Parameters:</p> Name Type Description Default <code>region_name</code> <code>str</code> <p>Name of a defined region in <code>self.regions</code>.</p> required <p>Returns:</p> Type Description <code>(NDArray[bool_], shape(n_bins))</code> <p>Boolean mask where True indicates the bin is within the region.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If <code>region_name</code> is not found in <code>self.regions</code>.</p> <code>ValueError</code> <p>If region type is unsupported or dimensions mismatch.</p> Notes <p>This is a convenience method that returns a boolean mask instead of bin indices. Equivalent to:     mask = np.zeros(env.n_bins, dtype=bool)     mask[env.bins_in_region(region_name)] = True</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; comp = CompositeEnvironment([env1, env2])\n&gt;&gt;&gt; comp.regions.add(\"arena\", polygon=shapely_polygon)\n&gt;&gt;&gt; arena_mask = comp.mask_for_region(\"arena\")\n&gt;&gt;&gt; occupancy_in_arena = occupancy[arena_mask]\n</code></pre> Source code in <code>src/neurospatial/composite.py</code> <pre><code>def mask_for_region(self, region_name: str) -&gt; NDArray[np.bool_]:\n    \"\"\"Get boolean mask for bins in a specified region.\n\n    Parameters\n    ----------\n    region_name : str\n        Name of a defined region in `self.regions`.\n\n    Returns\n    -------\n    NDArray[np.bool_], shape (n_bins,)\n        Boolean mask where True indicates the bin is within the region.\n\n    Raises\n    ------\n    KeyError\n        If `region_name` is not found in `self.regions`.\n    ValueError\n        If region type is unsupported or dimensions mismatch.\n\n    Notes\n    -----\n    This is a convenience method that returns a boolean mask instead of\n    bin indices. Equivalent to:\n        mask = np.zeros(env.n_bins, dtype=bool)\n        mask[env.bins_in_region(region_name)] = True\n\n    Examples\n    --------\n    &gt;&gt;&gt; comp = CompositeEnvironment([env1, env2])\n    &gt;&gt;&gt; comp.regions.add(\"arena\", polygon=shapely_polygon)\n    &gt;&gt;&gt; arena_mask = comp.mask_for_region(\"arena\")\n    &gt;&gt;&gt; occupancy_in_arena = occupancy[arena_mask]\n\n    \"\"\"\n    mask = np.zeros(self.n_bins, dtype=bool)\n    bins = self.bins_in_region(region_name)\n    mask[bins] = True\n    return mask\n</code></pre>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.shortest_path","title":"shortest_path","text":"<pre><code>shortest_path(source_bin: int, target_bin: int, edge_weight: str = 'distance') -&gt; list[int]\n</code></pre> <p>Find shortest path between two bin indices in the composite graph.</p> <p>Parameters:</p> Name Type Description Default <code>source_bin</code> <code>int</code> <p>Composite bin index to start from (0 to n_bins - 1).</p> required <code>target_bin</code> <code>int</code> <p>Composite bin index to reach (0 to n_bins - 1).</p> required <code>edge_weight</code> <code>str</code> <p>Edge attribute to use as weight for pathfinding.</p> <code>\"distance\"</code> <p>Returns:</p> Type Description <code>list[int]</code> <p>List of composite bin indices forming the shortest path from source_bin to target_bin, including both endpoints. Returns empty list if no path exists.</p> <p>Raises:</p> Type Description <code>NodeNotFound</code> <p>If source_bin or target_bin is not in the graph.</p> Warnings <p>UserWarning     If no path exists between the bins (disconnected components).</p> Notes <p>Uses NetworkX shortest_path with specified edge weights. The path may cross bridge edges connecting different sub-environments.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; comp = CompositeEnvironment([env1, env2], auto_bridge=True)\n&gt;&gt;&gt; path = comp.shortest_path(0, 100)  # Path from bin 0 to bin 100\n&gt;&gt;&gt; print(f\"Path length: {len(path)} bins\")\n</code></pre> Source code in <code>src/neurospatial/composite.py</code> <pre><code>def shortest_path(\n    self, source_bin: int, target_bin: int, edge_weight: str = \"distance\"\n) -&gt; list[int]:\n    \"\"\"Find shortest path between two bin indices in the composite graph.\n\n    Parameters\n    ----------\n    source_bin : int\n        Composite bin index to start from (0 to n_bins - 1).\n    target_bin : int\n        Composite bin index to reach (0 to n_bins - 1).\n    edge_weight : str, default=\"distance\"\n        Edge attribute to use as weight for pathfinding.\n\n    Returns\n    -------\n    list[int]\n        List of composite bin indices forming the shortest path from\n        source_bin to target_bin, including both endpoints. Returns\n        empty list if no path exists.\n\n    Raises\n    ------\n    nx.NodeNotFound\n        If source_bin or target_bin is not in the graph.\n\n    Warnings\n    --------\n    UserWarning\n        If no path exists between the bins (disconnected components).\n\n    Notes\n    -----\n    Uses NetworkX shortest_path with specified edge weights. The path\n    may cross bridge edges connecting different sub-environments.\n\n    Examples\n    --------\n    &gt;&gt;&gt; comp = CompositeEnvironment([env1, env2], auto_bridge=True)\n    &gt;&gt;&gt; path = comp.shortest_path(0, 100)  # Path from bin 0 to bin 100\n    &gt;&gt;&gt; print(f\"Path length: {len(path)} bins\")\n\n    \"\"\"\n    try:\n        path: list[int] = nx.shortest_path(\n            self.connectivity,\n            source=source_bin,\n            target=target_bin,\n            weight=edge_weight,\n        )\n        return path\n    except nx.NetworkXNoPath:\n        import warnings\n\n        warnings.warn(\n            f\"No path found between bin {source_bin} and bin {target_bin}. \"\n            f\"The bins may be in disconnected components. \"\n            f\"Returning empty path.\",\n            UserWarning,\n            stacklevel=2,\n        )\n        return []\n</code></pre>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.info","title":"info","text":"<pre><code>info(return_string: bool = False) -&gt; str | None\n</code></pre> <p>Print or return diagnostic information about the composite environment.</p> <p>Parameters:</p> Name Type Description Default <code>return_string</code> <code>bool</code> <p>If True, return the info string instead of printing.</p> <code>False</code> <p>Returns:</p> Type Description <code>str or None</code> <p>If return_string=True, returns the formatted info string. Otherwise prints to stdout and returns None.</p> Notes <p>Displays summary information including: - Number of sub-environments - Total bins and dimensions - Number of bridge edges connecting sub-environments - Per-sub-environment statistics (type, bins, regions) - Bridge edge statistics</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; comp = CompositeEnvironment([env1, env2], auto_bridge=True)\n&gt;&gt;&gt; comp.info()\nComposite Environment Information\n==================================\n...\n</code></pre> Source code in <code>src/neurospatial/composite.py</code> <pre><code>def info(self, return_string: bool = False) -&gt; str | None:\n    \"\"\"Print or return diagnostic information about the composite environment.\n\n    Parameters\n    ----------\n    return_string : bool, default=False\n        If True, return the info string instead of printing.\n\n    Returns\n    -------\n    str or None\n        If return_string=True, returns the formatted info string.\n        Otherwise prints to stdout and returns None.\n\n    Notes\n    -----\n    Displays summary information including:\n    - Number of sub-environments\n    - Total bins and dimensions\n    - Number of bridge edges connecting sub-environments\n    - Per-sub-environment statistics (type, bins, regions)\n    - Bridge edge statistics\n\n    Examples\n    --------\n    &gt;&gt;&gt; comp = CompositeEnvironment([env1, env2], auto_bridge=True)\n    &gt;&gt;&gt; comp.info()\n    Composite Environment Information\n    ==================================\n    ...\n\n    \"\"\"\n    lines = []\n    lines.append(\"Composite Environment Information\")\n    lines.append(\"=\" * 50)\n    lines.append(f\"Number of sub-environments: {len(self._subenvs_info)}\")\n    lines.append(f\"Total bins: {self.n_bins}\")\n    lines.append(f\"Dimensions: {self.n_dims}\")\n    lines.append(f\"Bridge edges: {len(self._bridge_list)}\")\n    lines.append(\"\")\n\n    lines.append(\"Sub-Environment Details:\")\n    lines.append(\"-\" * 50)\n    for i, block in enumerate(self._subenvs_info):\n        env_i = block[\"env\"]\n        lines.append(f\"  [{i}] {env_i.name or '(unnamed)'}\")\n        lines.append(f\"      Type: {env_i.layout_type}\")\n        lines.append(\n            f\"      Bins: {env_i.n_bins} (composite indices: {block['start_idx']}-{block['end_idx']})\"\n        )\n        lines.append(f\"      Regions: {len(env_i.regions)}\")\n        if len(env_i.regions) &gt; 0:\n            lines.append(f\"               {list(env_i.regions.keys())}\")\n    lines.append(\"\")\n\n    lines.append(\"Bridge Statistics:\")\n    lines.append(\"-\" * 50)\n    if self._bridge_list:\n        distances = [w for _, _, w in self._bridge_list]\n        lines.append(f\"  Count: {len(self._bridge_list)}\")\n        lines.append(f\"  Min distance: {min(distances):.4f}\")\n        lines.append(f\"  Max distance: {max(distances):.4f}\")\n        lines.append(f\"  Mean distance: {np.mean(distances):.4f}\")\n    else:\n        lines.append(\n            \"  No bridges (auto_bridge=False or no mutual nearest neighbors found)\"\n        )\n    lines.append(\"\")\n\n    lines.append(\"Composite Regions:\")\n    lines.append(\"-\" * 50)\n    if len(self.regions) &gt; 0:\n        for name, region in self.regions.items():\n            lines.append(f\"  - {name}: {region.kind}\")\n    else:\n        lines.append(\"  (No regions defined)\")\n\n    info_str = \"\\n\".join(lines)\n\n    if return_string:\n        return info_str\n    else:\n        print(info_str)\n        return None\n</code></pre>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.save","title":"save","text":"<pre><code>save(filepath: str) -&gt; None\n</code></pre> <p>Save the CompositeEnvironment to a file using pickle.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path where the composite environment will be saved.</p> required Warnings <p>This method uses pickle serialization. Only load files from trusted sources, as pickle can execute arbitrary code.</p> Notes <p>The saved file contains: - All sub-environments with their complete state - Bridge edges and connectivity information - Regions from all sub-environments - Composite metadata</p> <p>The file can be loaded with CompositeEnvironment.load().</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; comp = CompositeEnvironment([env1, env2])\n&gt;&gt;&gt; comp.save(\"my_composite_env.pkl\")\n&gt;&gt;&gt; loaded = CompositeEnvironment.load(\"my_composite_env.pkl\")\n</code></pre> Source code in <code>src/neurospatial/composite.py</code> <pre><code>def save(self, filepath: str) -&gt; None:\n    \"\"\"Save the CompositeEnvironment to a file using pickle.\n\n    Parameters\n    ----------\n    filepath : str\n        Path where the composite environment will be saved.\n\n    Warnings\n    --------\n    This method uses pickle serialization. Only load files from trusted\n    sources, as pickle can execute arbitrary code.\n\n    Notes\n    -----\n    The saved file contains:\n    - All sub-environments with their complete state\n    - Bridge edges and connectivity information\n    - Regions from all sub-environments\n    - Composite metadata\n\n    The file can be loaded with CompositeEnvironment.load().\n\n    Examples\n    --------\n    &gt;&gt;&gt; comp = CompositeEnvironment([env1, env2])\n    &gt;&gt;&gt; comp.save(\"my_composite_env.pkl\")\n    &gt;&gt;&gt; loaded = CompositeEnvironment.load(\"my_composite_env.pkl\")\n\n    \"\"\"\n    import pickle\n    from pathlib import Path\n\n    # Package everything needed to reconstruct the composite\n    save_dict = {\n        \"subenvs\": [block[\"env\"] for block in self._subenvs_info],\n        \"auto_bridge\": False,  # Don't re-infer bridges on load\n        \"max_mnn_distance\": None,\n        \"use_kdtree_query\": self._use_kdtree_query,\n        \"bridge_list\": self._bridge_list,\n        \"layout_params\": self._layout_params_used,\n    }\n\n    Path(filepath).write_bytes(pickle.dumps(save_dict))\n</code></pre>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(filepath: str) -&gt; CompositeEnvironment\n</code></pre> <p>Load a CompositeEnvironment from a file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the saved composite environment file.</p> required <p>Returns:</p> Type Description <code>CompositeEnvironment</code> <p>Reconstructed composite environment with all sub-environments and bridge edges restored.</p> Warnings <p>This method uses pickle deserialization. Only load files from trusted sources, as pickle can execute arbitrary code.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; comp = CompositeEnvironment.load(\"my_composite_env.pkl\")\n&gt;&gt;&gt; print(f\"Loaded composite with {comp.n_bins} bins\")\n</code></pre> Source code in <code>src/neurospatial/composite.py</code> <pre><code>@classmethod\ndef load(cls, filepath: str) -&gt; \"CompositeEnvironment\":\n    \"\"\"Load a CompositeEnvironment from a file.\n\n    Parameters\n    ----------\n    filepath : str\n        Path to the saved composite environment file.\n\n    Returns\n    -------\n    CompositeEnvironment\n        Reconstructed composite environment with all sub-environments\n        and bridge edges restored.\n\n    Warnings\n    --------\n    This method uses pickle deserialization. Only load files from trusted\n    sources, as pickle can execute arbitrary code.\n\n    Examples\n    --------\n    &gt;&gt;&gt; comp = CompositeEnvironment.load(\"my_composite_env.pkl\")\n    &gt;&gt;&gt; print(f\"Loaded composite with {comp.n_bins} bins\")\n\n    \"\"\"\n    import pickle\n    from pathlib import Path\n\n    save_dict = pickle.loads(Path(filepath).read_bytes())\n\n    # Reconstruct without auto-bridging\n    use_kdtree = save_dict.get(\n        \"use_kdtree_query\", True\n    )  # Default to True for backwards compatibility\n    comp = cls(\n        subenvs=save_dict[\"subenvs\"],\n        auto_bridge=False,\n        max_mnn_distance=None,\n        use_kdtree_query=use_kdtree,\n    )\n\n    # Restore the saved bridges\n    for (i_env, i_bin), (j_env, j_bin), w in save_dict[\"bridge_list\"]:\n        # Bridge already exists, skip if duplicate\n        source_composite_bin = comp._subenvs_info[i_env][\"start_idx\"] + i_bin\n        target_composite_bin = comp._subenvs_info[j_env][\"start_idx\"] + j_bin\n        if not comp.connectivity.has_edge(\n            source_composite_bin, target_composite_bin\n        ):\n            comp._add_bridge_edge(i_env, i_bin, j_env, j_bin, w)\n\n    return comp\n</code></pre>"},{"location":"api/neurospatial/composite/#neurospatial.composite.CompositeEnvironment.plot","title":"plot","text":"<pre><code>plot(ax: Axes | None = None, sub_env_plot_kwargs: dict[str, Any] | list[dict[str, Any] | None] | None = None, bridge_edge_kwargs: dict[str, Any] | None = None, show_sub_env_labels: bool = False, **kwargs) -&gt; matplotlib.axes.Axes\n</code></pre> <p>Plot the composite environment.</p> <p>This method plots each sub-environment and then overlays the bridge edges.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>The Matplotlib axes to plot on. If None, a new figure and axes are created. Defaults to None.</p> <code>None</code> <code>sub_env_plot_kwargs</code> <code>Optional[Union[Dict[str, Any], List[Optional[Dict[str, Any]]]]]</code> <p>Keyword arguments to pass to the <code>plot()</code> method of each sub-environment. If a single dict, it's applied to all sub-environments. If a list, it should have the same length as <code>subenvs</code>, and each element (a dict or None) is passed to the corresponding sub-environment's plot call. Defaults to None (empty dict for each).</p> <code>None</code> <code>bridge_edge_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments for plotting the bridge edges (passed to <code>ax.plot</code>). Defaults to {'color': 'red', 'linestyle': '--', 'linewidth': 0.8, 'alpha': 0.7}.</p> <code>None</code> <code>show_sub_env_labels</code> <code>bool</code> <p>If True, attempts to label the approximate center of each sub-environment.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>plt.subplots()</code> if <code>ax</code> is None.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the composite environment was plotted.</p> Source code in <code>src/neurospatial/composite.py</code> <pre><code>def plot(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    sub_env_plot_kwargs: dict[str, Any] | list[dict[str, Any] | None] | None = None,\n    bridge_edge_kwargs: dict[str, Any] | None = None,\n    show_sub_env_labels: bool = False,\n    **kwargs,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot the composite environment.\n\n    This method plots each sub-environment and then overlays the bridge edges.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        The Matplotlib axes to plot on. If None, a new figure and axes\n        are created. Defaults to None.\n    sub_env_plot_kwargs : Optional[Union[Dict[str, Any], List[Optional[Dict[str, Any]]]]], optional\n        Keyword arguments to pass to the `plot()` method of each sub-environment.\n        If a single dict, it's applied to all sub-environments.\n        If a list, it should have the same length as `subenvs`, and each element\n        (a dict or None) is passed to the corresponding sub-environment's plot call.\n        Defaults to None (empty dict for each).\n    bridge_edge_kwargs : Optional[Dict[str, Any]], optional\n        Keyword arguments for plotting the bridge edges (passed to `ax.plot`).\n        Defaults to {'color': 'red', 'linestyle': '--', 'linewidth': 0.8, 'alpha': 0.7}.\n    show_sub_env_labels : bool, default=False\n        If True, attempts to label the approximate center of each sub-environment.\n    **kwargs : Any\n        Additional keyword arguments passed to `plt.subplots()` if `ax` is None.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the composite environment was plotted.\n\n    \"\"\"\n    if ax is None:\n        fig_kwargs: dict[str, Any] = {\"figsize\": (10, 10)}  # Default figsize\n        fig_kwargs.update(kwargs)\n        # Determine if plot should be 3D based on n_dims\n        if self.n_dims == 3:\n            fig_kwargs[\"projection\"] = \"3d\"\n\n        is_3d = fig_kwargs.get(\"projection\") == \"3d\"\n        if is_3d:\n            figsize_val = fig_kwargs.get(\"figsize\", (10, 10))\n            fig = plt.figure(figsize=figsize_val)\n            ax = fig.add_subplot(111, projection=\"3d\")\n        else:\n            fig, ax = plt.subplots(\n                **{k: v for k, v in fig_kwargs.items() if k != \"projection\"},\n            )\n\n    # Plot each sub-environment\n    for i, block_info in enumerate(self._subenvs_info):\n        env_i = block_info[\"env\"]\n        current_env_kwargs: dict[str, Any] = {}\n        if isinstance(sub_env_plot_kwargs, list):\n            if i &lt; len(sub_env_plot_kwargs):\n                kwargs_i = sub_env_plot_kwargs[i]\n                if kwargs_i is not None:\n                    current_env_kwargs = kwargs_i\n        elif isinstance(sub_env_plot_kwargs, dict):\n            current_env_kwargs = sub_env_plot_kwargs\n\n        env_i.plot(ax=ax, **current_env_kwargs)\n\n        if show_sub_env_labels and env_i.n_bins &gt; 0:\n            # Add a label at the mean position of the sub-environment's bin centers\n            mean_pos = np.mean(env_i.bin_centers, axis=0)\n            label_text = f\"Env {i}\"\n            if env_i.name:\n                label_text += f\": {env_i.name}\"\n\n            if self.n_dims == 2:\n                ax.text(\n                    mean_pos[0],\n                    mean_pos[1],\n                    label_text,\n                    color=\"blue\",\n                    ha=\"center\",\n                    va=\"center\",\n                    bbox={\"facecolor\": \"white\", \"alpha\": 0.5, \"pad\": 0.1},\n                )\n            elif self.n_dims == 3:\n                # matplotlib 3D text() signature differs from 2D stubs\n                from typing import Any as _Any\n\n                text_func = cast(\"_Any\", ax.text)\n                text_func(\n                    mean_pos[0],\n                    mean_pos[1],\n                    mean_pos[2],\n                    label_text,\n                    color=\"blue\",\n                    ha=\"center\",\n                    va=\"center\",\n                )\n\n    # Plot bridge edges\n    _bridge_kwargs = {\n        \"color\": \"red\",\n        \"linestyle\": \"--\",\n        \"linewidth\": 1.0,\n        \"alpha\": 0.7,\n        \"zorder\": 0,\n    }\n    if bridge_edge_kwargs is not None:\n        _bridge_kwargs.update(bridge_edge_kwargs)\n\n    for (\n        (i_env_idx, i_bin_sub_idx),\n        (j_env_idx, j_bin_sub_idx),\n        _,\n    ) in self._bridge_list:\n        block_i = self._subenvs_info[i_env_idx]\n        block_j = self._subenvs_info[j_env_idx]\n\n        # Get original bin centers from sub-environments for plotting bridge start/end\n        # This avoids issues if self.bin_centers has a different order or structure\n        # than the sub-environment's original bin_centers array.\n        # However, self.bin_centers is authoritative for the composite.\n        # We need composite indices.\n\n        u_composite = block_i[\"start_idx\"] + i_bin_sub_idx\n        v_composite = block_j[\"start_idx\"] + j_bin_sub_idx\n\n        pos_u = self.bin_centers[u_composite]\n        pos_v = self.bin_centers[v_composite]\n\n        # matplotlib plot() stubs don't properly handle **kwargs\n        from typing import Any as _Any\n\n        plot_func = cast(\"_Any\", ax.plot)\n\n        if self.n_dims == 2:\n            plot_func([pos_u[0], pos_v[0]], [pos_u[1], pos_v[1]], **_bridge_kwargs)\n        elif self.n_dims == 3:\n            plot_func(\n                [pos_u[0], pos_v[0]],\n                [pos_u[1], pos_v[1]],\n                [pos_u[2], pos_v[2]],\n                **_bridge_kwargs,\n            )\n        # Add other dimensionalities if needed\n\n    ax.set_title(\"Composite Environment\")\n    return ax\n</code></pre>"},{"location":"api/neurospatial/composite/#neurospatial.composite-functions","title":"Functions","text":""},{"location":"api/neurospatial/distance/","title":"<code>neurospatial.distance</code>","text":""},{"location":"api/neurospatial/distance/#neurospatial.distance","title":"distance","text":""},{"location":"api/neurospatial/distance/#neurospatial.distance-functions","title":"Functions","text":""},{"location":"api/neurospatial/distance/#neurospatial.distance.euclidean_distance_matrix","title":"euclidean_distance_matrix","text":"<pre><code>euclidean_distance_matrix(centers: NDArray[float64]) -&gt; NDArray[np.float64]\n</code></pre> <p>Compute pairwise Euclidean distance matrix between points.</p> <p>Parameters:</p> Name Type Description Default <code>centers</code> <code>(NDArray[float64], shape(N, n_dims))</code> <p>Array of N points in n_dims-dimensional space.</p> required <p>Returns:</p> Type Description <code>(NDArray[float64], shape(N, N))</code> <p>Pairwise Euclidean distance matrix where element (i, j) is the distance between points i and j.</p> Source code in <code>src/neurospatial/distance.py</code> <pre><code>def euclidean_distance_matrix(centers: NDArray[np.float64]) -&gt; NDArray[np.float64]:\n    \"\"\"Compute pairwise Euclidean distance matrix between points.\n\n    Parameters\n    ----------\n    centers : NDArray[np.float64], shape (N, n_dims)\n        Array of N points in n_dims-dimensional space.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (N, N)\n        Pairwise Euclidean distance matrix where element (i, j) is the\n        distance between points i and j.\n\n    \"\"\"\n    from scipy.spatial.distance import pdist, squareform\n\n    if centers.shape[0] == 0:\n        return np.empty((0, 0), dtype=np.float64)\n    if centers.shape[0] == 1:\n        return np.zeros((1, 1), dtype=np.float64)\n    # scipy.spatial.distance functions return untyped arrays\n    result: NDArray[np.float64] = squareform(pdist(centers, metric=\"euclidean\"))\n    return result\n</code></pre>"},{"location":"api/neurospatial/distance/#neurospatial.distance.geodesic_distance_matrix","title":"geodesic_distance_matrix","text":"<pre><code>geodesic_distance_matrix(G: Graph, n_states: int, weight: str = 'distance') -&gt; NDArray[np.float64]\n</code></pre> <p>Compute geodesic (shortest-path) distance matrix on a graph.</p> <p>Parameters:</p> Name Type Description Default <code>G</code> <code>Graph</code> <p>NetworkX graph representing spatial connectivity.</p> required <code>n_states</code> <code>int</code> <p>Number of states/nodes in the graph.</p> required <code>weight</code> <code>str</code> <p>Edge attribute to use as weight for path length calculation.</p> <code>\"distance\"</code> <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_states, n_states))</code> <p>Geodesic distance matrix where element (i, j) is the shortest path length from node i to node j. Disconnected nodes have distance np.inf.</p> Source code in <code>src/neurospatial/distance.py</code> <pre><code>def geodesic_distance_matrix(\n    G: nx.Graph,\n    n_states: int,\n    weight: str = \"distance\",\n) -&gt; NDArray[np.float64]:\n    \"\"\"Compute geodesic (shortest-path) distance matrix on a graph.\n\n    Parameters\n    ----------\n    G : nx.Graph\n        NetworkX graph representing spatial connectivity.\n    n_states : int\n        Number of states/nodes in the graph.\n    weight : str, default=\"distance\"\n        Edge attribute to use as weight for path length calculation.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_states, n_states)\n        Geodesic distance matrix where element (i, j) is the shortest path\n        length from node i to node j. Disconnected nodes have distance np.inf.\n\n    \"\"\"\n    if G.number_of_nodes() == 0:\n        return np.empty((0, 0), dtype=np.float64)\n    dist_matrix = np.full((n_states, n_states), np.inf, dtype=np.float64)\n    np.fill_diagonal(dist_matrix, 0.0)\n    for src, lengths in nx.shortest_path_length(G, weight=weight):\n        for dst, L in lengths.items():\n            dist_matrix[src, dst] = float(L)\n    return dist_matrix\n</code></pre>"},{"location":"api/neurospatial/distance/#neurospatial.distance.geodesic_distance_between_points","title":"geodesic_distance_between_points","text":"<pre><code>geodesic_distance_between_points(G: Graph, bin_from: int, bin_to: int, default: float = np.inf) -&gt; float\n</code></pre> <p>Compute geodesic distance between two specific nodes in a graph.</p> <p>Parameters:</p> Name Type Description Default <code>G</code> <code>Graph</code> <p>NetworkX graph representing spatial connectivity.</p> required <code>bin_from</code> <code>int</code> <p>Source node/bin index.</p> required <code>bin_to</code> <code>int</code> <p>Target node/bin index.</p> required <code>default</code> <code>float</code> <p>Value to return if no path exists or nodes are invalid.</p> <code>np.inf</code> <p>Returns:</p> Type Description <code>float</code> <p>Shortest path length from bin_from to bin_to using edge weight \"distance\". Returns <code>default</code> if either index is invalid or no path exists.</p> Source code in <code>src/neurospatial/distance.py</code> <pre><code>def geodesic_distance_between_points(\n    G: nx.Graph,\n    bin_from: int,\n    bin_to: int,\n    default: float = np.inf,\n) -&gt; float:\n    \"\"\"Compute geodesic distance between two specific nodes in a graph.\n\n    Parameters\n    ----------\n    G : nx.Graph\n        NetworkX graph representing spatial connectivity.\n    bin_from : int\n        Source node/bin index.\n    bin_to : int\n        Target node/bin index.\n    default : float, default=np.inf\n        Value to return if no path exists or nodes are invalid.\n\n    Returns\n    -------\n    float\n        Shortest path length from bin_from to bin_to using edge weight \"distance\".\n        Returns `default` if either index is invalid or no path exists.\n\n    \"\"\"\n    try:\n        length = nx.shortest_path_length(\n            G,\n            source=bin_from,\n            target=bin_to,\n            weight=\"distance\",\n        )\n        return float(length)\n    except (nx.NetworkXNoPath, nx.NodeNotFound):\n        return default\n</code></pre>"},{"location":"api/neurospatial/distance/#neurospatial.distance.distance_field","title":"distance_field","text":"<pre><code>distance_field(G: Graph, sources: list[int] | NDArray[int_], weight: str = 'distance') -&gt; NDArray[np.float64]\n</code></pre> <p>Compute distance field: distance from each node to nearest source node.</p> <p>This is a common primitive for spatial analysis - compute the distance from every bin to the nearest bin in a set of source bins (e.g., goal locations, reward sites, or boundaries).</p> <p>Parameters:</p> Name Type Description Default <code>G</code> <code>Graph</code> <p>NetworkX graph representing spatial connectivity.</p> required <code>sources</code> <code>list[int] or NDArray[int_]</code> <p>List of source node indices. Distance field measures distance to nearest node in this set.</p> required <code>weight</code> <code>str</code> <p>Edge attribute to use as weight for path length calculation.</p> <code>\"distance\"</code> <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_nodes))</code> <p>For each node i, the distance to the nearest source node. Nodes unreachable from all sources have distance np.inf.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import networkx as nx\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial.distance import distance_field\n&gt;&gt;&gt; # Create a simple graph\n&gt;&gt;&gt; G = nx.Graph()\n&gt;&gt;&gt; G.add_edges_from([(0, 1), (1, 2), (2, 3), (3, 4)])\n&gt;&gt;&gt; for u, v in G.edges:\n...     G.edges[u, v][\"distance\"] = 1.0\n&gt;&gt;&gt; # Compute distance field from node 2\n&gt;&gt;&gt; dists = distance_field(G, sources=[2])\n&gt;&gt;&gt; dists\narray([2., 1., 0., 1., 2.])\n</code></pre> Notes <p>This function uses Dijkstra's algorithm with multiple sources, which is O((V + E) log V) where V is number of nodes and E is number of edges.</p> <p>For large graphs or repeated queries, consider caching the result.</p> See Also <p>geodesic_distance_matrix : Compute all-pairs distances pairwise_distances : Compute distances between specific node pairs</p> Source code in <code>src/neurospatial/distance.py</code> <pre><code>def distance_field(\n    G: nx.Graph,\n    sources: list[int] | NDArray[np.int_],\n    weight: str = \"distance\",\n) -&gt; NDArray[np.float64]:\n    \"\"\"Compute distance field: distance from each node to nearest source node.\n\n    This is a common primitive for spatial analysis - compute the distance\n    from every bin to the nearest bin in a set of source bins (e.g., goal\n    locations, reward sites, or boundaries).\n\n    Parameters\n    ----------\n    G : nx.Graph\n        NetworkX graph representing spatial connectivity.\n    sources : list[int] or NDArray[np.int_]\n        List of source node indices. Distance field measures distance to\n        nearest node in this set.\n    weight : str, default=\"distance\"\n        Edge attribute to use as weight for path length calculation.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_nodes,)\n        For each node i, the distance to the nearest source node.\n        Nodes unreachable from all sources have distance np.inf.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import networkx as nx\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial.distance import distance_field\n    &gt;&gt;&gt; # Create a simple graph\n    &gt;&gt;&gt; G = nx.Graph()\n    &gt;&gt;&gt; G.add_edges_from([(0, 1), (1, 2), (2, 3), (3, 4)])\n    &gt;&gt;&gt; for u, v in G.edges:\n    ...     G.edges[u, v][\"distance\"] = 1.0\n    &gt;&gt;&gt; # Compute distance field from node 2\n    &gt;&gt;&gt; dists = distance_field(G, sources=[2])\n    &gt;&gt;&gt; dists\n    array([2., 1., 0., 1., 2.])\n\n    Notes\n    -----\n    This function uses Dijkstra's algorithm with multiple sources, which is\n    O((V + E) log V) where V is number of nodes and E is number of edges.\n\n    For large graphs or repeated queries, consider caching the result.\n\n    See Also\n    --------\n    geodesic_distance_matrix : Compute all-pairs distances\n    pairwise_distances : Compute distances between specific node pairs\n\n    \"\"\"\n    sources_array = np.asarray(sources, dtype=int)\n\n    n_nodes = G.number_of_nodes()\n    if n_nodes == 0:\n        return np.empty(0, dtype=np.float64)\n\n    if len(sources_array) == 0:\n        raise ValueError(\"sources must contain at least one node\")\n\n    # Initialize distance array\n    distances = np.full(n_nodes, np.inf, dtype=np.float64)\n\n    # Check that all source nodes are valid\n    valid_sources = []\n    for src in sources_array:\n        if src in G.nodes:\n            valid_sources.append(int(src))\n        else:\n            import warnings\n\n            warnings.warn(f\"Source node {src} not in graph, skipping\", stacklevel=2)\n\n    if len(valid_sources) == 0:\n        raise ValueError(\"No valid source nodes found in graph\")\n\n    # Run Dijkstra from each source and keep minimum distance\n    for src in valid_sources:\n        lengths = nx.single_source_dijkstra_path_length(G, src, weight=weight)\n        for node, length in lengths.items():\n            distances[node] = min(distances[node], float(length))\n\n    return distances\n</code></pre>"},{"location":"api/neurospatial/distance/#neurospatial.distance.pairwise_distances","title":"pairwise_distances","text":"<pre><code>pairwise_distances(G: Graph, nodes: list[int] | NDArray[int_], weight: str = 'distance') -&gt; NDArray[np.float64]\n</code></pre> <p>Compute pairwise geodesic distances between specified nodes.</p> <p>This is more efficient than computing the full distance matrix when you only need distances between a subset of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>G</code> <code>Graph</code> <p>NetworkX graph representing spatial connectivity.</p> required <code>nodes</code> <code>list[int] or NDArray[int_]</code> <p>List of node indices to compute distances between.</p> required <code>weight</code> <code>str</code> <p>Edge attribute to use as weight for path length calculation.</p> <code>\"distance\"</code> <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_nodes, n_nodes))</code> <p>Pairwise distance matrix where element (i, j) is the shortest path length between nodes[i] and nodes[j]. Disconnected nodes have distance np.inf.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import networkx as nx\n&gt;&gt;&gt; from neurospatial.distance import pairwise_distances\n&gt;&gt;&gt; G = nx.cycle_graph(10)\n&gt;&gt;&gt; for u, v in G.edges:\n...     G.edges[u, v][\"distance\"] = 1.0\n&gt;&gt;&gt; # Compute distances between nodes 0, 3, 7\n&gt;&gt;&gt; dists = pairwise_distances(G, [0, 3, 7])\n&gt;&gt;&gt; dists.shape\n(3, 3)\n&gt;&gt;&gt; dists[0, 1]  # Distance from node 0 to node 3\n3.0\n</code></pre> See Also <p>geodesic_distance_matrix : Compute all-pairs distances distance_field : Compute distance to nearest source</p> Source code in <code>src/neurospatial/distance.py</code> <pre><code>def pairwise_distances(\n    G: nx.Graph,\n    nodes: list[int] | NDArray[np.int_],\n    weight: str = \"distance\",\n) -&gt; NDArray[np.float64]:\n    \"\"\"Compute pairwise geodesic distances between specified nodes.\n\n    This is more efficient than computing the full distance matrix when you\n    only need distances between a subset of nodes.\n\n    Parameters\n    ----------\n    G : nx.Graph\n        NetworkX graph representing spatial connectivity.\n    nodes : list[int] or NDArray[np.int_]\n        List of node indices to compute distances between.\n    weight : str, default=\"distance\"\n        Edge attribute to use as weight for path length calculation.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_nodes, n_nodes)\n        Pairwise distance matrix where element (i, j) is the shortest path\n        length between nodes[i] and nodes[j]. Disconnected nodes have distance np.inf.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import networkx as nx\n    &gt;&gt;&gt; from neurospatial.distance import pairwise_distances\n    &gt;&gt;&gt; G = nx.cycle_graph(10)\n    &gt;&gt;&gt; for u, v in G.edges:\n    ...     G.edges[u, v][\"distance\"] = 1.0\n    &gt;&gt;&gt; # Compute distances between nodes 0, 3, 7\n    &gt;&gt;&gt; dists = pairwise_distances(G, [0, 3, 7])\n    &gt;&gt;&gt; dists.shape\n    (3, 3)\n    &gt;&gt;&gt; dists[0, 1]  # Distance from node 0 to node 3\n    3.0\n\n    See Also\n    --------\n    geodesic_distance_matrix : Compute all-pairs distances\n    distance_field : Compute distance to nearest source\n\n    \"\"\"\n    nodes_array = np.asarray(nodes, dtype=int)\n    n = len(nodes_array)\n\n    if n == 0:\n        return np.empty((0, 0), dtype=np.float64)\n\n    dist_matrix = np.full((n, n), np.inf, dtype=np.float64)\n\n    # Compute distances\n    for i, src in enumerate(nodes_array):\n        if src not in G.nodes:\n            continue\n\n        # Set self-distance to 0 for valid nodes\n        dist_matrix[i, i] = 0.0\n\n        lengths = nx.single_source_dijkstra_path_length(G, src, weight=weight)\n        for j, dst in enumerate(nodes_array):\n            if dst in lengths:\n                dist_matrix[i, j] = float(lengths[dst])\n\n    return dist_matrix\n</code></pre>"},{"location":"api/neurospatial/environment/","title":"<code>neurospatial.environment</code>","text":""},{"location":"api/neurospatial/environment/#neurospatial.environment","title":"environment","text":""},{"location":"api/neurospatial/environment/#neurospatial.environment-classes","title":"Classes","text":""},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment","title":"Environment  <code>dataclass</code>","text":"<pre><code>Environment(name: str = '', layout: LayoutEngine | None = None, layout_type_used: str | None = None, layout_params_used: dict[str, Any] | None = None, regions: Regions | None = None)\n</code></pre> <p>Represents a discretized N-dimensional space with connectivity.</p> <p>This class serves as a comprehensive model of a spatial environment, discretized into bins or nodes. It stores the geometric properties of these bins (e.g., centers, areas), their connectivity, and provides methods for various spatial queries and operations.</p> <p>Instances are typically created using one of the provided classmethod factories (e.g., <code>Environment.from_samples(...)</code>, <code>Environment.from_graph(...)</code>). These factories handle the underlying <code>LayoutEngine</code> setup.</p> Terminology <p>Active Bins     In neuroscience experiments, an animal typically explores only a subset     of the physical environment. \"Active bins\" are spatial bins that contain     data (e.g., position samples) or meet specified criteria (e.g., minimum     sample count). Only active bins are included in the environment's     <code>bin_centers</code> and <code>connectivity</code> graph.</p> <pre><code>This filtering is scientifically important because:\n\n- **Meaningful analysis**: Neural activity (e.g., place fields) can only\n  be computed in locations the animal actually visited\n- **Computational efficiency**: Excludes empty regions, reducing memory\n  and computation costs\n- **Statistical validity**: Prevents analysis of bins with insufficient\n  data\n\nFor example, in a plus maze experiment, only the maze arms are active;\nthe surrounding room is excluded. In an open field with a circular\nboundary, only bins inside the circle are active.\n\nThe `infer_active_bins` parameter in `Environment.from_samples()` controls\nwhether bins are automatically filtered based on data presence. Additional\nparameters (`bin_count_threshold`, `dilate`, `fill_holes`, `close_gaps`)\nprovide fine-grained control over which bins are considered active.\n</code></pre> Choosing a Factory Method <p>The <code>Environment</code> class provides six factory methods for creating environments. Choose based on your data format and use case:</p> <p>Most Common (ordered by frequency of use)</p> <ol> <li> <p>from_samples - Discretize position data into bins    Use when you have a collection of position samples (e.g., animal tracking    data) and want to automatically infer the spatial extent and active bins.    Supports automatic filtering, morphological operations (dilate, fill_holes,    close_gaps), and flexible bin size specification.    See <code>from_samples()</code>.</p> </li> <li> <p>from_polygon - Create grid masked by a polygon boundary    Use when your environment has a well-defined geometric boundary (e.g.,    circular arena, irregular enclosure) specified as a Shapely polygon. The    grid is automatically clipped to the polygon interior.    See <code>from_polygon()</code>.</p> </li> <li> <p>from_graph - Create 1D linearized track environment    Use when analyzing data on tracks or mazes where 2D position should be    projected onto a 1D linearized representation. Supports automatic    linearization and conversion between 2D and 1D coordinates.    See <code>from_graph()</code>.</p> </li> </ol> <p>Specialized Use Cases</p> <ol> <li> <p>from_mask - Create environment from pre-computed mask    Use when you have already determined which bins should be active (e.g.,    from external analysis) as an N-D boolean array. Requires explicit    specification of grid edges.    See <code>from_mask()</code>.</p> </li> <li> <p>from_image - Create environment from binary image    Use when your environment boundary is defined by a binary image (e.g.,    segmentation mask, overhead camera view). Each white pixel becomes a    potential bin.    See <code>from_image()</code>.</p> </li> </ol> <p>Advanced</p> <ol> <li>from_layout - Create environment from custom LayoutEngine    Use when you need full control over the layout engine (e.g., HexagonalLayout,    TriangularMeshLayout, custom tessellations) or are implementing advanced    spatial discretization schemes. The factory method <code>create_layout()</code> provides    access to all available layout engines.    See <code>from_layout()</code> and <code>neurospatial.layout.factories.create_layout()</code>.</li> </ol> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>A user-defined name for the environment.</p> <code>layout</code> <code>LayoutEngine</code> <p>The layout engine instance that defines the geometry and connectivity of the discretized space.</p> <code>bin_centers</code> <code>NDArray[float64]</code> <p>Coordinates of the center of each active bin/node in the environment. Shape is (n_active_bins, n_dims). Populated by <code>_setup_from_layout</code>.</p> <code>connectivity</code> <code>Graph</code> <p>A NetworkX graph where nodes are integers from <code>0</code> to <code>n_active_bins - 1</code>, directly corresponding to the rows of <code>bin_centers</code>. Edges represent adjacency between bins. Populated by <code>_setup_from_layout</code>.</p> <code>dimension_ranges</code> <code>Optional[Sequence[Tuple[float, float]]]</code> <p>The effective min/max extent <code>[(min_d0, max_d0), ..., (min_dN-1, max_dN-1)]</code> covered by the layout's geometry. Populated by <code>_setup_from_layout</code>.</p> <code>grid_edges</code> <code>Optional[Tuple[NDArray[float64], ...]]</code> <p>For grid-based layouts, a tuple where each element is a 1D array of bin edge positions for that dimension of the original, full grid. <code>None</code> or <code>()</code> for non-grid or point-based layouts. Populated by <code>_setup_from_layout</code>.</p> <code>grid_shape</code> <code>Optional[Tuple[int, ...]]</code> <p>For grid-based layouts, the N-D shape of the original, full grid. For point-based/cell-based layouts without a full grid concept, this may be <code>(n_active_bins,)</code>. Populated by <code>_setup_from_layout</code>.</p> <code>active_mask</code> <code>Optional[NDArray[bool_]]</code> <ul> <li>For grid-based layouts: An N-D boolean mask indicating active bins   on the original, full grid.</li> <li>For point-based/cell-based layouts: A 1D array of <code>True</code> values,   shape <code>(n_active_bins,)</code>, corresponding to <code>bin_centers</code>. Populated by <code>_setup_from_layout</code>.</li> </ul> <code>regions</code> <code>RegionManager</code> <p>Manages symbolic spatial regions defined within this environment.</p> <code>_is_1d_env</code> <code>bool</code> <p>Internal flag indicating if the environment's layout is primarily 1-dimensional. Set based on <code>layout.is_1d</code>.</p> <code>_is_fitted</code> <code>bool</code> <p>Internal flag indicating if the environment has been fully initialized and its layout-dependent attributes are populated.</p> <code>_layout_type_used</code> <code>Optional[str]</code> <p>The string identifier of the <code>LayoutEngine</code> type used to create this environment (e.g., \"RegularGrid\"). For introspection and serialization.</p> <code>_layout_params_used</code> <code>Dict[str, Any]</code> <p>A dictionary of the parameters used to build the <code>LayoutEngine</code> instance. For introspection and serialization.</p> <p>Initialize the Environment.</p> <p>Note: This constructor is primarily intended for internal use by factory methods. Users should typically create Environment instances using classmethods like <code>Environment.from_samples(...)</code>. The provided <code>layout</code> instance is assumed to be already built and configured.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the environment, by default \"\".</p> <code>''</code> <code>layout</code> <code>LayoutEngine</code> <p>A fully built LayoutEngine instance that defines the environment's geometry and connectivity.</p> <code>None</code> <code>layout_type_used</code> <code>Optional[str]</code> <p>The string identifier for the type of layout used. If None, it's inferred from <code>layout._layout_type_tag</code>. Defaults to None.</p> <code>None</code> <code>layout_params_used</code> <code>Optional[Dict[str, Any]]</code> <p>Parameters used to build the layout. If None, inferred from <code>layout._build_params_used</code>. Defaults to None.</p> <code>None</code> Source code in <code>src/neurospatial/environment.py</code> <pre><code>def __init__(\n    self,\n    name: str = \"\",\n    layout: LayoutEngine | None = None,\n    layout_type_used: str | None = None,\n    layout_params_used: dict[str, Any] | None = None,\n    regions: Regions | None = None,\n):\n    \"\"\"Initialize the Environment.\n\n    Note: This constructor is primarily intended for internal use by factory\n    methods. Users should typically create Environment instances using\n    classmethods like `Environment.from_samples(...)`. The provided\n    `layout` instance is assumed to be already built and configured.\n\n    Parameters\n    ----------\n    name : str, optional\n        Name for the environment, by default \"\".\n    layout : LayoutEngine\n        A fully built LayoutEngine instance that defines the environment's\n        geometry and connectivity.\n    layout_type_used : Optional[str], optional\n        The string identifier for the type of layout used. If None, it's\n        inferred from `layout._layout_type_tag`. Defaults to None.\n    layout_params_used : Optional[Dict[str, Any]], optional\n        Parameters used to build the layout. If None, inferred from\n        `layout._build_params_used`. Defaults to None.\n\n    \"\"\"\n    if layout is None:\n        raise ValueError(\"layout parameter is required\")\n\n    self.name = name\n    self.layout = layout\n\n    self._layout_type_used = (\n        layout_type_used\n        if layout_type_used\n        else getattr(layout, \"_layout_type_tag\", None)\n    )\n    self._layout_params_used = (\n        layout_params_used\n        if layout_params_used is not None\n        else getattr(layout, \"_build_params_used\", {})\n    )\n\n    self._is_1d_env = self.layout.is_1d\n\n    # Initialize attributes that will be populated by _setup_from_layout\n    self.bin_centers = np.empty((0, 0))  # Placeholder\n    self.connectivity = nx.Graph()\n    self.dimension_ranges = None\n    self.grid_edges = ()\n    self.grid_shape = None\n    self.active_mask = None\n    self._is_fitted = False  # Will be set by _setup_from_layout\n    if layout_type_used is not None:\n        self._setup_from_layout()  # Populate attributes from the built layout\n    if regions is not None:\n        if not isinstance(regions, Regions):\n            raise TypeError(\n                f\"Expected 'regions' to be a Regions instance, got {type(regions)}.\",\n            )\n        self.regions = regions\n    else:\n        # Initialize with an empty Regions instance if not provided\n        self.regions = Regions()\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment-attributes","title":"Attributes","text":""},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.is_1d","title":"is_1d  <code>property</code>","text":"<pre><code>is_1d: bool\n</code></pre> <p>Indicate if the environment's layout is primarily 1-dimensional.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the underlying <code>LayoutEngine</code> (<code>self.layout</code>) reports itself as 1-dimensional (e.g., <code>GraphLayout</code>), False otherwise. This is determined by <code>self.layout.is_1d</code>.</p>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.n_dims","title":"n_dims  <code>property</code>","text":"<pre><code>n_dims: int\n</code></pre> <p>Return the number of spatial dimensions of the active bin centers.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of dimensions (e.g., 1 for a line, 2 for a plane). Derived from the shape of <code>self.bin_centers</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted or if <code>bin_centers</code> is not available.</p>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.layout_parameters","title":"layout_parameters  <code>property</code>","text":"<pre><code>layout_parameters: dict[str, Any]\n</code></pre> <p>Return the parameters used to build the layout engine.</p> <p>This includes all parameters that were passed to the <code>build</code> method of the underlying <code>LayoutEngine</code>.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary of parameters used to create the layout. Useful for introspection and serialization.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.layout_type","title":"layout_type  <code>property</code>","text":"<pre><code>layout_type: str\n</code></pre> <p>Return the type of layout used in the environment.</p> <p>Returns:</p> Type Description <code>str</code> <p>The layout type (e.g., \"RegularGrid\", \"Hexagonal\").</p>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.n_bins","title":"n_bins  <code>property</code>","text":"<pre><code>n_bins: int\n</code></pre> <p>Return the number of active bins in the environment.</p> <p>This is determined by the number of rows in <code>self.bin_centers</code>.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of active bins (0 if not fitted).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.bin_sizes","title":"bin_sizes  <code>cached</code> <code>property</code>","text":"<pre><code>bin_sizes: NDArray[float64]\n</code></pre> <p>Calculate the area (for 2D) or volume (for 3D+) of each active bin.</p> <p>This represent the actual size of each bin in the environment, as opposed to the requested <code>bin_size</code> which is the nominal size used during layout creation.</p> <p>For 1D environments, this typically returns the length of each bin. This method delegates to the <code>bin_sizes</code> method of the underlying <code>LayoutEngine</code>.</p> <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_active_bins))</code> <p>An array containing the area/volume/length of each active bin.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.boundary_bins","title":"boundary_bins  <code>cached</code> <code>property</code>","text":"<pre><code>boundary_bins: NDArray[int_]\n</code></pre> <p>Get the boundary bin indices.</p> <p>Returns:</p> Type Description <code>(NDArray[int_], shape(n_boundary_bins))</code> <p>An array of indices of the boundary bins in the environment. These are the bins that are at the edges of the active area.</p>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.linearization_properties","title":"linearization_properties  <code>cached</code> <code>property</code>","text":"<pre><code>linearization_properties: dict[str, Any] | None\n</code></pre> <p>If the environment uses a GraphLayout, returns properties needed for linearization (converting a 2D/3D track to a 1D line) using the <code>track_linearization</code> library.</p> <p>These properties are typically passed to <code>track_linearization.get_linearized_position</code>.</p> <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>A dictionary with keys 'track_graph', 'edge_order', 'edge_spacing' if the layout is <code>GraphLayout</code> and parameters are available. Returns <code>None</code> otherwise.</p>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.bin_attributes","title":"bin_attributes  <code>cached</code> <code>property</code>","text":"<pre><code>bin_attributes: DataFrame\n</code></pre> <p>Build a DataFrame of attributes for each active bin (node) in the environment's graph.</p> <p>Returns:</p> Name Type Description <code>df</code> <code>DataFrame</code> <p>Rows are indexed by <code>active_bin_id</code> (int), matching 0..(n_bins-1). Columns correspond to node attributes. If a 'pos' attribute exists for any node and is non-null, it will be expanded into columns 'pos_dim0', 'pos_dim1', ..., with numeric coordinates.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there are no active bins (graph has zero nodes).</p>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.edge_attributes","title":"edge_attributes  <code>cached</code> <code>property</code>","text":"<pre><code>edge_attributes: DataFrame\n</code></pre> <p>Return a Pandas DataFrame where each row corresponds to one directed edge (u \u2192 v) in the connectivity graph, and columns include all stored edge attributes (e.g. 'distance', 'vector', 'weight', 'angle_2d', etc.).</p> <p>The DataFrame will have a MultiIndex of (source_bin, target_bin). If you prefer flat columns, you can reset the index.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame whose index is a MultiIndex (source_bin, target_bin), and whose columns are the union of all attribute-keys stored on each edge.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there are no edges in the connectivity graph.</p> <code>RuntimeError</code> <p>If called before the environment is fitted.</p>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment-functions","title":"Functions","text":""},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.info","title":"info","text":"<pre><code>info() -&gt; str\n</code></pre> <p>Return a detailed multi-line diagnostic summary of the environment.</p> <p>This method provides comprehensive diagnostic information about the environment, including geometric properties, layout configuration, and spatial characteristics. The output is formatted for readability with clear labels and organized sections.</p> <p>Returns:</p> Type Description <code>str</code> <p>Multi-line formatted string containing detailed environment information.</p> See Also <p>repr : Single-line concise representation for quick inspection. repr_html : Rich HTML representation for Jupyter notebooks.</p> Notes <p>This method is particularly useful for:</p> <ul> <li>Debugging spatial binning issues</li> <li>Verifying environment configuration</li> <li>Understanding the structure of complex environments</li> <li>Documenting environment parameters for reproducibility</li> </ul> <p>The output includes all critical diagnostic information:</p> <ul> <li>Environment name and layout type</li> <li>Spatial dimensionality and bin count</li> <li>Physical extent in each dimension</li> <li>Bin size statistics (uniform or variable)</li> <li>Region of interest count</li> <li>Linearization status (for 1D environments)</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; data = np.random.rand(500, 2) * 100  # 2D data in cm\n&gt;&gt;&gt; env = Environment.from_samples(data, bin_size=5.0, name=\"OpenField\")\n&gt;&gt;&gt; print(env.info())\nEnvironment Information\n=======================\nName: OpenField\nLayout Type: RegularGridLayout\nDimensions: 2\nNumber of Bins: 400\n\nSpatial Extent:\n  Dimension 0: [-2.50, 102.50] (range: 105.00)\n  Dimension 1: [-2.50, 102.50] (range: 105.00)\n\nBin Sizes:\n  Dimension 0: 5.00\n  Dimension 1: 5.00\n\nRegions: 0\n</code></pre> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef info(self) -&gt; str:\n    \"\"\"Return a detailed multi-line diagnostic summary of the environment.\n\n    This method provides comprehensive diagnostic information about the\n    environment, including geometric properties, layout configuration, and\n    spatial characteristics. The output is formatted for readability with\n    clear labels and organized sections.\n\n    Returns\n    -------\n    str\n        Multi-line formatted string containing detailed environment information.\n\n    See Also\n    --------\n    __repr__ : Single-line concise representation for quick inspection.\n    _repr_html_ : Rich HTML representation for Jupyter notebooks.\n\n    Notes\n    -----\n    This method is particularly useful for:\n\n    - Debugging spatial binning issues\n    - Verifying environment configuration\n    - Understanding the structure of complex environments\n    - Documenting environment parameters for reproducibility\n\n    The output includes all critical diagnostic information:\n\n    - Environment name and layout type\n    - Spatial dimensionality and bin count\n    - Physical extent in each dimension\n    - Bin size statistics (uniform or variable)\n    - Region of interest count\n    - Linearization status (for 1D environments)\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; data = np.random.rand(500, 2) * 100  # 2D data in cm\n    &gt;&gt;&gt; env = Environment.from_samples(data, bin_size=5.0, name=\"OpenField\")\n    &gt;&gt;&gt; print(env.info())  # doctest: +SKIP\n    Environment Information\n    =======================\n    Name: OpenField\n    Layout Type: RegularGridLayout\n    Dimensions: 2\n    Number of Bins: 400\n    &lt;BLANKLINE&gt;\n    Spatial Extent:\n      Dimension 0: [-2.50, 102.50] (range: 105.00)\n      Dimension 1: [-2.50, 102.50] (range: 105.00)\n    &lt;BLANKLINE&gt;\n    Bin Sizes:\n      Dimension 0: 5.00\n      Dimension 1: 5.00\n    &lt;BLANKLINE&gt;\n    Regions: 0\n    \"\"\"\n    # Build output line by line\n    lines = []\n\n    # Header\n    lines.append(\"Environment Information\")\n    lines.append(\"=\" * 23)\n    lines.append(\"\")\n\n    # Basic information\n    name_display = self.name if self.name else \"(unnamed)\"\n    lines.append(f\"Name: {name_display}\")\n    lines.append(f\"Layout Type: {self.layout_type}\")\n    lines.append(f\"Dimensions: {self.n_dims}\")\n    lines.append(f\"Number of Bins: {self.n_bins}\")\n    lines.append(\"\")\n\n    # Spatial extent\n    if self.dimension_ranges is not None:\n        lines.append(\"Spatial Extent:\")\n        for dim_idx, (dim_min, dim_max) in enumerate(self.dimension_ranges):\n            dim_range = dim_max - dim_min\n            lines.append(\n                f\"  Dimension {dim_idx}: [{dim_min:.2f}, {dim_max:.2f}] \"\n                f\"(range: {dim_range:.2f})\"\n            )\n        lines.append(\"\")\n    else:\n        lines.append(\"Spatial Extent: Not available\")\n        lines.append(\"\")\n\n    # Bin sizes\n    lines.append(\"Bin Sizes:\")\n    try:\n        bin_sizes_array = self.bin_sizes\n\n        # Check if all bins have the same size (uniform)\n        if np.allclose(bin_sizes_array, bin_sizes_array[0]):\n            # Uniform bin size - for grids, extract per-dimension from grid_edges\n            if self.grid_edges and all(len(e) &gt; 1 for e in self.grid_edges):\n                for dim_idx, edges in enumerate(self.grid_edges):\n                    dim_sizes = np.diff(edges)\n                    if np.allclose(dim_sizes, dim_sizes[0]):\n                        lines.append(f\"  Dimension {dim_idx}: {dim_sizes[0]:.2f}\")\n                    else:\n                        lines.append(\n                            f\"  Dimension {dim_idx}: variable \"\n                            f\"(mean: {np.mean(dim_sizes):.2f}, \"\n                            f\"std: {np.std(dim_sizes):.2f})\"\n                        )\n            else:\n                # Non-grid layout or 1D - show the uniform measure\n                measure_name = (\n                    \"Size\"\n                    if self.n_dims == 1\n                    else \"Area\"\n                    if self.n_dims == 2\n                    else \"Volume\"\n                )\n                lines.append(f\"  {measure_name}: {bin_sizes_array[0]:.2f}\")\n        else:\n            # Variable bin sizes\n            lines.append(\n                f\"  Variable (mean: {np.mean(bin_sizes_array):.2f}, \"\n                f\"std: {np.std(bin_sizes_array):.2f}, \"\n                f\"range: [{np.min(bin_sizes_array):.2f}, {np.max(bin_sizes_array):.2f}])\"\n            )\n    except (AttributeError, RuntimeError, ValueError):\n        lines.append(\"  (not available)\")\n    lines.append(\"\")\n\n    # Regions\n    n_regions = len(self.regions) if self.regions else 0\n    if n_regions &gt; 0:\n        lines.append(f\"Regions: {n_regions} defined\")\n        # Show region names if not too many\n        if n_regions &lt;= 5:\n            for region_name in self.regions:\n                lines.append(f\"  - {region_name}\")\n        else:\n            lines.append(\"  (use env.regions to inspect all regions)\")\n    else:\n        lines.append(\"Regions: None\")\n    lines.append(\"\")\n\n    # 1D-specific information\n    if hasattr(self, \"is_1d\") and self.is_1d:\n        lines.append(\"Linearization: Available (1D environment)\")\n        lines.append(\"\")\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.from_samples","title":"from_samples  <code>classmethod</code>","text":"<pre><code>from_samples(data_samples: NDArray[float64], bin_size: float | Sequence[float], name: str = '', layout_kind: str = 'RegularGrid', infer_active_bins: bool = True, bin_count_threshold: int = 0, dilate: bool = False, fill_holes: bool = False, close_gaps: bool = False, add_boundary_bins: bool = False, connect_diagonal_neighbors: bool = True, **layout_specific_kwargs: Any) -&gt; Environment\n</code></pre> <p>Create an Environment by binning (discretizing) <code>data_samples</code> into a layout grid.</p> <p>Parameters:</p> Name Type Description Default <code>data_samples</code> <code>(array, shape(n_samples, n_dims))</code> <p>Coordinates of sample points used to infer which bins are \"active.\"</p> required <code>bin_size</code> <code>float or sequence of floats</code> <p>Size of each bin in the same units as <code>data_samples</code> coordinates. For RegularGrid: length of each square bin side (or per-dimension if sequence). For Hexagonal: hexagon width (flat-to-flat distance across hexagon). If your data is in centimeters, bin_size=5.0 creates 5cm bins.</p> required <code>name</code> <code>str</code> <p>Optional name for the resulting Environment.</p> <code>\"\"</code> <code>layout_kind</code> <code>str</code> <p>Either \"RegularGrid\" or \"Hexagonal\" (case-insensitive). Determines bin shape. For \"Hexagonal\", <code>bin_size</code> is interpreted as <code>hexagon_width</code>.</p> <code>\"RegularGrid\"</code> <code>infer_active_bins</code> <code>bool</code> <p>If True, only bins containing \u2265 <code>bin_count_threshold</code> samples are \u201cactive.\u201d</p> <code>True</code> <code>bin_count_threshold</code> <code>int</code> <p>Minimum number of data points required for a bin to be considered \u201cactive.\u201d</p> <code>0</code> <code>dilate</code> <code>bool</code> <p>If True, apply morphological dilation to the active-bin mask.</p> <code>False</code> <code>fill_holes</code> <code>bool</code> <p>If True, fill holes in the active-bin mask.</p> <code>False</code> <code>close_gaps</code> <code>bool</code> <p>If True, close small gaps between active bins.</p> <code>False</code> <code>add_boundary_bins</code> <code>bool</code> <p>If True, add peripheral bins around the bounding region of samples.</p> <code>False</code> <code>connect_diagonal_neighbors</code> <code>bool</code> <p>If True, connect grid bins diagonally when building connectivity.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>env</code> <code>Environment</code> <p>A newly created Environment, fitted to the discretized samples.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>data_samples</code> is not 2D or contains invalid coordinates.</p> <code>NotImplementedError</code> <p>If <code>layout_kind</code> is neither \"RegularGrid\" nor \"Hexagonal\".</p> See Also <p>from_polygon : Create environment with polygon-defined boundary. from_mask : Create environment from pre-defined boolean mask. from_image : Create environment from binary image mask. from_graph : Create 1D linearized track environment. from_layout : Create environment with custom LayoutEngine.</p> <p>Examples:</p> <p>Create a simple 2D environment from position data:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; # Simulate animal position data in a 100x100 cm arena\n&gt;&gt;&gt; np.random.seed(42)  # For reproducible examples\n&gt;&gt;&gt; positions = np.random.rand(1000, 2) * 100  # cm\n&gt;&gt;&gt; # Create environment with 5cm x 5cm bins\n&gt;&gt;&gt; env = Environment.from_samples(\n...     data_samples=positions,\n...     bin_size=5.0,\n...     name=\"arena\",  # bin_size in cm\n... )\n&gt;&gt;&gt; env.n_dims\n2\n&gt;&gt;&gt; env.n_bins &gt; 0\nTrue\n</code></pre> <p>Create environment with morphological operations to clean up the active region:</p> <pre><code>&gt;&gt;&gt; env = Environment.from_samples(\n...     data_samples=positions,\n...     bin_size=5.0,  # 5cm bins\n...     bin_count_threshold=5,  # Require 5 samples per bin (lowered from 10)\n...     dilate=True,  # Expand active region\n...     fill_holes=True,  # Fill interior holes\n... )\n</code></pre> <p>Create a hexagonal grid environment:</p> <pre><code>&gt;&gt;&gt; env = Environment.from_samples(\n...     data_samples=positions,\n...     layout_kind=\"Hexagonal\",\n...     bin_size=5.0,  # 5cm hexagon width\n... )\n</code></pre> Common Pitfalls <ol> <li> <p>bin_size too large: If bin_size is too large relative to your data    range, you may end up with very few bins or no active bins at all.    For example, if your data spans 0-100 cm and you use bin_size=200.0,    you'll only get 1 bin. Try reducing bin_size to create more spatial    resolution (e.g., bin_size=5.0 for 5cm bins).</p> </li> <li> <p>bin_count_threshold too high: Setting bin_count_threshold higher    than the number of samples per bin will result in no active bins.    If you have sparse data with only a few samples per location, try    reducing bin_count_threshold to 0 or 1, or use morphological operations    to expand the active region.</p> </li> <li> <p>Mismatched units: Ensure bin_size and data_samples use the same    units. If your data is in centimeters, bin_size should also be in    centimeters. Mixing units (e.g., data in meters, bin_size in centimeters)    will result in incorrect spatial binning. For example, if your data spans    0-1 meters (100 cm) and you set bin_size=5.0 thinking it's centimeters,    you'll get only 1 bin instead of 20 bins.</p> </li> <li> <p>Missing morphological operations with sparse data: If your data is    sparse (animal didn't visit all locations uniformly), the active region    may have holes or gaps. Enable dilate=True, fill_holes=True, or    close_gaps=True to create a more continuous active region. These    operations are particularly useful for connecting isolated bins or    filling small unvisited areas within explored regions.</p> </li> </ol> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef from_samples(\n    cls,\n    data_samples: NDArray[np.float64],\n    bin_size: float | Sequence[float],\n    name: str = \"\",\n    layout_kind: str = \"RegularGrid\",\n    infer_active_bins: bool = True,\n    bin_count_threshold: int = 0,\n    dilate: bool = False,\n    fill_holes: bool = False,\n    close_gaps: bool = False,\n    add_boundary_bins: bool = False,\n    connect_diagonal_neighbors: bool = True,\n    **layout_specific_kwargs: Any,\n) -&gt; Environment:\n    \"\"\"Create an Environment by binning (discretizing) `data_samples` into a layout grid.\n\n    Parameters\n    ----------\n    data_samples : array, shape (n_samples, n_dims)\n        Coordinates of sample points used to infer which bins are \"active.\"\n    bin_size : float or sequence of floats\n        Size of each bin in the same units as `data_samples` coordinates.\n        For RegularGrid: length of each square bin side (or per-dimension if sequence).\n        For Hexagonal: hexagon width (flat-to-flat distance across hexagon).\n        If your data is in centimeters, bin_size=5.0 creates 5cm bins.\n    name : str, default \"\"\n        Optional name for the resulting Environment.\n    layout_kind : str, default \"RegularGrid\"\n        Either \"RegularGrid\" or \"Hexagonal\" (case-insensitive). Determines\n        bin shape. For \"Hexagonal\", `bin_size` is interpreted as `hexagon_width`.\n    infer_active_bins : bool, default True\n        If True, only bins containing \u2265 `bin_count_threshold` samples are \u201cactive.\u201d\n    bin_count_threshold : int, default 0\n        Minimum number of data points required for a bin to be considered \u201cactive.\u201d\n    dilate : bool, default False\n        If True, apply morphological dilation to the active-bin mask.\n    fill_holes : bool, default False\n        If True, fill holes in the active-bin mask.\n    close_gaps : bool, default False\n        If True, close small gaps between active bins.\n    add_boundary_bins : bool, default False\n        If True, add peripheral bins around the bounding region of samples.\n    connect_diagonal_neighbors : bool, default True\n        If True, connect grid bins diagonally when building connectivity.\n\n    Returns\n    -------\n    env : Environment\n        A newly created Environment, fitted to the discretized samples.\n\n    Raises\n    ------\n    ValueError\n        If `data_samples` is not 2D or contains invalid coordinates.\n    NotImplementedError\n        If `layout_kind` is neither \"RegularGrid\" nor \"Hexagonal\".\n\n    See Also\n    --------\n    from_polygon : Create environment with polygon-defined boundary.\n    from_mask : Create environment from pre-defined boolean mask.\n    from_image : Create environment from binary image mask.\n    from_graph : Create 1D linearized track environment.\n    from_layout : Create environment with custom LayoutEngine.\n\n    Examples\n    --------\n    Create a simple 2D environment from position data:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; # Simulate animal position data in a 100x100 cm arena\n    &gt;&gt;&gt; np.random.seed(42)  # For reproducible examples\n    &gt;&gt;&gt; positions = np.random.rand(1000, 2) * 100  # cm\n    &gt;&gt;&gt; # Create environment with 5cm x 5cm bins\n    &gt;&gt;&gt; env = Environment.from_samples(\n    ...     data_samples=positions,\n    ...     bin_size=5.0,\n    ...     name=\"arena\",  # bin_size in cm\n    ... )\n    &gt;&gt;&gt; env.n_dims\n    2\n    &gt;&gt;&gt; env.n_bins &gt; 0\n    True\n\n    Create environment with morphological operations to clean up the active region:\n\n    &gt;&gt;&gt; env = Environment.from_samples(\n    ...     data_samples=positions,\n    ...     bin_size=5.0,  # 5cm bins\n    ...     bin_count_threshold=5,  # Require 5 samples per bin (lowered from 10)\n    ...     dilate=True,  # Expand active region\n    ...     fill_holes=True,  # Fill interior holes\n    ... )\n\n    Create a hexagonal grid environment:\n\n    &gt;&gt;&gt; env = Environment.from_samples(\n    ...     data_samples=positions,\n    ...     layout_kind=\"Hexagonal\",\n    ...     bin_size=5.0,  # 5cm hexagon width\n    ... )\n\n    Common Pitfalls\n    ---------------\n    1. **bin_size too large**: If bin_size is too large relative to your data\n       range, you may end up with very few bins or no active bins at all.\n       For example, if your data spans 0-100 cm and you use bin_size=200.0,\n       you'll only get 1 bin. Try reducing bin_size to create more spatial\n       resolution (e.g., bin_size=5.0 for 5cm bins).\n\n    2. **bin_count_threshold too high**: Setting bin_count_threshold higher\n       than the number of samples per bin will result in no active bins.\n       If you have sparse data with only a few samples per location, try\n       reducing bin_count_threshold to 0 or 1, or use morphological operations\n       to expand the active region.\n\n    3. **Mismatched units**: Ensure bin_size and data_samples use the same\n       units. If your data is in centimeters, bin_size should also be in\n       centimeters. Mixing units (e.g., data in meters, bin_size in centimeters)\n       will result in incorrect spatial binning. For example, if your data spans\n       0-1 meters (100 cm) and you set bin_size=5.0 thinking it's centimeters,\n       you'll get only 1 bin instead of 20 bins.\n\n    4. **Missing morphological operations with sparse data**: If your data is\n       sparse (animal didn't visit all locations uniformly), the active region\n       may have holes or gaps. Enable dilate=True, fill_holes=True, or\n       close_gaps=True to create a more continuous active region. These\n       operations are particularly useful for connecting isolated bins or\n       filling small unvisited areas within explored regions.\n\n    \"\"\"\n    # Convert and validate data_samples array with helpful error messages\n    try:\n        data_samples = np.asarray(data_samples, dtype=float)\n    except (TypeError, ValueError) as e:\n        actual_type = type(data_samples).__name__\n        raise TypeError(\n            f\"data_samples must be a numeric array-like object (e.g., numpy array, \"\n            f\"list of lists, pandas DataFrame). Got {actual_type}: {data_samples!r}\"\n        ) from e\n\n    if data_samples.ndim != 2:\n        raise ValueError(\n            f\"data_samples must be a 2D array of shape (n_points, n_dims), \"\n            f\"got shape {data_samples.shape}.\",\n        )\n\n    # Validate bin_size early to provide helpful error messages\n    if not isinstance(bin_size, (int, float, list, tuple, np.ndarray)):\n        actual_type = type(bin_size).__name__\n        raise TypeError(\n            f\"bin_size must be a numeric value or sequence of numeric values. \"\n            f\"Got {actual_type}: {bin_size!r}\"\n        )\n\n    # Standardize layout_kind to lowercase for comparison\n    kind_lower = layout_kind.lower()\n    if kind_lower not in (\"regulargrid\", \"hexagonal\"):\n        raise NotImplementedError(\n            f\"Layout kind '{layout_kind}' is not supported. \"\n            \"Use 'RegularGrid' or 'Hexagonal'.\",\n        )\n\n    # Build the dict of layout parameters\n    layout_params: dict[str, Any] = {\n        \"data_samples\": data_samples,\n        \"infer_active_bins\": infer_active_bins,\n        \"bin_count_threshold\": bin_count_threshold,\n        **layout_specific_kwargs,\n    }\n\n    if kind_lower == \"regulargrid\":\n        layout_params.update(\n            {\n                \"bin_size\": bin_size,\n                \"add_boundary_bins\": add_boundary_bins,\n                \"dilate\": dilate,\n                \"fill_holes\": fill_holes,\n                \"close_gaps\": close_gaps,\n                \"connect_diagonal_neighbors\": connect_diagonal_neighbors,\n            },\n        )\n    elif kind_lower == \"hexagonal\":\n        layout_params.update(\n            {\n                \"hexagon_width\": bin_size,\n            },\n        )\n    else:\n        raise NotImplementedError(\n            f\"Layout kind '{layout_kind}' is not supported. \"\n            \"Use 'RegularGrid' or 'Hexagonal'.\",\n        )\n\n    return cls.from_layout(kind=layout_kind, layout_params=layout_params, name=name)\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.from_graph","title":"from_graph  <code>classmethod</code>","text":"<pre><code>from_graph(graph: Graph, edge_order: list[tuple[Any, Any]], edge_spacing: float | Sequence[float], bin_size: float, name: str = '') -&gt; Environment\n</code></pre> <p>Create an Environment from a user-defined graph structure.</p> <p>This method is used for 1D environments where the spatial layout is defined by a graph, an ordered list of its edges, and spacing between these edges. The track is then linearized and binned.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>Graph</code> <p>The NetworkX graph defining the track segments. Nodes are expected to have a 'pos' attribute for their N-D coordinates.</p> required <code>edge_order</code> <code>List[Tuple[Any, Any]]</code> <p>An ordered list of edge tuples (node1, node2) from <code>graph</code> that defines the 1D bin ordering.</p> required <code>edge_spacing</code> <code>Union[float, Sequence[float]]</code> <p>The spacing to insert between consecutive edges in <code>edge_order</code> during linearization, in the same units as the graph node coordinates. If a float, applies to all gaps. If a sequence, specifies spacing for each gap.</p> required <code>bin_size</code> <code>float</code> <p>The length of each bin along the linearized track, in the same units as the graph node coordinates. For example, if node positions are in centimeters, bin_size=2.0 creates 2cm bins along the track.</p> required <code>name</code> <code>str</code> <p>A name for the created environment. Defaults to \"\".</p> <code>''</code> <p>Returns:</p> Type Description <code>Environment</code> <p>A new Environment instance with a <code>GraphLayout</code>.</p> See Also <p>from_samples : Create environment by binning position data. from_layout : Create environment with custom LayoutEngine.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef from_graph(\n    cls,\n    graph: nx.Graph,\n    edge_order: list[tuple[Any, Any]],\n    edge_spacing: float | Sequence[float],\n    bin_size: float,\n    name: str = \"\",\n) -&gt; Environment:\n    \"\"\"Create an Environment from a user-defined graph structure.\n\n    This method is used for 1D environments where the spatial layout is\n    defined by a graph, an ordered list of its edges, and spacing between\n    these edges. The track is then linearized and binned.\n\n    Parameters\n    ----------\n    graph : nx.Graph\n        The NetworkX graph defining the track segments. Nodes are expected\n        to have a 'pos' attribute for their N-D coordinates.\n    edge_order : List[Tuple[Any, Any]]\n        An ordered list of edge tuples (node1, node2) from `graph` that\n        defines the 1D bin ordering.\n    edge_spacing : Union[float, Sequence[float]]\n        The spacing to insert between consecutive edges in `edge_order`\n        during linearization, in the same units as the graph node coordinates.\n        If a float, applies to all gaps. If a sequence, specifies spacing for\n        each gap.\n    bin_size : float\n        The length of each bin along the linearized track, in the same units\n        as the graph node coordinates. For example, if node positions are in\n        centimeters, bin_size=2.0 creates 2cm bins along the track.\n    name : str, optional\n        A name for the created environment. Defaults to \"\".\n\n    Returns\n    -------\n    Environment\n        A new Environment instance with a `GraphLayout`.\n\n    See Also\n    --------\n    from_samples : Create environment by binning position data.\n    from_layout : Create environment with custom LayoutEngine.\n\n    \"\"\"\n    layout_params = {\n        \"graph_definition\": graph,\n        \"edge_order\": edge_order,\n        \"edge_spacing\": edge_spacing,\n        \"bin_size\": bin_size,\n    }\n    return cls.from_layout(kind=\"Graph\", layout_params=layout_params, name=name)\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.from_polygon","title":"from_polygon  <code>classmethod</code>","text":"<pre><code>from_polygon(polygon: PolygonType, bin_size: float | Sequence[float], name: str = '', connect_diagonal_neighbors: bool = True) -&gt; Environment\n</code></pre> <p>Create a 2D grid Environment masked by a Shapely Polygon.</p> <p>A regular grid is formed based on the polygon's bounds and <code>bin_size</code>. Only grid cells whose centers are contained within the polygon are considered active.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>The Shapely Polygon object that defines the boundary of the active area.</p> required <code>bin_size</code> <code>float or sequence of floats</code> <p>The side length(s) of the grid cells, in the same units as the polygon coordinates. If a float, creates square bins. If a sequence, specifies bin size per dimension.</p> required <code>name</code> <code>str</code> <p>A name for the created environment. Defaults to \"\".</p> <code>''</code> <code>connect_diagonal_neighbors</code> <code>bool</code> <p>Whether to connect diagonally adjacent active grid cells. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Environment</code> <p>A new Environment instance with a <code>ShapelyPolygonLayout</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the 'shapely' package is not installed.</p> See Also <p>from_samples : Create environment by binning position data. from_mask : Create environment from pre-defined boolean mask. from_image : Create environment from binary image mask.</p> <p>Examples:</p> <p>Create an environment from a rectangular polygon:</p> <pre><code>&gt;&gt;&gt; from shapely.geometry import Polygon\n&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; # Create a simple rectangular arena (100cm x 50cm)\n&gt;&gt;&gt; polygon = Polygon([(0, 0), (100, 0), (100, 50), (0, 50)])  # cm\n&gt;&gt;&gt; env = Environment.from_polygon(\n...     polygon=polygon,\n...     bin_size=5.0,\n...     name=\"rectangular_arena\",  # 5cm bins\n... )\n&gt;&gt;&gt; env.n_dims\n2\n</code></pre> <p>Create an environment from a circular arena:</p> <pre><code>&gt;&gt;&gt; from shapely.geometry import Point\n&gt;&gt;&gt; center = Point(50, 50)  # cm\n&gt;&gt;&gt; circular_polygon = center.buffer(25)  # Circle with radius 25cm\n&gt;&gt;&gt; env = Environment.from_polygon(\n...     polygon=circular_polygon,\n...     bin_size=2.0,  # 2cm bins\n... )\n</code></pre> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef from_polygon(\n    cls,\n    polygon: PolygonType,\n    bin_size: float | Sequence[float],\n    name: str = \"\",\n    connect_diagonal_neighbors: bool = True,\n) -&gt; Environment:\n    \"\"\"Create a 2D grid Environment masked by a Shapely Polygon.\n\n    A regular grid is formed based on the polygon's bounds and `bin_size`.\n    Only grid cells whose centers are contained within the polygon are\n    considered active.\n\n    Parameters\n    ----------\n    polygon : shapely.geometry.Polygon\n        The Shapely Polygon object that defines the boundary of the active area.\n    bin_size : float or sequence of floats\n        The side length(s) of the grid cells, in the same units as the polygon\n        coordinates. If a float, creates square bins. If a sequence, specifies\n        bin size per dimension.\n    name : str, optional\n        A name for the created environment. Defaults to \"\".\n    connect_diagonal_neighbors : bool, optional\n        Whether to connect diagonally adjacent active grid cells.\n        Defaults to True.\n\n    Returns\n    -------\n    Environment\n        A new Environment instance with a `ShapelyPolygonLayout`.\n\n    Raises\n    ------\n    RuntimeError\n        If the 'shapely' package is not installed.\n\n    See Also\n    --------\n    from_samples : Create environment by binning position data.\n    from_mask : Create environment from pre-defined boolean mask.\n    from_image : Create environment from binary image mask.\n\n    Examples\n    --------\n    Create an environment from a rectangular polygon:\n\n    &gt;&gt;&gt; from shapely.geometry import Polygon\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; # Create a simple rectangular arena (100cm x 50cm)\n    &gt;&gt;&gt; polygon = Polygon([(0, 0), (100, 0), (100, 50), (0, 50)])  # cm\n    &gt;&gt;&gt; env = Environment.from_polygon(\n    ...     polygon=polygon,\n    ...     bin_size=5.0,\n    ...     name=\"rectangular_arena\",  # 5cm bins\n    ... )\n    &gt;&gt;&gt; env.n_dims\n    2\n\n    Create an environment from a circular arena:\n\n    &gt;&gt;&gt; from shapely.geometry import Point\n    &gt;&gt;&gt; center = Point(50, 50)  # cm\n    &gt;&gt;&gt; circular_polygon = center.buffer(25)  # Circle with radius 25cm\n    &gt;&gt;&gt; env = Environment.from_polygon(\n    ...     polygon=circular_polygon,\n    ...     bin_size=2.0,  # 2cm bins\n    ... )\n\n    \"\"\"\n    layout_params = {\n        \"polygon\": polygon,\n        \"bin_size\": bin_size,\n        \"connect_diagonal_neighbors\": connect_diagonal_neighbors,\n    }\n    return cls.from_layout(\n        kind=\"ShapelyPolygon\",\n        layout_params=layout_params,\n        name=name,\n    )\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.from_mask","title":"from_mask  <code>classmethod</code>","text":"<pre><code>from_mask(active_mask: NDArray[bool_], grid_edges: tuple[NDArray[float64], ...], name: str = '', connect_diagonal_neighbors: bool = True) -&gt; Environment\n</code></pre> <p>Create an Environment from a pre-defined N-D boolean mask and grid edges.</p> <p>This factory method allows for precise specification of active bins in an N-dimensional grid.</p> <p>Parameters:</p> Name Type Description Default <code>active_mask</code> <code>NDArray[bool_]</code> <p>An N-dimensional boolean array where <code>True</code> indicates an active bin. The shape of this mask must correspond to the number of bins implied by <code>grid_edges</code> (i.e., <code>tuple(len(e)-1 for e in grid_edges)</code>).</p> required <code>grid_edges</code> <code>Tuple[NDArray[float64], ...]</code> <p>A tuple where each element is a 1D NumPy array of bin edge positions for that dimension, in physical units (e.g., cm, meters). The edges define the boundaries of bins along each dimension. For example, edges [0, 10, 20, 30] define three bins: [0-10], [10-20], [20-30].</p> required <code>name</code> <code>str</code> <p>A name for the created environment. Defaults to \"\".</p> <code>''</code> <code>connect_diagonal_neighbors</code> <code>bool</code> <p>Whether to connect diagonally adjacent active grid cells. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Environment</code> <p>A new Environment instance with a <code>MaskedGridLayout</code>.</p> See Also <p>from_samples : Create environment by binning position data. from_polygon : Create environment with polygon-defined boundary. from_image : Create environment from binary image mask.</p> <p>Examples:</p> <p>Create an environment from a custom mask:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; # Create a simple 2D mask (10x10 grid with center region active)\n&gt;&gt;&gt; mask = np.zeros((10, 10), dtype=bool)\n&gt;&gt;&gt; mask[3:7, 3:7] = True  # Center 4x4 region is active\n&gt;&gt;&gt; # Define grid edges (creates 10cm x 10cm bins)\n&gt;&gt;&gt; grid_edges = (\n...     np.linspace(0, 100, 11),  # x edges in cm\n...     np.linspace(0, 100, 11),  # y edges in cm\n... )\n&gt;&gt;&gt; env = Environment.from_mask(\n...     active_mask=mask, grid_edges=grid_edges, name=\"center_region\"\n... )\n&gt;&gt;&gt; env.n_bins\n16\n</code></pre> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef from_mask(\n    cls,\n    active_mask: NDArray[np.bool_],\n    grid_edges: tuple[NDArray[np.float64], ...],\n    name: str = \"\",\n    connect_diagonal_neighbors: bool = True,\n) -&gt; Environment:\n    \"\"\"Create an Environment from a pre-defined N-D boolean mask and grid edges.\n\n    This factory method allows for precise specification of active bins in\n    an N-dimensional grid.\n\n    Parameters\n    ----------\n    active_mask : NDArray[np.bool_]\n        An N-dimensional boolean array where `True` indicates an active bin.\n        The shape of this mask must correspond to the number of bins implied\n        by `grid_edges` (i.e., `tuple(len(e)-1 for e in grid_edges)`).\n    grid_edges : Tuple[NDArray[np.float64], ...]\n        A tuple where each element is a 1D NumPy array of bin edge positions\n        for that dimension, in physical units (e.g., cm, meters). The edges\n        define the boundaries of bins along each dimension. For example, edges\n        [0, 10, 20, 30] define three bins: [0-10], [10-20], [20-30].\n    name : str, optional\n        A name for the created environment. Defaults to \"\".\n    connect_diagonal_neighbors : bool, optional\n        Whether to connect diagonally adjacent active grid cells.\n        Defaults to True.\n\n    Returns\n    -------\n    Environment\n        A new Environment instance with a `MaskedGridLayout`.\n\n    See Also\n    --------\n    from_samples : Create environment by binning position data.\n    from_polygon : Create environment with polygon-defined boundary.\n    from_image : Create environment from binary image mask.\n\n    Examples\n    --------\n    Create an environment from a custom mask:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; # Create a simple 2D mask (10x10 grid with center region active)\n    &gt;&gt;&gt; mask = np.zeros((10, 10), dtype=bool)\n    &gt;&gt;&gt; mask[3:7, 3:7] = True  # Center 4x4 region is active\n    &gt;&gt;&gt; # Define grid edges (creates 10cm x 10cm bins)\n    &gt;&gt;&gt; grid_edges = (\n    ...     np.linspace(0, 100, 11),  # x edges in cm\n    ...     np.linspace(0, 100, 11),  # y edges in cm\n    ... )\n    &gt;&gt;&gt; env = Environment.from_mask(\n    ...     active_mask=mask, grid_edges=grid_edges, name=\"center_region\"\n    ... )\n    &gt;&gt;&gt; env.n_bins\n    16\n\n    \"\"\"\n    layout_params = {\n        \"active_mask\": active_mask,\n        \"grid_edges\": grid_edges,\n        \"connect_diagonal_neighbors\": connect_diagonal_neighbors,\n    }\n\n    return cls.from_layout(\n        kind=\"MaskedGrid\",\n        layout_params=layout_params,\n        name=name,\n    )\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.from_image","title":"from_image  <code>classmethod</code>","text":"<pre><code>from_image(image_mask: NDArray[bool_], bin_size: float | tuple[float, float], connect_diagonal_neighbors: bool = True, name: str = '') -&gt; Environment\n</code></pre> <p>Create a 2D Environment from a binary image mask.</p> <p>Each <code>True</code> pixel in the <code>image_mask</code> becomes an active bin in the environment. The <code>bin_size</code> determines the spatial scale of these pixels.</p> <p>Parameters:</p> Name Type Description Default <code>image_mask</code> <code>(NDArray[bool_], shape(n_rows, n_cols))</code> <p>A 2D boolean array where <code>True</code> pixels define active bins.</p> required <code>bin_size</code> <code>float or tuple of (float, float)</code> <p>The spatial size of each pixel in physical units (e.g., cm, meters). If a float, pixels are square. If a tuple <code>(width, height)</code>, specifies pixel dimensions. For example, if your camera captures images where each pixel represents 0.5cm, use bin_size=0.5.</p> required <code>connect_diagonal_neighbors</code> <code>bool</code> <p>Whether to connect diagonally adjacent active pixel-bins. Defaults to True.</p> <code>True</code> <code>name</code> <code>str</code> <p>A name for the created environment. Defaults to \"\".</p> <code>''</code> <p>Returns:</p> Type Description <code>Environment</code> <p>A new Environment instance with an <code>ImageMaskLayout</code>.</p> See Also <p>from_mask : Create environment from pre-defined boolean mask. from_polygon : Create environment with polygon-defined boundary. from_samples : Create environment by binning position data.</p> <p>Examples:</p> <p>Create an environment from a binary image mask:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; # Create a simple binary image (e.g., from thresholding camera frame)\n&gt;&gt;&gt; image_height, image_width = 480, 640\n&gt;&gt;&gt; mask = np.zeros((image_height, image_width), dtype=bool)\n&gt;&gt;&gt; # Mark a rectangular region as active\n&gt;&gt;&gt; mask[100:400, 150:500] = True\n&gt;&gt;&gt; env = Environment.from_image(\n...     image_mask=mask,\n...     bin_size=0.5,  # Each pixel = 0.5cm\n...     name=\"arena_from_image\",\n... )\n&gt;&gt;&gt; env.n_dims\n2\n</code></pre> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef from_image(\n    cls,\n    image_mask: NDArray[np.bool_],\n    bin_size: float | tuple[float, float],\n    connect_diagonal_neighbors: bool = True,\n    name: str = \"\",\n) -&gt; Environment:\n    \"\"\"Create a 2D Environment from a binary image mask.\n\n    Each `True` pixel in the `image_mask` becomes an active bin in the\n    environment. The `bin_size` determines the spatial scale of these pixels.\n\n    Parameters\n    ----------\n    image_mask : NDArray[np.bool_], shape (n_rows, n_cols)\n        A 2D boolean array where `True` pixels define active bins.\n    bin_size : float or tuple of (float, float)\n        The spatial size of each pixel in physical units (e.g., cm, meters).\n        If a float, pixels are square. If a tuple `(width, height)`, specifies\n        pixel dimensions. For example, if your camera captures images where\n        each pixel represents 0.5cm, use bin_size=0.5.\n    connect_diagonal_neighbors : bool, optional\n        Whether to connect diagonally adjacent active pixel-bins.\n        Defaults to True.\n    name : str, optional\n        A name for the created environment. Defaults to \"\".\n\n    Returns\n    -------\n    Environment\n        A new Environment instance with an `ImageMaskLayout`.\n\n    See Also\n    --------\n    from_mask : Create environment from pre-defined boolean mask.\n    from_polygon : Create environment with polygon-defined boundary.\n    from_samples : Create environment by binning position data.\n\n    Examples\n    --------\n    Create an environment from a binary image mask:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; # Create a simple binary image (e.g., from thresholding camera frame)\n    &gt;&gt;&gt; image_height, image_width = 480, 640\n    &gt;&gt;&gt; mask = np.zeros((image_height, image_width), dtype=bool)\n    &gt;&gt;&gt; # Mark a rectangular region as active\n    &gt;&gt;&gt; mask[100:400, 150:500] = True\n    &gt;&gt;&gt; env = Environment.from_image(\n    ...     image_mask=mask,\n    ...     bin_size=0.5,  # Each pixel = 0.5cm\n    ...     name=\"arena_from_image\",\n    ... )\n    &gt;&gt;&gt; env.n_dims\n    2\n\n    \"\"\"\n    layout_params = {\n        \"image_mask\": image_mask,\n        \"bin_size\": bin_size,\n        \"connect_diagonal_neighbors\": connect_diagonal_neighbors,\n    }\n\n    return cls.from_layout(kind=\"ImageMask\", layout_params=layout_params, name=name)\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.from_layout","title":"from_layout  <code>classmethod</code>","text":"<pre><code>from_layout(kind: str, layout_params: dict[str, Any], name: str = '', regions: Regions | None = None) -&gt; Environment\n</code></pre> <p>Create an Environment with a specified layout type and its build parameters.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str</code> <p>The string identifier of the <code>LayoutEngine</code> to use (e.g., \"RegularGrid\", \"Hexagonal\").</p> required <code>layout_params</code> <code>Dict[str, Any]</code> <p>A dictionary of parameters that will be passed to the <code>build</code> method of the chosen <code>LayoutEngine</code>.</p> required <code>name</code> <code>str</code> <p>A name for the created environment. Defaults to \"\".</p> <code>''</code> <code>regions</code> <code>Optional[Regions]</code> <p>A Regions instance to manage symbolic spatial regions within the environment.</p> <code>None</code> <p>Returns:</p> Type Description <code>Environment</code> <p>A new Environment instance.</p> See Also <p>from_samples : Create environment by binning position data. from_polygon : Create environment with polygon-defined boundary. from_mask : Create environment from pre-defined boolean mask. from_image : Create environment from binary image mask. from_graph : Create 1D linearized track environment.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef from_layout(\n    cls,\n    kind: str,\n    layout_params: dict[str, Any],\n    name: str = \"\",\n    regions: Regions | None = None,\n) -&gt; Environment:\n    \"\"\"Create an Environment with a specified layout type and its build parameters.\n\n    Parameters\n    ----------\n    kind : str\n        The string identifier of the `LayoutEngine` to use\n        (e.g., \"RegularGrid\", \"Hexagonal\").\n    layout_params : Dict[str, Any]\n        A dictionary of parameters that will be passed to the `build`\n        method of the chosen `LayoutEngine`.\n    name : str, optional\n        A name for the created environment. Defaults to \"\".\n    regions : Optional[Regions], optional\n        A Regions instance to manage symbolic spatial regions within the environment.\n\n    Returns\n    -------\n    Environment\n        A new Environment instance.\n\n    See Also\n    --------\n    from_samples : Create environment by binning position data.\n    from_polygon : Create environment with polygon-defined boundary.\n    from_mask : Create environment from pre-defined boolean mask.\n    from_image : Create environment from binary image mask.\n    from_graph : Create 1D linearized track environment.\n\n    \"\"\"\n    layout_instance = create_layout(kind=kind, **layout_params)\n    return cls(name, layout_instance, kind, layout_params, regions=regions)\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.bin_at","title":"bin_at","text":"<pre><code>bin_at(points_nd: NDArray[float64]) -&gt; NDArray[np.int_]\n</code></pre> <p>Map N-dimensional continuous points to discrete active bin indices.</p> <p>This method delegates to the <code>point_to_bin_index</code> method of the underlying <code>LayoutEngine</code>.</p> <p>Parameters:</p> Name Type Description Default <code>points_nd</code> <code>(NDArray[float64], shape(n_points, n_dims))</code> <p>An array of N-dimensional points to map.</p> required <p>Returns:</p> Type Description <code>(NDArray[int_], shape(n_points))</code> <p>An array of active bin indices (0 to <code>n_active_bins - 1</code>). A value of -1 indicates that the corresponding point did not map to any active bin (e.g., it's outside the environment).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef bin_at(self, points_nd: NDArray[np.float64]) -&gt; NDArray[np.int_]:\n    \"\"\"Map N-dimensional continuous points to discrete active bin indices.\n\n    This method delegates to the `point_to_bin_index` method of the\n    underlying `LayoutEngine`.\n\n    Parameters\n    ----------\n    points_nd : NDArray[np.float64], shape (n_points, n_dims)\n        An array of N-dimensional points to map.\n\n    Returns\n    -------\n    NDArray[np.int_], shape (n_points,)\n        An array of active bin indices (0 to `n_active_bins - 1`).\n        A value of -1 indicates that the corresponding point did not map\n        to any active bin (e.g., it's outside the environment).\n\n    Raises\n    ------\n    RuntimeError\n        If called before the environment is fitted.\n\n    \"\"\"\n    return self.layout.point_to_bin_index(points_nd)\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.contains","title":"contains","text":"<pre><code>contains(points_nd: NDArray[float64]) -&gt; NDArray[np.bool_]\n</code></pre> <p>Check if N-dimensional continuous points fall within any active bin.</p> <p>Parameters:</p> Name Type Description Default <code>points_nd</code> <code>(NDArray[float64], shape(n_points, n_dims))</code> <p>An array of N-dimensional points to check.</p> required <p>Returns:</p> Type Description <code>(NDArray[bool_], shape(n_points))</code> <p>A boolean array where <code>True</code> indicates the corresponding point maps to an active bin, and <code>False</code> indicates it does not.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p> Notes <p>This method is optimized to avoid redundant KDTree queries by reusing the bin index computation from <code>bin_at()</code> and checking for the -1 sentinel.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef contains(self, points_nd: NDArray[np.float64]) -&gt; NDArray[np.bool_]:\n    \"\"\"Check if N-dimensional continuous points fall within any active bin.\n\n    Parameters\n    ----------\n    points_nd : NDArray[np.float64], shape (n_points, n_dims)\n        An array of N-dimensional points to check.\n\n    Returns\n    -------\n    NDArray[np.bool_], shape (n_points,)\n        A boolean array where `True` indicates the corresponding point\n        maps to an active bin, and `False` indicates it does not.\n\n    Raises\n    ------\n    RuntimeError\n        If called before the environment is fitted.\n\n    Notes\n    -----\n    This method is optimized to avoid redundant KDTree queries by reusing\n    the bin index computation from `bin_at()` and checking for the -1 sentinel.\n\n    \"\"\"\n    # Optimized: compute indices once and check for -1 sentinel\n    # This avoids redundant KDTree queries compared to calling bin_at() separately\n    indices = self.layout.point_to_bin_index(points_nd)\n    return np.asarray(indices != -1, dtype=np.bool_)\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.bin_center_of","title":"bin_center_of","text":"<pre><code>bin_center_of(bin_indices: int | Sequence[int] | NDArray[int_]) -&gt; NDArray[np.float64]\n</code></pre> <p>Given one or more active-bin indices, return their N-D center coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>bin_indices</code> <code>int or sequence of int</code> <p>Index (or list/array of indices) of active bins (0 &lt;= idx &lt; self.n_bins).</p> required <p>Returns:</p> Name Type Description <code>centers</code> <code>array, shape (len(bin_indices), n_dims) if multiple indices,</code> <pre><code>        (n_dims,) if single index\n</code></pre> <p>The center coordinate(s) of the requested bin(s).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the environment is not fitted.</p> <code>IndexError</code> <p>If any bin index is out of range.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef bin_center_of(\n    self,\n    bin_indices: int | Sequence[int] | NDArray[np.int_],\n) -&gt; NDArray[np.float64]:\n    \"\"\"Given one or more active-bin indices, return their N-D center coordinates.\n\n    Parameters\n    ----------\n    bin_indices : int or sequence of int\n        Index (or list/array of indices) of active bins (0 &lt;= idx &lt; self.n_bins).\n\n    Returns\n    -------\n    centers : array, shape (len(bin_indices), n_dims) if multiple indices,\n                    (n_dims,) if single index\n        The center coordinate(s) of the requested bin(s).\n\n    Raises\n    ------\n    RuntimeError\n        If the environment is not fitted.\n    IndexError\n        If any bin index is out of range.\n\n    \"\"\"\n    return np.asarray(\n        self.bin_centers[np.asarray(bin_indices, dtype=int)], dtype=np.float64\n    )\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.neighbors","title":"neighbors","text":"<pre><code>neighbors(bin_index: int) -&gt; list[int]\n</code></pre> <p>Find indices of neighboring active bins for a given active bin index.</p> <p>This method delegates to the <code>neighbors</code> method of the underlying <code>LayoutEngine</code>, which typically uses the <code>connectivity</code>.</p> <p>Parameters:</p> Name Type Description Default <code>bin_index</code> <code>int</code> <p>The index (0 to <code>n_active_bins - 1</code>) of the active bin for which to find neighbors.</p> required <p>Returns:</p> Type Description <code>List[int]</code> <p>A list of active bin indices that are neighbors to <code>bin_index</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef neighbors(self, bin_index: int) -&gt; list[int]:\n    \"\"\"Find indices of neighboring active bins for a given active bin index.\n\n    This method delegates to the `neighbors` method of the\n    underlying `LayoutEngine`, which typically uses the `connectivity`.\n\n    Parameters\n    ----------\n    bin_index : int\n        The index (0 to `n_active_bins - 1`) of the active bin for which\n        to find neighbors.\n\n    Returns\n    -------\n    List[int]\n        A list of active bin indices that are neighbors to `bin_index`.\n\n    Raises\n    ------\n    RuntimeError\n        If called before the environment is fitted.\n\n    \"\"\"\n    return list(self.connectivity.neighbors(bin_index))\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.distance_between","title":"distance_between","text":"<pre><code>distance_between(point1: NDArray[float64], point2: NDArray[float64], edge_weight: str = 'distance') -&gt; float\n</code></pre> <p>Calculate the geodesic distance between two points in the environment.</p> <p>Points are first mapped to their nearest active bins using <code>self.bin_at()</code>. The geodesic distance (distance along the shortest path through the space) is then the shortest path length in the <code>connectivity</code> graph between these bins, using the specified <code>edge_weight</code>.</p> <p>Parameters:</p> Name Type Description Default <code>point1</code> <code>(PtArr, shape(n_dims) or (1, n_dims))</code> <p>The first N-dimensional point.</p> required <code>point2</code> <code>(PtArr, shape(n_dims) or (1, n_dims))</code> <p>The second N-dimensional point.</p> required <code>edge_weight</code> <code>str</code> <p>The edge attribute to use as weight for path calculation, by default \"distance\". If None, the graph is treated as unweighted.</p> <code>'distance'</code> <p>Returns:</p> Type Description <code>float</code> <p>The geodesic distance. Returns <code>np.inf</code> if points do not map to valid active bins, if bins are disconnected, or if the connectivity graph is not available.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>def distance_between(\n    self,\n    point1: NDArray[np.float64],\n    point2: NDArray[np.float64],\n    edge_weight: str = \"distance\",\n) -&gt; float:\n    \"\"\"Calculate the geodesic distance between two points in the environment.\n\n    Points are first mapped to their nearest active bins using `self.bin_at()`.\n    The geodesic distance (distance along the shortest path through the space)\n    is then the shortest path length in the `connectivity` graph between these\n    bins, using the specified `edge_weight`.\n\n    Parameters\n    ----------\n    point1 : PtArr, shape (n_dims,) or (1, n_dims)\n        The first N-dimensional point.\n    point2 : PtArr, shape (n_dims,) or (1, n_dims)\n        The second N-dimensional point.\n    edge_weight : str, optional\n        The edge attribute to use as weight for path calculation,\n        by default \"distance\". If None, the graph is treated as unweighted.\n\n    Returns\n    -------\n    float\n        The geodesic distance. Returns `np.inf` if points do not map to\n        valid active bins, if bins are disconnected, or if the connectivity\n        graph is not available.\n\n    \"\"\"\n    source_bin = self.bin_at(np.atleast_2d(point1))[0]\n    target_bin = self.bin_at(np.atleast_2d(point2))[0]\n\n    if source_bin == -1 or target_bin == -1:\n        # One or both points didn't map to a valid active bin\n        return np.inf\n\n    try:\n        return float(\n            nx.shortest_path_length(\n                self.connectivity,\n                source=source_bin,\n                target=target_bin,\n                weight=edge_weight,\n            )\n        )\n    except (nx.NetworkXNoPath, nx.NodeNotFound):\n        return np.inf\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.shortest_path","title":"shortest_path","text":"<pre><code>shortest_path(source_active_bin_idx: int, target_active_bin_idx: int) -&gt; list[int]\n</code></pre> <p>Find the shortest path between two active bins.</p> <p>The path is a sequence of active bin indices (0 to n_active_bins - 1) connecting the source to the target. Path calculation uses the 'distance' attribute on the edges of the <code>connectivity</code> as weights.</p> <p>Parameters:</p> Name Type Description Default <code>source_active_bin_idx</code> <code>int</code> <p>The active bin index (0 to n_active_bins - 1) for the start of the path.</p> required <code>target_active_bin_idx</code> <code>int</code> <p>The active bin index (0 to n_active_bins - 1) for the end of the path.</p> required <p>Returns:</p> Type Description <code>List[int]</code> <p>A list of active bin indices representing the shortest path from source to target. The list includes both the source and target indices. Returns an empty list if the source and target are the same, or if no path exists, or if nodes are not found.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p> <code>NodeNotFound</code> <p>If <code>source_active_bin_idx</code> or <code>target_active_bin_idx</code> is not a node in the <code>connectivity</code>.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef shortest_path(\n    self,\n    source_active_bin_idx: int,\n    target_active_bin_idx: int,\n) -&gt; list[int]:\n    \"\"\"Find the shortest path between two active bins.\n\n    The path is a sequence of active bin indices (0 to n_active_bins - 1)\n    connecting the source to the target. Path calculation uses the\n    'distance' attribute on the edges of the `connectivity`\n    as weights.\n\n    Parameters\n    ----------\n    source_active_bin_idx : int\n        The active bin index (0 to n_active_bins - 1) for the start of the path.\n    target_active_bin_idx : int\n        The active bin index (0 to n_active_bins - 1) for the end of the path.\n\n    Returns\n    -------\n    List[int]\n        A list of active bin indices representing the shortest path from\n        source to target. The list includes both the source and target indices.\n        Returns an empty list if the source and target are the same, or if\n        no path exists, or if nodes are not found.\n\n    Raises\n    ------\n    RuntimeError\n        If called before the environment is fitted.\n    nx.NodeNotFound\n        If `source_active_bin_idx` or `target_active_bin_idx` is not\n        a node in the `connectivity`.\n\n    \"\"\"\n    graph = self.connectivity\n\n    if source_active_bin_idx == target_active_bin_idx:\n        return [source_active_bin_idx]\n\n    try:\n        path = nx.shortest_path(\n            graph,\n            source=source_active_bin_idx,\n            target=target_active_bin_idx,\n            weight=\"distance\",\n        )\n        return list(path)\n    except nx.NetworkXNoPath:\n        warnings.warn(\n            f\"No path found between active bin {source_active_bin_idx} \"\n            f\"and {target_active_bin_idx}.\",\n            UserWarning,\n        )\n        return []\n    except nx.NodeNotFound as e:\n        # Re-raise if the user provides an invalid node index for active bins\n        raise nx.NodeNotFound(\n            f\"Node not found in connectivity graph: {e}. \"\n            \"Ensure source/target indices are valid active bin indices.\",\n        ) from e\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.to_linear","title":"to_linear","text":"<pre><code>to_linear(points_nd: NDArray[float64]) -&gt; NDArray[np.float64]\n</code></pre> <p>Convert N-dimensional points to 1D linearized coordinates.</p> <p>This method is only applicable if the environment uses a <code>GraphLayout</code> and <code>is_1d</code> is True. It delegates to the layout's <code>to_linear</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>points_nd</code> <code>(NDArray[float64], shape(n_points, n_dims))</code> <p>N-dimensional points to linearize.</p> required <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_points))</code> <p>1D linearized coordinates corresponding to the input points.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the environment is not 1D or not based on a <code>GraphLayout</code>.</p> <code>RuntimeError</code> <p>If called before the environment is fitted.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef to_linear(self, points_nd: NDArray[np.float64]) -&gt; NDArray[np.float64]:\n    \"\"\"Convert N-dimensional points to 1D linearized coordinates.\n\n    This method is only applicable if the environment uses a `GraphLayout`\n    and `is_1d` is True. It delegates to the layout's\n    `to_linear` method.\n\n    Parameters\n    ----------\n    points_nd : NDArray[np.float64], shape (n_points, n_dims)\n        N-dimensional points to linearize.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_points,)\n        1D linearized coordinates corresponding to the input points.\n\n    Raises\n    ------\n    TypeError\n        If the environment is not 1D or not based on a `GraphLayout`.\n    RuntimeError\n        If called before the environment is fitted.\n\n    \"\"\"\n    # Use hasattr instead of isinstance to avoid Protocol/concrete class conflict\n    if not self.is_1d or not hasattr(self.layout, \"to_linear\"):\n        raise TypeError(\"Linearized coordinate only for GraphLayout environments.\")\n    result = self.layout.to_linear(points_nd)\n    return np.asarray(result, dtype=np.float64)\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.linear_to_nd","title":"linear_to_nd","text":"<pre><code>linear_to_nd(linear_coordinates: NDArray[float64]) -&gt; NDArray[np.float64]\n</code></pre> <p>Convert 1D linearized coordinates back to N-dimensional coordinates.</p> <p>This method is only applicable if the environment uses a <code>GraphLayout</code> and <code>is_1d</code> is True. It delegates to the layout's <code>linear_to_nd</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>linear_coordinates</code> <code>(NDArray[float64], shape(n_points))</code> <p>1D linearized coordinates to map to N-D space.</p> required <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_points, n_dims))</code> <p>N-dimensional coordinates corresponding to the input linear coordinates.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the environment is not 1D or not based on a <code>GraphLayout</code>.</p> <code>RuntimeError</code> <p>If called before the environment is fitted.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef linear_to_nd(\n    self,\n    linear_coordinates: NDArray[np.float64],\n) -&gt; NDArray[np.float64]:\n    \"\"\"Convert 1D linearized coordinates back to N-dimensional coordinates.\n\n    This method is only applicable if the environment uses a `GraphLayout`\n    and `is_1d` is True. It delegates to the layout's\n    `linear_to_nd` method.\n\n    Parameters\n    ----------\n    linear_coordinates : NDArray[np.float64], shape (n_points,)\n        1D linearized coordinates to map to N-D space.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_points, n_dims)\n        N-dimensional coordinates corresponding to the input linear coordinates.\n\n    Raises\n    ------\n    TypeError\n        If the environment is not 1D or not based on a `GraphLayout`.\n    RuntimeError\n        If called before the environment is fitted.\n\n    \"\"\"\n    # Use hasattr instead of isinstance to avoid Protocol/concrete class conflict\n    if not self.is_1d or not hasattr(self.layout, \"linear_to_nd\"):\n        raise TypeError(\"Mapping linear to N-D only for GraphLayout environments.\")\n    result = self.layout.linear_to_nd(linear_coordinates)\n    return np.asarray(result, dtype=np.float64)\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.plot","title":"plot","text":"<pre><code>plot(ax: Axes | None = None, show_regions: bool = False, layout_plot_kwargs: dict[str, Any] | None = None, regions_plot_kwargs: dict[str, Any] | None = None, **kwargs: Any) -&gt; matplotlib.axes.Axes\n</code></pre> <p>Plot the environment's layout and optionally defined regions.</p> <p>This method delegates plotting of the base layout to the <code>plot</code> method of the underlying <code>LayoutEngine</code>. If <code>show_regions</code> is True, it then overlays any defined spatial regions managed by <code>self.regions</code>.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>The Matplotlib axes to plot on. If None, a new figure and axes are created. Defaults to None.</p> <code>None</code> <code>show_regions</code> <code>bool</code> <p>If True, plot defined spatial regions on top of the layout. Defaults to False.</p> <code>False</code> <code>layout_plot_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments to pass to the <code>layout.plot()</code> method. Defaults to None.</p> <code>None</code> <code>regions_plot_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments to pass to the <code>regions.plot_regions()</code> method. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments that are passed to <code>layout.plot()</code>. These can be overridden by <code>layout_plot_kwargs</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the environment was plotted.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef plot(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    show_regions: bool = False,\n    layout_plot_kwargs: dict[str, Any] | None = None,\n    regions_plot_kwargs: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot the environment's layout and optionally defined regions.\n\n    This method delegates plotting of the base layout to the `plot` method\n    of the underlying `LayoutEngine`. If `show_regions` is True, it then\n    overlays any defined spatial regions managed by `self.regions`.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        The Matplotlib axes to plot on. If None, a new figure and axes\n        are created. Defaults to None.\n    show_regions : bool, optional\n        If True, plot defined spatial regions on top of the layout.\n        Defaults to False.\n    layout_plot_kwargs : Optional[Dict[str, Any]], optional\n        Keyword arguments to pass to the `layout.plot()` method.\n        Defaults to None.\n    regions_plot_kwargs : Optional[Dict[str, Any]], optional\n        Keyword arguments to pass to the `regions.plot_regions()` method.\n        Defaults to None.\n    **kwargs : Any\n        Additional keyword arguments that are passed to `layout.plot()`.\n        These can be overridden by `layout_plot_kwargs`.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the environment was plotted.\n\n    Raises\n    ------\n    RuntimeError\n        If called before the environment is fitted.\n\n    \"\"\"\n    l_kwargs = layout_plot_kwargs if layout_plot_kwargs is not None else {}\n    l_kwargs.update(kwargs)  # Allow direct kwargs to override for layout.plot\n\n    ax = self.layout.plot(ax=ax, **l_kwargs)\n\n    if show_regions and hasattr(self, \"regions\") and self.regions is not None:\n        from neurospatial.regions.plot import plot_regions\n\n        r_kwargs = regions_plot_kwargs if regions_plot_kwargs is not None else {}\n        plot_regions(self.regions, ax=ax, **r_kwargs)\n\n    plot_title = self.name\n    if (\n        self.layout\n        and hasattr(self.layout, \"_layout_type_tag\")\n        and self.layout._layout_type_tag\n    ):\n        plot_title += f\" ({self.layout._layout_type_tag})\"\n\n    # Only set title if layout.plot didn't set one or user didn't pass one via kwargs to layout.plot\n    if ax.get_title() == \"\":\n        ax.set_title(plot_title)\n\n    return ax\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.plot_1d","title":"plot_1d","text":"<pre><code>plot_1d(ax: Axes | None = None, layout_plot_kwargs: dict[str, Any] | None = None, **kwargs: Any)\n</code></pre> <p>Plot a 1D representation of the environment, if applicable.</p> <p>This method is primarily for environments where <code>is_1d</code> is True (e.g., using <code>GraphLayout</code>). It calls the <code>plot_linear_layout</code> method of the underlying layout if it exists and the layout is 1D.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>The Matplotlib axes to plot on. If None, a new figure and axes are created. Defaults to None.</p> <code>None</code> <code>layout_plot_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments to pass to the layout's 1D plotting method.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the layout's 1D plotting method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the 1D layout was plotted, or the original <code>ax</code> if plotting was not applicable.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called before the environment is fitted.</p> <code>AttributeError</code> <p>If <code>self.layout.is_1d</code> is True but the layout does not have a <code>plot_linear_layout</code> method.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>def plot_1d(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    layout_plot_kwargs: dict[str, Any] | None = None,\n    **kwargs: Any,\n):\n    \"\"\"Plot a 1D representation of the environment, if applicable.\n\n    This method is primarily for environments where `is_1d` is True\n    (e.g., using `GraphLayout`). It calls the `plot_linear_layout`\n    method of the underlying layout if it exists and the layout is 1D.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        The Matplotlib axes to plot on. If None, a new figure and axes\n        are created. Defaults to None.\n    layout_plot_kwargs : Optional[Dict[str, Any]], optional\n        Keyword arguments to pass to the layout's 1D plotting method.\n    **kwargs : Any\n        Additional keyword arguments passed to the layout's 1D plotting method.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the 1D layout was plotted, or the original `ax`\n        if plotting was not applicable.\n\n    Raises\n    ------\n    RuntimeError\n        If called before the environment is fitted.\n    AttributeError\n        If `self.layout.is_1d` is True but the layout does not have a\n        `plot_linear_layout` method.\n\n    \"\"\"\n    l_kwargs = layout_plot_kwargs if layout_plot_kwargs is not None else {}\n    l_kwargs.update(kwargs)  # Allow direct kwargs to override for layout.plot\n    if self.layout.is_1d:\n        if hasattr(self.layout, \"plot_linear_layout\"):\n            ax = self.layout.plot_linear_layout(ax=ax, **l_kwargs)\n        else:\n            warnings.warn(\n                f\"Layout '{self._layout_type_used}' is 1D but does not \"\n                \"have a 'plot_linear_layout' method. Skipping 1D plot.\",\n                UserWarning,\n            )\n    else:\n        warnings.warn(\n            \"Environment is not 1D. Skipping 1D plot. Use regular plot() method.\",\n            UserWarning,\n        )\n\n    return ax\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.save","title":"save","text":"<pre><code>save(filename: str = 'environment.pkl') -&gt; None\n</code></pre> <p>Save the Environment object to a file using pickle.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to save the environment to. Defaults to \"environment.pkl\".</p> <code>'environment.pkl'</code> Warnings <p>This method uses pickle for serialization. Pickle files can execute arbitrary code during deserialization. Only share pickle files with trusted users and only load files from trusted sources.</p> See Also <p>load : Load an Environment from a pickle file.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef save(self, filename: str = \"environment.pkl\") -&gt; None:\n    \"\"\"Save the Environment object to a file using pickle.\n\n    Parameters\n    ----------\n    filename : str, optional\n        The name of the file to save the environment to.\n        Defaults to \"environment.pkl\".\n\n    Warnings\n    --------\n    This method uses pickle for serialization. Pickle files can execute\n    arbitrary code during deserialization. Only share pickle files with\n    trusted users and only load files from trusted sources.\n\n    See Also\n    --------\n    load : Load an Environment from a pickle file.\n\n    \"\"\"\n    with Path(filename).open(\"wb\") as fh:\n        pickle.dump(self, fh, protocol=pickle.HIGHEST_PROTOCOL)\n    logger.info(\"Environment saved to %s\", filename)\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(filename: str) -&gt; Environment\n</code></pre> <p>Load an Environment object from a pickled file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to load the environment from.</p> required <p>Returns:</p> Type Description <code>Environment</code> <p>The loaded Environment object.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the loaded object is not an instance of the Environment class.</p> Warnings <p>This method uses pickle for deserialization. Only load files from trusted sources, as pickle can execute arbitrary code during deserialization. Do not load pickle files from untrusted or unknown sources.</p> See Also <p>save : Save an Environment to a pickle file.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef load(cls, filename: str) -&gt; Environment:\n    \"\"\"Load an Environment object from a pickled file.\n\n    Parameters\n    ----------\n    filename : str\n        The name of the file to load the environment from.\n\n    Returns\n    -------\n    Environment\n        The loaded Environment object.\n\n    Raises\n    ------\n    TypeError\n        If the loaded object is not an instance of the Environment class.\n\n    Warnings\n    --------\n    This method uses pickle for deserialization. **Only load files from\n    trusted sources**, as pickle can execute arbitrary code during\n    deserialization. Do not load pickle files from untrusted or\n    unknown sources.\n\n    See Also\n    --------\n    save : Save an Environment to a pickle file.\n\n    \"\"\"\n    with Path(filename).open(\"rb\") as fh:\n        environment = pickle.load(fh)\n    if not isinstance(environment, cls):\n        raise TypeError(f\"Loaded object is not type {cls.__name__}\")\n    return environment\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.to_file","title":"to_file","text":"<pre><code>to_file(path: str | Path) -&gt; None\n</code></pre> <p>Save Environment to versioned JSON + npz files.</p> <p>This method provides stable, reproducible serialization that is safer than pickle and compatible across Python versions. Creates two files: <code>{path}.json</code> (metadata) and <code>{path}.npz</code> (arrays).</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>Base path for output files (without extension). Will create <code>{path}.json</code> and <code>{path}.npz</code>.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; env = Environment.from_samples(data, bin_size=2.0)\n&gt;&gt;&gt; env.to_file(\"my_environment\")\n</code></pre> See Also <p>from_file : Load environment from saved files save : Legacy pickle-based serialization</p> Notes <p>This format is safer than pickle (no arbitrary code execution) and more portable across Python versions and platforms.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>def to_file(self, path: str | Path) -&gt; None:\n    \"\"\"Save Environment to versioned JSON + npz files.\n\n    This method provides stable, reproducible serialization that is safer\n    than pickle and compatible across Python versions. Creates two files:\n    `{path}.json` (metadata) and `{path}.npz` (arrays).\n\n    Parameters\n    ----------\n    path : str or Path\n        Base path for output files (without extension).\n        Will create `{path}.json` and `{path}.npz`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; env = Environment.from_samples(data, bin_size=2.0)\n    &gt;&gt;&gt; env.to_file(\"my_environment\")\n\n    See Also\n    --------\n    from_file : Load environment from saved files\n    save : Legacy pickle-based serialization\n\n    Notes\n    -----\n    This format is safer than pickle (no arbitrary code execution) and\n    more portable across Python versions and platforms.\n\n    \"\"\"\n    from neurospatial.io import to_file as _to_file\n\n    _to_file(self, path)\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.from_file","title":"from_file  <code>classmethod</code>","text":"<pre><code>from_file(path: str | Path) -&gt; Environment\n</code></pre> <p>Load Environment from versioned JSON + npz files.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>Base path to load from (without extension). Will read <code>{path}.json</code> and <code>{path}.npz</code>.</p> required <p>Returns:</p> Type Description <code>Environment</code> <p>Reconstructed Environment instance.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; env = Environment.from_file(\"my_environment\")\n</code></pre> See Also <p>to_file : Save environment to files load : Legacy pickle-based deserialization</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef from_file(cls, path: str | Path) -&gt; Environment:\n    \"\"\"Load Environment from versioned JSON + npz files.\n\n    Parameters\n    ----------\n    path : str or Path\n        Base path to load from (without extension).\n        Will read `{path}.json` and `{path}.npz`.\n\n    Returns\n    -------\n    Environment\n        Reconstructed Environment instance.\n\n    Examples\n    --------\n    &gt;&gt;&gt; env = Environment.from_file(\"my_environment\")\n\n    See Also\n    --------\n    to_file : Save environment to files\n    load : Legacy pickle-based deserialization\n\n    \"\"\"\n    from neurospatial.io import from_file as _from_file\n\n    return _from_file(path)\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert Environment to dictionary for in-memory handoff.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary representation with all arrays as lists.</p> See Also <p>from_dict : Reconstruct from dictionary to_file : Save to disk with efficient binary format</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert Environment to dictionary for in-memory handoff.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary representation with all arrays as lists.\n\n    See Also\n    --------\n    from_dict : Reconstruct from dictionary\n    to_file : Save to disk with efficient binary format\n\n    \"\"\"\n    from neurospatial.io import to_dict as _to_dict\n\n    return _to_dict(self)\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: dict[str, Any]) -&gt; Environment\n</code></pre> <p>Reconstruct Environment from dictionary representation.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[str, Any]</code> <p>Dictionary from <code>to_dict()</code>.</p> required <p>Returns:</p> Type Description <code>Environment</code> <p>Reconstructed instance.</p> See Also <p>to_dict : Convert to dictionary</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; Environment:\n    \"\"\"Reconstruct Environment from dictionary representation.\n\n    Parameters\n    ----------\n    data : dict[str, Any]\n        Dictionary from `to_dict()`.\n\n    Returns\n    -------\n    Environment\n        Reconstructed instance.\n\n    See Also\n    --------\n    to_dict : Convert to dictionary\n\n    \"\"\"\n    from neurospatial.io import from_dict as _from_dict\n\n    return _from_dict(data)\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.bins_in_region","title":"bins_in_region","text":"<pre><code>bins_in_region(region_name: str) -&gt; NDArray[np.int_]\n</code></pre> <p>Get active bin indices that fall within a specified named region.</p> <p>Parameters:</p> Name Type Description Default <code>region_name</code> <code>str</code> <p>The name of a defined region in <code>self.regions</code>.</p> required <p>Returns:</p> Type Description <code>NDArray[int_]</code> <p>Array of active bin indices (0 to n_active_bins - 1) that are part of the region.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If <code>region_name</code> is not found in <code>self.regions</code>.</p> <code>ValueError</code> <p>If region kind is unsupported or mask dimensions mismatch.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef bins_in_region(self, region_name: str) -&gt; NDArray[np.int_]:\n    \"\"\"Get active bin indices that fall within a specified named region.\n\n    Parameters\n    ----------\n    region_name : str\n        The name of a defined region in `self.regions`.\n\n    Returns\n    -------\n    NDArray[np.int_]\n        Array of active bin indices (0 to n_active_bins - 1)\n        that are part of the region.\n\n    Raises\n    ------\n    KeyError\n        If `region_name` is not found in `self.regions`.\n    ValueError\n        If region kind is unsupported or mask dimensions mismatch.\n\n    \"\"\"\n    region = self.regions[region_name]\n\n    if region.kind == \"point\":\n        point_nd = np.asarray(region.data).reshape(1, -1)\n        if point_nd.shape[1] != self.n_dims:\n            raise ValueError(\n                f\"Region point dimension {point_nd.shape[1]} \"\n                f\"does not match environment dimension {self.n_dims}.\",\n            )\n        bin_idx = self.bin_at(point_nd)\n        return np.asarray(bin_idx[bin_idx != -1], dtype=int)\n\n    if region.kind == \"polygon\":\n        if not _HAS_SHAPELY:  # pragma: no cover\n            raise RuntimeError(\"Polygon region queries require 'shapely'.\")\n        if self.n_dims != 2:  # pragma: no cover\n            raise ValueError(\n                \"Polygon regions are only supported for 2D environments.\",\n            )\n\n        import shapely\n\n        polygon = region.data\n        contained_mask = shapely.contains_xy(\n            polygon,\n            self.bin_centers[:, 0],\n            self.bin_centers[:, 1],\n        )\n\n        return np.flatnonzero(contained_mask)\n\n    # pragma: no cover\n    raise ValueError(f\"Unsupported region kind: {region.kind}\")\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment.Environment.mask_for_region","title":"mask_for_region","text":"<pre><code>mask_for_region(region_name: str) -&gt; NDArray[np.bool_]\n</code></pre> <p>Get a boolean mask over active bins indicating membership in a region.</p> <p>Parameters:</p> Name Type Description Default <code>region_name</code> <code>str</code> <p>Name of region to query.</p> required <p>Returns:</p> Type Description <code>NDArray[bool_]</code> <p>Boolean array of shape (n_active_bins,). True if an active bin is part of the region.</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>@check_fitted\ndef mask_for_region(self, region_name: str) -&gt; NDArray[np.bool_]:\n    \"\"\"Get a boolean mask over active bins indicating membership in a region.\n\n    Parameters\n    ----------\n    region_name : str\n        Name of region to query.\n\n    Returns\n    -------\n    NDArray[np.bool_]\n        Boolean array of shape (n_active_bins,). True if an active bin\n        is part of the region.\n\n    \"\"\"\n    active_bins_for_mask = self.bins_in_region(region_name)\n    mask = np.zeros(self.bin_centers.shape[0], dtype=bool)\n    if active_bins_for_mask.size &gt; 0:\n        mask[active_bins_for_mask] = True\n    return mask\n</code></pre>"},{"location":"api/neurospatial/environment/#neurospatial.environment-functions","title":"Functions","text":""},{"location":"api/neurospatial/environment/#neurospatial.environment.check_fitted","title":"check_fitted","text":"<pre><code>check_fitted(method)\n</code></pre> <p>Decorator to ensure that an Environment method is called only after fitting.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>callable</code> <p>Method to decorate.</p> required <p>Returns:</p> Type Description <code>callable</code> <p>Wrapped method that checks fitted status before execution.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the method is called on an Environment instance that has not been fully initialized (i.e., <code>_is_fitted</code> is False).</p> Source code in <code>src/neurospatial/environment.py</code> <pre><code>def check_fitted(method):\n    \"\"\"Decorator to ensure that an Environment method is called only after fitting.\n\n    Parameters\n    ----------\n    method : callable\n        Method to decorate.\n\n    Returns\n    -------\n    callable\n        Wrapped method that checks fitted status before execution.\n\n    Raises\n    ------\n    RuntimeError\n        If the method is called on an Environment instance that has not been\n        fully initialized (i.e., `_is_fitted` is False).\n\n    \"\"\"\n\n    @wraps(method)\n    def _inner(self: Environment, *args, **kwargs):\n        if not getattr(self, \"_is_fitted\", False):\n            raise RuntimeError(\n                f\"{self.__class__.__name__}.{method.__name__}() \"\n                \"requires the environment to be fully initialized. \"\n                \"Ensure it was created with a factory method.\\n\\n\"\n                \"Example (correct usage):\\n\"\n                \"    env = Environment.from_samples(data, bin_size=2.0)\\n\"\n                \"    result = env.bin_at(points)\\n\\n\"\n                \"Avoid:\\n\"\n                \"    env = Environment()  # This will not work!\",\n            )\n        return method(self, *args, **kwargs)\n\n    return _inner\n</code></pre>"},{"location":"api/neurospatial/io/","title":"<code>neurospatial.io</code>","text":""},{"location":"api/neurospatial/io/#neurospatial.io","title":"io","text":""},{"location":"api/neurospatial/io/#neurospatial.io--iopy-stable-serialization-for-environment-objects","title":"io.py - Stable serialization for Environment objects","text":"<p>This module provides versioned JSON + npz serialization for Environment objects, enabling reproducible workflows and cross-tool interoperability.</p> Schema <p>The serialization format uses: - JSON for metadata, structure, and small arrays - NumPy .npz for large numerical arrays (bin_centers, etc.)</p> <p>Files are saved as a directory (or zip) containing: - metadata.json: Schema version, library version, timestamps, parameters - arrays.npz: Binary arrays (bin_centers, etc.) - graph.json: NetworkX graph in node-link format - regions.json: Regions data (if present)</p>"},{"location":"api/neurospatial/io/#neurospatial.io-classes","title":"Classes","text":""},{"location":"api/neurospatial/io/#neurospatial.io-functions","title":"Functions","text":""},{"location":"api/neurospatial/io/#neurospatial.io.to_file","title":"to_file","text":"<pre><code>to_file(env: Environment, path: str | Path) -&gt; None\n</code></pre> <p>Save Environment to a versioned JSON + npz file pair.</p> <p>Creates two files: - <code>path.json</code>: Metadata, graph structure, and small arrays - <code>path.npz</code>: Large numerical arrays (bin_centers, etc.)</p> <p>The format is stable across versions and supports forward/backward compatibility through schema versioning.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Environment instance to save.</p> required <code>path</code> <code>str or Path</code> <p>Base path for output files (without extension). Will create <code>{path}.json</code> and <code>{path}.npz</code>.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; env = Environment.from_samples(data, bin_size=2.0)\n&gt;&gt;&gt; env.to_file(\n...     \"my_environment\"\n... )  # Creates my_environment.json and my_environment.npz\n</code></pre> See Also <p>from_file : Load environment from saved files Environment.save : Legacy pickle-based serialization (less safe)</p> Notes <p>This format is safer than pickle (no arbitrary code execution) and more portable across Python versions and platforms.</p> Source code in <code>src/neurospatial/io.py</code> <pre><code>def to_file(env: Environment, path: str | Path) -&gt; None:\n    \"\"\"Save Environment to a versioned JSON + npz file pair.\n\n    Creates two files:\n    - `path.json`: Metadata, graph structure, and small arrays\n    - `path.npz`: Large numerical arrays (bin_centers, etc.)\n\n    The format is stable across versions and supports forward/backward\n    compatibility through schema versioning.\n\n    Parameters\n    ----------\n    env : Environment\n        Environment instance to save.\n    path : str or Path\n        Base path for output files (without extension).\n        Will create `{path}.json` and `{path}.npz`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; env = Environment.from_samples(data, bin_size=2.0)\n    &gt;&gt;&gt; env.to_file(\n    ...     \"my_environment\"\n    ... )  # Creates my_environment.json and my_environment.npz\n\n    See Also\n    --------\n    from_file : Load environment from saved files\n    Environment.save : Legacy pickle-based serialization (less safe)\n\n    Notes\n    -----\n    This format is safer than pickle (no arbitrary code execution) and\n    more portable across Python versions and platforms.\n\n    \"\"\"\n    path_obj = Path(path)\n    json_path = path_obj.with_suffix(\".json\")\n    npz_path = path_obj.with_suffix(\".npz\")\n\n    # Ensure parent directory exists\n    json_path.parent.mkdir(parents=True, exist_ok=True)\n\n    # Build metadata dictionary\n    metadata: dict[str, Any] = {\n        \"schema_version\": _SCHEMA_VERSION,\n        \"library_version\": _get_library_version(),\n        \"created_at\": datetime.now(timezone.utc).isoformat(),\n        \"name\": env.name,\n        \"n_dims\": int(env.n_dims),\n        \"n_bins\": int(env.n_bins),\n        \"is_1d\": bool(env.is_1d),\n        \"layout_type\": env.layout_type,\n        \"layout_parameters\": env.layout_parameters,\n    }\n\n    # Add optional attributes\n    if env.dimension_ranges is not None:\n        metadata[\"dimension_ranges\"] = [\n            [float(lo), float(hi)] for lo, hi in env.dimension_ranges\n        ]\n\n    if env.grid_shape is not None:\n        metadata[\"grid_shape\"] = [int(x) for x in env.grid_shape]\n\n    # Add units and frame if present\n    if hasattr(env, \"units\") and env.units is not None:\n        metadata[\"units\"] = env.units\n    if hasattr(env, \"frame\") and env.frame is not None:\n        metadata[\"frame\"] = env.frame\n\n    # Serialize graph to node-link format\n    graph_data = nx.node_link_data(env.connectivity, edges=\"links\")\n    metadata[\"graph\"] = graph_data\n\n    # Serialize regions if present\n    if env.regions and len(env.regions) &gt; 0:\n        metadata[\"regions\"] = [reg.to_dict() for reg in env.regions.values()]\n    else:\n        metadata[\"regions\"] = []\n\n    # Convert entire metadata to JSON-safe format (must be done AFTER all modifications)\n    metadata = _convert_arrays_to_lists(metadata)\n\n    # Write JSON metadata\n    with json_path.open(\"w\") as f:\n        json.dump(metadata, f, indent=2)\n\n    # Prepare arrays for npz\n    arrays_to_save: dict[str, NDArray] = {\n        \"bin_centers\": env.bin_centers,\n    }\n\n    # Add optional arrays\n    if env.active_mask is not None:\n        arrays_to_save[\"active_mask\"] = env.active_mask\n\n    if env.grid_edges is not None and len(env.grid_edges) &gt; 0:\n        # Save grid edges as separate arrays (grid_edges_0, grid_edges_1, ...)\n        for i, edges in enumerate(env.grid_edges):\n            arrays_to_save[f\"grid_edges_{i}\"] = edges\n\n    # Write npz arrays\n    # numpy.savez_compressed has overly strict type stubs - cast to work around\n    np.savez_compressed(str(npz_path), **cast(\"Any\", arrays_to_save))\n</code></pre>"},{"location":"api/neurospatial/io/#neurospatial.io.from_file","title":"from_file","text":"<pre><code>from_file(path: str | Path) -&gt; Environment\n</code></pre> <p>Load Environment from a versioned JSON + npz file pair.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>Base path to load from (without extension). Will read <code>{path}.json</code> and <code>{path}.npz</code>.</p> required <p>Returns:</p> Type Description <code>Environment</code> <p>Reconstructed Environment instance.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If required files are not found.</p> <code>ValueError</code> <p>If schema version is incompatible or data is malformed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; env = from_file(\"my_environment\")\n&gt;&gt;&gt; print(env.n_bins)\n</code></pre> See Also <p>to_file : Save environment to files Environment.load : Legacy pickle-based deserialization</p> Source code in <code>src/neurospatial/io.py</code> <pre><code>def from_file(path: str | Path) -&gt; Environment:\n    \"\"\"Load Environment from a versioned JSON + npz file pair.\n\n    Parameters\n    ----------\n    path : str or Path\n        Base path to load from (without extension).\n        Will read `{path}.json` and `{path}.npz`.\n\n    Returns\n    -------\n    Environment\n        Reconstructed Environment instance.\n\n    Raises\n    ------\n    FileNotFoundError\n        If required files are not found.\n    ValueError\n        If schema version is incompatible or data is malformed.\n\n    Examples\n    --------\n    &gt;&gt;&gt; env = from_file(\"my_environment\")\n    &gt;&gt;&gt; print(env.n_bins)\n\n    See Also\n    --------\n    to_file : Save environment to files\n    Environment.load : Legacy pickle-based deserialization\n\n    \"\"\"\n    from neurospatial.environment import Environment\n    from neurospatial.regions import Region, Regions\n\n    path_obj = Path(path)\n    json_path = path_obj.with_suffix(\".json\")\n    npz_path = path_obj.with_suffix(\".npz\")\n\n    if not json_path.exists():\n        raise FileNotFoundError(f\"Metadata file not found: {json_path}\")\n    if not npz_path.exists():\n        raise FileNotFoundError(f\"Array file not found: {npz_path}\")\n\n    # Load metadata\n    with json_path.open(\"r\") as f:\n        metadata = json.load(f)\n\n    # Check schema version\n    schema_version = metadata.get(\"schema_version\")\n    if schema_version != _SCHEMA_VERSION:\n        warnings.warn(\n            f\"Schema version mismatch: file has {schema_version!r}, \"\n            f\"expected {_SCHEMA_VERSION!r}. Attempting to load anyway.\",\n            stacklevel=2,\n        )\n\n    # Load arrays\n    arrays = np.load(npz_path)\n\n    # Reconstruct graph\n    graph_data = metadata[\"graph\"]\n    connectivity = nx.node_link_graph(graph_data, edges=\"links\")\n\n    # Reconstruct dimension_ranges\n    dimension_ranges = None\n    if \"dimension_ranges\" in metadata:\n        dimension_ranges = [tuple(r) for r in metadata[\"dimension_ranges\"]]\n\n    # Reconstruct grid_edges from separate arrays\n    grid_edges = None\n    if \"grid_shape\" in metadata:\n        n_dims = metadata[\"n_dims\"]\n        grid_edges_list = []\n        for i in range(n_dims):\n            key = f\"grid_edges_{i}\"\n            if key in arrays:\n                grid_edges_list.append(arrays[key])\n        if grid_edges_list:\n            grid_edges = tuple(grid_edges_list)\n\n    # Reconstruct active_mask\n    active_mask = arrays.get(\"active_mask\")\n\n    # Reconstruct grid_shape\n    grid_shape = None\n    if \"grid_shape\" in metadata:\n        grid_shape = tuple(metadata[\"grid_shape\"])\n\n    # Create layout engine from parameters\n    # Note: We use from_layout() pattern to reconstruct\n    layout_type = metadata[\"layout_type\"]\n    layout_params = metadata[\"layout_parameters\"]\n\n    # Convert lists back to numpy arrays in layout parameters\n    layout_params = _convert_lists_to_arrays(layout_params)\n\n    # Create environment from layout\n    env = Environment.from_layout(layout_type, layout_params, name=metadata[\"name\"])\n\n    # Override attributes with saved values (handles cases where layout recreation differs)\n    env.bin_centers = arrays[\"bin_centers\"]\n    env.connectivity = connectivity\n    env.dimension_ranges = dimension_ranges\n    env.grid_edges = grid_edges\n    env.grid_shape = grid_shape\n    env.active_mask = active_mask\n\n    # Reconstruct regions\n    if metadata.get(\"regions\"):\n        regions_list = [Region.from_dict(r) for r in metadata[\"regions\"]]\n        env.regions = Regions(regions_list)\n\n    # Restore units and frame if present\n    if \"units\" in metadata:\n        env.units = metadata[\"units\"]\n    if \"frame\" in metadata:\n        env.frame = metadata[\"frame\"]\n\n    return env\n</code></pre>"},{"location":"api/neurospatial/io/#neurospatial.io.to_dict","title":"to_dict","text":"<pre><code>to_dict(env: Environment) -&gt; dict[str, Any]\n</code></pre> <p>Convert Environment to a dictionary for in-memory handoff.</p> <p>This is useful for passing environments between processes or for temporary storage without writing to disk.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Environment instance to convert.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary representation of the environment. All arrays are converted to lists for JSON compatibility.</p> Notes <p>For large environments, prefer <code>to_file()</code> which uses efficient binary serialization for arrays.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; env = Environment.from_samples(data, bin_size=2.0)\n&gt;&gt;&gt; env_dict = to_dict(env)\n&gt;&gt;&gt; # Pass to another process or serialize to JSON\n&gt;&gt;&gt; import json\n&gt;&gt;&gt; json_str = json.dumps(env_dict)\n</code></pre> See Also <p>from_dict : Reconstruct environment from dictionary to_file : Save to disk with efficient binary format</p> Source code in <code>src/neurospatial/io.py</code> <pre><code>def to_dict(env: Environment) -&gt; dict[str, Any]:\n    \"\"\"Convert Environment to a dictionary for in-memory handoff.\n\n    This is useful for passing environments between processes or for\n    temporary storage without writing to disk.\n\n    Parameters\n    ----------\n    env : Environment\n        Environment instance to convert.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary representation of the environment.\n        All arrays are converted to lists for JSON compatibility.\n\n    Notes\n    -----\n    For large environments, prefer `to_file()` which uses efficient\n    binary serialization for arrays.\n\n    Examples\n    --------\n    &gt;&gt;&gt; env = Environment.from_samples(data, bin_size=2.0)\n    &gt;&gt;&gt; env_dict = to_dict(env)\n    &gt;&gt;&gt; # Pass to another process or serialize to JSON\n    &gt;&gt;&gt; import json\n    &gt;&gt;&gt; json_str = json.dumps(env_dict)\n\n    See Also\n    --------\n    from_dict : Reconstruct environment from dictionary\n    to_file : Save to disk with efficient binary format\n\n    \"\"\"\n    # Similar to to_file but with arrays as lists\n    metadata: dict[str, Any] = {\n        \"schema_version\": _SCHEMA_VERSION,\n        \"library_version\": _get_library_version(),\n        \"created_at\": datetime.now(timezone.utc).isoformat(),\n        \"name\": env.name,\n        \"n_dims\": int(env.n_dims),\n        \"n_bins\": int(env.n_bins),\n        \"is_1d\": bool(env.is_1d),\n        \"layout_type\": env.layout_type,\n        \"layout_parameters\": env.layout_parameters,\n        \"bin_centers\": env.bin_centers.tolist(),\n    }\n\n    # Add optional attributes\n    if env.dimension_ranges is not None:\n        metadata[\"dimension_ranges\"] = [\n            [float(lo), float(hi)] for lo, hi in env.dimension_ranges\n        ]\n\n    if env.grid_shape is not None:\n        metadata[\"grid_shape\"] = [int(x) for x in env.grid_shape]\n\n    if env.active_mask is not None:\n        metadata[\"active_mask\"] = env.active_mask.tolist()\n\n    if env.grid_edges is not None and len(env.grid_edges) &gt; 0:\n        metadata[\"grid_edges\"] = [edges.tolist() for edges in env.grid_edges]\n\n    # Add units and frame if present\n    if hasattr(env, \"units\") and env.units is not None:\n        metadata[\"units\"] = env.units\n    if hasattr(env, \"frame\") and env.frame is not None:\n        metadata[\"frame\"] = env.frame\n\n    # Serialize graph\n    graph_data = nx.node_link_data(env.connectivity, edges=\"links\")\n    metadata[\"graph\"] = graph_data\n\n    # Serialize regions\n    if env.regions and len(env.regions) &gt; 0:\n        metadata[\"regions\"] = [reg.to_dict() for reg in env.regions.values()]\n    else:\n        metadata[\"regions\"] = []\n\n    # Convert entire metadata to JSON-safe format\n    metadata = _convert_arrays_to_lists(metadata)\n\n    return metadata\n</code></pre>"},{"location":"api/neurospatial/io/#neurospatial.io.from_dict","title":"from_dict","text":"<pre><code>from_dict(data: dict[str, Any]) -&gt; Environment\n</code></pre> <p>Reconstruct Environment from dictionary representation.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[str, Any]</code> <p>Dictionary representation from <code>to_dict()</code>.</p> required <p>Returns:</p> Type Description <code>Environment</code> <p>Reconstructed Environment instance.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; env_dict = to_dict(env)\n&gt;&gt;&gt; env_restored = from_dict(env_dict)\n</code></pre> See Also <p>to_dict : Convert environment to dictionary from_file : Load from disk files</p> Source code in <code>src/neurospatial/io.py</code> <pre><code>def from_dict(data: dict[str, Any]) -&gt; Environment:\n    \"\"\"Reconstruct Environment from dictionary representation.\n\n    Parameters\n    ----------\n    data : dict[str, Any]\n        Dictionary representation from `to_dict()`.\n\n    Returns\n    -------\n    Environment\n        Reconstructed Environment instance.\n\n    Examples\n    --------\n    &gt;&gt;&gt; env_dict = to_dict(env)\n    &gt;&gt;&gt; env_restored = from_dict(env_dict)\n\n    See Also\n    --------\n    to_dict : Convert environment to dictionary\n    from_file : Load from disk files\n\n    \"\"\"\n    from neurospatial.environment import Environment\n    from neurospatial.regions import Region, Regions\n\n    # Check schema version\n    schema_version = data.get(\"schema_version\")\n    if schema_version != _SCHEMA_VERSION:\n        warnings.warn(\n            f\"Schema version mismatch: data has {schema_version!r}, \"\n            f\"expected {_SCHEMA_VERSION!r}. Attempting to load anyway.\",\n            stacklevel=2,\n        )\n\n    # Reconstruct arrays\n    bin_centers = np.array(data[\"bin_centers\"], dtype=np.float64)\n\n    # Reconstruct graph\n    graph_data = data[\"graph\"]\n    connectivity = nx.node_link_graph(graph_data, edges=\"links\")\n\n    # Reconstruct dimension_ranges\n    dimension_ranges = None\n    if \"dimension_ranges\" in data:\n        dimension_ranges = [tuple(r) for r in data[\"dimension_ranges\"]]\n\n    # Reconstruct grid_edges\n    grid_edges = None\n    if \"grid_edges\" in data:\n        grid_edges = tuple(np.array(e, dtype=np.float64) for e in data[\"grid_edges\"])\n\n    # Reconstruct active_mask\n    active_mask = None\n    if \"active_mask\" in data:\n        active_mask = np.array(data[\"active_mask\"], dtype=bool)\n\n    # Reconstruct grid_shape\n    grid_shape = None\n    if \"grid_shape\" in data:\n        grid_shape = tuple(data[\"grid_shape\"])\n\n    # Create layout and environment\n    layout_type = data[\"layout_type\"]\n    layout_params = data[\"layout_parameters\"]\n\n    # Convert lists back to numpy arrays in layout parameters\n    layout_params = _convert_lists_to_arrays(layout_params)\n\n    # Create environment\n    env = Environment.from_layout(layout_type, layout_params, name=data[\"name\"])\n\n    # Override attributes\n    env.bin_centers = bin_centers\n    env.connectivity = connectivity\n    env.dimension_ranges = dimension_ranges\n    env.grid_edges = grid_edges\n    env.grid_shape = grid_shape\n    env.active_mask = active_mask\n\n    # Reconstruct regions\n    if data.get(\"regions\"):\n        regions_list = [Region.from_dict(r) for r in data[\"regions\"]]\n        env.regions = Regions(regions_list)\n\n    # Restore units and frame if present\n    if \"units\" in data:\n        env.units = data[\"units\"]\n    if \"frame\" in data:\n        env.frame = data[\"frame\"]\n\n    return env\n</code></pre>"},{"location":"api/neurospatial/spatial/","title":"<code>neurospatial.spatial</code>","text":""},{"location":"api/neurospatial/spatial/#neurospatial.spatial","title":"spatial","text":""},{"location":"api/neurospatial/spatial/#neurospatial.spatial--spatialpy-spatial-query-utilities-for-neurospatial","title":"spatial.py - Spatial query utilities for neurospatial","text":"<p>This module provides high-performance spatial query utilities including: - Batch mapping of points to bins with KD-tree caching - Deterministic tie-breaking on bin boundaries - Distance calculations</p> <p>These are core primitives used throughout neurospatial and by downstream packages.</p>"},{"location":"api/neurospatial/spatial/#neurospatial.spatial-classes","title":"Classes","text":""},{"location":"api/neurospatial/spatial/#neurospatial.spatial-functions","title":"Functions","text":""},{"location":"api/neurospatial/spatial/#neurospatial.spatial.map_points_to_bins","title":"map_points_to_bins","text":"<pre><code>map_points_to_bins(points: NDArray[float64], env: Environment, *, tie_break: Literal['lowest_index', 'closest_center'] = 'lowest_index', return_dist: bool = False) -&gt; NDArray[np.int64] | tuple[NDArray[np.int64], NDArray[np.float64]]\n</code></pre> <p>Map points to bin indices with deterministic tie-breaking.</p> <p>This function provides fast, batch mapping of continuous coordinates to discrete bin indices using KD-tree queries. It handles edge cases like boundary points consistently through configurable tie-breaking rules.</p> <p>Internally caches a KD-tree on first call for O(log N) lookups.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>(NDArray[float64], shape(n_points, n_dims))</code> <p>Continuous coordinates to map to bins.</p> required <code>env</code> <code>Environment</code> <p>Environment containing the bin discretization.</p> required <code>tie_break</code> <code>('lowest_index', 'closest_center')</code> <p>Strategy for resolving ties when a point is equidistant from multiple bin centers:</p> <ul> <li>\"lowest_index\": Choose the bin with smallest index (deterministic)</li> <li>\"closest_center\": Return the actual closest (may be non-deterministic   for exact ties, but faster)</li> </ul> <code>\"lowest_index\"</code> <code>return_dist</code> <code>bool</code> <p>If True, also return the distance from each point to its assigned bin center.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bin_indices</code> <code>(NDArray[int_], shape(n_points))</code> <p>Bin index for each point. Value of -1 indicates point is outside all bins.</p> <code>distances</code> <code>(NDArray[float64], shape(n_points), optional)</code> <p>Distance from each point to its assigned bin center. Only returned if <code>return_dist=True</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; from neurospatial.spatial import map_points_to_bins\n&gt;&gt;&gt; data = np.random.randn(1000, 2) * 10\n&gt;&gt;&gt; env = Environment.from_samples(data, bin_size=2.0)\n&gt;&gt;&gt; points = np.array([[0.0, 0.0], [10.0, 10.0], [50.0, 50.0]])\n&gt;&gt;&gt; bins = map_points_to_bins(points, env)\n&gt;&gt;&gt; bins\narray([ 42,  89,  -1])\n</code></pre> <pre><code>&gt;&gt;&gt; # Get distances too\n&gt;&gt;&gt; bins, dists = map_points_to_bins(points, env, return_dist=True)\n&gt;&gt;&gt; dists\narray([0.23, 0.45, inf])\n</code></pre> Notes <p>This function builds and caches a KD-tree on the environment's bin_centers on first call. Subsequent calls reuse the cached tree for O(log N) performance.</p> <p>The cache is stored as a private attribute on the Environment object. If bin_centers are modified after creation (not recommended), the cache will become stale.</p> See Also <p>Environment.bin_at : Basic point-to-bin mapping (delegates to layout engine) Environment.contains : Check if points are within environment bounds</p> Source code in <code>src/neurospatial/spatial.py</code> <pre><code>def map_points_to_bins(\n    points: NDArray[np.float64],\n    env: Environment,\n    *,\n    tie_break: Literal[\"lowest_index\", \"closest_center\"] = \"lowest_index\",\n    return_dist: bool = False,\n) -&gt; NDArray[np.int64] | tuple[NDArray[np.int64], NDArray[np.float64]]:\n    \"\"\"Map points to bin indices with deterministic tie-breaking.\n\n    This function provides fast, batch mapping of continuous coordinates to\n    discrete bin indices using KD-tree queries. It handles edge cases like\n    boundary points consistently through configurable tie-breaking rules.\n\n    Internally caches a KD-tree on first call for O(log N) lookups.\n\n    Parameters\n    ----------\n    points : NDArray[np.float64], shape (n_points, n_dims)\n        Continuous coordinates to map to bins.\n    env : Environment\n        Environment containing the bin discretization.\n    tie_break : {\"lowest_index\", \"closest_center\"}, default=\"lowest_index\"\n        Strategy for resolving ties when a point is equidistant from multiple\n        bin centers:\n\n        - \"lowest_index\": Choose the bin with smallest index (deterministic)\n        - \"closest_center\": Return the actual closest (may be non-deterministic\n          for exact ties, but faster)\n\n    return_dist : bool, default=False\n        If True, also return the distance from each point to its assigned bin center.\n\n    Returns\n    -------\n    bin_indices : NDArray[np.int_], shape (n_points,)\n        Bin index for each point. Value of -1 indicates point is outside all bins.\n    distances : NDArray[np.float64], shape (n_points,), optional\n        Distance from each point to its assigned bin center.\n        Only returned if `return_dist=True`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; from neurospatial.spatial import map_points_to_bins\n    &gt;&gt;&gt; data = np.random.randn(1000, 2) * 10\n    &gt;&gt;&gt; env = Environment.from_samples(data, bin_size=2.0)\n    &gt;&gt;&gt; points = np.array([[0.0, 0.0], [10.0, 10.0], [50.0, 50.0]])\n    &gt;&gt;&gt; bins = map_points_to_bins(points, env)\n    &gt;&gt;&gt; bins\n    array([ 42,  89,  -1])\n\n    &gt;&gt;&gt; # Get distances too\n    &gt;&gt;&gt; bins, dists = map_points_to_bins(points, env, return_dist=True)\n    &gt;&gt;&gt; dists\n    array([0.23, 0.45, inf])\n\n    Notes\n    -----\n    This function builds and caches a KD-tree on the environment's bin_centers\n    on first call. Subsequent calls reuse the cached tree for O(log N) performance.\n\n    The cache is stored as a private attribute on the Environment object. If\n    bin_centers are modified after creation (not recommended), the cache will\n    become stale.\n\n    See Also\n    --------\n    Environment.bin_at : Basic point-to-bin mapping (delegates to layout engine)\n    Environment.contains : Check if points are within environment bounds\n\n    \"\"\"\n    # Build or retrieve cached KD-tree\n    if not hasattr(env, \"_kdtree_cache\") or env._kdtree_cache is None:\n        env._kdtree_cache = cKDTree(env.bin_centers)\n\n    kdtree: cKDTree = env._kdtree_cache\n\n    # Query KD-tree\n    if tie_break == \"closest_center\":\n        # Fast path: just use nearest neighbor\n        distances, indices = kdtree.query(points, k=1, workers=-1)\n        bin_indices: NDArray[np.int64] = indices.astype(np.int64)\n\n    elif tie_break == \"lowest_index\":\n        # Deterministic path: find all ties and pick lowest index\n        # Query for nearest neighbor\n        distances, indices = kdtree.query(points, k=1, workers=-1)\n\n        # For boundary points, we need to check if there are multiple\n        # equidistant bins. Query for k=2 to detect ties.\n        distances_k2, _ = kdtree.query(points, k=2, workers=-1)\n\n        # Check where distance to 2nd nearest equals 1st nearest (within tolerance)\n        has_tie = np.abs(distances_k2[:, 0] - distances_k2[:, 1]) &lt; 1e-10\n\n        if np.any(has_tie):\n            # For tied points, query more neighbors and pick lowest index\n            # Adaptive: query enough neighbors to find all at same distance\n            max_neighbors = min(10, len(env.bin_centers))\n            distances_kn, indices_kn = kdtree.query(\n                points[has_tie], k=max_neighbors, workers=-1\n            )\n\n            # For each tied point, find all neighbors at same distance and pick min index\n            for i, (dists, idxs) in enumerate(\n                zip(distances_kn, indices_kn, strict=False)\n            ):\n                min_dist = dists[0]\n                tied_indices = idxs[np.abs(dists - min_dist) &lt; 1e-10]\n                indices[has_tie][i] = tied_indices.min()\n\n        bin_indices = indices.astype(np.int64)\n\n    else:\n        raise ValueError(\n            f\"Invalid tie_break mode: {tie_break!r}. \"\n            f\"Must be 'lowest_index' or 'closest_center'.\"\n        )\n\n    # Check if any points are outside the environment\n    # Points far from any bin center should be marked as -1\n    # Use a heuristic: if distance &gt; 10 * mean_bin_size, mark as outside\n    if len(env.bin_centers) &gt; 1:\n        # Estimate typical bin spacing from nearest-neighbor distances\n        sample_size = min(100, len(env.bin_centers))\n        sample_indices = np.random.choice(\n            len(env.bin_centers), size=sample_size, replace=False\n        )\n        sample_centers = env.bin_centers[sample_indices]\n        nn_dists, _ = kdtree.query(sample_centers, k=2, workers=-1)\n        typical_bin_spacing = np.median(nn_dists[:, 1])\n\n        # Mark points that are suspiciously far as outside\n        threshold = 10 * typical_bin_spacing\n        bin_indices[distances &gt; threshold] = -1\n\n    if return_dist:\n        # Set distance to inf for points outside environment\n        distances_out = distances.copy()\n        distances_out[bin_indices == -1] = np.inf\n        return (bin_indices, distances_out)\n\n    return bin_indices\n</code></pre>"},{"location":"api/neurospatial/spatial/#neurospatial.spatial.clear_kdtree_cache","title":"clear_kdtree_cache","text":"<pre><code>clear_kdtree_cache(env: Environment) -&gt; None\n</code></pre> <p>Clear the cached KD-tree for an environment.</p> <p>This is useful if bin_centers have been modified (not recommended) or to free memory.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Environment whose KD-tree cache should be cleared.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neurospatial.spatial import clear_kdtree_cache\n&gt;&gt;&gt; clear_kdtree_cache(env)\n</code></pre> Source code in <code>src/neurospatial/spatial.py</code> <pre><code>def clear_kdtree_cache(env: Environment) -&gt; None:\n    \"\"\"Clear the cached KD-tree for an environment.\n\n    This is useful if bin_centers have been modified (not recommended) or\n    to free memory.\n\n    Parameters\n    ----------\n    env : Environment\n        Environment whose KD-tree cache should be cleared.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from neurospatial.spatial import clear_kdtree_cache\n    &gt;&gt;&gt; clear_kdtree_cache(env)\n\n    \"\"\"\n    if hasattr(env, \"_kdtree_cache\"):\n        env._kdtree_cache = None\n</code></pre>"},{"location":"api/neurospatial/transforms/","title":"<code>neurospatial.transforms</code>","text":""},{"location":"api/neurospatial/transforms/#neurospatial.transforms","title":"transforms","text":""},{"location":"api/neurospatial/transforms/#neurospatial.transforms--transformspy-minimal-2-d-coordinate-transforms","title":"transforms.py - minimal 2-D coordinate transforms","text":"<p>Important: This module is specifically for 2D transformations. For 3D environments, use <code>scipy.spatial.transform.Rotation</code> or implement custom 3D transformation matrices. See docs/dimensionality_support.md for details on 3D support status.</p> Two complementary APIs <ol> <li>Composable objects (<code>Affine2D</code>, <code>SpatialTransform</code>)     Build a transform once, reuse everywhere, keep provenance.</li> <li>Quick helpers (<code>flip_y_data</code>, <code>convert_to_cm</code>, <code>convert_to_pixels</code>)     One-liners for scripts that just need a NumPy array back.</li> </ol> <p>All functions assume coordinates are shaped <code>(..., 2)</code> and are no-ops on the x-axis unless you chain additional transforms.</p>"},{"location":"api/neurospatial/transforms/#neurospatial.transforms-classes","title":"Classes","text":""},{"location":"api/neurospatial/transforms/#neurospatial.transforms.SpatialTransform","title":"SpatialTransform","text":"<p>               Bases: <code>Protocol</code></p> <p>Callable that maps an (N, 2) array of points \u2192 (N, 2) array.</p>"},{"location":"api/neurospatial/transforms/#neurospatial.transforms.Affine2D","title":"Affine2D  <code>dataclass</code>","text":"<pre><code>Affine2D(A: NDArray[float64])\n</code></pre> <p>               Bases: <code>SpatialTransform</code></p> <p>2-D affine transform expressed as a 3 \u00d7 3 homogeneous matrix A such that</p> <pre><code>[x', y', 1]^T  =  A @ [x, y, 1]^T\n</code></pre> <p>Attributes:</p> Name Type Description <code>A</code> <code>(NDArray[float64], shape(3, 3))</code> <p>Homogeneous transformation matrix representing the affine transformation. The matrix encodes rotation, scaling, translation, and shear operations. The bottom row is always [0, 0, 1].</p> <p>Examples:</p> <p>Create a transform that scales then translates:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial.transforms import translate, scale_2d\n&gt;&gt;&gt; transform = translate(10, 20) @ scale_2d(2.0)\n&gt;&gt;&gt; points = np.array([[0, 0], [1, 1]])\n&gt;&gt;&gt; transformed = transform(points)\n&gt;&gt;&gt; transformed\narray([[10., 20.],\n       [12., 22.]])\n</code></pre>"},{"location":"api/neurospatial/transforms/#neurospatial.transforms.Affine2D-functions","title":"Functions","text":""},{"location":"api/neurospatial/transforms/#neurospatial.transforms.Affine2D.inverse","title":"inverse","text":"<pre><code>inverse() -&gt; Affine2D\n</code></pre> <p>Compute the inverse transformation.</p> <p>Returns:</p> Type Description <code>Affine2D</code> <p>New Affine2D representing the inverse transformation.</p> <p>Raises:</p> Type Description <code>LinAlgError</code> <p>If transformation matrix is singular (non-invertible).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neurospatial.transforms import translate\n&gt;&gt;&gt; transform = translate(10, 20)\n&gt;&gt;&gt; inv = transform.inverse()\n&gt;&gt;&gt; points = np.array([[10, 20]])\n&gt;&gt;&gt; inv(points)\narray([[0., 0.]])\n</code></pre> Source code in <code>src/neurospatial/transforms.py</code> <pre><code>def inverse(self) -&gt; Affine2D:\n    \"\"\"Compute the inverse transformation.\n\n    Returns\n    -------\n    Affine2D\n        New Affine2D representing the inverse transformation.\n\n    Raises\n    ------\n    np.linalg.LinAlgError\n        If transformation matrix is singular (non-invertible).\n\n    Examples\n    --------\n    &gt;&gt;&gt; from neurospatial.transforms import translate\n    &gt;&gt;&gt; transform = translate(10, 20)\n    &gt;&gt;&gt; inv = transform.inverse()\n    &gt;&gt;&gt; points = np.array([[10, 20]])\n    &gt;&gt;&gt; inv(points)\n    array([[0., 0.]])\n\n    \"\"\"\n    return Affine2D(np.asarray(np.linalg.inv(self.A), dtype=np.float64))\n</code></pre>"},{"location":"api/neurospatial/transforms/#neurospatial.transforms.Affine2D.compose","title":"compose","text":"<pre><code>compose(other: Affine2D) -&gt; Affine2D\n</code></pre> <p>Compose this transformation with another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Affine2D</code> <p>Transformation to compose with (applied first).</p> required <p>Returns:</p> Type Description <code>Affine2D</code> <p>New transformation representing <code>self \u2218 other</code>.</p> Notes <p>The resulting transformation applies <code>other</code> first, then <code>self</code>. Composition order matters: <code>a.compose(b)</code> \u2260 <code>b.compose(a)</code> in general.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neurospatial.transforms import translate\n&gt;&gt;&gt; t1 = translate(10, 0)\n&gt;&gt;&gt; t2 = translate(0, 20)\n&gt;&gt;&gt; combined = t1.compose(t2)\n&gt;&gt;&gt; points = np.array([[0, 0]])\n&gt;&gt;&gt; combined(points)\narray([[10., 20.]])\n</code></pre> Source code in <code>src/neurospatial/transforms.py</code> <pre><code>def compose(self, other: Affine2D) -&gt; Affine2D:\n    \"\"\"Compose this transformation with another.\n\n    Parameters\n    ----------\n    other : Affine2D\n        Transformation to compose with (applied first).\n\n    Returns\n    -------\n    Affine2D\n        New transformation representing ``self \u2218 other``.\n\n    Notes\n    -----\n    The resulting transformation applies `other` first, then `self`.\n    Composition order matters: ``a.compose(b)`` \u2260 ``b.compose(a)`` in general.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from neurospatial.transforms import translate\n    &gt;&gt;&gt; t1 = translate(10, 0)\n    &gt;&gt;&gt; t2 = translate(0, 20)\n    &gt;&gt;&gt; combined = t1.compose(t2)\n    &gt;&gt;&gt; points = np.array([[0, 0]])\n    &gt;&gt;&gt; combined(points)\n    array([[10., 20.]])\n\n    \"\"\"\n    return Affine2D(self.A @ other.A)\n</code></pre>"},{"location":"api/neurospatial/transforms/#neurospatial.transforms-functions","title":"Functions","text":""},{"location":"api/neurospatial/transforms/#neurospatial.transforms.identity","title":"identity","text":"<pre><code>identity() -&gt; Affine2D\n</code></pre> <p>Return the identity transform.</p> <p>Returns:</p> Type Description <code>Affine2D</code> <p>Identity transformation (no change to input points).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; transform = identity()\n&gt;&gt;&gt; points = np.array([[1, 2], [3, 4]])\n&gt;&gt;&gt; transform(points)\narray([[1., 2.],\n       [3., 4.]])\n</code></pre> Source code in <code>src/neurospatial/transforms.py</code> <pre><code>def identity() -&gt; Affine2D:\n    \"\"\"Return the identity transform.\n\n    Returns\n    -------\n    Affine2D\n        Identity transformation (no change to input points).\n\n    Examples\n    --------\n    &gt;&gt;&gt; transform = identity()\n    &gt;&gt;&gt; points = np.array([[1, 2], [3, 4]])\n    &gt;&gt;&gt; transform(points)\n    array([[1., 2.],\n           [3., 4.]])\n\n    \"\"\"\n    return Affine2D(np.eye(3))\n</code></pre>"},{"location":"api/neurospatial/transforms/#neurospatial.transforms.scale_2d","title":"scale_2d","text":"<pre><code>scale_2d(sx: float = 1.0, sy: float | None = None) -&gt; Affine2D\n</code></pre> <p>Create uniform or anisotropic scaling transformation.</p> <p>Parameters:</p> Name Type Description Default <code>sx</code> <code>float</code> <p>Scale factor for x-axis.</p> <code>1.0</code> <code>sy</code> <code>float or None</code> <p>Scale factor for y-axis. If None, uses <code>sx</code> for uniform scaling.</p> <code>None</code> <p>Returns:</p> Type Description <code>Affine2D</code> <p>Scaling transformation.</p> <p>Examples:</p> <p>Uniform scaling:</p> <pre><code>&gt;&gt;&gt; transform = scale_2d(2.0)\n&gt;&gt;&gt; points = np.array([[1, 2]])\n&gt;&gt;&gt; transform(points)\narray([[2., 4.]])\n</code></pre> <p>Anisotropic scaling:</p> <pre><code>&gt;&gt;&gt; transform = scale_2d(sx=2.0, sy=0.5)\n&gt;&gt;&gt; points = np.array([[1, 2]])\n&gt;&gt;&gt; transform(points)\narray([[2., 1.]])\n</code></pre> Source code in <code>src/neurospatial/transforms.py</code> <pre><code>def scale_2d(sx: float = 1.0, sy: float | None = None) -&gt; Affine2D:\n    \"\"\"Create uniform or anisotropic scaling transformation.\n\n    Parameters\n    ----------\n    sx : float, default=1.0\n        Scale factor for x-axis.\n    sy : float or None, default=None\n        Scale factor for y-axis. If None, uses `sx` for uniform scaling.\n\n    Returns\n    -------\n    Affine2D\n        Scaling transformation.\n\n    Examples\n    --------\n    Uniform scaling:\n\n    &gt;&gt;&gt; transform = scale_2d(2.0)\n    &gt;&gt;&gt; points = np.array([[1, 2]])\n    &gt;&gt;&gt; transform(points)\n    array([[2., 4.]])\n\n    Anisotropic scaling:\n\n    &gt;&gt;&gt; transform = scale_2d(sx=2.0, sy=0.5)\n    &gt;&gt;&gt; points = np.array([[1, 2]])\n    &gt;&gt;&gt; transform(points)\n    array([[2., 1.]])\n\n    \"\"\"\n    sy = sx if sy is None else sy\n    return Affine2D(np.array([[sx, 0.0, 0.0], [0.0, sy, 0.0], [0.0, 0.0, 1.0]]))\n</code></pre>"},{"location":"api/neurospatial/transforms/#neurospatial.transforms.translate","title":"translate","text":"<pre><code>translate(tx: float = 0.0, ty: float = 0.0) -&gt; Affine2D\n</code></pre> <p>Create translation transformation.</p> <p>Parameters:</p> Name Type Description Default <code>tx</code> <code>float</code> <p>Translation in x direction.</p> <code>0.0</code> <code>ty</code> <code>float</code> <p>Translation in y direction.</p> <code>0.0</code> <p>Returns:</p> Type Description <code>Affine2D</code> <p>Translation transformation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; transform = translate(10, 20)\n&gt;&gt;&gt; points = np.array([[0, 0], [1, 1]])\n&gt;&gt;&gt; transform(points)\narray([[10., 20.],\n       [11., 21.]])\n</code></pre> Source code in <code>src/neurospatial/transforms.py</code> <pre><code>def translate(tx: float = 0.0, ty: float = 0.0) -&gt; Affine2D:\n    \"\"\"Create translation transformation.\n\n    Parameters\n    ----------\n    tx : float, default=0.0\n        Translation in x direction.\n    ty : float, default=0.0\n        Translation in y direction.\n\n    Returns\n    -------\n    Affine2D\n        Translation transformation.\n\n    Examples\n    --------\n    &gt;&gt;&gt; transform = translate(10, 20)\n    &gt;&gt;&gt; points = np.array([[0, 0], [1, 1]])\n    &gt;&gt;&gt; transform(points)\n    array([[10., 20.],\n           [11., 21.]])\n\n    \"\"\"\n    return Affine2D(np.array([[1.0, 0.0, tx], [0.0, 1.0, ty], [0.0, 0.0, 1.0]]))\n</code></pre>"},{"location":"api/neurospatial/transforms/#neurospatial.transforms.flip_y","title":"flip_y","text":"<pre><code>flip_y(frame_height_px: float) -&gt; Affine2D\n</code></pre> <p>Flip the y-axis of pixel coordinates so that origin moves from top-left to bottom-left.</p> <p>Parameters:</p> Name Type Description Default <code>frame_height_px</code> <code>float</code> <p>Height of the video frame in pixels.</p> required <p>Returns:</p> Type Description <code>Affine2D</code> <p>Transformation that flips y-axis around frame center.</p> Source code in <code>src/neurospatial/transforms.py</code> <pre><code>def flip_y(frame_height_px: float) -&gt; Affine2D:\n    \"\"\"Flip the *y*-axis of pixel coordinates so that origin moves\n    from top-left to bottom-left.\n\n    Parameters\n    ----------\n    frame_height_px : float\n        Height of the video frame in pixels.\n\n    Returns\n    -------\n    Affine2D\n        Transformation that flips y-axis around frame center.\n\n    \"\"\"\n    return Affine2D(\n        np.array([[1.0, 0.0, 0.0], [0.0, -1.0, frame_height_px], [0.0, 0.0, 1.0]]),\n    )\n</code></pre>"},{"location":"api/neurospatial/transforms/#neurospatial.transforms.flip_y_data","title":"flip_y_data","text":"<pre><code>flip_y_data(data: NDArray[float64] | tuple | list, frame_size_px: tuple[float, float]) -&gt; NDArray[np.float64]\n</code></pre> <p>Flip y-axis of coordinates so that the origin moves from image-space top-left to Cartesian bottom-left.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArray[float64] or tuple or list</code> <p>Input coordinates in pixel space, shape (..., 2).</p> required <code>frame_size_px</code> <code>tuple[float, float]</code> <p>Size of the video frame in pixels (width, height).</p> required <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>Flipped coordinates, shape (..., 2).</p> Notes <p>Equivalent to::</p> <pre><code>Affine2D([[1, 0, 0], [0, -1, H], [0, 0, 1]])(data)\n</code></pre> <p>but without the user having to build the transform.</p> Source code in <code>src/neurospatial/transforms.py</code> <pre><code>def flip_y_data(\n    data: NDArray[np.float64] | tuple | list,\n    frame_size_px: tuple[float, float],\n) -&gt; NDArray[np.float64]:\n    \"\"\"Flip y-axis of coordinates so that the origin moves from\n    image-space top-left to Cartesian bottom-left.\n\n    Parameters\n    ----------\n    data : NDArray[np.float64] or tuple or list\n        Input coordinates in pixel space, shape (..., 2).\n    frame_size_px : tuple[float, float]\n        Size of the video frame in pixels (width, height).\n\n    Returns\n    -------\n    NDArray[np.float64]\n        Flipped coordinates, shape (..., 2).\n\n    Notes\n    -----\n    Equivalent to::\n\n        Affine2D([[1, 0, 0], [0, -1, H], [0, 0, 1]])(data)\n\n    but without the user having to build the transform.\n\n    \"\"\"\n    transform = flip_y(frame_height_px=frame_size_px[1])\n    return transform(np.asanyarray(data, dtype=float))\n</code></pre>"},{"location":"api/neurospatial/transforms/#neurospatial.transforms.convert_to_cm","title":"convert_to_cm","text":"<pre><code>convert_to_cm(data_px: NDArray[float64] | tuple | list, frame_size_px: tuple[float, float], cm_per_px: float = 1.0) -&gt; NDArray[np.float64]\n</code></pre> <p>Convert pixel coordinates to centimeter coordinates.</p> <p>Pixel  \u2192  centimeter coordinates and y-flip in one shot.</p> <p>Internally constructs <code>scale_2d(cm_per_px) @ flip_y(H)</code> and applies it.</p> <p>Parameters:</p> Name Type Description Default <code>data_px</code> <code>array - like</code> <p>Input coordinates in pixel space, shape (..., 2).</p> required <code>frame_size_px</code> <code>tuple[float, float]</code> <p>Size of the video frame in pixels (width, height).</p> required <code>cm_per_px</code> <code>float</code> <p>Conversion factor from pixels to centimeters (default is 1.0).</p> <code>1.0</code> <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>Converted coordinates in centimeters, shape (..., 2).</p> Source code in <code>src/neurospatial/transforms.py</code> <pre><code>def convert_to_cm(\n    data_px: NDArray[np.float64] | tuple | list,\n    frame_size_px: tuple[float, float],\n    cm_per_px: float = 1.0,\n) -&gt; NDArray[np.float64]:\n    \"\"\"Convert pixel coordinates to centimeter coordinates.\n\n    Pixel  \u2192  centimeter coordinates *and* y-flip in one shot.\n\n    Internally constructs ``scale_2d(cm_per_px) @ flip_y(H)`` and applies it.\n\n    Parameters\n    ----------\n    data_px : array-like\n        Input coordinates in pixel space, shape (..., 2).\n    frame_size_px : tuple[float, float]\n        Size of the video frame in pixels (width, height).\n    cm_per_px : float, optional\n        Conversion factor from pixels to centimeters (default is 1.0).\n\n    Returns\n    -------\n    NDArray[np.float64]\n        Converted coordinates in centimeters, shape (..., 2).\n\n    \"\"\"\n    T = scale_2d(cm_per_px) @ flip_y(frame_height_px=frame_size_px[1])\n    return T(np.asanyarray(data_px, dtype=float))\n</code></pre>"},{"location":"api/neurospatial/transforms/#neurospatial.transforms.convert_to_pixels","title":"convert_to_pixels","text":"<pre><code>convert_to_pixels(data_cm: NDArray[float64] | tuple | list, frame_size_px: tuple[float, float], cm_per_px: float = 1.0) -&gt; NDArray[np.float64]\n</code></pre> <p>Convert centimeter coordinates to pixel coordinates with y-flip.</p> <p>Parameters:</p> Name Type Description Default <code>data_cm</code> <code>NDArray[float64] or tuple or list</code> <p>Input coordinates in centimeter space, shape (..., 2).</p> required <code>frame_size_px</code> <code>tuple[float, float]</code> <p>Size of the video frame in pixels (width, height).</p> required <code>cm_per_px</code> <code>float</code> <p>Conversion factor from pixels to centimeters.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>Converted coordinates in pixel space, shape (..., 2).</p> Notes <p>Inverse of <code>convert_to_cm</code>. Internally constructs <code>flip_y(H) @ scale_2d(1/cm_per_px)</code>.</p> Source code in <code>src/neurospatial/transforms.py</code> <pre><code>def convert_to_pixels(\n    data_cm: NDArray[np.float64] | tuple | list,\n    frame_size_px: tuple[float, float],\n    cm_per_px: float = 1.0,\n) -&gt; NDArray[np.float64]:\n    \"\"\"Convert centimeter coordinates to pixel coordinates with y-flip.\n\n    Parameters\n    ----------\n    data_cm : NDArray[np.float64] or tuple or list\n        Input coordinates in centimeter space, shape (..., 2).\n    frame_size_px : tuple[float, float]\n        Size of the video frame in pixels (width, height).\n    cm_per_px : float, default=1.0\n        Conversion factor from pixels to centimeters.\n\n    Returns\n    -------\n    NDArray[np.float64]\n        Converted coordinates in pixel space, shape (..., 2).\n\n    Notes\n    -----\n    Inverse of `convert_to_cm`. Internally constructs ``flip_y(H) @ scale_2d(1/cm_per_px)``.\n\n    \"\"\"\n    T = flip_y(frame_height_px=frame_size_px[1]) @ scale_2d(1.0 / cm_per_px)\n    return T(np.asanyarray(data_cm, dtype=float))\n</code></pre>"},{"location":"api/neurospatial/transforms/#neurospatial.transforms.estimate_transform","title":"estimate_transform","text":"<pre><code>estimate_transform(src: NDArray[float64], dst: NDArray[float64], kind: str = 'rigid') -&gt; Affine2D\n</code></pre> <p>Estimate 2D transformation from point correspondences.</p> <p>Given pairs of corresponding points in source and destination coordinate systems, compute the best-fit transformation (rigid, similarity, or affine).</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>(NDArray[float64], shape(N, 2))</code> <p>Source points (N &gt;= 2 for rigid/similarity, N &gt;= 3 for affine).</p> required <code>dst</code> <code>(NDArray[float64], shape(N, 2))</code> <p>Destination points corresponding to src.</p> required <code>kind</code> <code>('rigid', 'similarity', 'affine')</code> <p>Type of transformation to estimate:</p> <ul> <li>\"rigid\": Rotation + translation (preserves distances and angles)</li> <li>\"similarity\": Rotation + uniform scaling + translation   (preserves angles, scales distances uniformly)</li> <li>\"affine\": Full affine (rotation, scaling, shear, translation)</li> </ul> <code>\"rigid\"</code> <p>Returns:</p> Type Description <code>Affine2D</code> <p>Estimated transformation that maps src \u2192 dst.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If insufficient points for the requested transformation type, or if points are degenerate (collinear, etc.).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neurospatial.transforms import estimate_transform\n&gt;&gt;&gt; # Define corresponding points (e.g., landmarks in two sessions)\n&gt;&gt;&gt; src_pts = np.array([[0, 0], [10, 0], [10, 10], [0, 10]])\n&gt;&gt;&gt; # Rotated 45 degrees and translated\n&gt;&gt;&gt; angle = np.pi / 4\n&gt;&gt;&gt; dst_pts = src_pts @ [\n...     [np.cos(angle), -np.sin(angle)],\n...     [np.sin(angle), np.cos(angle)],\n... ] + [5, 5]\n&gt;&gt;&gt; T = estimate_transform(src_pts, dst_pts, kind=\"rigid\")\n&gt;&gt;&gt; transformed = T(src_pts)\n&gt;&gt;&gt; np.allclose(transformed, dst_pts)\nTrue\n</code></pre> Notes <p>Uses Procrustes analysis for rigid and similarity transforms, and least-squares for affine transforms.</p> <p>For cross-session alignment, collect 3-4 landmark points (e.g., corners of arena) in both sessions and use this function to compute the alignment.</p> See Also <p>Affine2D : 2D affine transformation class apply_transform_to_environment : Apply transform to Environment</p> Source code in <code>src/neurospatial/transforms.py</code> <pre><code>def estimate_transform(\n    src: NDArray[np.float64],\n    dst: NDArray[np.float64],\n    kind: str = \"rigid\",\n) -&gt; Affine2D:\n    \"\"\"Estimate 2D transformation from point correspondences.\n\n    Given pairs of corresponding points in source and destination coordinate\n    systems, compute the best-fit transformation (rigid, similarity, or affine).\n\n    Parameters\n    ----------\n    src : NDArray[np.float64], shape (N, 2)\n        Source points (N &gt;= 2 for rigid/similarity, N &gt;= 3 for affine).\n    dst : NDArray[np.float64], shape (N, 2)\n        Destination points corresponding to src.\n    kind : {\"rigid\", \"similarity\", \"affine\"}, default=\"rigid\"\n        Type of transformation to estimate:\n\n        - \"rigid\": Rotation + translation (preserves distances and angles)\n        - \"similarity\": Rotation + uniform scaling + translation\n          (preserves angles, scales distances uniformly)\n        - \"affine\": Full affine (rotation, scaling, shear, translation)\n\n    Returns\n    -------\n    Affine2D\n        Estimated transformation that maps src \u2192 dst.\n\n    Raises\n    ------\n    ValueError\n        If insufficient points for the requested transformation type,\n        or if points are degenerate (collinear, etc.).\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neurospatial.transforms import estimate_transform\n    &gt;&gt;&gt; # Define corresponding points (e.g., landmarks in two sessions)\n    &gt;&gt;&gt; src_pts = np.array([[0, 0], [10, 0], [10, 10], [0, 10]])\n    &gt;&gt;&gt; # Rotated 45 degrees and translated\n    &gt;&gt;&gt; angle = np.pi / 4\n    &gt;&gt;&gt; dst_pts = src_pts @ [\n    ...     [np.cos(angle), -np.sin(angle)],\n    ...     [np.sin(angle), np.cos(angle)],\n    ... ] + [5, 5]\n    &gt;&gt;&gt; T = estimate_transform(src_pts, dst_pts, kind=\"rigid\")\n    &gt;&gt;&gt; transformed = T(src_pts)\n    &gt;&gt;&gt; np.allclose(transformed, dst_pts)\n    True\n\n    Notes\n    -----\n    Uses Procrustes analysis for rigid and similarity transforms, and\n    least-squares for affine transforms.\n\n    For cross-session alignment, collect 3-4 landmark points (e.g., corners\n    of arena) in both sessions and use this function to compute the alignment.\n\n    See Also\n    --------\n    Affine2D : 2D affine transformation class\n    apply_transform_to_environment : Apply transform to Environment\n\n    \"\"\"\n    from scipy.linalg import orthogonal_procrustes\n\n    src = np.asanyarray(src, dtype=float)\n    dst = np.asanyarray(dst, dtype=float)\n\n    if src.shape != dst.shape:\n        raise ValueError(\n            f\"src and dst must have same shape, got {src.shape} and {dst.shape}\"\n        )\n\n    if src.ndim != 2 or src.shape[1] != 2:\n        raise ValueError(\n            f\"src and dst must be (N, 2) arrays for 2D transforms, got shape {src.shape}\"\n        )\n\n    n_points = src.shape[0]\n\n    if kind in (\"rigid\", \"similarity\"):\n        if n_points &lt; 2:\n            raise ValueError(\n                f\"{kind} transform requires at least 2 point pairs, got {n_points}\"\n            )\n\n        # Center the points\n        src_mean = src.mean(axis=0)\n        dst_mean = dst.mean(axis=0)\n        src_centered = src - src_mean\n        dst_centered = dst - dst_mean\n\n        # Estimate rotation using Procrustes\n        # Note: orthogonal_procrustes finds R such that ||src @ R - dst|| is minimized\n        # But we want transformation T(x) = x @ R_transform^T\n        # So R_transform = R^T\n        R_proc, _ = orthogonal_procrustes(src_centered, dst_centered)\n        R = R_proc.T\n\n        # Ensure R is a proper rotation (det(R) = +1, not -1)\n        # If det(R) &lt; 0, we have a reflection; flip one axis to get rotation\n        if np.linalg.det(R) &lt; 0:\n            # Flip the second column to convert reflection to rotation\n            R[:, 1] = -R[:, 1]\n\n        if kind == \"rigid\":\n            # Rigid: rotation + translation\n            # T(x) = R @ x + t\n            # Solve for t: dst_mean = R @ src_mean + t\n            t = dst_mean - R @ src_mean\n\n            # Build homogeneous matrix\n            A = np.eye(3)\n            A[:2, :2] = R\n            A[:2, 2] = t\n\n            return Affine2D(A)\n\n        else:  # similarity\n            # Similarity: rotation + uniform scale + translation\n            # Estimate scale: ratio of RMS distances from centroid\n            src_rms = np.sqrt(np.mean(np.sum(src_centered**2, axis=1)))\n            dst_rms = np.sqrt(np.mean(np.sum(dst_centered**2, axis=1)))\n\n            if src_rms &lt; 1e-10:\n                raise ValueError(\"Source points are degenerate (all at same location)\")\n\n            scale = dst_rms / src_rms\n\n            # Build transformation: T(x) = scale * R @ x + t\n            # where t = dst_mean - scale * R @ src_mean\n            t = dst_mean - scale * (R @ src_mean)\n\n            A = np.eye(3)\n            A[:2, :2] = scale * R\n            A[:2, 2] = t\n\n            return Affine2D(A)\n\n    elif kind == \"affine\":\n        if n_points &lt; 3:\n            raise ValueError(\n                f\"affine transform requires at least 3 point pairs, got {n_points}\"\n            )\n\n        # Solve affine transform using least squares\n        # T(x, y) = [a, b, tx] @ [x, y, 1]^T  for x-coordinate\n        #           [c, d, ty] @ [x, y, 1]^T  for y-coordinate\n\n        # Build design matrix: [x, y, 1] for each point\n        X = np.c_[src, np.ones(n_points)]  # (N, 3)\n\n        # Solve for each row of transformation matrix independently\n        # For x: [a, b, tx] = argmin ||X @ [a, b, tx]^T - dst_x||^2\n        # For y: [c, d, ty] = argmin ||X @ [c, d, ty]^T - dst_y||^2\n        params_x = np.linalg.lstsq(X, dst[:, 0], rcond=None)[0]  # [a, b, tx]\n        params_y = np.linalg.lstsq(X, dst[:, 1], rcond=None)[0]  # [c, d, ty]\n\n        # Build homogeneous matrix\n        A = np.eye(3)\n        A[0, :] = params_x  # [a, b, tx]\n        A[1, :] = params_y  # [c, d, ty]\n\n        return Affine2D(A)\n\n    else:\n        raise ValueError(\n            f\"Invalid kind: {kind!r}. Must be 'rigid', 'similarity', or 'affine'.\"\n        )\n</code></pre>"},{"location":"api/neurospatial/transforms/#neurospatial.transforms.apply_transform_to_environment","title":"apply_transform_to_environment","text":"<pre><code>apply_transform_to_environment(env: Environment, transform: Affine2D, *, name: str | None = None) -&gt; Environment\n</code></pre> <p>Apply 2D affine transformation to an Environment, returning a new instance.</p> <p>This function creates a new Environment with transformed bin_centers and updated connectivity graph. All other properties (regions, metadata) are copied from the source environment.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Source environment to transform (must be 2D).</p> required <code>transform</code> <code>Affine2D</code> <p>Transformation to apply.</p> required <code>name</code> <code>str</code> <p>Name for the new environment. If None, appends \"_transformed\" to original name.</p> <code>None</code> <p>Returns:</p> Type Description <code>Environment</code> <p>New Environment instance with transformed coordinates.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If environment is not 2D (transforms only support 2D currently).</p> <code>RuntimeError</code> <p>If environment is not fitted.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; from neurospatial.transforms import (\n...     estimate_transform,\n...     apply_transform_to_environment,\n... )\n&gt;&gt;&gt; # Create environment from session 1\n&gt;&gt;&gt; env1 = Environment.from_samples(data1, bin_size=2.0)\n&gt;&gt;&gt; # Estimate transform from landmarks\n&gt;&gt;&gt; T = estimate_transform(landmarks_session1, landmarks_session2, kind=\"rigid\")\n&gt;&gt;&gt; # Transform environment to session 2 coordinates\n&gt;&gt;&gt; env1_aligned = apply_transform_to_environment(env1, T, name=\"session1_aligned\")\n</code></pre> See Also <p>estimate_transform : Estimate transformation from point pairs Affine2D : 2D affine transformation class</p> Notes <p>This function is pure: it does not modify the source environment.</p> <p>The transformation is applied to: - bin_centers - graph node 'pos' attributes - regions (points and polygons)</p> <p>Edge distances and vectors are recomputed after transformation.</p> Source code in <code>src/neurospatial/transforms.py</code> <pre><code>def apply_transform_to_environment(\n    env: Environment,\n    transform: Affine2D,\n    *,\n    name: str | None = None,\n) -&gt; Environment:\n    \"\"\"Apply 2D affine transformation to an Environment, returning a new instance.\n\n    This function creates a new Environment with transformed bin_centers and\n    updated connectivity graph. All other properties (regions, metadata) are\n    copied from the source environment.\n\n    Parameters\n    ----------\n    env : Environment\n        Source environment to transform (must be 2D).\n    transform : Affine2D\n        Transformation to apply.\n    name : str, optional\n        Name for the new environment. If None, appends \"_transformed\" to original name.\n\n    Returns\n    -------\n    Environment\n        New Environment instance with transformed coordinates.\n\n    Raises\n    ------\n    ValueError\n        If environment is not 2D (transforms only support 2D currently).\n    RuntimeError\n        If environment is not fitted.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; from neurospatial.transforms import (\n    ...     estimate_transform,\n    ...     apply_transform_to_environment,\n    ... )\n    &gt;&gt;&gt; # Create environment from session 1\n    &gt;&gt;&gt; env1 = Environment.from_samples(data1, bin_size=2.0)\n    &gt;&gt;&gt; # Estimate transform from landmarks\n    &gt;&gt;&gt; T = estimate_transform(landmarks_session1, landmarks_session2, kind=\"rigid\")\n    &gt;&gt;&gt; # Transform environment to session 2 coordinates\n    &gt;&gt;&gt; env1_aligned = apply_transform_to_environment(env1, T, name=\"session1_aligned\")\n\n    See Also\n    --------\n    estimate_transform : Estimate transformation from point pairs\n    Affine2D : 2D affine transformation class\n\n    Notes\n    -----\n    This function is pure: it does not modify the source environment.\n\n    The transformation is applied to:\n    - bin_centers\n    - graph node 'pos' attributes\n    - regions (points and polygons)\n\n    Edge distances and vectors are recomputed after transformation.\n\n    \"\"\"\n    from neurospatial.environment import Environment\n    from neurospatial.regions import Region, Regions\n\n    # Validate\n    if not getattr(env, \"_is_fitted\", False):\n        raise RuntimeError(\n            \"Environment must be fitted before applying transforms. \"\n            \"Use a factory method like Environment.from_samples().\"\n        )\n\n    if env.n_dims != 2:\n        raise ValueError(\n            f\"apply_transform_to_environment only supports 2D environments, \"\n            f\"got {env.n_dims}D. For 3D, use scipy.spatial.transform.Rotation.\"\n        )\n\n    # Transform bin centers\n    transformed_centers = transform(env.bin_centers)\n\n    # Create new connectivity graph with updated node positions\n\n    new_graph = env.connectivity.copy()\n    for node_id in new_graph.nodes:\n        old_pos = new_graph.nodes[node_id][\"pos\"]\n        new_pos = transform(np.array([old_pos]))[0]\n        new_graph.nodes[node_id][\"pos\"] = tuple(new_pos)\n\n    # Recompute edge attributes (distance, vector, angle_2d)\n    for u, v in new_graph.edges:\n        pos_u = np.array(new_graph.nodes[u][\"pos\"])\n        pos_v = np.array(new_graph.nodes[v][\"pos\"])\n        vec = pos_v - pos_u\n        dist = float(np.linalg.norm(vec))\n\n        new_graph.edges[u, v][\"vector\"] = tuple(vec)\n        new_graph.edges[u, v][\"distance\"] = dist\n\n        # Recompute angle_2d if present\n        if \"angle_2d\" in new_graph.edges[u, v]:\n            angle = float(np.arctan2(vec[1], vec[0]))\n            new_graph.edges[u, v][\"angle_2d\"] = angle\n\n    # Transform dimension_ranges\n    transformed_dim_ranges = None\n    if env.dimension_ranges is not None:\n        # Transform corner points\n        lo_x, hi_x = env.dimension_ranges[0]\n        lo_y, hi_y = env.dimension_ranges[1]\n        corners = np.array([[lo_x, lo_y], [hi_x, lo_y], [hi_x, hi_y], [lo_x, hi_y]])\n        transformed_corners = transform(corners)\n\n        # New bounding box\n        new_lo_x, new_hi_x = (\n            transformed_corners[:, 0].min(),\n            transformed_corners[:, 0].max(),\n        )\n        new_lo_y, new_hi_y = (\n            transformed_corners[:, 1].min(),\n            transformed_corners[:, 1].max(),\n        )\n        transformed_dim_ranges = [(new_lo_x, new_hi_x), (new_lo_y, new_hi_y)]\n\n    # Create new Environment using from_layout pattern\n    # We'll create a minimal layout wrapper\n\n    class TransformedLayout:\n        \"\"\"Minimal layout wrapper for transformed environment.\"\"\"\n\n        def __init__(self, centers, graph, dim_ranges, original_layout):\n            self.bin_centers = centers\n            self.connectivity = graph\n            self.dimension_ranges = dim_ranges\n            self.is_1d = original_layout.is_1d\n            self._layout_type_tag = f\"{original_layout._layout_type_tag}_transformed\"\n            self._build_params_used = {\n                **getattr(original_layout, \"_build_params_used\", {}),\n                \"transformed\": True,\n            }\n\n            # Copy grid attributes if present\n            for attr in (\"grid_edges\", \"grid_shape\", \"active_mask\"):\n                if hasattr(original_layout, attr):\n                    setattr(self, attr, getattr(original_layout, attr))\n\n        def build(self):\n            pass  # Already built\n\n        def point_to_bin_index(self, points):\n            # Use KD-tree on transformed centers\n            from scipy.spatial import cKDTree\n\n            kdtree = cKDTree(self.bin_centers)\n            _, indices = kdtree.query(points)\n            return indices\n\n        def bin_sizes(self):\n            # Approximate from nearest neighbors\n            from scipy.spatial import cKDTree\n\n            if len(self.bin_centers) &lt; 2:\n                return np.array([1.0] * len(self.bin_centers))\n            kdtree = cKDTree(self.bin_centers)\n            dists, _ = kdtree.query(self.bin_centers, k=2)\n            return dists[:, 1] ** 2  # Approximate area\n\n        def plot(self, *args, **kwargs):\n            raise NotImplementedError(\n                \"Plotting not implemented for transformed layouts\"\n            )\n\n    transformed_layout = TransformedLayout(\n        transformed_centers, new_graph, transformed_dim_ranges, env.layout\n    )\n\n    # Create new environment\n    new_name = name if name is not None else f\"{env.name}_transformed\"\n    # Cast to LayoutEngine since TransformedLayout satisfies the protocol structurally\n    new_env = Environment(\n        name=new_name, layout=cast(\"LayoutEngine\", transformed_layout)\n    )\n    new_env._setup_from_layout()\n\n    # Transform and copy regions\n    if env.regions and len(env.regions) &gt; 0:\n        transformed_regions = []\n        for region in env.regions.values():\n            if region.kind == \"point\":\n                # Transform point\n                old_point = np.array(region.data)\n                new_point = transform(old_point.reshape(1, -1))[0]\n                new_region = Region(\n                    name=region.name,\n                    kind=\"point\",\n                    data=new_point,\n                    metadata={**region.metadata, \"transformed\": True},\n                )\n            elif region.kind == \"polygon\":\n                # Transform polygon\n                import shapely.geometry as shp\n                from shapely.geometry import Polygon\n\n                # Type narrowing: region.data is a Polygon when kind == \"polygon\"\n                if not isinstance(region.data, Polygon):\n                    raise TypeError(\n                        f\"Region '{region.name}' has kind='polygon' but data is not a Polygon\"\n                    )\n                old_coords = np.array(region.data.exterior.coords)\n                new_coords = transform(old_coords)\n                new_poly = shp.Polygon(new_coords)\n                new_region = Region(\n                    name=region.name,\n                    kind=\"polygon\",\n                    data=new_poly,\n                    metadata={**region.metadata, \"transformed\": True},\n                )\n\n            transformed_regions.append(new_region)\n\n        new_env.regions = Regions(transformed_regions)\n\n    # Copy units and frame\n    if hasattr(env, \"units\"):\n        new_env.units = env.units\n    if hasattr(env, \"frame\"):\n        new_env.frame = f\"{env.frame}_transformed\" if env.frame else \"transformed\"\n\n    return new_env\n</code></pre>"},{"location":"api/neurospatial/layout/","title":"<code>neurospatial.layout</code>","text":""},{"location":"api/neurospatial/layout/#neurospatial.layout","title":"layout","text":""},{"location":"api/neurospatial/layout/#neurospatial.layout-classes","title":"Classes","text":""},{"location":"api/neurospatial/layout/#neurospatial.layout.LayoutEngine","title":"LayoutEngine","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol defining the interface for all spatial layout engines.</p> <p>A LayoutEngine is responsible for discretizing a continuous N-dimensional space into a set of bins or elements and constructing a graph representation of their connectivity.</p> <p>Attributes:</p> Name Type Description <code>bin_centers</code> <code>NDArray[float64]</code> <p>Coordinates of the center of each active bin/node. Shape is (n_active_bins, n_dims).</p> <code>connectivity</code> <code>Optional[Graph]</code> <p>Graph where nodes are integers from <code>0</code> to <code>n_active_bins - 1</code>, directly corresponding to rows in <code>bin_centers</code>. Mandatory Node Attributes:     - 'pos': Tuple[float, ...] - N-D coordinates of the active bin center.     - 'source_grid_flat_index': int - Flat index in the original       full conceptual grid from which this active bin originated.     - 'original_grid_nd_index': Tuple[int, ...] - N-D tuple index       in the original full conceptual grid. Mandatory Edge Attributes:     - 'distance': float - Euclidean distance between connected bin centers.     - 'vector': Tuple[float, ...] - Displacement vector between centers.     - 'edge_id': int - Unique ID for the edge within this graph. Recommended Edge Attributes:     - 'angle_2d': Optional[float] - Angle of displacement for 2D layouts.</p> <code>is_1d</code> <code>bool</code> <p>True if the layout represents a primarily 1-dimensional structure (e.g., a linearized track), False otherwise.</p> <code>dimension_ranges</code> <code>Optional[Sequence[Tuple[float, float]]]</code> <p>The actual min/max extent <code>[(min_d0, max_d0), ..., (min_dN-1, max_dN-1)]</code> covered by the layout's geometry.</p> <code>grid_edges</code> <code>Optional[Tuple[NDArray[float64], ...]]</code> <p>For grid-based layouts: A tuple of 1D arrays, where each array contains the bin edge positions for one dimension of the original, full grid. <code>None</code> or <code>()</code> for non-grid or point-based layouts.</p> <code>grid_shape</code> <code>Optional[Tuple[int, ...]]</code> <p>For grid-based layouts: The N-D shape (number of bins in each dimension) of the original, full grid. For point-based/cell-based layouts without a full grid concept: Typically <code>(n_active_bins,)</code>.</p> <code>active_mask</code> <code>Optional[NDArray[bool_]]</code> <ul> <li>For grid-based layouts: An N-D boolean mask indicating active bins   on the original, full grid (shape matches <code>grid_shape</code>).</li> <li>For point-based/cell-based layouts: A 1D array of <code>True</code> values,   shape <code>(n_active_bins,)</code>, corresponding to <code>bin_centers</code>.</li> </ul> <code>_layout_type_tag</code> <code>str</code> <p>A string identifier for the type of layout (e.g., \"RegularGrid\"). Used for introspection and serialization.</p> <code>_build_params_used</code> <code>Dict[str, Any]</code> <p>A dictionary of the parameters used to construct this layout instance. Used for introspection and serialization.</p>"},{"location":"api/neurospatial/layout/#neurospatial.layout.LayoutEngine-attributes","title":"Attributes","text":""},{"location":"api/neurospatial/layout/#neurospatial.layout.LayoutEngine.is_1d","title":"is_1d  <code>property</code>","text":"<pre><code>is_1d: bool\n</code></pre> <p>Indicate if the layout structure is primarily 1-dimensional.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the layout represents a 1D structure (e.g., a linearized track), False otherwise.</p>"},{"location":"api/neurospatial/layout/#neurospatial.layout.LayoutEngine-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/#neurospatial.layout.LayoutEngine.build","title":"build","text":"<pre><code>build(**kwargs) -&gt; None\n</code></pre> <p>Construct the layout's geometry, bins, and connectivity graph.</p> <p>This method is responsible for populating all the attributes defined in the <code>LayoutEngine</code> protocol (e.g., <code>bin_centers</code>, <code>connectivity</code>, etc.) based on the provided keyword arguments. The specific arguments required will vary depending on the concrete implementation of the layout engine.</p> Source code in <code>src/neurospatial/layout/base.py</code> <pre><code>def build(self, **kwargs) -&gt; None:\n    \"\"\"Construct the layout's geometry, bins, and connectivity graph.\n\n    This method is responsible for populating all the attributes defined\n    in the `LayoutEngine` protocol (e.g., `bin_centers`,\n    `connectivity`, etc.) based on the provided keyword arguments.\n    The specific arguments required will vary depending on the concrete\n    implementation of the layout engine.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.LayoutEngine.point_to_bin_index","title":"point_to_bin_index","text":"<pre><code>point_to_bin_index(points: NDArray[float64]) -&gt; NDArray[np.int_]\n</code></pre> <p>Map continuous N-D points to discrete active bin indices.</p> <p>The returned indices range from <code>0</code> to <code>n_active_bins - 1</code>. A value of -1 indicates that the corresponding point did not map to any active bin (e.g., it's outside the defined environment).</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>(NDArray[float64], shape(n_points, n_dims))</code> <p>An array of N-dimensional points to map to bin indices.</p> required <p>Returns:</p> Type Description <code>(NDArray[int_], shape(n_points))</code> <p>An array of active bin indices corresponding to the input points. -1 for points outside the layout's active bins.</p> Source code in <code>src/neurospatial/layout/base.py</code> <pre><code>def point_to_bin_index(self, points: NDArray[np.float64]) -&gt; NDArray[np.int_]:\n    \"\"\"Map continuous N-D points to discrete active bin indices.\n\n    The returned indices range from `0` to `n_active_bins - 1`.\n    A value of -1 indicates that the corresponding point did not map\n    to any active bin (e.g., it's outside the defined environment).\n\n    Parameters\n    ----------\n    points : NDArray[np.float64], shape (n_points, n_dims)\n        An array of N-dimensional points to map to bin indices.\n\n    Returns\n    -------\n    NDArray[np.int_], shape (n_points,)\n        An array of active bin indices corresponding to the input points.\n        -1 for points outside the layout's active bins.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.LayoutEngine.bin_sizes","title":"bin_sizes","text":"<pre><code>bin_sizes() -&gt; NDArray[np.float64]\n</code></pre> <p>Return the area (2D) or volume (3D+) of each active bin.</p> <p>For 1D layouts, this typically returns the length of each bin. The measures should correspond to the dimensionality of the space the bins occupy.</p> <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_active_bins))</code> <p>An array where each element is the area/volume/length of the corresponding active bin.</p> Source code in <code>src/neurospatial/layout/base.py</code> <pre><code>def bin_sizes(self) -&gt; NDArray[np.float64]:\n    \"\"\"Return the area (2D) or volume (3D+) of each active bin.\n\n    For 1D layouts, this typically returns the length of each bin.\n    The measures should correspond to the dimensionality of the space\n    the bins occupy.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_active_bins,)\n        An array where each element is the area/volume/length of the\n        corresponding active bin.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.LayoutEngine.plot","title":"plot","text":"<pre><code>plot(ax: Axes | None = None, **kwargs) -&gt; matplotlib.axes.Axes\n</code></pre> <p>Plot the layout's geometry.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>The Matplotlib axes to plot on. If None, a new figure and axes are created. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for plot customization, specific to the layout engine implementation.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the layout is plotted.</p> Source code in <code>src/neurospatial/layout/base.py</code> <pre><code>def plot(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    **kwargs,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot the layout's geometry.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        The Matplotlib axes to plot on. If None, a new figure and axes\n        are created. Defaults to None.\n    **kwargs : Any\n        Additional keyword arguments for plot customization, specific to\n        the layout engine implementation.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the layout is plotted.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.GraphLayout","title":"GraphLayout","text":"<pre><code>GraphLayout()\n</code></pre> <p>               Bases: <code>_KDTreeMixin</code></p> <p>Layout defined by a user-provided graph, typically for 1D tracks.</p> <p>The graph's nodes (with 'pos' attributes) and a specified edge order are used to create a linearized representation of the space, which is then binned. Connectivity is derived from this binned structure. Uses <code>_KDTreeMixin</code> for point mapping and neighbor finding on the N-D embeddings of the linearized bin centers.</p> <p>Initialize a GraphLayout engine.</p> Source code in <code>src/neurospatial/layout/engines/graph.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize a GraphLayout engine.\"\"\"\n    self._layout_type_tag = \"Graph\"\n    self._build_params_used = {}\n    self.bin_centers = np.empty((0, 0), dtype=np.float64)\n    self.connectivity = None\n    self.dimension_ranges = None\n    self.grid_edges = None\n    self.grid_shape = None\n    self.active_mask = None\n    self.linear_bin_centers_ = None\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.GraphLayout-attributes","title":"Attributes","text":""},{"location":"api/neurospatial/layout/#neurospatial.layout.GraphLayout.is_1d","title":"is_1d  <code>property</code>","text":"<pre><code>is_1d: bool\n</code></pre> <p>Graph layouts are treated as 1-dimensional due to linearization.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Always True, indicating a 1D linearized layout.</p>"},{"location":"api/neurospatial/layout/#neurospatial.layout.GraphLayout-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/#neurospatial.layout.GraphLayout.build","title":"build","text":"<pre><code>build(*, graph_definition: Graph, edge_order: list[tuple[Any, Any]], edge_spacing: float | Sequence[float], bin_size: float) -&gt; None\n</code></pre> <p>Build the graph-based (linearized track) layout.</p> <p>Parameters:</p> Name Type Description Default <code>graph_definition</code> <code>Graph</code> <p>The original NetworkX graph. Nodes must have a 'pos' attribute (e.g., <code>(x, y)</code> coordinates) and edges should ideally have a 'distance' attribute if not relying on Euclidean distance calculation.</p> required <code>edge_order</code> <code>List[Tuple[Any, Any]]</code> <p>An ordered sequence of edge tuples (node_id_1, node_id_2) from <code>graph_definition</code> that defines the ordering of edges in the linear space.</p> required <code>edge_spacing</code> <code>Union[float, Sequence[float]]</code> <p>Spacing (gap) to insert between consecutive edges in <code>edge_order</code> during linearization. If float, same gap for all. If sequence, specifies each gap; length must be <code>len(edge_order) - 1</code>.</p> required <code>bin_size</code> <code>float</code> <p>The desired length of each bin along the linearized space.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>graph_definition</code> is not a NetworkX graph.</p> <code>ValueError</code> <p>If <code>edge_order</code> is empty or <code>bin_size</code> is not positive.</p> Source code in <code>src/neurospatial/layout/engines/graph.py</code> <pre><code>@capture_build_params\ndef build(\n    self,\n    *,\n    graph_definition: nx.Graph,  # Original user-provided graph\n    edge_order: list[tuple[Any, Any]],\n    edge_spacing: float | Sequence[float],\n    bin_size: float,  # Linearized bin size\n) -&gt; None:\n    \"\"\"Build the graph-based (linearized track) layout.\n\n    Parameters\n    ----------\n    graph_definition : nx.Graph\n        The original NetworkX graph. Nodes must have a 'pos' attribute\n        (e.g., `(x, y)` coordinates) and edges should ideally have a\n        'distance' attribute if not relying on Euclidean distance calculation.\n    edge_order : List[Tuple[Any, Any]]\n        An ordered sequence of edge tuples (node_id_1, node_id_2) from\n        `graph_definition` that defines the ordering of edges in the\n        linear space.\n    edge_spacing : Union[float, Sequence[float]]\n        Spacing (gap) to insert between consecutive edges in `edge_order`\n        during linearization. If float, same gap for all. If sequence,\n        specifies each gap; length must be `len(edge_order) - 1`.\n    bin_size : float\n        The desired length of each bin along the linearized space.\n\n    Raises\n    ------\n    TypeError\n        If `graph_definition` is not a NetworkX graph.\n    ValueError\n        If `edge_order` is empty or `bin_size` is not positive.\n\n    \"\"\"\n    if not isinstance(graph_definition, nx.Graph):\n        raise TypeError(\"graph_definition must be a NetworkX graph.\")\n    if not edge_order:  # Empty edge_order means no path to linearize\n        raise ValueError(\"edge_order must not be empty.\")\n    if bin_size &lt;= 0:\n        raise ValueError(\"bin_size must be positive.\")\n\n    (linear_bin_centers, self.grid_edges, self.active_mask, edge_ids) = (\n        _get_graph_bins(\n            graph=graph_definition,\n            edge_order=edge_order,\n            edge_spacing=edge_spacing,\n            bin_size=bin_size,\n        )\n    )\n\n    self.linear_bin_centers_ = linear_bin_centers[self.active_mask]\n    self.bin_centers = _project_1d_to_2d(\n        self.linear_bin_centers_,\n        graph_definition,\n        edge_order,\n        edge_spacing,\n    )\n    self.grid_shape = (len(self.grid_edges[0]) - 1,)\n    self.connectivity = _create_graph_layout_connectivity_graph(\n        graph=graph_definition,\n        bin_centers_nd=self.bin_centers,\n        linear_bin_centers=self.linear_bin_centers_,\n        original_edge_ids=edge_ids,\n        edge_order=edge_order,\n    )\n    self.dimension_ranges = (\n        (\n            np.min(self.bin_centers[:, 0]),\n            np.max(self.bin_centers[:, 0]),\n        ),\n        (np.min(self.bin_centers[:, 1]), np.max(self.bin_centers[:, 1])),\n    )\n\n    # --- Build KDTree ---\n    self._build_kdtree(points_for_tree=self.bin_centers)\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.GraphLayout.plot","title":"plot","text":"<pre><code>plot(ax: Axes | None = None, **kwargs) -&gt; matplotlib.axes.Axes\n</code></pre> <p>Plot the N-D embedding of the graph-based layout.</p> <p>Displays the original graph used for definition, the N-D positions of the binned track segments (active bin centers), and their connectivity.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Axes to plot on. If None, new figure and axes are created.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments: - <code>figsize</code> (tuple): Figure size if <code>ax</code> is None. - <code>node_kwargs</code> (dict): Kwargs for plotting original graph nodes. - <code>edge_kwargs</code> (dict): Kwargs for plotting original graph edges. - <code>bin_node_kwargs</code> (dict): Kwargs for plotting active bin center nodes. - <code>bin_edge_kwargs</code> (dict): Kwargs for plotting connectivity graph edges. - <code>show_bin_edges</code> (bool): Whether to project and plot 1D bin edges in N-D.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the layout is plotted.</p> Source code in <code>src/neurospatial/layout/engines/graph.py</code> <pre><code>def plot(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    **kwargs,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot the N-D embedding of the graph-based layout.\n\n    Displays the original graph used for definition, the N-D positions of\n    the binned track segments (active bin centers), and their connectivity.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        Axes to plot on. If None, new figure and axes are created.\n    **kwargs : Any\n        Additional keyword arguments:\n        - `figsize` (tuple): Figure size if `ax` is None.\n        - `node_kwargs` (dict): Kwargs for plotting original graph nodes.\n        - `edge_kwargs` (dict): Kwargs for plotting original graph edges.\n        - `bin_node_kwargs` (dict): Kwargs for plotting active bin center nodes.\n        - `bin_edge_kwargs` (dict): Kwargs for plotting connectivity graph edges.\n        - `show_bin_edges` (bool): Whether to project and plot 1D bin edges in N-D.\n\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the layout is plotted.\n\n    \"\"\"\n    if ax is None:\n        _, ax = plt.subplots(figsize=(7, 7))\n\n    # Draw the original graph nodes\n    original_node_pos = nx.get_node_attributes(\n        self._build_params_used[\"graph_definition\"],\n        \"pos\",\n    )\n    nx.draw_networkx_nodes(\n        self._build_params_used[\"graph_definition\"],\n        original_node_pos,\n        ax=ax,\n        node_size=300,\n        node_color=\"#1f77b4\",\n    )\n    # Draw the original graph edges\n    for node_id1, node_id2 in self._build_params_used[\"graph_definition\"].edges:\n        pos = np.stack(\n            (\n                original_node_pos[node_id1],\n                original_node_pos[node_id2],\n            ),\n        )\n        ax.plot(\n            pos[:, 0],\n            pos[:, 1],\n            color=\"gray\",\n            zorder=-1,\n            label=\"original edges\",\n        )\n\n    for node_id, pos in original_node_pos.items():\n        plt.text(\n            pos[0],\n            pos[1],\n            str(node_id),\n            ha=\"center\",\n            va=\"center\",\n            zorder=10,\n        )\n\n    # Draw the bin centers\n    bin_centers = nx.get_node_attributes(self.connectivity, \"pos\")\n    nx.draw_networkx_nodes(\n        self.connectivity,\n        bin_centers,\n        ax=ax,\n        node_size=30,\n        node_color=\"black\",\n    )\n\n    # Draw connectivity graph edges\n    if self.connectivity is not None:\n        for node_id1, node_id2 in self.connectivity.edges:\n            pos = np.stack((bin_centers[node_id1], bin_centers[node_id2]))\n            ax.plot(pos[:, 0], pos[:, 1], color=\"black\", zorder=-1)\n\n    if self.grid_edges is not None:\n        grid_line_2d = _project_1d_to_2d(\n            self.grid_edges[0],\n            self._build_params_used[\"graph_definition\"],\n            self._build_params_used[\"edge_order\"],\n            self._build_params_used[\"edge_spacing\"],\n        )\n        for grid_line in grid_line_2d:\n            ax.plot(\n                grid_line[0],\n                grid_line[1],\n                color=\"gray\",\n                marker=\"+\",\n                alpha=0.8,\n                label=\"bin edges\",\n            )\n    return ax\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.GraphLayout.plot_linear_layout","title":"plot_linear_layout","text":"<pre><code>plot_linear_layout(ax: Axes | None = None, **kwargs) -&gt; matplotlib.axes.Axes\n</code></pre> <p>Plot the 1D linearized representation of the graph layout.</p> <p>Uses <code>track_linearization.plot_graph_as_1D</code> to display the track segments and nodes in their 1D linearized positions. Overlays the 1D bin edges from <code>self.grid_edges</code>.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Axes to plot on. If None, new figure and axes are created.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>track_linearization.plot_graph_as_1D</code> and for customizing the appearance of bin edge lines.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the 1D layout is plotted.</p> Source code in <code>src/neurospatial/layout/engines/graph.py</code> <pre><code>def plot_linear_layout(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    **kwargs,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot the 1D linearized representation of the graph layout.\n\n    Uses `track_linearization.plot_graph_as_1D` to display the track\n    segments and nodes in their 1D linearized positions. Overlays the\n    1D bin edges from `self.grid_edges`.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        Axes to plot on. If None, new figure and axes are created.\n    **kwargs : Any\n        Additional keyword arguments passed to\n        `track_linearization.plot_graph_as_1D` and for customizing\n        the appearance of bin edge lines.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the 1D layout is plotted.\n\n    \"\"\"\n    if ax is None:\n        _, ax = plt.subplots(figsize=kwargs.get(\"figsize\", (10, 3)))\n\n    plot_graph_as_1D(\n        self._build_params_used[\"graph_definition\"],\n        self._build_params_used[\"edge_order\"],\n        self._build_params_used[\"edge_spacing\"],\n        ax=ax,\n        **kwargs,\n    )\n    if self.grid_edges is not None:\n        for grid_line in self.grid_edges[0]:\n            ax.axvline(grid_line, color=\"gray\", linestyle=\"--\", alpha=0.5)\n    ax.set_title(f\"{self._layout_type_tag} Layout\")\n    ax.set_xlabel(\"Linearized Position\")\n    ax.set_ylabel(\"Bin Index\")\n\n    return ax\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.GraphLayout.to_linear","title":"to_linear","text":"<pre><code>to_linear(data_points: NDArray[float64]) -&gt; NDArray[np.float64]\n</code></pre> <p>Convert N-D points to 1D linearized coordinates along the track.</p> <p>Uses <code>track_linearization.get_linearized_position</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_points</code> <code>(NDArray[float64], shape(n_points, n_dims))</code> <p>N-D points to linearize.</p> required <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_points))</code> <p>1D linearized coordinates. NaNs may be returned for points far from the track.</p> Source code in <code>src/neurospatial/layout/engines/graph.py</code> <pre><code>def to_linear(self, data_points: NDArray[np.float64]) -&gt; NDArray[np.float64]:\n    \"\"\"Convert N-D points to 1D linearized coordinates along the track.\n\n    Uses `track_linearization.get_linearized_position`.\n\n    Parameters\n    ----------\n    data_points : NDArray[np.float64], shape (n_points, n_dims)\n        N-D points to linearize.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_points,)\n        1D linearized coordinates. NaNs may be returned for points\n        far from the track.\n\n    \"\"\"\n    result = _get_linearized_position(\n        data_points,\n        self._build_params_used[\"graph_definition\"],\n        self._build_params_used[\"edge_order\"],\n        self._build_params_used[\"edge_spacing\"],\n    ).linear_position.to_numpy()\n    return np.asarray(result, dtype=np.float64)\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.GraphLayout.linear_to_nd","title":"linear_to_nd","text":"<pre><code>linear_to_nd(linear_coordinates: NDArray[float64]) -&gt; NDArray[np.float64]\n</code></pre> <p>Map 1D linearized coordinates back to N-D coordinates on the track graph.</p> <p>Parameters:</p> Name Type Description Default <code>linear_coordinates</code> <code>(NDArray[float64], shape(n_points))</code> <p>1D linearized coordinates to map.</p> required <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_points, n_dims))</code> <p>N-D coordinates corresponding to the input linear positions.</p> Source code in <code>src/neurospatial/layout/engines/graph.py</code> <pre><code>def linear_to_nd(\n    self,\n    linear_coordinates: NDArray[np.float64],\n) -&gt; NDArray[np.float64]:\n    \"\"\"Map 1D linearized coordinates back to N-D coordinates on the track graph.\n\n    Parameters\n    ----------\n    linear_coordinates : NDArray[np.float64], shape (n_points,)\n        1D linearized coordinates to map.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_points, n_dims)\n        N-D coordinates corresponding to the input linear positions.\n\n    \"\"\"\n    return _project_1d_to_2d(\n        linear_coordinates,\n        self._build_params_used[\"graph_definition\"],\n        self._build_params_used[\"edge_order\"],\n        self._build_params_used[\"edge_spacing\"],\n    )\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.GraphLayout.linear_point_to_bin_ind","title":"linear_point_to_bin_ind","text":"<pre><code>linear_point_to_bin_ind(data_points: NDArray[float64]) -&gt; NDArray[np.int_]\n</code></pre> <p>Map 1D linearized positions to active 1D bin indices.</p> <p>Parameters:</p> Name Type Description Default <code>data_points</code> <code>(NDArray[float64], shape(n_points))</code> <p>1D linearized positions.</p> required <p>Returns:</p> Type Description <code>(NDArray[int_], shape(n_points))</code> <p>Indices of the active 1D bins corresponding to each linear position. Returns -1 for positions outside active bins or in gaps. Note: These are indices relative to the set of active 1D bins, not indices into the full <code>linear_bin_centers_all</code> array.</p> Source code in <code>src/neurospatial/layout/engines/graph.py</code> <pre><code>def linear_point_to_bin_ind(\n    self,\n    data_points: NDArray[np.float64],\n) -&gt; NDArray[np.int_]:\n    \"\"\"Map 1D linearized positions to active 1D bin indices.\n\n    Parameters\n    ----------\n    data_points : NDArray[np.float64], shape (n_points,)\n        1D linearized positions.\n\n    Returns\n    -------\n    NDArray[np.int_], shape (n_points,)\n        Indices of the active 1D bins corresponding to each linear position.\n        Returns -1 for positions outside active bins or in gaps.\n        Note: These are indices relative to the set of *active* 1D bins,\n        not indices into the full `linear_bin_centers_all` array.\n\n    \"\"\"\n    if self.grid_edges is None:\n        raise RuntimeError(\"grid_edges not available\")\n    result = _find_bin_for_linear_position(\n        data_points,\n        bin_edges=self.grid_edges[0],\n        active_mask=self.active_mask,\n    )\n    # Ensure we return NDArray, not int\n    if isinstance(result, int):\n        return np.array([result], dtype=int)\n    return result\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.GraphLayout.bin_sizes","title":"bin_sizes","text":"<pre><code>bin_sizes() -&gt; NDArray[np.float64]\n</code></pre> <p>Return the length of each active 1D bin along the linearized track.</p> <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_active_bins))</code> <p>Array containing the length of each active linearized bin.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>grid_edges</code> or <code>active_mask</code> is not populated.</p> Source code in <code>src/neurospatial/layout/engines/graph.py</code> <pre><code>def bin_sizes(self) -&gt; NDArray[np.float64]:\n    \"\"\"Return the length of each active 1D bin along the linearized track.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_active_bins,)\n        Array containing the length of each active linearized bin.\n\n    Raises\n    ------\n    RuntimeError\n        If `grid_edges` or `active_mask` is not populated.\n\n    \"\"\"\n    if self.grid_edges is None or self.active_mask is None:  # pragma: no cover\n        raise RuntimeError(\"Layout not built; grid_edges or active_mask missing.\")\n    if not self.grid_edges or self.grid_edges[0].size &lt;= 1:  # pragma: no cover\n        raise ValueError(\n            \"grid_edges (1D) are not properly defined for length calculation.\",\n        )\n\n    all_1d_bin_lengths = np.diff(self.grid_edges[0])\n    return all_1d_bin_lengths[self.active_mask]\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.HexagonalLayout","title":"HexagonalLayout","text":"<pre><code>HexagonalLayout()\n</code></pre> <p>2D layout that tiles a rectangular area with a hexagonal lattice.</p> <p>Bin centers are the centers of the hexagons. Hexagons are connected to their immediate neighbors. Active hexagons can be inferred from data sample occupancy.</p> <p>Initialize a HexagonalLayout engine.</p> Source code in <code>src/neurospatial/layout/engines/hexagonal.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize a HexagonalLayout engine.\"\"\"\n    self._layout_type_tag = \"Hexagonal\"\n    self._build_params_used = {}\n    self.bin_centers = np.empty((0, 2))\n    self.connectivity = None\n    self.dimension_ranges = None\n    self.grid_edges = ()\n    self.grid_shape = None\n    self.active_mask = None\n    self.hexagon_width = None\n    self.hex_radius_ = None\n    self.hex_orientation_ = None\n    self.grid_offset_x_ = None\n    self.grid_offset_y_ = None\n    self._source_flat_to_active_id_map = None\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.HexagonalLayout-attributes","title":"Attributes","text":""},{"location":"api/neurospatial/layout/#neurospatial.layout.HexagonalLayout.is_1d","title":"is_1d  <code>property</code>","text":"<pre><code>is_1d: bool\n</code></pre> <p>Hexagonal layouts are 2-dimensional.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Always False, indicating a 2D layout.</p>"},{"location":"api/neurospatial/layout/#neurospatial.layout.HexagonalLayout-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/#neurospatial.layout.HexagonalLayout.build","title":"build","text":"<pre><code>build(*, hexagon_width: float, dimension_ranges: tuple[tuple[float, float], tuple[float, float]] | None = None, data_samples: NDArray[float64] | None = None, infer_active_bins: bool = True, bin_count_threshold: int = 0) -&gt; None\n</code></pre> <p>Build the hexagonal grid layout.</p> <p>Parameters:</p> Name Type Description Default <code>hexagon_width</code> <code>float</code> <p>The width of the hexagons (distance between parallel sides).</p> required <code>dimension_ranges</code> <code>Optional[Tuple[Tuple[float, float], Tuple[float, float]]]</code> <p>Explicit <code>[(min_x, max_x), (min_y, max_y)]</code> for the area to tile. If None (default), range is inferred from <code>data_samples</code>.</p> <code>None</code> <code>data_samples</code> <code>(Optional[NDArray[float64]], shape(n_samples, 2))</code> <p>2D data used to infer <code>dimension_ranges</code> (if not provided) and/or to infer active hexagons (if <code>infer_active_bins</code> is True). Defaults to None.</p> <code>None</code> <code>infer_active_bins</code> <code>bool</code> <p>If True and <code>data_samples</code> are provided, infers active hexagons based on occupancy. If False, all hexagons within the defined area are considered active.</p> <code>True</code> <code>bin_count_threshold</code> <code>int</code> <p>If <code>infer_active_bins</code> is True, the minimum number of samples a hexagon must contain to be considered active.</p> <code>0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>dimension_ranges</code> and <code>data_samples</code> are both None, or if <code>hexagon_width</code> is not positive.</p> Source code in <code>src/neurospatial/layout/engines/hexagonal.py</code> <pre><code>@capture_build_params\ndef build(\n    self,\n    *,\n    hexagon_width: float,\n    dimension_ranges: tuple[tuple[float, float], tuple[float, float]] | None = None,\n    data_samples: NDArray[np.float64] | None = None,\n    infer_active_bins: bool = True,\n    bin_count_threshold: int = 0,\n) -&gt; None:\n    \"\"\"Build the hexagonal grid layout.\n\n    Parameters\n    ----------\n    hexagon_width : float\n        The width of the hexagons (distance between parallel sides).\n    dimension_ranges : Optional[Tuple[Tuple[float,float], Tuple[float,float]]], optional\n        Explicit `[(min_x, max_x), (min_y, max_y)]` for the area to tile.\n        If None (default), range is inferred from `data_samples`.\n    data_samples : Optional[NDArray[np.float64]], shape (n_samples, 2), optional\n        2D data used to infer `dimension_ranges` (if not provided) and/or\n        to infer active hexagons (if `infer_active_bins` is True).\n        Defaults to None.\n    infer_active_bins : bool, default=True\n        If True and `data_samples` are provided, infers active hexagons\n        based on occupancy. If False, all hexagons within the defined\n        area are considered active.\n    bin_count_threshold : int, default=0\n        If `infer_active_bins` is True, the minimum number of samples a\n        hexagon must contain to be considered active.\n\n    Raises\n    ------\n    ValueError\n        If `dimension_ranges` and `data_samples` are both None, or if\n        `hexagon_width` is not positive.\n\n    \"\"\"\n    self.hexagon_width = hexagon_width\n    (\n        full_grid_bin_centers,\n        self.grid_shape,\n        self.hex_radius_,\n        self.hex_orientation_,\n        self.grid_offset_x_,\n        self.grid_offset_y_,\n        self.dimension_ranges,\n    ) = _create_hex_grid(\n        data_samples=data_samples,\n        dimension_range=dimension_ranges,\n        hexagon_width=self.hexagon_width,\n    )\n    if infer_active_bins and data_samples is not None:\n        active_bin_original_flat_indices = _infer_active_bins_from_hex_grid(\n            data_samples=data_samples,\n            centers_shape=self.grid_shape,\n            hex_radius=self.hex_radius_,\n            min_x=self.grid_offset_x_,\n            min_y=self.grid_offset_y_,\n            bin_count_threshold=bin_count_threshold,\n        )\n    else:\n        active_bin_original_flat_indices = np.arange(len(full_grid_bin_centers))\n\n    nd_active_mask = np.zeros(self.grid_shape, dtype=bool).ravel()\n    nd_active_mask[active_bin_original_flat_indices] = True\n    self.active_mask = nd_active_mask.reshape(self.grid_shape)\n\n    self.bin_centers = full_grid_bin_centers[active_bin_original_flat_indices]\n\n    self.connectivity = _create_hex_connectivity_graph(\n        active_original_flat_indices=active_bin_original_flat_indices,\n        full_grid_bin_centers=full_grid_bin_centers,\n        centers_shape=self.grid_shape,\n    )\n\n    self._source_flat_to_active_id_map = {\n        data[\"source_grid_flat_index\"]: node_id\n        for node_id, data in self.connectivity.nodes(data=True)\n    }\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.HexagonalLayout.plot","title":"plot","text":"<pre><code>plot(ax: Axes | None = None, **kwargs) -&gt; matplotlib.axes.Axes\n</code></pre> <p>Plot the hexagonal layout.</p> <p>Displays active hexagons and their connectivity graph.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Axes to plot on. If None, new figure and axes are created.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments: - <code>show_hexagons</code> (bool, default=True): Whether to draw hexagon cells. - <code>hexagon_kwargs</code> (dict): Kwargs for <code>matplotlib.patches.RegularPolygon</code>. - Other kwargs are passed to <code>_generic_graph_plot</code> for the graph.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the layout is plotted.</p> Source code in <code>src/neurospatial/layout/engines/hexagonal.py</code> <pre><code>def plot(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    **kwargs,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot the hexagonal layout.\n\n    Displays active hexagons and their connectivity graph.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        Axes to plot on. If None, new figure and axes are created.\n    **kwargs : Any\n        Additional keyword arguments:\n        - `show_hexagons` (bool, default=True): Whether to draw hexagon cells.\n        - `hexagon_kwargs` (dict): Kwargs for `matplotlib.patches.RegularPolygon`.\n        - Other kwargs are passed to `_generic_graph_plot` for the graph.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the layout is plotted.\n\n    \"\"\"\n    ax = _generic_graph_plot(\n        ax=ax,\n        graph=self.connectivity,\n        name=self._layout_type_tag,\n        **kwargs,\n    )\n\n    if (\n        kwargs.get(\"show_hexagons\", True)\n        and self.hex_radius_ is not None\n        and self.bin_centers is not None\n        and self.bin_centers.shape[0] &gt; 0\n    ):\n        hex_kws = kwargs.get(\n            \"hexagon_kwargs\",\n            {\n                \"edgecolor\": \"gray\",\n                \"facecolor\": \"none\",\n                \"alpha\": 0.5,\n                \"linewidth\": 0.5,\n            },\n        )\n\n        ax.scatter(\n            self.bin_centers[:, 0],\n            self.bin_centers[:, 1],\n            s=1,\n            label=\"hexagonal grid\",\n        )\n        patches = [\n            RegularPolygon(\n                (x, y),\n                numVertices=6,\n                radius=self.hex_radius_,\n                orientation=self.hex_orientation_,\n            )\n            for x, y in self.bin_centers\n        ]\n\n        collection = PatchCollection(patches, **hex_kws)\n        ax.add_collection(collection)\n        ax.plot(\n            self.bin_centers[:, 0],\n            self.bin_centers[:, 1],\n            marker=\"o\",\n            markersize=1,\n            color=\"blue\",\n            linestyle=\"None\",\n            label=\"midpoint\",\n        )\n\n        ax.set_title(f\"{self._layout_type_tag} Layout\")\n        padding = 1.1 * self.hex_radius_\n        if self.dimension_ranges is not None:\n            ax.set_xlim(\n                (\n                    self.dimension_ranges[0][0] - padding,\n                    self.dimension_ranges[0][1] + padding,\n                ),\n            )\n            ax.set_ylim(\n                (\n                    self.dimension_ranges[1][0] - padding,\n                    self.dimension_ranges[1][1] + padding,\n                ),\n            )\n        ax.set_aspect(\"equal\", adjustable=\"box\")\n    return ax\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.HexagonalLayout.point_to_bin_index","title":"point_to_bin_index","text":"<pre><code>point_to_bin_index(points: NDArray[float64]) -&gt; NDArray[np.int_]\n</code></pre> <p>Map 2D points to active hexagonal bin indices.</p> <p>Uses specialized logic to determine which hexagon each point falls into, then maps this to an active bin index.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>(NDArray[float64], shape(n_points, 2))</code> <p>2D points to map.</p> required <p>Returns:</p> Type Description <code>(NDArray[int_], shape(n_points))</code> <p>Active bin indices (0 to N-1). -1 for points not in an active hexagon.</p> Source code in <code>src/neurospatial/layout/engines/hexagonal.py</code> <pre><code>def point_to_bin_index(self, points: NDArray[np.float64]) -&gt; NDArray[np.int_]:\n    \"\"\"Map 2D points to active hexagonal bin indices.\n\n    Uses specialized logic to determine which hexagon each point falls into,\n    then maps this to an active bin index.\n\n    Parameters\n    ----------\n    points : NDArray[np.float64], shape (n_points, 2)\n        2D points to map.\n\n    Returns\n    -------\n    NDArray[np.int_], shape (n_points,)\n        Active bin indices (0 to N-1). -1 for points not in an active hexagon.\n\n    \"\"\"\n    if (\n        self.grid_offset_x_ is None\n        or self.grid_offset_y_ is None\n        or self.hex_radius_ is None\n        or self.grid_shape is None\n        or self._source_flat_to_active_id_map is None\n    ):\n        # This can happen if build() failed or was incomplete (e.g. no active bins)\n        warnings.warn(\n            \"HexagonalLayout is not fully initialized or has no active bins. \"\n            \"Cannot map points to bin indices.\",\n            RuntimeWarning,\n        )\n        return np.full(points.shape[0], -1, dtype=int)\n\n    # grid_shape is guaranteed to be tuple[int, int] for hexagonal layouts\n    assert self.grid_shape is not None and len(self.grid_shape) == 2\n    centers_shape_2d: tuple[int, int] = (self.grid_shape[0], self.grid_shape[1])\n\n    original_flat_indices = _points_to_hex_bin_ind(\n        points=points,\n        grid_offset_x=self.grid_offset_x_,\n        grid_offset_y=self.grid_offset_y_,\n        hex_radius=self.hex_radius_,\n        centers_shape=centers_shape_2d,\n    )\n    return np.array(\n        [\n            self._source_flat_to_active_id_map.get(idx, -1)\n            for idx in original_flat_indices\n        ],\n        dtype=int,\n    )\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.HexagonalLayout.bin_sizes","title":"bin_sizes","text":"<pre><code>bin_sizes() -&gt; NDArray[np.float64]\n</code></pre> <p>Calculate the area of each hexagonal bin.</p> <p>All active hexagons are assumed to have the same area.</p> <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_active_bins))</code> <p>Array containing the constant area for each active hexagonal bin.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>hex_radius_</code> or <code>bin_centers</code> is not populated.</p> Source code in <code>src/neurospatial/layout/engines/hexagonal.py</code> <pre><code>def bin_sizes(self) -&gt; NDArray[np.float64]:\n    \"\"\"Calculate the area of each hexagonal bin.\n\n    All active hexagons are assumed to have the same area.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_active_bins,)\n        Array containing the constant area for each active hexagonal bin.\n\n    Raises\n    ------\n    RuntimeError\n        If `hex_radius_` or `bin_centers` is not populated.\n\n    \"\"\"\n    if self.hex_radius_ is None or self.bin_centers is None:  # pragma: no cover\n        raise RuntimeError(\"Layout not built; hex_radius_ or bin_centers missing.\")\n\n    # Area of a regular hexagon: (3 * sqrt(3) / 2) * side_length^2\n    # For pointy-top hexagons, side_length (s) is equal to hex_radius_ (R, center to vertex).\n    single_hex_area = 3.0 * np.sqrt(3.0) / 2.0 * self.hex_radius_**2.0\n    return np.full(self.bin_centers.shape[0], single_hex_area)\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.ImageMaskLayout","title":"ImageMaskLayout","text":"<pre><code>ImageMaskLayout()\n</code></pre> <p>               Bases: <code>_GridMixin</code></p> <p>2D layout derived from a boolean image mask.</p> <p>Each <code>True</code> pixel in the input <code>image_mask</code> corresponds to an active bin in the environment. The spatial scale of these pixel-bins is determined by <code>bin_size</code>. Inherits grid functionalities from <code>_GridMixin</code>.</p> <p>Initialize an ImageMaskLayout engine.</p> Source code in <code>src/neurospatial/layout/engines/image_mask.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize an ImageMaskLayout engine.\"\"\"\n    self._layout_type_tag = \"ImageMask\"\n    self._build_params_used = {}\n    self.bin_centers = np.empty((0, 2), dtype=np.float64)\n    self.connectivity = None\n    self.dimension_ranges = None\n    self.grid_edges = None\n    self.grid_shape = None\n    self.active_mask = None\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.ImageMaskLayout-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/#neurospatial.layout.ImageMaskLayout.build","title":"build","text":"<pre><code>build(*, image_mask: NDArray[bool_], bin_size: float | tuple[float, float] = 1.0, connect_diagonal_neighbors: bool = True) -&gt; None\n</code></pre> <p>Build the layout from a 2D image mask.</p> <p>Parameters:</p> Name Type Description Default <code>image_mask</code> <code>(NDArray[bool_], shape(n_rows, n_cols))</code> <p>A 2D boolean array where <code>True</code> pixels define active bins.</p> required <code>bin_size</code> <code>Union[float, Tuple[float, float]]</code> <p>The spatial size of each pixel. If float: pixels are square (size x size). If tuple (width, height): specifies pixel_width and pixel_height.</p> <code>1.0</code> <code>connect_diagonal_neighbors</code> <code>bool</code> <p>If True, connect diagonally adjacent active pixel-bins.</p> <code>True</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>image_mask</code> is not a NumPy array.</p> <code>ValueError</code> <p>If <code>image_mask</code> is not 2D, not boolean, or <code>bin_size</code> is invalid, or if <code>image_mask</code> contains no True values or non-finite values.</p> Source code in <code>src/neurospatial/layout/engines/image_mask.py</code> <pre><code>@capture_build_params\ndef build(\n    self,\n    *,\n    image_mask: NDArray[np.bool_],  # Defines candidate pixels\n    bin_size: float | tuple[float, float] = 1.0,  # one pixel\n    connect_diagonal_neighbors: bool = True,\n) -&gt; None:\n    \"\"\"Build the layout from a 2D image mask.\n\n    Parameters\n    ----------\n    image_mask : NDArray[np.bool_], shape (n_rows, n_cols)\n        A 2D boolean array where `True` pixels define active bins.\n    bin_size : Union[float, Tuple[float, float]], default=1.0\n        The spatial size of each pixel.\n        If float: pixels are square (size x size).\n        If tuple (width, height): specifies pixel_width and pixel_height.\n    connect_diagonal_neighbors : bool, default=True\n        If True, connect diagonally adjacent active pixel-bins.\n\n    Raises\n    ------\n    TypeError\n        If `image_mask` is not a NumPy array.\n    ValueError\n        If `image_mask` is not 2D, not boolean, or `bin_size` is invalid,\n        or if `image_mask` contains no True values or non-finite values.\n\n    \"\"\"\n    if not isinstance(image_mask, np.ndarray):\n        raise TypeError(\"image_mask must be a numpy array.\")\n    if image_mask.ndim != 2:\n        raise ValueError(\"image_mask must be a 2D array.\")\n    if not np.issubdtype(image_mask.dtype, np.bool_):\n        raise ValueError(\"image_mask must be a boolean array.\")\n\n    # Validate bin_size\n    if isinstance(bin_size, tuple):\n        if any(s &lt;= 0 for s in bin_size):\n            raise ValueError(\"bin_size must be positive.\")\n    else:\n        if bin_size &lt;= 0:\n            raise ValueError(\"bin_size must be positive.\")\n    if not np.any(image_mask):\n        raise ValueError(\"image_mask must contain at least one True value.\")\n    if not np.all(np.isfinite(image_mask)):\n        raise ValueError(\"image_mask must not contain NaN or Inf values.\")\n\n    # Determine bin_sizes for x and y (units per pixel)\n    bin_size_x: float\n    bin_size_y: float\n    if isinstance(bin_size, (float, int, np.number)):\n        bin_size_x = float(bin_size)\n        bin_size_y = float(bin_size)\n    elif isinstance(bin_size, (list, tuple, np.ndarray)) and len(bin_size) == 2:\n        bin_size_x = float(bin_size[0])  # width of pixel\n        bin_size_y = float(bin_size[1])  # height of pixel\n    else:\n        raise ValueError(\n            \"bin_size for ImageMaskLayout must be a float or a 2-element sequence (width, height).\",\n        )\n\n    if bin_size_x &lt;= 0 or bin_size_y &lt;= 0:\n        raise ValueError(\"bin_size components must be positive.\")\n\n    n_rows, n_cols = image_mask.shape\n    self.grid_shape = (n_rows, n_cols)  # Note: (rows, cols) often (y_dim, x_dim)\n    y_edges = np.arange(n_rows + 1) * bin_size_y\n    x_edges = np.arange(n_cols + 1) * bin_size_x\n    self.grid_edges = (y_edges, x_edges)\n    self.dimension_ranges = (\n        (x_edges[0], x_edges[-1]),\n        (y_edges[0], y_edges[-1]),\n    )\n\n    y_centers = (np.arange(n_rows) + 0.5) * bin_size_y\n    x_centers = (np.arange(n_cols) + 0.5) * bin_size_x\n    xv, yv = np.meshgrid(\n        x_centers,\n        y_centers,\n        indexing=\"xy\",\n    )  # x is cols, y is rows\n    full_grid_bin_centers = np.stack(\n        (\n            yv.ravel(),\n            xv.ravel(),\n        ),\n        axis=1,\n    )\n\n    self.active_mask = image_mask\n    self.bin_centers = full_grid_bin_centers[self.active_mask.ravel()]\n    self.connectivity = _create_regular_grid_connectivity_graph(\n        full_grid_bin_centers=full_grid_bin_centers,\n        active_mask_nd=self.active_mask,\n        grid_shape=self.grid_shape,\n        connect_diagonal=connect_diagonal_neighbors,\n    )\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.MaskedGridLayout","title":"MaskedGridLayout","text":"<pre><code>MaskedGridLayout()\n</code></pre> <p>               Bases: <code>_GridMixin</code></p> <p>Layout from a pre-defined N-D boolean mask and explicit grid edges.</p> <p>Allows for precise specification of active bins in an N-dimensional grid by providing the complete grid structure (<code>grid_edges</code>) and a mask (<code>active_mask</code>) that designates which cells of that grid are active. Inherits grid functionalities from <code>_GridMixin</code>.</p> <p>Initialize a MaskedGridLayout engine.</p> Source code in <code>src/neurospatial/layout/engines/masked_grid.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize a MaskedGridLayout engine.\"\"\"\n    self._layout_type_tag = \"MaskedGrid\"\n    self._build_params_used = {}\n    self.bin_centers = np.empty((0, 2), dtype=np.float64)\n    self.connectivity = None\n    self.dimension_ranges = None\n    self.grid_edges = None\n    self.grid_shape = None\n    self.active_mask = None\n    self.bin_size_ = None\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.MaskedGridLayout-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/#neurospatial.layout.MaskedGridLayout.build","title":"build","text":"<pre><code>build(*, active_mask: NDArray[bool_], grid_edges: tuple[NDArray[float64], ...], connect_diagonal_neighbors: bool = True) -&gt; None\n</code></pre> <p>Build the layout from a mask and grid edges.</p> <p>Parameters:</p> Name Type Description Default <code>active_mask</code> <code>NDArray[bool_]</code> <p>N-dimensional boolean array where <code>True</code> indicates an active bin. Its shape must correspond to the number of bins defined by <code>grid_edges</code> (i.e., <code>tuple(len(e)-1 for e in grid_edges)</code>).</p> required <code>grid_edges</code> <code>Tuple[NDArray[float64], ...]</code> <p>A tuple where each element is a 1D NumPy array of bin edge positions for that dimension, defining the full grid structure.</p> required <code>connect_diagonal_neighbors</code> <code>bool</code> <p>If True, connect diagonally adjacent active grid cells.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>active_mask</code> shape does not match <code>grid_edges</code> definition, or if <code>grid_edges</code> are invalid.</p> Source code in <code>src/neurospatial/layout/engines/masked_grid.py</code> <pre><code>@capture_build_params\ndef build(\n    self,\n    *,\n    active_mask: NDArray[np.bool_],  # User's N-D definition mask\n    grid_edges: tuple[NDArray[np.float64], ...],\n    connect_diagonal_neighbors: bool = True,\n) -&gt; None:\n    \"\"\"Build the layout from a mask and grid edges.\n\n    Parameters\n    ----------\n    active_mask : NDArray[np.bool_]\n        N-dimensional boolean array where `True` indicates an active bin.\n        Its shape must correspond to the number of bins defined by `grid_edges`\n        (i.e., `tuple(len(e)-1 for e in grid_edges)`).\n    grid_edges : Tuple[NDArray[np.float64], ...]\n        A tuple where each element is a 1D NumPy array of bin edge\n        positions for that dimension, defining the full grid structure.\n    connect_diagonal_neighbors : bool, default=True\n        If True, connect diagonally adjacent active grid cells.\n\n    Raises\n    ------\n    ValueError\n        If `active_mask` shape does not match `grid_edges` definition,\n        or if `grid_edges` are invalid.\n\n    \"\"\"\n    self.active_mask = active_mask\n    self.grid_edges = grid_edges\n    self.grid_shape = tuple(len(edge) - 1 for edge in grid_edges)\n\n    if self.active_mask.shape != self.grid_shape:\n        raise ValueError(\n            f\"active_mask shape {self.active_mask.shape} must match \"\n            f\"the shape implied by grid_edges {self.grid_shape}.\",\n        )\n\n    # Create full_grid_bin_centers as (N_total_bins, N_dims) array\n    centers_per_dim = [get_centers(edge_dim) for edge_dim in self.grid_edges]\n    mesh_centers_list = np.meshgrid(*centers_per_dim, indexing=\"ij\", sparse=False)\n    full_grid_bin_centers = np.stack(\n        [c.ravel() for c in mesh_centers_list],\n        axis=-1,\n    )\n\n    self.bin_size_ = np.array(\n        [np.diff(edge_dim)[0] for edge_dim in self.grid_edges],\n        dtype=np.float64,\n    )\n\n    self.dimension_ranges = tuple(\n        (edge_dim[0], edge_dim[-1]) for edge_dim in self.grid_edges\n    )\n    self.bin_centers = full_grid_bin_centers[self.active_mask.ravel()]\n\n    self.connectivity = _create_regular_grid_connectivity_graph(\n        full_grid_bin_centers=full_grid_bin_centers,\n        active_mask_nd=self.active_mask,\n        grid_shape=self.grid_shape,\n        connect_diagonal=connect_diagonal_neighbors,\n    )\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.RegularGridLayout","title":"RegularGridLayout","text":"<pre><code>RegularGridLayout()\n</code></pre> <p>               Bases: <code>_GridMixin</code></p> <p>Axis-aligned rectangular N-D grid layout.</p> <p>Discretizes space into a uniform N-dimensional grid. Can infer the active portion of this grid based on provided data samples using occupancy and morphological operations. Inherits grid-based functionalities from <code>_GridMixin</code>.</p> <p>Initialize a RegularGridLayout engine.</p> Source code in <code>src/neurospatial/layout/engines/regular_grid.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize a RegularGridLayout engine.\"\"\"\n    self._layout_type_tag = \"RegularGrid\"\n    self._build_params_used = {}\n    # Initialize all protocol attributes to satisfy type checkers, even if None\n    self.bin_centers = np.empty((0, 0))\n    self.connectivity = None\n    self.dimension_ranges = None\n    self.grid_edges = None\n    self.grid_shape = None\n    self.active_mask = None\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.RegularGridLayout-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/#neurospatial.layout.RegularGridLayout.build","title":"build","text":"<pre><code>build(*, bin_size: float | Sequence[float], dimension_ranges: Sequence[tuple[float, float]] | None = None, data_samples: NDArray[float64] | None = None, add_boundary_bins: bool = False, infer_active_bins: bool = True, dilate: bool = True, fill_holes: bool = True, close_gaps: bool = True, bin_count_threshold: int = 0, connect_diagonal_neighbors: bool = True) -&gt; None\n</code></pre> <p>Build the regular N-D grid layout.</p> <p>Parameters:</p> Name Type Description Default <code>bin_size</code> <code>Union[float, Sequence[float]]</code> <p>Desired size of bins in each dimension.</p> required <code>dimension_ranges</code> <code>Optional[Sequence[Tuple[float, float]]]</code> <p>Explicit <code>[(min_d0, max_d0), ..., (min_dN-1, max_dN-1)]</code> for the grid. If None, range is inferred from <code>data_samples</code>.</p> <code>None</code> <code>data_samples</code> <code>(Optional[NDArray[float64]], shape(n_samples, n_dims))</code> <p>Data used to infer <code>dimension_ranges</code> (if not provided) and/or to infer active bins (if <code>infer_active_bins</code> is True).</p> <code>None</code> <code>add_boundary_bins</code> <code>bool</code> <p>If True, adds one bin on each side of the grid, extending the range.</p> <code>False</code> <code>infer_active_bins</code> <code>bool</code> <p>If True and <code>data_samples</code> are provided, infers active bins based on occupancy and morphological operations.</p> <code>True</code> <code>dilate</code> <code>bool</code> <p>If <code>infer_active_bins</code> is True, dilates the inferred active area.</p> <code>False</code> <code>fill_holes</code> <code>bool</code> <p>If <code>infer_active_bins</code> is True, fills holes in the inferred active area.</p> <code>False</code> <code>close_gaps</code> <code>bool</code> <p>If <code>infer_active_bins</code> is True, closes gaps in the inferred active area.</p> <code>False</code> <code>bin_count_threshold</code> <code>int</code> <p>If <code>infer_active_bins</code> is True, minimum samples in a bin to be considered initially occupied.</p> <code>0</code> <code>connect_diagonal_neighbors</code> <code>bool</code> <p>If True, connects diagonal neighbors in the connectivity graph.</p> <code>True</code> Source code in <code>src/neurospatial/layout/engines/regular_grid.py</code> <pre><code>@capture_build_params\ndef build(\n    self,\n    *,\n    bin_size: float | Sequence[float],\n    dimension_ranges: Sequence[tuple[float, float]] | None = None,\n    data_samples: NDArray[np.float64] | None = None,\n    add_boundary_bins: bool = False,\n    infer_active_bins: bool = True,\n    dilate: bool = True,\n    fill_holes: bool = True,\n    close_gaps: bool = True,\n    bin_count_threshold: int = 0,\n    connect_diagonal_neighbors: bool = True,\n) -&gt; None:\n    \"\"\"Build the regular N-D grid layout.\n\n    Parameters\n    ----------\n    bin_size : Union[float, Sequence[float]]\n        Desired size of bins in each dimension.\n    dimension_ranges : Optional[Sequence[Tuple[float, float]]], optional\n        Explicit `[(min_d0, max_d0), ..., (min_dN-1, max_dN-1)]` for the grid.\n        If None, range is inferred from `data_samples`.\n    data_samples : Optional[NDArray[np.float64]], shape (n_samples, n_dims), optional\n        Data used to infer `dimension_ranges` (if not provided) and/or to\n        infer active bins (if `infer_active_bins` is True).\n    add_boundary_bins : bool, default=False\n        If True, adds one bin on each side of the grid, extending the range.\n    infer_active_bins : bool, default=True\n        If True and `data_samples` are provided, infers active bins based\n        on occupancy and morphological operations.\n    dilate : bool, default=False\n        If `infer_active_bins` is True, dilates the inferred active area.\n    fill_holes : bool, default=False\n        If `infer_active_bins` is True, fills holes in the inferred active area.\n    close_gaps : bool, default=False\n        If `infer_active_bins` is True, closes gaps in the inferred active area.\n    bin_count_threshold : int, default=0\n        If `infer_active_bins` is True, minimum samples in a bin to be\n        considered initially occupied.\n    connect_diagonal_neighbors : bool, default=True\n        If True, connects diagonal neighbors in the connectivity graph.\n\n    \"\"\"\n\n    # --- Determine dimension_ranges if not provided ---\n    if dimension_ranges is not None:\n        self.dimension_ranges = dimension_ranges\n    else:\n        # Infer ranges from data_samples\n        if data_samples is None:\n            raise ValueError(\n                \"dimension_ranges must be provided if data_samples is None.\",\n            )\n\n        buffer_for_inference = (\n            bin_size / 2.0\n            if isinstance(bin_size, (float, int, np.number))\n            else bin_size\n        )\n        # Infer ranges from data_samples\n        self.dimension_ranges = _infer_dimension_ranges_from_samples(\n            data_samples=data_samples,\n            buffer_around_data=buffer_for_inference,\n        )\n\n    (\n        self.grid_edges,\n        full_grid_bin_centers,\n        self.grid_shape,\n    ) = _create_regular_grid(\n        data_samples=data_samples,\n        bin_size=bin_size,\n        dimension_range=self.dimension_ranges,\n        add_boundary_bins=add_boundary_bins,\n    )\n\n    if infer_active_bins and data_samples is not None:\n        self.active_mask = _infer_active_bins_from_regular_grid(\n            data_samples=data_samples,\n            edges=self.grid_edges,\n            close_gaps=close_gaps,\n            fill_holes=fill_holes,\n            dilate=dilate,\n            bin_count_threshold=bin_count_threshold,\n            boundary_exists=add_boundary_bins,\n        )\n    else:\n        # No data_samples or not inferring active bins, use all bins\n        self.active_mask = np.ones(self.grid_shape, dtype=bool)\n\n    if not np.any(self.active_mask):\n        # Build comprehensive error message with diagnostics\n        error_lines = [\"No active bins found after filtering.\"]\n        error_lines.append(\"\")  # Blank line\n\n        # Add diagnostic information\n        error_lines.append(\"Diagnostics:\")\n\n        # Show data range\n        if data_samples is not None:\n            data_clean = data_samples[~np.any(np.isnan(data_samples), axis=1)]\n            if len(data_clean) &gt; 0:\n                # Convert to Python native types for cleaner display\n                data_min = data_clean.min(axis=0).tolist()\n                data_max = data_clean.max(axis=0).tolist()\n                data_range = (\n                    data_clean.max(axis=0) - data_clean.min(axis=0)\n                ).tolist()\n                error_lines.append(\n                    f\"  Data range: {list(zip(data_min, data_max, strict=True))}\"\n                )\n                error_lines.append(f\"  Data extent: {data_range}\")\n                error_lines.append(f\"  Number of samples: {len(data_clean)}\")\n            else:\n                # All data is NaN - inform user clearly\n                error_lines.append(\"  Data samples: All NaN (no valid data)\")\n                error_lines.append(\n                    f\"  Number of samples (including NaN): {len(data_samples)}\"\n                )\n\n        # Show grid information\n        if isinstance(bin_size, (float, int, np.number)):\n            bin_size_str = f\"{bin_size}\"\n        else:\n            bin_size_str = f\"{list(bin_size)}\"\n        error_lines.append(f\"  bin_size: {bin_size_str}\")\n        error_lines.append(f\"  Grid shape: {self.grid_shape}\")\n        error_lines.append(f\"  Total bins in grid: {np.prod(self.grid_shape)}\")\n\n        # Show filtering parameters\n        error_lines.append(f\"  bin_count_threshold: {bin_count_threshold}\")\n        error_lines.append(\n            f\"  Morphological operations: dilate={dilate}, fill_holes={fill_holes}, close_gaps={close_gaps}\"\n        )\n        error_lines.append(\"\")  # Blank line\n\n        # Explain WHY this happened (common causes)\n        error_lines.append(\"Common causes:\")\n        error_lines.append(\"  1. bin_size is too large relative to your data range\")\n        error_lines.append(\n            \"  2. bin_count_threshold is too high (no bins have enough samples)\"\n        )\n        error_lines.append(\n            \"  3. Data is too sparse and morphological operations are disabled\"\n        )\n        error_lines.append(\"\")  # Blank line\n\n        # Explain HOW to fix (specific suggestions)\n        error_lines.append(\"Suggestions to fix:\")\n        error_lines.append(\"  1. Reduce bin_size to create more bins\")\n        error_lines.append(\n            \"  2. Reduce bin_count_threshold (try 0 for initial testing)\"\n        )\n        error_lines.append(\n            \"  3. Enable morphological operations (dilate=True, fill_holes=True, close_gaps=True)\"\n        )\n        error_lines.append(\n            \"  4. Check that data_samples covers the expected spatial range\"\n        )\n\n        raise ValueError(\"\\n\".join(error_lines))\n\n    self.bin_centers = full_grid_bin_centers[self.active_mask.ravel()]\n    self.connectivity = _create_regular_grid_connectivity_graph(\n        full_grid_bin_centers=full_grid_bin_centers,\n        active_mask_nd=self.active_mask,\n        grid_shape=self.grid_shape,\n        connect_diagonal=connect_diagonal_neighbors,\n    )\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.ShapelyPolygonLayout","title":"ShapelyPolygonLayout","text":"<pre><code>ShapelyPolygonLayout()\n</code></pre> <p>               Bases: <code>_GridMixin</code></p> <p>2D grid layout masked by a Shapely Polygon.</p> <p>Creates a regular grid based on the polygon's bounds and specified <code>bin_size</code>. Only grid cells whose centers are contained within the polygon are considered active. Inherits grid functionalities from <code>_GridMixin</code>.</p> <p>Initialize a ShapelyPolygonLayout engine.</p> Source code in <code>src/neurospatial/layout/engines/shapely_polygon.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize a ShapelyPolygonLayout engine.\"\"\"\n    self._layout_type_tag = \"ShapelyPolygon\"\n    self._build_params_used = {}\n    self.bin_centers = np.empty((0, 2), dtype=np.float64)  # 2D Layout\n    self.connectivity = None\n    self.dimension_ranges = None\n    self.grid_edges = None\n    self.grid_shape = None\n    self.active_mask = None\n    self.polygon_definition_ = None\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.ShapelyPolygonLayout-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/#neurospatial.layout.ShapelyPolygonLayout.build","title":"build","text":"<pre><code>build(*, polygon: Polygon, bin_size: float | Sequence[float], connect_diagonal_neighbors: bool = True) -&gt; None\n</code></pre> <p>Build the Shapely Polygon masked grid layout.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>The Shapely Polygon object that defines the boundary of the active area.</p> required <code>bin_size</code> <code>Union[float, Sequence[float]]</code> <p>The side length(s) of the grid cells. If float, cells are square (or cubic). If sequence (length 2 for 2D), specifies (width, height).</p> required <code>connect_diagonal_neighbors</code> <code>bool</code> <p>If True, connect diagonally adjacent active grid cells in the <code>connectivity</code>.</p> <code>True</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the 'shapely' package is not installed (should be caught by SHAPELY_AVAILABLE check at class definition).</p> <code>TypeError</code> <p>If <code>polygon</code> is not a Shapely Polygon.</p> Source code in <code>src/neurospatial/layout/engines/shapely_polygon.py</code> <pre><code>@capture_build_params\ndef build(\n    self,\n    *,\n    polygon: Polygon,\n    bin_size: float | Sequence[float],\n    connect_diagonal_neighbors: bool = True,\n) -&gt; None:\n    \"\"\"Build the Shapely Polygon masked grid layout.\n\n    Parameters\n    ----------\n    polygon : shapely.geometry.Polygon\n        The Shapely Polygon object that defines the boundary of the\n        active area.\n    bin_size : Union[float, Sequence[float]]\n        The side length(s) of the grid cells. If float, cells are\n        square (or cubic). If sequence (length 2 for 2D), specifies\n        (width, height).\n    connect_diagonal_neighbors : bool, default=True\n        If True, connect diagonally adjacent active grid cells in the\n        `connectivity`.\n\n    Raises\n    ------\n    RuntimeError\n        If the 'shapely' package is not installed (should be caught by\n        SHAPELY_AVAILABLE check at class definition).\n    TypeError\n        If `polygon` is not a Shapely Polygon.\n\n    \"\"\"\n    if not isinstance(polygon, Polygon):\n        raise TypeError(\"polygon must be a Shapely Polygon object.\")\n\n    self.polygon_definition_ = polygon\n    minx, miny, maxx, maxy = polygon.bounds\n    self.dimension_ranges = [(minx, maxx), (miny, maxy)]\n\n    (\n        self.grid_edges,\n        full_grid_bin_centers,\n        self.grid_shape,\n    ) = _create_regular_grid(\n        data_samples=None,\n        bin_size=bin_size,\n        dimension_range=self.dimension_ranges,\n        add_boundary_bins=False,\n    )\n\n    # 1. Intrinsic mask from Shapely\n    pts_to_check = (\n        full_grid_bin_centers[:, :2]\n        if full_grid_bin_centers.shape[0] &gt; 0\n        else np.empty((0, 2))\n    )\n    shapely_mask_flat = (\n        shapely.contains(polygon, shapely.points(pts_to_check))\n        if pts_to_check.shape[0] &gt; 0\n        else np.array([], dtype=bool)\n    )\n    self.active_mask = shapely_mask_flat.reshape(self.grid_shape)\n\n    self.bin_centers = full_grid_bin_centers[self.active_mask.ravel()]\n    self.connectivity = _create_regular_grid_connectivity_graph(\n        full_grid_bin_centers=full_grid_bin_centers,\n        active_mask_nd=self.active_mask,\n        grid_shape=self.grid_shape,\n        connect_diagonal=connect_diagonal_neighbors,\n    )\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.ShapelyPolygonLayout.plot","title":"plot","text":"<pre><code>plot(ax: Axes | None = None, figsize=(7, 7), cmap: str = 'bone_r', alpha: float = 0.7, show_connectivity: bool = True, node_size: float = 20, node_color: str = 'blue') -&gt; matplotlib.axes.Axes\n</code></pre> <p>Plot the ShapelyPolygon layout.</p> <p>Displays the active grid cells and overlays the defining polygon. Inherits base grid plotting from <code>_GridMixin.plot</code> and adds polygon visualization.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Axes to plot on. If None, new figure and axes are created.</p> <code>None</code> <code>figsize</code> <code>Tuple[float, float]</code> <p>Size of the figure if <code>ax</code> is None.</p> <code>(7, 7)</code> <code>cmap</code> <code>str</code> <p>Colormap for the grid visualization.</p> <code>\"bone_r\"</code> <code>alpha</code> <code>float</code> <p>Transparency level for the grid.</p> <code>0.7</code> <code>show_connectivity</code> <code>bool</code> <p>Whether to show connections between bins.</p> <code>True</code> <code>node_size</code> <code>float</code> <p>Size of nodes in the connectivity graph.</p> <code>20</code> <code>node_color</code> <code>str</code> <p>Color of nodes in the connectivity graph.</p> <code>\"blue\"</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the layout is plotted.</p> Source code in <code>src/neurospatial/layout/engines/shapely_polygon.py</code> <pre><code>def plot(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    figsize=(7, 7),\n    cmap: str = \"bone_r\",\n    alpha: float = 0.7,\n    show_connectivity: bool = True,\n    node_size: float = 20,\n    node_color: str = \"blue\",\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot the ShapelyPolygon layout.\n\n    Displays the active grid cells and overlays the defining polygon.\n    Inherits base grid plotting from `_GridMixin.plot` and adds\n    polygon visualization.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        Axes to plot on. If None, new figure and axes are created.\n    figsize : Tuple[float, float], default=(7, 7)\n        Size of the figure if `ax` is None.\n    cmap : str, default=\"bone_r\"\n        Colormap for the grid visualization.\n    alpha : float, default=0.7\n        Transparency level for the grid.\n    show_connectivity : bool, default=True\n        Whether to show connections between bins.\n    node_size : float, default=20\n        Size of nodes in the connectivity graph.\n    node_color : str, default=\"blue\"\n        Color of nodes in the connectivity graph.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the layout is plotted.\n\n    \"\"\"\n    if (\n        self.bin_centers is None\n        or self.grid_edges is None\n        or self.active_mask is None\n        or self.grid_shape is None\n        or self.connectivity is None\n    ):\n        raise RuntimeError(\"Layout not built. Call `build` first.\")\n\n    is_2d_grid = len(self.grid_shape) == 2 and len(self.grid_edges) == 2\n\n    if is_2d_grid:\n        if ax is None:\n            _, ax = plt.subplots(figsize=figsize)\n        ax.pcolormesh(\n            self.grid_edges[0],\n            self.grid_edges[1],\n            self.active_mask.T,\n            cmap=cmap,\n            alpha=alpha,\n            shading=\"auto\",\n        )\n        ax.set_xticks(self.grid_edges[0])\n        ax.set_yticks(self.grid_edges[1])\n        ax.grid(True, ls=\"-\", lw=0.5, c=\"gray\")\n        ax.set_aspect(\"equal\")\n        ax.set_title(f\"{self._layout_type_tag} (2D Grid)\")\n        ax.set_xlabel(\"Dimension 0\")\n        ax.set_ylabel(\"Dimension 1\")\n        if self.dimension_ranges:\n            ax.set_xlim(self.dimension_ranges[0])\n            ax.set_ylim(self.dimension_ranges[1])\n\n        if show_connectivity:\n            node_position = nx.get_node_attributes(self.connectivity, \"pos\")\n            nx.draw_networkx_nodes(\n                self.connectivity,\n                node_position,\n                ax=ax,\n                node_size=node_size,\n                node_color=node_color,\n            )\n            for node_id1, node_id2 in self.connectivity.edges:\n                pos = np.stack((node_position[node_id1], node_position[node_id2]))\n                ax.plot(pos[:, 0], pos[:, 1], color=\"black\", zorder=-1)\n\n        # Plot polygon\n        poly_patch_kwargs = {\n            \"alpha\": 0.3,\n            \"fc\": \"gray\",\n            \"ec\": \"black\",\n        }\n        if hasattr(self.polygon_definition_, \"geoms\"):  # MultiPolygon\n            for geom in self.polygon_definition_.geoms:\n                if hasattr(geom, \"exterior\"):\n                    x, y = geom.exterior.xy\n                    ax.fill(x, y, **poly_patch_kwargs)\n        elif hasattr(self.polygon_definition_, \"exterior\"):  # Polygon\n            x, y = self.polygon_definition_.exterior.xy\n            ax.fill(x, y, **poly_patch_kwargs)\n\n        return ax\n    raise NotImplementedError(\n        \"Plotting for non-2D grid layouts is not implemented yet.\",\n    )\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.TriangularMeshLayout","title":"TriangularMeshLayout","text":"<pre><code>TriangularMeshLayout()\n</code></pre> <p>A LayoutEngine that builds a triangular mesh over interior points (auto-generated) clipped to a boundary polygon. Each triangle whose centroid lies inside the polygon is kept as an active bin. Connectivity by shared faces.</p> Source code in <code>src/neurospatial/layout/engines/triangular_mesh.py</code> <pre><code>def __init__(self):\n    self.bin_centers = np.empty((0, 2), dtype=float)\n    self.connectivity = nx.Graph()\n    self.dimension_ranges = None\n    self.grid_edges = ()  # For non-grid layouts, this is typically empty\n    self.grid_shape = None\n    self.active_mask = None  # Will be updated in build\n    self._build_params_used = {}\n\n    self._full_delaunay_tri = None\n    self._original_simplex_to_active_idx_map = None\n    self._active_original_simplex_indices = None\n    self._boundary_polygon_stored = None\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.TriangularMeshLayout-attributes","title":"Attributes","text":""},{"location":"api/neurospatial/layout/#neurospatial.layout.TriangularMeshLayout.is_1d","title":"is_1d  <code>property</code>","text":"<pre><code>is_1d: bool\n</code></pre> <p>Always False, as this is a 2D mesh layout.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Always False, indicating a 2D layout.</p>"},{"location":"api/neurospatial/layout/#neurospatial.layout.TriangularMeshLayout-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/#neurospatial.layout.TriangularMeshLayout.build","title":"build","text":"<pre><code>build(boundary_polygon: Polygon, point_spacing: float) -&gt; None\n</code></pre> <p>Build the triangular mesh layout.</p> <p>Parameters:</p> Name Type Description Default <code>boundary_polygon</code> <code>Polygon</code> <p>The polygon defining the boundary. Triangles with centroids outside this polygon are discarded.</p> required <code>point_spacing</code> <code>float</code> <p>Desired spacing (in same units as polygon) between generated sample points used for triangulation.</p> required Source code in <code>src/neurospatial/layout/engines/triangular_mesh.py</code> <pre><code>def build(self, boundary_polygon: Polygon, point_spacing: float) -&gt; None:\n    \"\"\"Build the triangular mesh layout.\n\n    Parameters\n    ----------\n    boundary_polygon : shapely.geometry.Polygon\n        The polygon defining the boundary. Triangles with centroids\n        outside this polygon are discarded.\n    point_spacing : float\n        Desired spacing (in same units as polygon) between generated sample points\n        used for triangulation.\n\n    \"\"\"\n    if not isinstance(boundary_polygon, Polygon):\n        raise TypeError(\"boundary_polygon must be a Shapely Polygon.\")\n    if boundary_polygon.is_empty:\n        raise ValueError(\"boundary_polygon cannot be empty.\")\n    if boundary_polygon.geom_type == \"MultiPolygon\":\n        raise ValueError(\n            \"MultiPolygon boundaries are not directly supported. \"\n            \"Please provide a single Polygon component.\",\n        )\n    if point_spacing &lt;= 0:\n        raise ValueError(f\"point_spacing must be positive, got {point_spacing}.\")\n\n    # Store build parameters.\n    # For boundary_polygon, store exterior and interior coords for better serialization.\n    # Note: This simple serialization of polygon might not capture all Shapely Polygon features perfectly.\n    boundary_exterior_coords = list(boundary_polygon.exterior.coords)\n    boundary_interior_coords_list = [\n        list(interior.coords) for interior in boundary_polygon.interiors\n    ]\n    self._build_params_used = {\n        \"boundary_exterior_coords\": boundary_exterior_coords,\n        \"boundary_interior_coords_list\": boundary_interior_coords_list,\n        \"point_spacing\": float(point_spacing),\n    }\n    self._boundary_polygon_stored = (\n        boundary_polygon  # Store the actual object for use\n    )\n\n    # 1. Generate sample points for triangulation\n    sample_points = _generate_interior_points_for_mesh(\n        boundary_polygon,\n        point_spacing,\n    )\n    if sample_points.shape[0] &lt; 3:  # Delaunay needs at least N+1 points in N-D\n        raise ValueError(\n            f\"Not enough interior sample points ({sample_points.shape[0]}) generated \"\n            \"to form any triangle. Try decreasing point_spacing or ensuring \"\n            \"the polygon is large enough relative to the spacing.\",\n        )\n    exterior_coords = _sample_polygon_boundary(boundary_polygon, point_spacing)\n    # 4) Stack the interior grid points with the boundary vertices.\n    if sample_points.size == 0:\n        sample_points = exterior_coords.copy()\n    else:\n        sample_points = np.vstack([sample_points, exterior_coords])\n\n    # 2. Perform Delaunay triangulation\n    self._full_delaunay_tri = _triangulate_points(sample_points)\n\n    # 3. Filter active simplices (triangles)\n    active_original_indices, all_centroids = _filter_active_simplices_by_centroid(\n        self._full_delaunay_tri,\n        boundary_polygon,\n    )\n    n_total_delaunay_triangles = self._full_delaunay_tri.simplices.shape[0]\n\n    if active_original_indices.size == 0:\n        raise ValueError(\n            \"No triangles found with centroids inside the boundary polygon. \"\n            \"Check boundary_polygon shape, point_spacing, or point generation strategy.\",\n        )\n\n    self._active_original_simplex_indices = active_original_indices\n\n    # 4. Create mapping from original Delaunay simplex index to active triangle index\n    self._original_simplex_to_active_idx_map = {\n        orig_idx: active_idx\n        for active_idx, orig_idx in enumerate(active_original_indices)\n    }\n\n    # 5. Populate core attributes for active triangles\n    self.bin_centers = all_centroids[active_original_indices]\n\n    # 6. Build connectivity graph for active triangles\n    self.connectivity = _build_mesh_connectivity_graph(\n        active_original_indices,\n        all_centroids,\n        self._original_simplex_to_active_idx_map,\n        self._full_delaunay_tri,\n    )\n\n    # 7. Compute dimension_ranges based on active bin centers\n    self.dimension_ranges = _compute_mesh_dimension_ranges(self.bin_centers)\n\n    # 8. Set grid-related attributes for protocol conformance\n    # The \"conceptual grid\" here is the list of all Delaunay triangles.\n    self.grid_shape = (n_total_delaunay_triangles,)\n    self.active_mask = np.zeros(n_total_delaunay_triangles, dtype=bool)\n    self.active_mask[active_original_indices] = True\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.TriangularMeshLayout.point_to_bin_index","title":"point_to_bin_index","text":"<pre><code>point_to_bin_index(points: NDArray[float64]) -&gt; NDArray[np.int_]\n</code></pre> <p>Map each 2D point to an active triangle index, or -1 if outside.</p> <p>Uses Delaunay.find_simplex() \u2192 original-simplex index \u2192 active-triangle index via a fast lookup array. Then enforces that the point itself must lie inside (or on) the boundary polygon.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>(NDArray[float64], shape(n_points, 2))</code> <p>2D points to map to triangle indices.</p> required <p>Returns:</p> Type Description <code>NDArray[int_]</code> <p>Each entry is in [0..n_active-1] or -1 if outside.</p> Source code in <code>src/neurospatial/layout/engines/triangular_mesh.py</code> <pre><code>def point_to_bin_index(self, points: NDArray[np.float64]) -&gt; NDArray[np.int_]:\n    \"\"\"Map each 2D point to an active triangle index, or -1 if outside.\n\n    Uses Delaunay.find_simplex() \u2192 original-simplex index \u2192 active-triangle index via\n    a fast lookup array. Then enforces that the point itself must lie inside (or on)\n    the boundary polygon.\n\n    Parameters\n    ----------\n    points : NDArray[np.float64], shape (n_points, 2)\n        2D points to map to triangle indices.\n\n    Returns\n    -------\n    NDArray[np.int_]\n        Each entry is in [0..n_active-1] or -1 if outside.\n\n    \"\"\"\n    if (\n        self._full_delaunay_tri is None\n        or self._original_simplex_to_active_idx_map is None\n    ):\n        raise RuntimeError(\"TriangularMeshLayout is not built. Call build() first.\")\n\n    pts2d = np.atleast_2d(points).astype(np.float64, copy=False)\n    if pts2d.ndim != 2 or pts2d.shape[1] != 2:\n        raise ValueError(f\"Expected points of shape (M, 2), got {pts2d.shape}.\")\n\n    # 1) Find which Delaunay simplex each point falls into (-1 if outside hull)\n    orig_simplices = self._full_delaunay_tri.find_simplex(pts2d)\n\n    # 2) Build a 1D lookup array once, mapping original simplex idx -&gt; active idx\n    n_total = self._full_delaunay_tri.simplices.shape[0]\n    orig2active_arr = np.full(n_total, -1, dtype=int)\n    for orig_idx, active_idx in self._original_simplex_to_active_idx_map.items():\n        orig2active_arr[orig_idx] = active_idx\n\n    # 3) Initialize result array to -1\n    active_triangle_idxs = np.full(orig_simplices.shape, -1, dtype=int)\n\n    # 4) Wherever orig_simplices != -1, do a vectorized assignment\n    valid_mask = orig_simplices != -1\n    if np.any(valid_mask):\n        found_orig = orig_simplices[valid_mask]\n        active_triangle_idxs[valid_mask] = orig2active_arr[found_orig]\n\n        # 5) Now ensure each point is itself inside (or on) the boundary\n        if self._boundary_polygon_stored is not None:\n            xcoords = pts2d[valid_mask, 0]\n            ycoords = pts2d[valid_mask, 1]\n            on_or_inside = shapely.contains_xy(\n                self._boundary_polygon_stored,\n                xcoords,\n                ycoords,\n            )\n            idxs = np.flatnonzero(valid_mask)\n            for local_i, keep in enumerate(on_or_inside):\n                if not keep:\n                    active_triangle_idxs[idxs[local_i]] = -1\n\n    return active_triangle_idxs\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.TriangularMeshLayout.plot","title":"plot","text":"<pre><code>plot(ax: Axes | None = None, show_triangles: bool = True, show_centroids: bool = True, show_connectivity: bool = True, show_boundary: bool = True, triangle_kwargs: dict[str, Any] | None = None, centroid_kwargs: dict[str, Any] | None = None, connectivity_kwargs: dict[str, Any] | None = None, boundary_kwargs: dict[str, Any] | None = None) -&gt; matplotlib.axes.Axes\n</code></pre> <p>Plot the triangular mesh layout.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Axes to plot on. If None, a new figure and axes are created.</p> <code>None</code> <code>show_triangles</code> <code>bool</code> <p>Whether to draw the filled active triangles. Defaults to True.</p> <code>True</code> <code>show_centroids</code> <code>bool</code> <p>Whether to draw the centroids of active triangles. Defaults to True.</p> <code>True</code> <code>show_connectivity</code> <code>bool</code> <p>Whether to draw edges of the connectivity graph. Defaults to True.</p> <code>True</code> <code>show_boundary</code> <code>bool</code> <p>Whether to draw the original boundary polygon. Defaults to True.</p> <code>True</code> <code>triangle_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments for <code>matplotlib.collections.PatchCollection</code> of triangles.</p> <code>None</code> <code>centroid_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments for <code>ax.scatter</code> plotting centroids.</p> <code>None</code> <code>connectivity_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments for plotting connectivity edges.</p> <code>None</code> <code>boundary_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments for plotting the boundary polygon.</p> <code>None</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the layout was plotted.</p> Source code in <code>src/neurospatial/layout/engines/triangular_mesh.py</code> <pre><code>def plot(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    show_triangles: bool = True,\n    show_centroids: bool = True,\n    show_connectivity: bool = True,\n    show_boundary: bool = True,\n    triangle_kwargs: dict[str, Any] | None = None,\n    centroid_kwargs: dict[str, Any] | None = None,\n    connectivity_kwargs: dict[str, Any] | None = None,\n    boundary_kwargs: dict[str, Any] | None = None,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot the triangular mesh layout.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        Axes to plot on. If None, a new figure and axes are created.\n    show_triangles : bool, optional\n        Whether to draw the filled active triangles. Defaults to True.\n    show_centroids : bool, optional\n        Whether to draw the centroids of active triangles. Defaults to True.\n    show_connectivity : bool, optional\n        Whether to draw edges of the connectivity graph. Defaults to True.\n    show_boundary : bool, optional\n        Whether to draw the original boundary polygon. Defaults to True.\n    triangle_kwargs : Optional[Dict[str, Any]], optional\n        Keyword arguments for `matplotlib.collections.PatchCollection` of triangles.\n    centroid_kwargs : Optional[Dict[str, Any]], optional\n        Keyword arguments for `ax.scatter` plotting centroids.\n    connectivity_kwargs : Optional[Dict[str, Any]], optional\n        Keyword arguments for plotting connectivity edges.\n    boundary_kwargs : Optional[Dict[str, Any]], optional\n        Keyword arguments for plotting the boundary polygon.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the layout was plotted.\n\n    \"\"\"\n    if (\n        self._full_delaunay_tri is None\n        or self._active_original_simplex_indices is None\n        or self.bin_centers is None\n        or self.connectivity is None\n        or self.dimension_ranges is None\n    ):\n        raise RuntimeError(\"TriangularMeshLayout is not built. Call build() first.\")\n\n    if ax is None:\n        _, ax = plt.subplots(figsize=(7, 7))  # Default figsize\n\n    # Default kwargs\n    _triangle_kwargs = {\n        \"alpha\": 0.4,\n        \"facecolor\": \"lightblue\",\n        \"edgecolor\": \"gray\",\n        \"linewidth\": 0.5,\n    }\n    if triangle_kwargs:\n        _triangle_kwargs.update(triangle_kwargs)\n\n    _centroid_kwargs = {\"color\": \"blue\", \"s\": 10, \"zorder\": 3}\n    if centroid_kwargs:\n        _centroid_kwargs.update(centroid_kwargs)\n\n    _connectivity_kwargs = {\n        \"color\": \"black\",\n        \"alpha\": 0.5,\n        \"linewidth\": 0.75,\n        \"zorder\": 2,\n    }\n    if connectivity_kwargs:\n        _connectivity_kwargs.update(connectivity_kwargs)\n\n    _boundary_kwargs = {\n        \"color\": \"black\",\n        \"linewidth\": 1.5,\n        \"linestyle\": \"--\",\n        \"zorder\": 4,\n    }\n    if boundary_kwargs:\n        _boundary_kwargs.update(boundary_kwargs)\n\n    # Plot boundary polygon\n    if show_boundary and self._boundary_polygon_stored:\n        xb, yb = self._boundary_polygon_stored.exterior.xy\n        # Use cast to work around matplotlib stub limitations\n        plot_func = cast(\"Any\", ax.plot)\n        plot_func(xb, yb, label=\"Boundary\", **_boundary_kwargs)\n        for interior in self._boundary_polygon_stored.interiors:\n            xbi, ybi = interior.xy\n            plot_func(xbi, ybi, **_boundary_kwargs)\n\n    # Plot active triangles\n    if show_triangles:\n        patches: list[MplPolygon] = []\n        mesh_points = self._full_delaunay_tri.points\n        active_simplices_vertices = mesh_points[\n            self._full_delaunay_tri.simplices[self._active_original_simplex_indices]\n        ]\n\n        for vertices in active_simplices_vertices:  # Iterate over (n_active, 3, 2)\n            patches.append(MplPolygon(vertices, closed=True))\n\n        # Use cast to work around matplotlib stub limitations\n        pc_constructor = cast(\"Any\", PatchCollection)\n        pc = pc_constructor(patches, **_triangle_kwargs)\n        ax.add_collection(pc)\n\n    # Plot centroids (which are self.bin_centers)\n    if show_centroids and self.bin_centers.shape[0] &gt; 0:\n        # Use cast to work around matplotlib stub limitations\n        scatter_func = cast(\"Any\", ax.scatter)\n        scatter_func(\n            self.bin_centers[:, 0],\n            self.bin_centers[:, 1],\n            **_centroid_kwargs,\n        )\n\n    # Plot connectivity edges\n    if show_connectivity:\n        # Use cast to work around matplotlib stub limitations\n        plot_func2 = cast(\"Any\", ax.plot)\n        for u, v in self.connectivity.edges():\n            pos_u = self.connectivity.nodes[u][\"pos\"]\n            pos_v = self.connectivity.nodes[v][\"pos\"]\n            plot_func2(\n                [pos_u[0], pos_v[0]],\n                [pos_u[1], pos_v[1]],\n                **_connectivity_kwargs,\n            )\n\n    ax.set_aspect(\"equal\", adjustable=\"box\")\n    ax.set_xlim(self.dimension_ranges[0])\n    ax.set_ylim(self.dimension_ranges[1])\n    ax.set_xlabel(\"X coordinate\")\n    ax.set_ylabel(\"Y coordinate\")\n    ax.set_title(self._layout_type_tag)\n    if (\n        show_boundary and self._boundary_polygon_stored\n    ):  # Add legend if boundary shown\n        ax.legend()\n    return ax\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.TriangularMeshLayout.bin_sizes","title":"bin_sizes","text":"<pre><code>bin_sizes() -&gt; NDArray[np.float64]\n</code></pre> <p>Return the N-dimensional volume of each active N-simplex (bin).</p> <p>For 2D, this is area. For 3D, this is volume, and so on. The volume of an N-simplex with vertices v0, v1, ..., vn is calculated as: V = (1 / n!) * |det([v1-v0, v2-v0, ..., vn-v0])| where n is the number of dimensions.</p> <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>Array of N-dimensional volumes, shape (n_active_simplices,).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the layout is not built (e.g., <code>_full_delaunay_tri</code> or <code>_active_original_simplex_indices</code> is None).</p> <code>ValueError</code> <p>If the dimensionality is less than 1.</p> Source code in <code>src/neurospatial/layout/engines/triangular_mesh.py</code> <pre><code>def bin_sizes(self) -&gt; NDArray[np.float64]:\n    \"\"\"Return the N-dimensional volume of each active N-simplex (bin).\n\n    For 2D, this is area. For 3D, this is volume, and so on.\n    The volume of an N-simplex with vertices v0, v1, ..., vn is calculated as:\n    V = (1 / n!) * |det([v1-v0, v2-v0, ..., vn-v0])|\n    where n is the number of dimensions.\n\n    Returns\n    -------\n    NDArray[np.float64]\n        Array of N-dimensional volumes, shape (n_active_simplices,).\n\n    Raises\n    ------\n    RuntimeError\n        If the layout is not built (e.g., `_full_delaunay_tri` or\n        `_active_original_simplex_indices` is None).\n    ValueError\n        If the dimensionality is less than 1.\n\n    \"\"\"\n    if (\n        self._full_delaunay_tri is None\n        or self._active_original_simplex_indices is None\n    ):  # pragma: no cover\n        raise RuntimeError(\"TriangularMeshLayout is not built. Call build() first.\")\n\n    # Get the vertices of all active N-simplices\n    # .points has shape (total_points, n_dim)\n    # .simplices has shape (total_simplices, n_dim + 1)\n    all_mesh_points = self._full_delaunay_tri.points\n    active_simplices_vertex_indices = self._full_delaunay_tri.simplices[\n        self._active_original_simplex_indices\n    ]\n\n    if active_simplices_vertex_indices.shape[0] == 0:\n        return np.array([], dtype=float)  # No active simplices\n\n    # nsimplex_vertices will have shape:\n    # (num_active_simplices, num_vertices_per_simplex, n_dim)\n    nsimplex_vertices = all_mesh_points[active_simplices_vertex_indices]\n\n    n_dim = all_mesh_points.shape[1]\n\n    if n_dim == 1:\n        # For 1D simplices (line segments), volume is length\n        # Vertices are (n_active, 2, 1)\n        # v0 is (n_active, 1), v1 is (n_active, 1)\n        v0 = nsimplex_vertices[:, 0, :]  # First vertex of each simplex\n        v1 = nsimplex_vertices[:, 1, :]  # Second vertex of each simplex\n        lengths = np.abs(v1 - v0).squeeze(axis=-1)\n        return np.asarray(lengths, dtype=np.float64)\n\n    # Select one vertex from each simplex as the origin (v0)\n    # v0 will have shape (num_active_simplices, n_dim)\n    v0 = nsimplex_vertices[:, 0, :]\n\n    # Create vectors from v0 to all other vertices (v1-v0, v2-v0, ..., vn-v0)\n    # These vectors form the rows (or columns) of the matrix for the determinant.\n    # nsimplex_vertices[:, 1:, :] has shape (n_active, n_dim, n_dim)\n    # v0[:, np.newaxis, :] broadcasts v0 to match for subtraction\n    # matrix_for_determinant will have shape (n_active, n_dim, n_dim)\n    matrix_for_determinant = nsimplex_vertices[:, 1:, :] - v0[:, np.newaxis, :]\n\n    # Calculate the determinant for each simplex's matrix\n    # np.linalg.det operates on the last two axes by default.\n    determinants = np.linalg.det(matrix_for_determinant)\n\n    # Volume = abs(determinant) / n!\n    n_factorial = float(math.factorial(n_dim))\n    volumes = np.abs(determinants) / n_factorial\n\n    return np.asarray(volumes, dtype=np.float64)\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/#neurospatial.layout.create_layout","title":"create_layout","text":"<pre><code>create_layout(kind: str, **kwargs) -&gt; LayoutEngine\n</code></pre> <p>Factory for creating and building a spatial-layout engine.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str</code> <p>Case-insensitive name of the layout engine to create (e.g., \"RegularGrid\", \"Hexagonal\", \"Graph\", etc.).</p> required <code>**kwargs</code> <code>any</code> <p>Parameters passed to the chosen engine\u2019s <code>build(...)</code> method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>LayoutEngine</code> <p>A fully constructed layout engine.</p> <p>Raises:</p> Type Description <code>ValueError</code> <ul> <li>If <code>kind</code> is not one of the available layouts.</li> <li>If any unexpected keyword arguments are passed to <code>build</code>.</li> </ul> Source code in <code>src/neurospatial/layout/factories.py</code> <pre><code>def create_layout(kind: str, **kwargs) -&gt; LayoutEngine:\n    \"\"\"Factory for creating and building a spatial-layout engine.\n\n    Parameters\n    ----------\n    kind : str\n        Case-insensitive name of the layout engine to create\n        (e.g., \"RegularGrid\", \"Hexagonal\", \"Graph\", etc.).\n    **kwargs : any\n        Parameters passed to the chosen engine\u2019s `build(...)` method.\n\n    Returns\n    -------\n    LayoutEngine\n        A fully constructed layout engine.\n\n    Raises\n    ------\n    ValueError\n        - If `kind` is not one of the available layouts.\n        - If any unexpected keyword arguments are passed to `build`.\n\n    \"\"\"\n    # 1) Normalize user input and find matching key\n    norm_query = \"\".join(ch for ch in kind if ch.isalnum()).lower()\n    found_key = next(\n        (\n            name\n            for name in _LAYOUT_MAP\n            if \"\".join(ch for ch in name if ch.isalnum()).lower() == norm_query\n        ),\n        None,\n    )\n    if found_key is None:\n        suggestions = \", \".join(list_available_layouts())\n        raise ValueError(f\"Unknown layout kind '{kind}'. Available: {suggestions}\")\n\n    # 2) Instantiate the class\n    engine_cls = _LAYOUT_MAP[found_key]\n    engine: LayoutEngine = engine_cls()\n\n    # 3) Validate `kwargs` against `build(...)` signature\n    sig = inspect.signature(engine.build)\n    allowed = {param for param in sig.parameters if param != \"self\"}\n    unexpected = set(kwargs) - allowed\n    if unexpected:\n        raise ValueError(f\"Unexpected arguments for {found_key}.build(): {unexpected}\")\n\n    # 4) Call `build(...)` with validated params\n    engine.build(**{k: kwargs[k] for k in allowed if k in kwargs})\n    # At this point, engine is a LayoutEngine (Protocol check happens at runtime)\n    return engine\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.get_layout_parameters","title":"get_layout_parameters","text":"<pre><code>get_layout_parameters(layout_type: str) -&gt; dict[str, dict[str, Any]]\n</code></pre> <p>Retrieve expected build parameters for a specified layout engine type.</p> <p>Inspects the <code>build</code> method signature of the specified <code>LayoutEngine</code> class to determine its required and optional parameters.</p> <p>Parameters:</p> Name Type Description Default <code>layout_type</code> <code>str</code> <p>The string identifier of the layout engine type (case-insensitive, ignores non-alphanumeric characters).</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Any]]</code> <p>A dictionary where keys are parameter names for the <code>build</code> method. Each value is another dictionary containing: - 'annotation': The type annotation of the parameter. - 'default': The default value, or <code>None</code> if no default. - 'kind': The parameter kind (e.g., 'keyword-only').</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>layout_type</code> is unknown.</p> Source code in <code>src/neurospatial/layout/factories.py</code> <pre><code>def get_layout_parameters(layout_type: str) -&gt; dict[str, dict[str, Any]]:\n    \"\"\"Retrieve expected build parameters for a specified layout engine type.\n\n    Inspects the `build` method signature of the specified `LayoutEngine`\n    class to determine its required and optional parameters.\n\n    Parameters\n    ----------\n    layout_type : str\n        The string identifier of the layout engine type (case-insensitive,\n        ignores non-alphanumeric characters).\n\n    Returns\n    -------\n    Dict[str, Dict[str, Any]]\n        A dictionary where keys are parameter names for the `build` method.\n        Each value is another dictionary containing:\n        - 'annotation': The type annotation of the parameter.\n        - 'default': The default value, or `None` if no default.\n        - 'kind': The parameter kind (e.g., 'keyword-only').\n\n    Raises\n    ------\n    ValueError\n        If `layout_type` is unknown.\n\n    \"\"\"\n    normalized_kind_query = _normalize_name(layout_type)\n    found_key = next(\n        (\n            name\n            for name in _LAYOUT_MAP\n            if _normalize_name(name) == normalized_kind_query\n        ),\n        None,\n    )\n    if not found_key:\n        raise ValueError(\n            f\"Unknown engine kind '{layout_type}'. Available: {list_available_layouts()}\",\n        )\n    engine_class = _LAYOUT_MAP[found_key]\n    sig = inspect.signature(engine_class.build)\n    params_info: dict[str, dict[str, Any]] = {}\n    for name, param in sig.parameters.items():\n        if name == \"self\":\n            continue\n        params_info[name] = {\n            \"annotation\": (\n                param.annotation\n                if param.annotation is not inspect.Parameter.empty\n                else None\n            ),\n            \"default\": (\n                param.default if param.default is not inspect.Parameter.empty else None\n            ),\n            \"kind\": param.kind.description,\n        }\n    return params_info\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.list_available_layouts","title":"list_available_layouts","text":"<pre><code>list_available_layouts() -&gt; list[str]\n</code></pre> <p>List user-friendly type strings for all available layout engines.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>A sorted list of unique string identifiers for available <code>LayoutEngine</code> types (e.g., \"RegularGrid\", \"Hexagonal\").</p> Source code in <code>src/neurospatial/layout/factories.py</code> <pre><code>def list_available_layouts() -&gt; list[str]:\n    \"\"\"List user-friendly type strings for all available layout engines.\n\n    Returns\n    -------\n    List[str]\n        A sorted list of unique string identifiers for available\n        `LayoutEngine` types (e.g., \"RegularGrid\", \"Hexagonal\").\n\n    \"\"\"\n    unique_options: list[str] = []\n    processed_normalized_options: set[str] = set()\n    for opt in _LAYOUT_MAP:\n        norm_opt = _normalize_name(opt)\n        if norm_opt not in processed_normalized_options:\n            unique_options.append(opt)\n            processed_normalized_options.add(norm_opt)\n    return sorted(unique_options)\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.get_centers","title":"get_centers","text":"<pre><code>get_centers(bin_edges: NDArray[float64]) -&gt; NDArray[np.float64]\n</code></pre> <p>Calculate the center of each bin given its edges.</p> <p>Parameters:</p> Name Type Description Default <code>bin_edges</code> <code>(NDArray[float64], shape(n_edges))</code> <p>A 1D array of sorted coordinates representing the edges that define a sequence of bins. For <code>N</code> bins, there will be <code>N+1</code> edges.</p> required <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_edges - 1))</code> <p>A 1D array containing the center coordinate of each bin.</p> Source code in <code>src/neurospatial/layout/helpers/utils.py</code> <pre><code>def get_centers(bin_edges: NDArray[np.float64]) -&gt; NDArray[np.float64]:\n    \"\"\"Calculate the center of each bin given its edges.\n\n    Parameters\n    ----------\n    bin_edges : NDArray[np.float64], shape (n_edges,)\n        A 1D array of sorted coordinates representing the edges that define\n        a sequence of bins. For `N` bins, there will be `N+1` edges.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_edges - 1,)\n        A 1D array containing the center coordinate of each bin.\n\n    \"\"\"\n    return bin_edges[:-1] + np.diff(bin_edges) / 2\n</code></pre>"},{"location":"api/neurospatial/layout/#neurospatial.layout.get_n_bins","title":"get_n_bins","text":"<pre><code>get_n_bins(data_samples: NDArray[float64], bin_size: float | Sequence[float], dimension_range: Sequence[tuple[float, float]] | None = None) -&gt; NDArray[np.int_]\n</code></pre> <p>Calculate the number of bins needed for each dimension of a dataset.</p> <p>The number of bins is determined based on the extent of the data (or a specified <code>dimension_range</code>) and the desired <code>bin_size</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_samples</code> <code>(NDArray[float64], shape(n_samples, n_dims))</code> <p>N-dimensional data samples. Used to determine the data extent if <code>dimension_range</code> is not provided. NaNs are ignored for range calculation.</p> required <code>bin_size</code> <code>Union[float, Sequence[float]]</code> <p>The desired size of the bins. If a float, this size is applied to all dimensions. If a sequence, it specifies the bin size for each dimension and its length must match <code>n_dims</code>. Must be positive.</p> required <code>dimension_range</code> <code>Optional[Sequence[Tuple[float, float]]]</code> <p>Explicit range <code>[(min_d0, max_d0), ..., (min_dN-1, max_dN-1)]</code> for each dimension. If None (default), the range is calculated from the min/max of <code>data_samples</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>(NDArray[int_], shape(n_dims))</code> <p>An array containing the calculated number of bins required for each dimension. Each value is at least 1.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>bin_size</code> is not positive or if its length (if a sequence) does not match the number of dimensions. If <code>dimension_range</code> (if provided) does not have two values (min, max) per dimension.</p> Source code in <code>src/neurospatial/layout/helpers/utils.py</code> <pre><code>def get_n_bins(\n    data_samples: NDArray[np.float64],\n    bin_size: float | Sequence[float],\n    dimension_range: Sequence[tuple[float, float]] | None = None,\n) -&gt; NDArray[np.int_]:\n    \"\"\"Calculate the number of bins needed for each dimension of a dataset.\n\n    The number of bins is determined based on the extent of the data (or a\n    specified `dimension_range`) and the desired `bin_size`.\n\n    Parameters\n    ----------\n    data_samples : NDArray[np.float64], shape (n_samples, n_dims)\n        N-dimensional data samples. Used to determine the data extent if\n        `dimension_range` is not provided. NaNs are ignored for range calculation.\n    bin_size : Union[float, Sequence[float]]\n        The desired size of the bins. If a float, this size is applied to\n        all dimensions. If a sequence, it specifies the bin size for each\n        dimension and its length must match `n_dims`. Must be positive.\n    dimension_range : Optional[Sequence[Tuple[float, float]]], optional\n        Explicit range `[(min_d0, max_d0), ..., (min_dN-1, max_dN-1)]` for\n        each dimension. If None (default), the range is calculated from\n        the min/max of `data_samples`.\n\n    Returns\n    -------\n    NDArray[np.int_], shape (n_dims,)\n        An array containing the calculated number of bins required for each\n        dimension. Each value is at least 1.\n\n    Raises\n    ------\n    ValueError\n        If `bin_size` is not positive or if its length (if a sequence)\n        does not match the number of dimensions.\n        If `dimension_range` (if provided) does not have two values (min, max)\n        per dimension.\n\n    \"\"\"\n    if dimension_range is not None:\n        # Ensure dimension_range is numpy array for consistent processing\n        pr = np.asarray(dimension_range)\n        if pr.shape[1] != 2:\n            raise ValueError(\"dimension_range must be sequence of (min, max) pairs.\")\n        extent = np.diff(pr, axis=1).squeeze(axis=1)\n    else:\n        # Ignore NaNs when calculating range from data\n        extent = np.nanmax(data_samples, axis=0) - np.nanmin(data_samples, axis=0)\n\n    # Validate and convert bin_size with helpful error messages\n    try:\n        bin_size_arr = np.asarray(bin_size, dtype=float)\n    except (TypeError, ValueError) as e:\n        # Provide helpful error message for type conversion failures\n        actual_type = type(bin_size).__name__\n        raise TypeError(\n            f\"bin_size must be a numeric value or sequence of numeric values. \"\n            f\"Got {actual_type}: {bin_size!r}\"\n        ) from e\n\n    # Check for NaN or Inf values separately\n    if np.any(np.isnan(bin_size_arr)):\n        raise ValueError(\n            f\"bin_size contains NaN (Not a Number) values (got {bin_size}). \"\n            \"bin_size must be finite numeric values.\"\n        )\n    if np.any(np.isinf(bin_size_arr)):\n        raise ValueError(\n            f\"bin_size contains infinite values (got {bin_size}). \"\n            \"bin_size must be finite numeric values.\"\n        )\n\n    # Ensure bin_size is positive\n    if np.any(bin_size_arr &lt;= 0.0):\n        raise ValueError(f\"bin_size must be positive (got {bin_size}).\")\n\n    # Calculate number of bins, ensuring at least 1 bin even if extent is 0\n    n_bins = np.ceil(extent / bin_size_arr).astype(np.int32)\n    n_bins[n_bins == 0] = 1  # Handle zero extent case\n\n    # Convert to int64 to match expected return type\n    return np.asarray(n_bins, dtype=np.int64)\n</code></pre>"},{"location":"api/neurospatial/layout/base/","title":"<code>neurospatial.layout.base</code>","text":""},{"location":"api/neurospatial/layout/base/#neurospatial.layout.base","title":"base","text":""},{"location":"api/neurospatial/layout/base/#neurospatial.layout.base-classes","title":"Classes","text":""},{"location":"api/neurospatial/layout/base/#neurospatial.layout.base.LayoutEngine","title":"LayoutEngine","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol defining the interface for all spatial layout engines.</p> <p>A LayoutEngine is responsible for discretizing a continuous N-dimensional space into a set of bins or elements and constructing a graph representation of their connectivity.</p> <p>Attributes:</p> Name Type Description <code>bin_centers</code> <code>NDArray[float64]</code> <p>Coordinates of the center of each active bin/node. Shape is (n_active_bins, n_dims).</p> <code>connectivity</code> <code>Optional[Graph]</code> <p>Graph where nodes are integers from <code>0</code> to <code>n_active_bins - 1</code>, directly corresponding to rows in <code>bin_centers</code>. Mandatory Node Attributes:     - 'pos': Tuple[float, ...] - N-D coordinates of the active bin center.     - 'source_grid_flat_index': int - Flat index in the original       full conceptual grid from which this active bin originated.     - 'original_grid_nd_index': Tuple[int, ...] - N-D tuple index       in the original full conceptual grid. Mandatory Edge Attributes:     - 'distance': float - Euclidean distance between connected bin centers.     - 'vector': Tuple[float, ...] - Displacement vector between centers.     - 'edge_id': int - Unique ID for the edge within this graph. Recommended Edge Attributes:     - 'angle_2d': Optional[float] - Angle of displacement for 2D layouts.</p> <code>is_1d</code> <code>bool</code> <p>True if the layout represents a primarily 1-dimensional structure (e.g., a linearized track), False otherwise.</p> <code>dimension_ranges</code> <code>Optional[Sequence[Tuple[float, float]]]</code> <p>The actual min/max extent <code>[(min_d0, max_d0), ..., (min_dN-1, max_dN-1)]</code> covered by the layout's geometry.</p> <code>grid_edges</code> <code>Optional[Tuple[NDArray[float64], ...]]</code> <p>For grid-based layouts: A tuple of 1D arrays, where each array contains the bin edge positions for one dimension of the original, full grid. <code>None</code> or <code>()</code> for non-grid or point-based layouts.</p> <code>grid_shape</code> <code>Optional[Tuple[int, ...]]</code> <p>For grid-based layouts: The N-D shape (number of bins in each dimension) of the original, full grid. For point-based/cell-based layouts without a full grid concept: Typically <code>(n_active_bins,)</code>.</p> <code>active_mask</code> <code>Optional[NDArray[bool_]]</code> <ul> <li>For grid-based layouts: An N-D boolean mask indicating active bins   on the original, full grid (shape matches <code>grid_shape</code>).</li> <li>For point-based/cell-based layouts: A 1D array of <code>True</code> values,   shape <code>(n_active_bins,)</code>, corresponding to <code>bin_centers</code>.</li> </ul> <code>_layout_type_tag</code> <code>str</code> <p>A string identifier for the type of layout (e.g., \"RegularGrid\"). Used for introspection and serialization.</p> <code>_build_params_used</code> <code>Dict[str, Any]</code> <p>A dictionary of the parameters used to construct this layout instance. Used for introspection and serialization.</p>"},{"location":"api/neurospatial/layout/base/#neurospatial.layout.base.LayoutEngine-attributes","title":"Attributes","text":""},{"location":"api/neurospatial/layout/base/#neurospatial.layout.base.LayoutEngine.is_1d","title":"is_1d  <code>property</code>","text":"<pre><code>is_1d: bool\n</code></pre> <p>Indicate if the layout structure is primarily 1-dimensional.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the layout represents a 1D structure (e.g., a linearized track), False otherwise.</p>"},{"location":"api/neurospatial/layout/base/#neurospatial.layout.base.LayoutEngine-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/base/#neurospatial.layout.base.LayoutEngine.build","title":"build","text":"<pre><code>build(**kwargs) -&gt; None\n</code></pre> <p>Construct the layout's geometry, bins, and connectivity graph.</p> <p>This method is responsible for populating all the attributes defined in the <code>LayoutEngine</code> protocol (e.g., <code>bin_centers</code>, <code>connectivity</code>, etc.) based on the provided keyword arguments. The specific arguments required will vary depending on the concrete implementation of the layout engine.</p> Source code in <code>src/neurospatial/layout/base.py</code> <pre><code>def build(self, **kwargs) -&gt; None:\n    \"\"\"Construct the layout's geometry, bins, and connectivity graph.\n\n    This method is responsible for populating all the attributes defined\n    in the `LayoutEngine` protocol (e.g., `bin_centers`,\n    `connectivity`, etc.) based on the provided keyword arguments.\n    The specific arguments required will vary depending on the concrete\n    implementation of the layout engine.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/neurospatial/layout/base/#neurospatial.layout.base.LayoutEngine.point_to_bin_index","title":"point_to_bin_index","text":"<pre><code>point_to_bin_index(points: NDArray[float64]) -&gt; NDArray[np.int_]\n</code></pre> <p>Map continuous N-D points to discrete active bin indices.</p> <p>The returned indices range from <code>0</code> to <code>n_active_bins - 1</code>. A value of -1 indicates that the corresponding point did not map to any active bin (e.g., it's outside the defined environment).</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>(NDArray[float64], shape(n_points, n_dims))</code> <p>An array of N-dimensional points to map to bin indices.</p> required <p>Returns:</p> Type Description <code>(NDArray[int_], shape(n_points))</code> <p>An array of active bin indices corresponding to the input points. -1 for points outside the layout's active bins.</p> Source code in <code>src/neurospatial/layout/base.py</code> <pre><code>def point_to_bin_index(self, points: NDArray[np.float64]) -&gt; NDArray[np.int_]:\n    \"\"\"Map continuous N-D points to discrete active bin indices.\n\n    The returned indices range from `0` to `n_active_bins - 1`.\n    A value of -1 indicates that the corresponding point did not map\n    to any active bin (e.g., it's outside the defined environment).\n\n    Parameters\n    ----------\n    points : NDArray[np.float64], shape (n_points, n_dims)\n        An array of N-dimensional points to map to bin indices.\n\n    Returns\n    -------\n    NDArray[np.int_], shape (n_points,)\n        An array of active bin indices corresponding to the input points.\n        -1 for points outside the layout's active bins.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/neurospatial/layout/base/#neurospatial.layout.base.LayoutEngine.bin_sizes","title":"bin_sizes","text":"<pre><code>bin_sizes() -&gt; NDArray[np.float64]\n</code></pre> <p>Return the area (2D) or volume (3D+) of each active bin.</p> <p>For 1D layouts, this typically returns the length of each bin. The measures should correspond to the dimensionality of the space the bins occupy.</p> <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_active_bins))</code> <p>An array where each element is the area/volume/length of the corresponding active bin.</p> Source code in <code>src/neurospatial/layout/base.py</code> <pre><code>def bin_sizes(self) -&gt; NDArray[np.float64]:\n    \"\"\"Return the area (2D) or volume (3D+) of each active bin.\n\n    For 1D layouts, this typically returns the length of each bin.\n    The measures should correspond to the dimensionality of the space\n    the bins occupy.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_active_bins,)\n        An array where each element is the area/volume/length of the\n        corresponding active bin.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/neurospatial/layout/base/#neurospatial.layout.base.LayoutEngine.plot","title":"plot","text":"<pre><code>plot(ax: Axes | None = None, **kwargs) -&gt; matplotlib.axes.Axes\n</code></pre> <p>Plot the layout's geometry.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>The Matplotlib axes to plot on. If None, a new figure and axes are created. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for plot customization, specific to the layout engine implementation.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the layout is plotted.</p> Source code in <code>src/neurospatial/layout/base.py</code> <pre><code>def plot(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    **kwargs,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot the layout's geometry.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        The Matplotlib axes to plot on. If None, a new figure and axes\n        are created. Defaults to None.\n    **kwargs : Any\n        Additional keyword arguments for plot customization, specific to\n        the layout engine implementation.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the layout is plotted.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/neurospatial/layout/base/#neurospatial.layout.base-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/base/#neurospatial.layout.base.capture_build_params","title":"capture_build_params","text":"<pre><code>capture_build_params(build_method)\n</code></pre> <p>Decorator to capture build parameters for layout engines.</p> <p>This decorator automatically captures all parameters passed to a layout engine's <code>build()</code> method and stores them in <code>self._build_params_used</code>. This eliminates the need for manual <code>locals().copy()</code> bookkeeping.</p> <p>Parameters:</p> Name Type Description Default <code>build_method</code> <code>callable</code> <p>The build method to decorate.</p> required <p>Returns:</p> Type Description <code>callable</code> <p>Wrapped build method that captures parameters.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; class MyLayout:\n...     @capture_build_params\n...     def build(self, *, bin_size: float, dimension_ranges=None):\n...         # Clean implementation without manual parameter capture\n...         pass\n</code></pre> Notes <p>This decorator uses <code>inspect.signature()</code> to bind arguments and capture all parameters (including defaults) that were passed to the method. The <code>self</code> parameter is automatically excluded from the captured parameters.</p> Source code in <code>src/neurospatial/layout/base.py</code> <pre><code>def capture_build_params(build_method):\n    \"\"\"Decorator to capture build parameters for layout engines.\n\n    This decorator automatically captures all parameters passed to a layout\n    engine's `build()` method and stores them in `self._build_params_used`.\n    This eliminates the need for manual `locals().copy()` bookkeeping.\n\n    Parameters\n    ----------\n    build_method : callable\n        The build method to decorate.\n\n    Returns\n    -------\n    callable\n        Wrapped build method that captures parameters.\n\n    Examples\n    --------\n    &gt;&gt;&gt; class MyLayout:\n    ...     @capture_build_params\n    ...     def build(self, *, bin_size: float, dimension_ranges=None):\n    ...         # Clean implementation without manual parameter capture\n    ...         pass\n\n    Notes\n    -----\n    This decorator uses `inspect.signature()` to bind arguments and capture\n    all parameters (including defaults) that were passed to the method.\n    The `self` parameter is automatically excluded from the captured parameters.\n\n    \"\"\"\n    sig = inspect.signature(build_method)\n\n    @wraps(build_method)\n    def wrapper(self, *args, **kwargs):\n        # Bind all arguments to the signature\n        bound = sig.bind(self, *args, **kwargs)\n        bound.apply_defaults()\n\n        # Convert to dict and remove 'self'\n        params = dict(bound.arguments)\n        params.pop(\"self\", None)\n\n        # Store captured parameters\n        self._build_params_used = params\n\n        # Call the original method\n        return build_method(self, *args, **kwargs)\n\n    return wrapper\n</code></pre>"},{"location":"api/neurospatial/layout/factories/","title":"<code>neurospatial.layout.factories</code>","text":""},{"location":"api/neurospatial/layout/factories/#neurospatial.layout.factories","title":"factories","text":""},{"location":"api/neurospatial/layout/factories/#neurospatial.layout.factories-classes","title":"Classes","text":""},{"location":"api/neurospatial/layout/factories/#neurospatial.layout.factories-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/factories/#neurospatial.layout.factories.list_available_layouts","title":"list_available_layouts","text":"<pre><code>list_available_layouts() -&gt; list[str]\n</code></pre> <p>List user-friendly type strings for all available layout engines.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>A sorted list of unique string identifiers for available <code>LayoutEngine</code> types (e.g., \"RegularGrid\", \"Hexagonal\").</p> Source code in <code>src/neurospatial/layout/factories.py</code> <pre><code>def list_available_layouts() -&gt; list[str]:\n    \"\"\"List user-friendly type strings for all available layout engines.\n\n    Returns\n    -------\n    List[str]\n        A sorted list of unique string identifiers for available\n        `LayoutEngine` types (e.g., \"RegularGrid\", \"Hexagonal\").\n\n    \"\"\"\n    unique_options: list[str] = []\n    processed_normalized_options: set[str] = set()\n    for opt in _LAYOUT_MAP:\n        norm_opt = _normalize_name(opt)\n        if norm_opt not in processed_normalized_options:\n            unique_options.append(opt)\n            processed_normalized_options.add(norm_opt)\n    return sorted(unique_options)\n</code></pre>"},{"location":"api/neurospatial/layout/factories/#neurospatial.layout.factories.get_layout_parameters","title":"get_layout_parameters","text":"<pre><code>get_layout_parameters(layout_type: str) -&gt; dict[str, dict[str, Any]]\n</code></pre> <p>Retrieve expected build parameters for a specified layout engine type.</p> <p>Inspects the <code>build</code> method signature of the specified <code>LayoutEngine</code> class to determine its required and optional parameters.</p> <p>Parameters:</p> Name Type Description Default <code>layout_type</code> <code>str</code> <p>The string identifier of the layout engine type (case-insensitive, ignores non-alphanumeric characters).</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Any]]</code> <p>A dictionary where keys are parameter names for the <code>build</code> method. Each value is another dictionary containing: - 'annotation': The type annotation of the parameter. - 'default': The default value, or <code>None</code> if no default. - 'kind': The parameter kind (e.g., 'keyword-only').</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>layout_type</code> is unknown.</p> Source code in <code>src/neurospatial/layout/factories.py</code> <pre><code>def get_layout_parameters(layout_type: str) -&gt; dict[str, dict[str, Any]]:\n    \"\"\"Retrieve expected build parameters for a specified layout engine type.\n\n    Inspects the `build` method signature of the specified `LayoutEngine`\n    class to determine its required and optional parameters.\n\n    Parameters\n    ----------\n    layout_type : str\n        The string identifier of the layout engine type (case-insensitive,\n        ignores non-alphanumeric characters).\n\n    Returns\n    -------\n    Dict[str, Dict[str, Any]]\n        A dictionary where keys are parameter names for the `build` method.\n        Each value is another dictionary containing:\n        - 'annotation': The type annotation of the parameter.\n        - 'default': The default value, or `None` if no default.\n        - 'kind': The parameter kind (e.g., 'keyword-only').\n\n    Raises\n    ------\n    ValueError\n        If `layout_type` is unknown.\n\n    \"\"\"\n    normalized_kind_query = _normalize_name(layout_type)\n    found_key = next(\n        (\n            name\n            for name in _LAYOUT_MAP\n            if _normalize_name(name) == normalized_kind_query\n        ),\n        None,\n    )\n    if not found_key:\n        raise ValueError(\n            f\"Unknown engine kind '{layout_type}'. Available: {list_available_layouts()}\",\n        )\n    engine_class = _LAYOUT_MAP[found_key]\n    sig = inspect.signature(engine_class.build)\n    params_info: dict[str, dict[str, Any]] = {}\n    for name, param in sig.parameters.items():\n        if name == \"self\":\n            continue\n        params_info[name] = {\n            \"annotation\": (\n                param.annotation\n                if param.annotation is not inspect.Parameter.empty\n                else None\n            ),\n            \"default\": (\n                param.default if param.default is not inspect.Parameter.empty else None\n            ),\n            \"kind\": param.kind.description,\n        }\n    return params_info\n</code></pre>"},{"location":"api/neurospatial/layout/factories/#neurospatial.layout.factories.create_layout","title":"create_layout","text":"<pre><code>create_layout(kind: str, **kwargs) -&gt; LayoutEngine\n</code></pre> <p>Factory for creating and building a spatial-layout engine.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str</code> <p>Case-insensitive name of the layout engine to create (e.g., \"RegularGrid\", \"Hexagonal\", \"Graph\", etc.).</p> required <code>**kwargs</code> <code>any</code> <p>Parameters passed to the chosen engine\u2019s <code>build(...)</code> method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>LayoutEngine</code> <p>A fully constructed layout engine.</p> <p>Raises:</p> Type Description <code>ValueError</code> <ul> <li>If <code>kind</code> is not one of the available layouts.</li> <li>If any unexpected keyword arguments are passed to <code>build</code>.</li> </ul> Source code in <code>src/neurospatial/layout/factories.py</code> <pre><code>def create_layout(kind: str, **kwargs) -&gt; LayoutEngine:\n    \"\"\"Factory for creating and building a spatial-layout engine.\n\n    Parameters\n    ----------\n    kind : str\n        Case-insensitive name of the layout engine to create\n        (e.g., \"RegularGrid\", \"Hexagonal\", \"Graph\", etc.).\n    **kwargs : any\n        Parameters passed to the chosen engine\u2019s `build(...)` method.\n\n    Returns\n    -------\n    LayoutEngine\n        A fully constructed layout engine.\n\n    Raises\n    ------\n    ValueError\n        - If `kind` is not one of the available layouts.\n        - If any unexpected keyword arguments are passed to `build`.\n\n    \"\"\"\n    # 1) Normalize user input and find matching key\n    norm_query = \"\".join(ch for ch in kind if ch.isalnum()).lower()\n    found_key = next(\n        (\n            name\n            for name in _LAYOUT_MAP\n            if \"\".join(ch for ch in name if ch.isalnum()).lower() == norm_query\n        ),\n        None,\n    )\n    if found_key is None:\n        suggestions = \", \".join(list_available_layouts())\n        raise ValueError(f\"Unknown layout kind '{kind}'. Available: {suggestions}\")\n\n    # 2) Instantiate the class\n    engine_cls = _LAYOUT_MAP[found_key]\n    engine: LayoutEngine = engine_cls()\n\n    # 3) Validate `kwargs` against `build(...)` signature\n    sig = inspect.signature(engine.build)\n    allowed = {param for param in sig.parameters if param != \"self\"}\n    unexpected = set(kwargs) - allowed\n    if unexpected:\n        raise ValueError(f\"Unexpected arguments for {found_key}.build(): {unexpected}\")\n\n    # 4) Call `build(...)` with validated params\n    engine.build(**{k: kwargs[k] for k in allowed if k in kwargs})\n    # At this point, engine is a LayoutEngine (Protocol check happens at runtime)\n    return engine\n</code></pre>"},{"location":"api/neurospatial/layout/mixins/","title":"<code>neurospatial.layout.mixins</code>","text":""},{"location":"api/neurospatial/layout/mixins/#neurospatial.layout.mixins","title":"mixins","text":""},{"location":"api/neurospatial/layout/validation/","title":"<code>neurospatial.layout.validation</code>","text":""},{"location":"api/neurospatial/layout/validation/#neurospatial.layout.validation","title":"validation","text":"<p>Graph and environment validation utilities for neurospatial.</p> <p>This module provides validation functions to ensure connectivity graphs and environments have the required structure and metadata attributes as documented in CLAUDE.md.</p> <p>All layout engines must produce graphs with mandatory node and edge attributes. This validator enforces those requirements and provides clear error messages when violations are detected.</p>"},{"location":"api/neurospatial/layout/validation/#neurospatial.layout.validation-classes","title":"Classes","text":""},{"location":"api/neurospatial/layout/validation/#neurospatial.layout.validation.GraphValidationError","title":"GraphValidationError","text":"<p>               Bases: <code>ValueError</code></p> <p>Raised when connectivity graph has invalid structure or metadata.</p> <p>This error indicates a bug in the layout engine that produced the graph, not a user error. All layout engines must produce graphs that pass validation.</p> See Also <p>validate_connectivity_graph : Main validation function</p>"},{"location":"api/neurospatial/layout/validation/#neurospatial.layout.validation-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/validation/#neurospatial.layout.validation.validate_connectivity_graph","title":"validate_connectivity_graph","text":"<pre><code>validate_connectivity_graph(graph: Graph, n_dims: int, check_node_attrs: bool = True, check_edge_attrs: bool = True) -&gt; None\n</code></pre> <p>Validate that connectivity graph has required structure and metadata.</p> <p>This function enforces the mandatory graph metadata requirements documented in CLAUDE.md. All layout engines must produce graphs that pass this validation.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>Graph</code> <p>The connectivity graph to validate</p> required <code>n_dims</code> <code>int</code> <p>Expected number of spatial dimensions</p> required <code>check_node_attrs</code> <code>bool</code> <p>Verify all required node attributes are present with correct types</p> <code>True</code> <code>check_edge_attrs</code> <code>bool</code> <p>Verify all required edge attributes are present with correct types</p> <code>True</code> <p>Raises:</p> Type Description <code>GraphValidationError</code> <p>If graph structure or metadata is invalid. Error message includes details about what is missing and which node/edge failed validation.</p> Notes <p>Required node attributes (all nodes must have these):     - 'pos' : tuple/list/array of length n_dims     - 'source_grid_flat_index' : int     - 'original_grid_nd_index' : tuple of ints</p> <p>Required edge attributes (all edges must have these):     - 'distance' : float &gt;= 0     - 'vector' : tuple/list/array of length n_dims     - 'edge_id' : int</p> <p>Optional edge attributes:     - 'angle_2d' : float (for 2D layouts only)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import networkx as nx\n&gt;&gt;&gt; G = nx.Graph()\n&gt;&gt;&gt; G.add_node(\n...     0, pos=(10.0, 20.0), source_grid_flat_index=0, original_grid_nd_index=(0, 0)\n... )\n&gt;&gt;&gt; G.add_node(\n...     1, pos=(12.0, 20.0), source_grid_flat_index=1, original_grid_nd_index=(1, 0)\n... )\n&gt;&gt;&gt; G.add_edge(0, 1, distance=2.0, vector=(2.0, 0.0), edge_id=0)\n&gt;&gt;&gt; validate_connectivity_graph(G, n_dims=2)  # Passes validation\n</code></pre> <pre><code>&gt;&gt;&gt; # Missing required attributes will raise error\n&gt;&gt;&gt; G2 = nx.Graph()\n&gt;&gt;&gt; G2.add_node(0, pos=(10.0, 20.0))  # Missing other attrs\n&gt;&gt;&gt; validate_connectivity_graph(G2, n_dims=2)\nGraphValidationError: Node 0 missing required attributes: {...}\n</code></pre> See Also <p>neurospatial.environment.Environment._setup_from_layout : Calls this validator</p> Source code in <code>src/neurospatial/layout/validation.py</code> <pre><code>def validate_connectivity_graph(\n    graph: nx.Graph,\n    n_dims: int,\n    check_node_attrs: bool = True,\n    check_edge_attrs: bool = True,\n) -&gt; None:\n    \"\"\"Validate that connectivity graph has required structure and metadata.\n\n    This function enforces the mandatory graph metadata requirements documented\n    in CLAUDE.md. All layout engines must produce graphs that pass this\n    validation.\n\n    Parameters\n    ----------\n    graph : nx.Graph\n        The connectivity graph to validate\n    n_dims : int\n        Expected number of spatial dimensions\n    check_node_attrs : bool, default=True\n        Verify all required node attributes are present with correct types\n    check_edge_attrs : bool, default=True\n        Verify all required edge attributes are present with correct types\n\n    Raises\n    ------\n    GraphValidationError\n        If graph structure or metadata is invalid. Error message includes\n        details about what is missing and which node/edge failed validation.\n\n    Notes\n    -----\n    Required node attributes (all nodes must have these):\n        - 'pos' : tuple/list/array of length n_dims\n        - 'source_grid_flat_index' : int\n        - 'original_grid_nd_index' : tuple of ints\n\n    Required edge attributes (all edges must have these):\n        - 'distance' : float &gt;= 0\n        - 'vector' : tuple/list/array of length n_dims\n        - 'edge_id' : int\n\n    Optional edge attributes:\n        - 'angle_2d' : float (for 2D layouts only)\n\n    Examples\n    --------\n    &gt;&gt;&gt; import networkx as nx\n    &gt;&gt;&gt; G = nx.Graph()\n    &gt;&gt;&gt; G.add_node(\n    ...     0, pos=(10.0, 20.0), source_grid_flat_index=0, original_grid_nd_index=(0, 0)\n    ... )\n    &gt;&gt;&gt; G.add_node(\n    ...     1, pos=(12.0, 20.0), source_grid_flat_index=1, original_grid_nd_index=(1, 0)\n    ... )\n    &gt;&gt;&gt; G.add_edge(0, 1, distance=2.0, vector=(2.0, 0.0), edge_id=0)\n    &gt;&gt;&gt; validate_connectivity_graph(G, n_dims=2)  # Passes validation\n\n    &gt;&gt;&gt; # Missing required attributes will raise error\n    &gt;&gt;&gt; G2 = nx.Graph()\n    &gt;&gt;&gt; G2.add_node(0, pos=(10.0, 20.0))  # Missing other attrs\n    &gt;&gt;&gt; validate_connectivity_graph(G2, n_dims=2)  # doctest: +SKIP\n    GraphValidationError: Node 0 missing required attributes: {...}\n\n    See Also\n    --------\n    neurospatial.environment.Environment._setup_from_layout : Calls this validator\n    \"\"\"\n    # Validate graph type\n    if not isinstance(graph, nx.Graph):\n        raise GraphValidationError(\n            f\"Expected networkx.Graph, got {type(graph).__name__}. \"\n            f\"Layout engines must produce NetworkX Graph objects.\"\n        )\n\n    # Allow empty graphs (edge case: all bins masked out)\n    # If empty, skip validation\n    if len(graph.nodes) == 0:\n        return\n\n    # Validate dimensionality is positive\n    if n_dims &lt;= 0:\n        raise GraphValidationError(\n            f\"n_dims must be positive, got {n_dims}. \"\n            f\"This indicates a bug in the layout engine.\"\n        )\n\n    # Validate node attributes\n    if check_node_attrs:\n        for node_id in graph.nodes:\n            node_data = graph.nodes[node_id]\n            missing = REQUIRED_NODE_ATTRS - set(node_data.keys())\n\n            if missing:\n                raise GraphValidationError(\n                    f\"Node {node_id} missing required attributes: {missing}.\\n\\n\"\n                    f\"All nodes must have: {REQUIRED_NODE_ATTRS}.\\n\"\n                    f\"Node {node_id} has: {set(node_data.keys())}\\n\\n\"\n                    f\"This is a layout engine bug. Please report this issue.\\n\"\n                    f\"See CLAUDE.md section 'Graph Metadata Requirements' for details.\"\n                )\n\n            # Validate pos attribute\n            pos = node_data[\"pos\"]\n            if not isinstance(pos, (tuple, list, np.ndarray)):\n                raise GraphValidationError(\n                    f\"Node {node_id} 'pos' must be tuple/list/array, \"\n                    f\"got {type(pos).__name__}. \"\n                    f\"This is a layout engine bug.\"\n                )\n\n            # Validate pos dimensionality\n            try:\n                pos_len = len(pos)\n            except TypeError as e:\n                raise GraphValidationError(\n                    f\"Node {node_id} 'pos' is not a sequence: {pos}. \"\n                    f\"Must be tuple/list/array of coordinates.\"\n                ) from e\n\n            if pos_len != n_dims:\n                raise GraphValidationError(\n                    f\"Node {node_id} 'pos' has {pos_len} dimensions, \"\n                    f\"expected {n_dims}.\\n\"\n                    f\"pos = {pos}\\n\"\n                    f\"This is a layout engine bug.\"\n                )\n\n            # Validate pos contains numbers\n            try:\n                _ = [float(x) for x in pos]\n            except (TypeError, ValueError) as e:\n                raise GraphValidationError(\n                    f\"Node {node_id} 'pos' contains non-numeric values: {pos}. \"\n                    f\"Error: {e}\"\n                ) from e\n\n            # Validate source_grid_flat_index is integer\n            flat_idx = node_data[\"source_grid_flat_index\"]\n            if not isinstance(flat_idx, (int, np.integer)):\n                raise GraphValidationError(\n                    f\"Node {node_id} 'source_grid_flat_index' must be int, \"\n                    f\"got {type(flat_idx).__name__}.\"\n                )\n\n            # Validate original_grid_nd_index\n            nd_idx = node_data[\"original_grid_nd_index\"]\n            if not isinstance(nd_idx, (tuple, list, np.ndarray)):\n                raise GraphValidationError(\n                    f\"Node {node_id} 'original_grid_nd_index' must be tuple/list/array, \"\n                    f\"got {type(nd_idx).__name__}.\"\n                )\n\n    # Validate edge attributes\n    if check_edge_attrs and len(graph.edges) &gt; 0:\n        for u, v in graph.edges:\n            edge_data = graph.edges[u, v]\n            missing = REQUIRED_EDGE_ATTRS - set(edge_data.keys())\n\n            if missing:\n                raise GraphValidationError(\n                    f\"Edge ({u}, {v}) missing required attributes: {missing}.\\n\\n\"\n                    f\"All edges must have: {REQUIRED_EDGE_ATTRS}.\\n\"\n                    f\"Edge ({u}, {v}) has: {set(edge_data.keys())}\\n\\n\"\n                    f\"This is a layout engine bug. Please report this issue.\\n\"\n                    f\"See CLAUDE.md section 'Graph Metadata Requirements' for details.\"\n                )\n\n            # Validate distance\n            distance = edge_data[\"distance\"]\n            try:\n                distance_float = float(distance)\n            except (TypeError, ValueError) as e:\n                raise GraphValidationError(\n                    f\"Edge ({u}, {v}) 'distance' must be numeric, \"\n                    f\"got {type(distance).__name__}: {distance}. \"\n                    f\"Error: {e}\"\n                ) from e\n\n            if distance_float &lt; 0:\n                raise GraphValidationError(\n                    f\"Edge ({u}, {v}) 'distance' must be non-negative, \"\n                    f\"got {distance_float}. \"\n                    f\"This is a layout engine bug.\"\n                )\n\n            if not np.isfinite(distance_float):\n                raise GraphValidationError(\n                    f\"Edge ({u}, {v}) 'distance' must be finite, \"\n                    f\"got {distance_float}. \"\n                    f\"This is a layout engine bug.\"\n                )\n\n            # Validate vector\n            vector = edge_data[\"vector\"]\n            if not isinstance(vector, (tuple, list, np.ndarray)):\n                raise GraphValidationError(\n                    f\"Edge ({u}, {v}) 'vector' must be tuple/list/array, \"\n                    f\"got {type(vector).__name__}.\"\n                )\n\n            # Validate vector dimensionality\n            try:\n                vec_len = len(vector)\n            except TypeError as e:\n                raise GraphValidationError(\n                    f\"Edge ({u}, {v}) 'vector' is not a sequence: {vector}. \"\n                    f\"Must be tuple/list/array of displacement.\"\n                ) from e\n\n            if vec_len != n_dims:\n                raise GraphValidationError(\n                    f\"Edge ({u}, {v}) 'vector' has {vec_len} dimensions, \"\n                    f\"expected {n_dims}.\\n\"\n                    f\"vector = {vector}\\n\"\n                    f\"This is a layout engine bug.\"\n                )\n\n            # Validate vector contains numbers\n            try:\n                _ = [float(x) for x in vector]\n            except (TypeError, ValueError) as e:\n                raise GraphValidationError(\n                    f\"Edge ({u}, {v}) 'vector' contains non-numeric values: {vector}. \"\n                    f\"Error: {e}\"\n                ) from e\n\n            # Validate edge_id is integer\n            edge_id = edge_data[\"edge_id\"]\n            if not isinstance(edge_id, (int, np.integer)):\n                raise GraphValidationError(\n                    f\"Edge ({u}, {v}) 'edge_id' must be int, \"\n                    f\"got {type(edge_id).__name__}.\"\n                )\n</code></pre>"},{"location":"api/neurospatial/layout/validation/#neurospatial.layout.validation.validate_environment","title":"validate_environment","text":"<pre><code>validate_environment(env: Environment, *, strict: bool = True) -&gt; None\n</code></pre> <p>Validate that an Environment satisfies all structural invariants.</p> <p>This function provides a single entry point for validating Environment objects. It checks: - Required node/edge attributes on connectivity graph - Bin geometry consistency (bin_centers matches graph nodes) - Connectivity structure (no duplicate edges, consistent node IDs) - Unit presence (if strict=True, warns about missing units/frame)</p> <p>Downstream packages can use this to verify invariants before processing.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Environment instance to validate.</p> required <code>strict</code> <code>bool</code> <p>If True, performs additional checks like warning about missing units. If False, only validates critical structural requirements.</p> <code>True</code> <p>Raises:</p> Type Description <code>GraphValidationError</code> <p>If connectivity graph is invalid (missing attributes, wrong dimensions).</p> <code>ValueError</code> <p>If bin_centers and connectivity graph are inconsistent.</p> <code>RuntimeError</code> <p>If environment is not fitted (was not created with factory method).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neurospatial import Environment\n&gt;&gt;&gt; from neurospatial.layout.validation import validate_environment\n&gt;&gt;&gt; env = Environment.from_samples(data, bin_size=2.0)\n&gt;&gt;&gt; validate_environment(env)  # Passes if environment is valid\n</code></pre> <pre><code>&gt;&gt;&gt; # Catch validation errors\n&gt;&gt;&gt; try:\n...     validate_environment(potentially_invalid_env)\n... except (GraphValidationError, ValueError) as e:\n...     print(f\"Environment is invalid: {e}\")\n</code></pre> See Also <p>validate_connectivity_graph : Lower-level graph validation Environment._setup_from_layout : Calls validation during creation</p> Notes <p>This validator is fail-fast with standardized error messages. It is designed to catch layout engine bugs and data corruption early.</p> <p>Downstream packages that rely on neurospatial environments should call this at their entry points to ensure invariants hold, avoiding the need for duplicate defensive checks.</p> Source code in <code>src/neurospatial/layout/validation.py</code> <pre><code>def validate_environment(env: Environment, *, strict: bool = True) -&gt; None:\n    \"\"\"Validate that an Environment satisfies all structural invariants.\n\n    This function provides a single entry point for validating Environment\n    objects. It checks:\n    - Required node/edge attributes on connectivity graph\n    - Bin geometry consistency (bin_centers matches graph nodes)\n    - Connectivity structure (no duplicate edges, consistent node IDs)\n    - Unit presence (if strict=True, warns about missing units/frame)\n\n    Downstream packages can use this to verify invariants before processing.\n\n    Parameters\n    ----------\n    env : Environment\n        Environment instance to validate.\n    strict : bool, default=True\n        If True, performs additional checks like warning about missing units.\n        If False, only validates critical structural requirements.\n\n    Raises\n    ------\n    GraphValidationError\n        If connectivity graph is invalid (missing attributes, wrong dimensions).\n    ValueError\n        If bin_centers and connectivity graph are inconsistent.\n    RuntimeError\n        If environment is not fitted (was not created with factory method).\n\n    Examples\n    --------\n    &gt;&gt;&gt; from neurospatial import Environment\n    &gt;&gt;&gt; from neurospatial.layout.validation import validate_environment\n    &gt;&gt;&gt; env = Environment.from_samples(data, bin_size=2.0)\n    &gt;&gt;&gt; validate_environment(env)  # Passes if environment is valid\n\n    &gt;&gt;&gt; # Catch validation errors\n    &gt;&gt;&gt; try:\n    ...     validate_environment(potentially_invalid_env)\n    ... except (GraphValidationError, ValueError) as e:\n    ...     print(f\"Environment is invalid: {e}\")\n\n    See Also\n    --------\n    validate_connectivity_graph : Lower-level graph validation\n    Environment._setup_from_layout : Calls validation during creation\n\n    Notes\n    -----\n    This validator is fail-fast with standardized error messages. It is\n    designed to catch layout engine bugs and data corruption early.\n\n    Downstream packages that rely on neurospatial environments should call\n    this at their entry points to ensure invariants hold, avoiding the need\n    for duplicate defensive checks.\n\n    \"\"\"\n    import warnings\n\n    # Check fitted status\n    if not getattr(env, \"_is_fitted\", False):\n        raise RuntimeError(\n            f\"Environment '{env.name}' is not fitted. \"\n            f\"Environments must be created with factory methods \"\n            f\"(e.g., Environment.from_samples()) before validation.\"\n        )\n\n    # Validate connectivity graph\n    n_dims = env.n_dims\n    validate_connectivity_graph(\n        env.connectivity, n_dims=n_dims, check_node_attrs=True, check_edge_attrs=True\n    )\n\n    # Validate bin_centers consistency with graph\n    n_bins_from_centers = env.bin_centers.shape[0]\n    n_nodes_from_graph = len(env.connectivity.nodes)\n\n    if n_bins_from_centers != n_nodes_from_graph:\n        raise ValueError(\n            f\"bin_centers and connectivity graph are inconsistent.\\n\"\n            f\"  bin_centers has {n_bins_from_centers} rows\\n\"\n            f\"  connectivity graph has {n_nodes_from_graph} nodes\\n\"\n            f\"These must match. This indicates a layout engine bug.\"\n        )\n\n    # Validate node IDs are sequential from 0 to n_bins-1\n    node_ids = sorted(env.connectivity.nodes)\n    expected_ids = list(range(n_bins_from_centers))\n    if node_ids != expected_ids:\n        raise ValueError(\n            f\"connectivity graph node IDs are not sequential.\\n\"\n            f\"  Expected: [0, 1, ..., {n_bins_from_centers - 1}]\\n\"\n            f\"  Got: {node_ids[:10]}{'...' if len(node_ids) &gt; 10 else ''}\\n\"\n            f\"This indicates a layout engine bug.\"\n        )\n\n    # Validate bin_centers has correct shape\n    if env.bin_centers.ndim != 2:\n        raise ValueError(\n            f\"bin_centers must be 2D array (n_bins, n_dims), \"\n            f\"got shape {env.bin_centers.shape}\"\n        )\n\n    if env.bin_centers.shape[1] != n_dims:\n        raise ValueError(\n            f\"bin_centers has {env.bin_centers.shape[1]} columns, \"\n            f\"expected {n_dims} dimensions\"\n        )\n\n    # Check for duplicate edges (undirected graph should have only one edge per pair)\n    edges_set = set()\n    for u, v in env.connectivity.edges:\n        edge_tuple = tuple(sorted([u, v]))\n        if edge_tuple in edges_set:\n            raise ValueError(\n                f\"Duplicate edge found: {edge_tuple}. \"\n                f\"This indicates a layout engine bug.\"\n            )\n        edges_set.add(edge_tuple)\n\n    # Strict mode checks\n    if strict:\n        # Warn about missing units\n        if not hasattr(env, \"units\") or env.units is None:\n            warnings.warn(\n                f\"Environment '{env.name}' has no units specified. \"\n                f\"Consider setting env.units (e.g., 'cm', 'px', 'm') \"\n                f\"to prevent unit confusion in downstream analysis.\",\n                stacklevel=2,\n            )\n\n        # Warn about missing coordinate frame\n        if not hasattr(env, \"frame\") or env.frame is None:\n            warnings.warn(\n                f\"Environment '{env.name}' has no coordinate frame specified. \"\n                f\"Consider setting env.frame (e.g., 'world', 'camera_1') \"\n                f\"to prevent confusion when aligning multiple sessions.\",\n                stacklevel=2,\n            )\n</code></pre>"},{"location":"api/neurospatial/layout/engines/","title":"<code>neurospatial.layout.engines</code>","text":""},{"location":"api/neurospatial/layout/engines/#neurospatial.layout.engines","title":"engines","text":""},{"location":"api/neurospatial/layout/engines/graph/","title":"<code>neurospatial.layout.engines.graph</code>","text":""},{"location":"api/neurospatial/layout/engines/graph/#neurospatial.layout.engines.graph","title":"graph","text":""},{"location":"api/neurospatial/layout/engines/graph/#neurospatial.layout.engines.graph-classes","title":"Classes","text":""},{"location":"api/neurospatial/layout/engines/graph/#neurospatial.layout.engines.graph.GraphLayout","title":"GraphLayout","text":"<pre><code>GraphLayout()\n</code></pre> <p>               Bases: <code>_KDTreeMixin</code></p> <p>Layout defined by a user-provided graph, typically for 1D tracks.</p> <p>The graph's nodes (with 'pos' attributes) and a specified edge order are used to create a linearized representation of the space, which is then binned. Connectivity is derived from this binned structure. Uses <code>_KDTreeMixin</code> for point mapping and neighbor finding on the N-D embeddings of the linearized bin centers.</p> <p>Initialize a GraphLayout engine.</p> Source code in <code>src/neurospatial/layout/engines/graph.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize a GraphLayout engine.\"\"\"\n    self._layout_type_tag = \"Graph\"\n    self._build_params_used = {}\n    self.bin_centers = np.empty((0, 0), dtype=np.float64)\n    self.connectivity = None\n    self.dimension_ranges = None\n    self.grid_edges = None\n    self.grid_shape = None\n    self.active_mask = None\n    self.linear_bin_centers_ = None\n</code></pre>"},{"location":"api/neurospatial/layout/engines/graph/#neurospatial.layout.engines.graph.GraphLayout-attributes","title":"Attributes","text":""},{"location":"api/neurospatial/layout/engines/graph/#neurospatial.layout.engines.graph.GraphLayout.is_1d","title":"is_1d  <code>property</code>","text":"<pre><code>is_1d: bool\n</code></pre> <p>Graph layouts are treated as 1-dimensional due to linearization.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Always True, indicating a 1D linearized layout.</p>"},{"location":"api/neurospatial/layout/engines/graph/#neurospatial.layout.engines.graph.GraphLayout-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/engines/graph/#neurospatial.layout.engines.graph.GraphLayout.build","title":"build","text":"<pre><code>build(*, graph_definition: Graph, edge_order: list[tuple[Any, Any]], edge_spacing: float | Sequence[float], bin_size: float) -&gt; None\n</code></pre> <p>Build the graph-based (linearized track) layout.</p> <p>Parameters:</p> Name Type Description Default <code>graph_definition</code> <code>Graph</code> <p>The original NetworkX graph. Nodes must have a 'pos' attribute (e.g., <code>(x, y)</code> coordinates) and edges should ideally have a 'distance' attribute if not relying on Euclidean distance calculation.</p> required <code>edge_order</code> <code>List[Tuple[Any, Any]]</code> <p>An ordered sequence of edge tuples (node_id_1, node_id_2) from <code>graph_definition</code> that defines the ordering of edges in the linear space.</p> required <code>edge_spacing</code> <code>Union[float, Sequence[float]]</code> <p>Spacing (gap) to insert between consecutive edges in <code>edge_order</code> during linearization. If float, same gap for all. If sequence, specifies each gap; length must be <code>len(edge_order) - 1</code>.</p> required <code>bin_size</code> <code>float</code> <p>The desired length of each bin along the linearized space.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>graph_definition</code> is not a NetworkX graph.</p> <code>ValueError</code> <p>If <code>edge_order</code> is empty or <code>bin_size</code> is not positive.</p> Source code in <code>src/neurospatial/layout/engines/graph.py</code> <pre><code>@capture_build_params\ndef build(\n    self,\n    *,\n    graph_definition: nx.Graph,  # Original user-provided graph\n    edge_order: list[tuple[Any, Any]],\n    edge_spacing: float | Sequence[float],\n    bin_size: float,  # Linearized bin size\n) -&gt; None:\n    \"\"\"Build the graph-based (linearized track) layout.\n\n    Parameters\n    ----------\n    graph_definition : nx.Graph\n        The original NetworkX graph. Nodes must have a 'pos' attribute\n        (e.g., `(x, y)` coordinates) and edges should ideally have a\n        'distance' attribute if not relying on Euclidean distance calculation.\n    edge_order : List[Tuple[Any, Any]]\n        An ordered sequence of edge tuples (node_id_1, node_id_2) from\n        `graph_definition` that defines the ordering of edges in the\n        linear space.\n    edge_spacing : Union[float, Sequence[float]]\n        Spacing (gap) to insert between consecutive edges in `edge_order`\n        during linearization. If float, same gap for all. If sequence,\n        specifies each gap; length must be `len(edge_order) - 1`.\n    bin_size : float\n        The desired length of each bin along the linearized space.\n\n    Raises\n    ------\n    TypeError\n        If `graph_definition` is not a NetworkX graph.\n    ValueError\n        If `edge_order` is empty or `bin_size` is not positive.\n\n    \"\"\"\n    if not isinstance(graph_definition, nx.Graph):\n        raise TypeError(\"graph_definition must be a NetworkX graph.\")\n    if not edge_order:  # Empty edge_order means no path to linearize\n        raise ValueError(\"edge_order must not be empty.\")\n    if bin_size &lt;= 0:\n        raise ValueError(\"bin_size must be positive.\")\n\n    (linear_bin_centers, self.grid_edges, self.active_mask, edge_ids) = (\n        _get_graph_bins(\n            graph=graph_definition,\n            edge_order=edge_order,\n            edge_spacing=edge_spacing,\n            bin_size=bin_size,\n        )\n    )\n\n    self.linear_bin_centers_ = linear_bin_centers[self.active_mask]\n    self.bin_centers = _project_1d_to_2d(\n        self.linear_bin_centers_,\n        graph_definition,\n        edge_order,\n        edge_spacing,\n    )\n    self.grid_shape = (len(self.grid_edges[0]) - 1,)\n    self.connectivity = _create_graph_layout_connectivity_graph(\n        graph=graph_definition,\n        bin_centers_nd=self.bin_centers,\n        linear_bin_centers=self.linear_bin_centers_,\n        original_edge_ids=edge_ids,\n        edge_order=edge_order,\n    )\n    self.dimension_ranges = (\n        (\n            np.min(self.bin_centers[:, 0]),\n            np.max(self.bin_centers[:, 0]),\n        ),\n        (np.min(self.bin_centers[:, 1]), np.max(self.bin_centers[:, 1])),\n    )\n\n    # --- Build KDTree ---\n    self._build_kdtree(points_for_tree=self.bin_centers)\n</code></pre>"},{"location":"api/neurospatial/layout/engines/graph/#neurospatial.layout.engines.graph.GraphLayout.plot","title":"plot","text":"<pre><code>plot(ax: Axes | None = None, **kwargs) -&gt; matplotlib.axes.Axes\n</code></pre> <p>Plot the N-D embedding of the graph-based layout.</p> <p>Displays the original graph used for definition, the N-D positions of the binned track segments (active bin centers), and their connectivity.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Axes to plot on. If None, new figure and axes are created.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments: - <code>figsize</code> (tuple): Figure size if <code>ax</code> is None. - <code>node_kwargs</code> (dict): Kwargs for plotting original graph nodes. - <code>edge_kwargs</code> (dict): Kwargs for plotting original graph edges. - <code>bin_node_kwargs</code> (dict): Kwargs for plotting active bin center nodes. - <code>bin_edge_kwargs</code> (dict): Kwargs for plotting connectivity graph edges. - <code>show_bin_edges</code> (bool): Whether to project and plot 1D bin edges in N-D.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the layout is plotted.</p> Source code in <code>src/neurospatial/layout/engines/graph.py</code> <pre><code>def plot(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    **kwargs,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot the N-D embedding of the graph-based layout.\n\n    Displays the original graph used for definition, the N-D positions of\n    the binned track segments (active bin centers), and their connectivity.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        Axes to plot on. If None, new figure and axes are created.\n    **kwargs : Any\n        Additional keyword arguments:\n        - `figsize` (tuple): Figure size if `ax` is None.\n        - `node_kwargs` (dict): Kwargs for plotting original graph nodes.\n        - `edge_kwargs` (dict): Kwargs for plotting original graph edges.\n        - `bin_node_kwargs` (dict): Kwargs for plotting active bin center nodes.\n        - `bin_edge_kwargs` (dict): Kwargs for plotting connectivity graph edges.\n        - `show_bin_edges` (bool): Whether to project and plot 1D bin edges in N-D.\n\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the layout is plotted.\n\n    \"\"\"\n    if ax is None:\n        _, ax = plt.subplots(figsize=(7, 7))\n\n    # Draw the original graph nodes\n    original_node_pos = nx.get_node_attributes(\n        self._build_params_used[\"graph_definition\"],\n        \"pos\",\n    )\n    nx.draw_networkx_nodes(\n        self._build_params_used[\"graph_definition\"],\n        original_node_pos,\n        ax=ax,\n        node_size=300,\n        node_color=\"#1f77b4\",\n    )\n    # Draw the original graph edges\n    for node_id1, node_id2 in self._build_params_used[\"graph_definition\"].edges:\n        pos = np.stack(\n            (\n                original_node_pos[node_id1],\n                original_node_pos[node_id2],\n            ),\n        )\n        ax.plot(\n            pos[:, 0],\n            pos[:, 1],\n            color=\"gray\",\n            zorder=-1,\n            label=\"original edges\",\n        )\n\n    for node_id, pos in original_node_pos.items():\n        plt.text(\n            pos[0],\n            pos[1],\n            str(node_id),\n            ha=\"center\",\n            va=\"center\",\n            zorder=10,\n        )\n\n    # Draw the bin centers\n    bin_centers = nx.get_node_attributes(self.connectivity, \"pos\")\n    nx.draw_networkx_nodes(\n        self.connectivity,\n        bin_centers,\n        ax=ax,\n        node_size=30,\n        node_color=\"black\",\n    )\n\n    # Draw connectivity graph edges\n    if self.connectivity is not None:\n        for node_id1, node_id2 in self.connectivity.edges:\n            pos = np.stack((bin_centers[node_id1], bin_centers[node_id2]))\n            ax.plot(pos[:, 0], pos[:, 1], color=\"black\", zorder=-1)\n\n    if self.grid_edges is not None:\n        grid_line_2d = _project_1d_to_2d(\n            self.grid_edges[0],\n            self._build_params_used[\"graph_definition\"],\n            self._build_params_used[\"edge_order\"],\n            self._build_params_used[\"edge_spacing\"],\n        )\n        for grid_line in grid_line_2d:\n            ax.plot(\n                grid_line[0],\n                grid_line[1],\n                color=\"gray\",\n                marker=\"+\",\n                alpha=0.8,\n                label=\"bin edges\",\n            )\n    return ax\n</code></pre>"},{"location":"api/neurospatial/layout/engines/graph/#neurospatial.layout.engines.graph.GraphLayout.plot_linear_layout","title":"plot_linear_layout","text":"<pre><code>plot_linear_layout(ax: Axes | None = None, **kwargs) -&gt; matplotlib.axes.Axes\n</code></pre> <p>Plot the 1D linearized representation of the graph layout.</p> <p>Uses <code>track_linearization.plot_graph_as_1D</code> to display the track segments and nodes in their 1D linearized positions. Overlays the 1D bin edges from <code>self.grid_edges</code>.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Axes to plot on. If None, new figure and axes are created.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>track_linearization.plot_graph_as_1D</code> and for customizing the appearance of bin edge lines.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the 1D layout is plotted.</p> Source code in <code>src/neurospatial/layout/engines/graph.py</code> <pre><code>def plot_linear_layout(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    **kwargs,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot the 1D linearized representation of the graph layout.\n\n    Uses `track_linearization.plot_graph_as_1D` to display the track\n    segments and nodes in their 1D linearized positions. Overlays the\n    1D bin edges from `self.grid_edges`.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        Axes to plot on. If None, new figure and axes are created.\n    **kwargs : Any\n        Additional keyword arguments passed to\n        `track_linearization.plot_graph_as_1D` and for customizing\n        the appearance of bin edge lines.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the 1D layout is plotted.\n\n    \"\"\"\n    if ax is None:\n        _, ax = plt.subplots(figsize=kwargs.get(\"figsize\", (10, 3)))\n\n    plot_graph_as_1D(\n        self._build_params_used[\"graph_definition\"],\n        self._build_params_used[\"edge_order\"],\n        self._build_params_used[\"edge_spacing\"],\n        ax=ax,\n        **kwargs,\n    )\n    if self.grid_edges is not None:\n        for grid_line in self.grid_edges[0]:\n            ax.axvline(grid_line, color=\"gray\", linestyle=\"--\", alpha=0.5)\n    ax.set_title(f\"{self._layout_type_tag} Layout\")\n    ax.set_xlabel(\"Linearized Position\")\n    ax.set_ylabel(\"Bin Index\")\n\n    return ax\n</code></pre>"},{"location":"api/neurospatial/layout/engines/graph/#neurospatial.layout.engines.graph.GraphLayout.to_linear","title":"to_linear","text":"<pre><code>to_linear(data_points: NDArray[float64]) -&gt; NDArray[np.float64]\n</code></pre> <p>Convert N-D points to 1D linearized coordinates along the track.</p> <p>Uses <code>track_linearization.get_linearized_position</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_points</code> <code>(NDArray[float64], shape(n_points, n_dims))</code> <p>N-D points to linearize.</p> required <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_points))</code> <p>1D linearized coordinates. NaNs may be returned for points far from the track.</p> Source code in <code>src/neurospatial/layout/engines/graph.py</code> <pre><code>def to_linear(self, data_points: NDArray[np.float64]) -&gt; NDArray[np.float64]:\n    \"\"\"Convert N-D points to 1D linearized coordinates along the track.\n\n    Uses `track_linearization.get_linearized_position`.\n\n    Parameters\n    ----------\n    data_points : NDArray[np.float64], shape (n_points, n_dims)\n        N-D points to linearize.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_points,)\n        1D linearized coordinates. NaNs may be returned for points\n        far from the track.\n\n    \"\"\"\n    result = _get_linearized_position(\n        data_points,\n        self._build_params_used[\"graph_definition\"],\n        self._build_params_used[\"edge_order\"],\n        self._build_params_used[\"edge_spacing\"],\n    ).linear_position.to_numpy()\n    return np.asarray(result, dtype=np.float64)\n</code></pre>"},{"location":"api/neurospatial/layout/engines/graph/#neurospatial.layout.engines.graph.GraphLayout.linear_to_nd","title":"linear_to_nd","text":"<pre><code>linear_to_nd(linear_coordinates: NDArray[float64]) -&gt; NDArray[np.float64]\n</code></pre> <p>Map 1D linearized coordinates back to N-D coordinates on the track graph.</p> <p>Parameters:</p> Name Type Description Default <code>linear_coordinates</code> <code>(NDArray[float64], shape(n_points))</code> <p>1D linearized coordinates to map.</p> required <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_points, n_dims))</code> <p>N-D coordinates corresponding to the input linear positions.</p> Source code in <code>src/neurospatial/layout/engines/graph.py</code> <pre><code>def linear_to_nd(\n    self,\n    linear_coordinates: NDArray[np.float64],\n) -&gt; NDArray[np.float64]:\n    \"\"\"Map 1D linearized coordinates back to N-D coordinates on the track graph.\n\n    Parameters\n    ----------\n    linear_coordinates : NDArray[np.float64], shape (n_points,)\n        1D linearized coordinates to map.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_points, n_dims)\n        N-D coordinates corresponding to the input linear positions.\n\n    \"\"\"\n    return _project_1d_to_2d(\n        linear_coordinates,\n        self._build_params_used[\"graph_definition\"],\n        self._build_params_used[\"edge_order\"],\n        self._build_params_used[\"edge_spacing\"],\n    )\n</code></pre>"},{"location":"api/neurospatial/layout/engines/graph/#neurospatial.layout.engines.graph.GraphLayout.linear_point_to_bin_ind","title":"linear_point_to_bin_ind","text":"<pre><code>linear_point_to_bin_ind(data_points: NDArray[float64]) -&gt; NDArray[np.int_]\n</code></pre> <p>Map 1D linearized positions to active 1D bin indices.</p> <p>Parameters:</p> Name Type Description Default <code>data_points</code> <code>(NDArray[float64], shape(n_points))</code> <p>1D linearized positions.</p> required <p>Returns:</p> Type Description <code>(NDArray[int_], shape(n_points))</code> <p>Indices of the active 1D bins corresponding to each linear position. Returns -1 for positions outside active bins or in gaps. Note: These are indices relative to the set of active 1D bins, not indices into the full <code>linear_bin_centers_all</code> array.</p> Source code in <code>src/neurospatial/layout/engines/graph.py</code> <pre><code>def linear_point_to_bin_ind(\n    self,\n    data_points: NDArray[np.float64],\n) -&gt; NDArray[np.int_]:\n    \"\"\"Map 1D linearized positions to active 1D bin indices.\n\n    Parameters\n    ----------\n    data_points : NDArray[np.float64], shape (n_points,)\n        1D linearized positions.\n\n    Returns\n    -------\n    NDArray[np.int_], shape (n_points,)\n        Indices of the active 1D bins corresponding to each linear position.\n        Returns -1 for positions outside active bins or in gaps.\n        Note: These are indices relative to the set of *active* 1D bins,\n        not indices into the full `linear_bin_centers_all` array.\n\n    \"\"\"\n    if self.grid_edges is None:\n        raise RuntimeError(\"grid_edges not available\")\n    result = _find_bin_for_linear_position(\n        data_points,\n        bin_edges=self.grid_edges[0],\n        active_mask=self.active_mask,\n    )\n    # Ensure we return NDArray, not int\n    if isinstance(result, int):\n        return np.array([result], dtype=int)\n    return result\n</code></pre>"},{"location":"api/neurospatial/layout/engines/graph/#neurospatial.layout.engines.graph.GraphLayout.bin_sizes","title":"bin_sizes","text":"<pre><code>bin_sizes() -&gt; NDArray[np.float64]\n</code></pre> <p>Return the length of each active 1D bin along the linearized track.</p> <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_active_bins))</code> <p>Array containing the length of each active linearized bin.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>grid_edges</code> or <code>active_mask</code> is not populated.</p> Source code in <code>src/neurospatial/layout/engines/graph.py</code> <pre><code>def bin_sizes(self) -&gt; NDArray[np.float64]:\n    \"\"\"Return the length of each active 1D bin along the linearized track.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_active_bins,)\n        Array containing the length of each active linearized bin.\n\n    Raises\n    ------\n    RuntimeError\n        If `grid_edges` or `active_mask` is not populated.\n\n    \"\"\"\n    if self.grid_edges is None or self.active_mask is None:  # pragma: no cover\n        raise RuntimeError(\"Layout not built; grid_edges or active_mask missing.\")\n    if not self.grid_edges or self.grid_edges[0].size &lt;= 1:  # pragma: no cover\n        raise ValueError(\n            \"grid_edges (1D) are not properly defined for length calculation.\",\n        )\n\n    all_1d_bin_lengths = np.diff(self.grid_edges[0])\n    return all_1d_bin_lengths[self.active_mask]\n</code></pre>"},{"location":"api/neurospatial/layout/engines/graph/#neurospatial.layout.engines.graph-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/engines/hexagonal/","title":"<code>neurospatial.layout.engines.hexagonal</code>","text":""},{"location":"api/neurospatial/layout/engines/hexagonal/#neurospatial.layout.engines.hexagonal","title":"hexagonal","text":""},{"location":"api/neurospatial/layout/engines/hexagonal/#neurospatial.layout.engines.hexagonal-classes","title":"Classes","text":""},{"location":"api/neurospatial/layout/engines/hexagonal/#neurospatial.layout.engines.hexagonal.HexagonalLayout","title":"HexagonalLayout","text":"<pre><code>HexagonalLayout()\n</code></pre> <p>2D layout that tiles a rectangular area with a hexagonal lattice.</p> <p>Bin centers are the centers of the hexagons. Hexagons are connected to their immediate neighbors. Active hexagons can be inferred from data sample occupancy.</p> <p>Initialize a HexagonalLayout engine.</p> Source code in <code>src/neurospatial/layout/engines/hexagonal.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize a HexagonalLayout engine.\"\"\"\n    self._layout_type_tag = \"Hexagonal\"\n    self._build_params_used = {}\n    self.bin_centers = np.empty((0, 2))\n    self.connectivity = None\n    self.dimension_ranges = None\n    self.grid_edges = ()\n    self.grid_shape = None\n    self.active_mask = None\n    self.hexagon_width = None\n    self.hex_radius_ = None\n    self.hex_orientation_ = None\n    self.grid_offset_x_ = None\n    self.grid_offset_y_ = None\n    self._source_flat_to_active_id_map = None\n</code></pre>"},{"location":"api/neurospatial/layout/engines/hexagonal/#neurospatial.layout.engines.hexagonal.HexagonalLayout-attributes","title":"Attributes","text":""},{"location":"api/neurospatial/layout/engines/hexagonal/#neurospatial.layout.engines.hexagonal.HexagonalLayout.is_1d","title":"is_1d  <code>property</code>","text":"<pre><code>is_1d: bool\n</code></pre> <p>Hexagonal layouts are 2-dimensional.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Always False, indicating a 2D layout.</p>"},{"location":"api/neurospatial/layout/engines/hexagonal/#neurospatial.layout.engines.hexagonal.HexagonalLayout-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/engines/hexagonal/#neurospatial.layout.engines.hexagonal.HexagonalLayout.build","title":"build","text":"<pre><code>build(*, hexagon_width: float, dimension_ranges: tuple[tuple[float, float], tuple[float, float]] | None = None, data_samples: NDArray[float64] | None = None, infer_active_bins: bool = True, bin_count_threshold: int = 0) -&gt; None\n</code></pre> <p>Build the hexagonal grid layout.</p> <p>Parameters:</p> Name Type Description Default <code>hexagon_width</code> <code>float</code> <p>The width of the hexagons (distance between parallel sides).</p> required <code>dimension_ranges</code> <code>Optional[Tuple[Tuple[float, float], Tuple[float, float]]]</code> <p>Explicit <code>[(min_x, max_x), (min_y, max_y)]</code> for the area to tile. If None (default), range is inferred from <code>data_samples</code>.</p> <code>None</code> <code>data_samples</code> <code>(Optional[NDArray[float64]], shape(n_samples, 2))</code> <p>2D data used to infer <code>dimension_ranges</code> (if not provided) and/or to infer active hexagons (if <code>infer_active_bins</code> is True). Defaults to None.</p> <code>None</code> <code>infer_active_bins</code> <code>bool</code> <p>If True and <code>data_samples</code> are provided, infers active hexagons based on occupancy. If False, all hexagons within the defined area are considered active.</p> <code>True</code> <code>bin_count_threshold</code> <code>int</code> <p>If <code>infer_active_bins</code> is True, the minimum number of samples a hexagon must contain to be considered active.</p> <code>0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>dimension_ranges</code> and <code>data_samples</code> are both None, or if <code>hexagon_width</code> is not positive.</p> Source code in <code>src/neurospatial/layout/engines/hexagonal.py</code> <pre><code>@capture_build_params\ndef build(\n    self,\n    *,\n    hexagon_width: float,\n    dimension_ranges: tuple[tuple[float, float], tuple[float, float]] | None = None,\n    data_samples: NDArray[np.float64] | None = None,\n    infer_active_bins: bool = True,\n    bin_count_threshold: int = 0,\n) -&gt; None:\n    \"\"\"Build the hexagonal grid layout.\n\n    Parameters\n    ----------\n    hexagon_width : float\n        The width of the hexagons (distance between parallel sides).\n    dimension_ranges : Optional[Tuple[Tuple[float,float], Tuple[float,float]]], optional\n        Explicit `[(min_x, max_x), (min_y, max_y)]` for the area to tile.\n        If None (default), range is inferred from `data_samples`.\n    data_samples : Optional[NDArray[np.float64]], shape (n_samples, 2), optional\n        2D data used to infer `dimension_ranges` (if not provided) and/or\n        to infer active hexagons (if `infer_active_bins` is True).\n        Defaults to None.\n    infer_active_bins : bool, default=True\n        If True and `data_samples` are provided, infers active hexagons\n        based on occupancy. If False, all hexagons within the defined\n        area are considered active.\n    bin_count_threshold : int, default=0\n        If `infer_active_bins` is True, the minimum number of samples a\n        hexagon must contain to be considered active.\n\n    Raises\n    ------\n    ValueError\n        If `dimension_ranges` and `data_samples` are both None, or if\n        `hexagon_width` is not positive.\n\n    \"\"\"\n    self.hexagon_width = hexagon_width\n    (\n        full_grid_bin_centers,\n        self.grid_shape,\n        self.hex_radius_,\n        self.hex_orientation_,\n        self.grid_offset_x_,\n        self.grid_offset_y_,\n        self.dimension_ranges,\n    ) = _create_hex_grid(\n        data_samples=data_samples,\n        dimension_range=dimension_ranges,\n        hexagon_width=self.hexagon_width,\n    )\n    if infer_active_bins and data_samples is not None:\n        active_bin_original_flat_indices = _infer_active_bins_from_hex_grid(\n            data_samples=data_samples,\n            centers_shape=self.grid_shape,\n            hex_radius=self.hex_radius_,\n            min_x=self.grid_offset_x_,\n            min_y=self.grid_offset_y_,\n            bin_count_threshold=bin_count_threshold,\n        )\n    else:\n        active_bin_original_flat_indices = np.arange(len(full_grid_bin_centers))\n\n    nd_active_mask = np.zeros(self.grid_shape, dtype=bool).ravel()\n    nd_active_mask[active_bin_original_flat_indices] = True\n    self.active_mask = nd_active_mask.reshape(self.grid_shape)\n\n    self.bin_centers = full_grid_bin_centers[active_bin_original_flat_indices]\n\n    self.connectivity = _create_hex_connectivity_graph(\n        active_original_flat_indices=active_bin_original_flat_indices,\n        full_grid_bin_centers=full_grid_bin_centers,\n        centers_shape=self.grid_shape,\n    )\n\n    self._source_flat_to_active_id_map = {\n        data[\"source_grid_flat_index\"]: node_id\n        for node_id, data in self.connectivity.nodes(data=True)\n    }\n</code></pre>"},{"location":"api/neurospatial/layout/engines/hexagonal/#neurospatial.layout.engines.hexagonal.HexagonalLayout.plot","title":"plot","text":"<pre><code>plot(ax: Axes | None = None, **kwargs) -&gt; matplotlib.axes.Axes\n</code></pre> <p>Plot the hexagonal layout.</p> <p>Displays active hexagons and their connectivity graph.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Axes to plot on. If None, new figure and axes are created.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments: - <code>show_hexagons</code> (bool, default=True): Whether to draw hexagon cells. - <code>hexagon_kwargs</code> (dict): Kwargs for <code>matplotlib.patches.RegularPolygon</code>. - Other kwargs are passed to <code>_generic_graph_plot</code> for the graph.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the layout is plotted.</p> Source code in <code>src/neurospatial/layout/engines/hexagonal.py</code> <pre><code>def plot(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    **kwargs,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot the hexagonal layout.\n\n    Displays active hexagons and their connectivity graph.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        Axes to plot on. If None, new figure and axes are created.\n    **kwargs : Any\n        Additional keyword arguments:\n        - `show_hexagons` (bool, default=True): Whether to draw hexagon cells.\n        - `hexagon_kwargs` (dict): Kwargs for `matplotlib.patches.RegularPolygon`.\n        - Other kwargs are passed to `_generic_graph_plot` for the graph.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the layout is plotted.\n\n    \"\"\"\n    ax = _generic_graph_plot(\n        ax=ax,\n        graph=self.connectivity,\n        name=self._layout_type_tag,\n        **kwargs,\n    )\n\n    if (\n        kwargs.get(\"show_hexagons\", True)\n        and self.hex_radius_ is not None\n        and self.bin_centers is not None\n        and self.bin_centers.shape[0] &gt; 0\n    ):\n        hex_kws = kwargs.get(\n            \"hexagon_kwargs\",\n            {\n                \"edgecolor\": \"gray\",\n                \"facecolor\": \"none\",\n                \"alpha\": 0.5,\n                \"linewidth\": 0.5,\n            },\n        )\n\n        ax.scatter(\n            self.bin_centers[:, 0],\n            self.bin_centers[:, 1],\n            s=1,\n            label=\"hexagonal grid\",\n        )\n        patches = [\n            RegularPolygon(\n                (x, y),\n                numVertices=6,\n                radius=self.hex_radius_,\n                orientation=self.hex_orientation_,\n            )\n            for x, y in self.bin_centers\n        ]\n\n        collection = PatchCollection(patches, **hex_kws)\n        ax.add_collection(collection)\n        ax.plot(\n            self.bin_centers[:, 0],\n            self.bin_centers[:, 1],\n            marker=\"o\",\n            markersize=1,\n            color=\"blue\",\n            linestyle=\"None\",\n            label=\"midpoint\",\n        )\n\n        ax.set_title(f\"{self._layout_type_tag} Layout\")\n        padding = 1.1 * self.hex_radius_\n        if self.dimension_ranges is not None:\n            ax.set_xlim(\n                (\n                    self.dimension_ranges[0][0] - padding,\n                    self.dimension_ranges[0][1] + padding,\n                ),\n            )\n            ax.set_ylim(\n                (\n                    self.dimension_ranges[1][0] - padding,\n                    self.dimension_ranges[1][1] + padding,\n                ),\n            )\n        ax.set_aspect(\"equal\", adjustable=\"box\")\n    return ax\n</code></pre>"},{"location":"api/neurospatial/layout/engines/hexagonal/#neurospatial.layout.engines.hexagonal.HexagonalLayout.point_to_bin_index","title":"point_to_bin_index","text":"<pre><code>point_to_bin_index(points: NDArray[float64]) -&gt; NDArray[np.int_]\n</code></pre> <p>Map 2D points to active hexagonal bin indices.</p> <p>Uses specialized logic to determine which hexagon each point falls into, then maps this to an active bin index.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>(NDArray[float64], shape(n_points, 2))</code> <p>2D points to map.</p> required <p>Returns:</p> Type Description <code>(NDArray[int_], shape(n_points))</code> <p>Active bin indices (0 to N-1). -1 for points not in an active hexagon.</p> Source code in <code>src/neurospatial/layout/engines/hexagonal.py</code> <pre><code>def point_to_bin_index(self, points: NDArray[np.float64]) -&gt; NDArray[np.int_]:\n    \"\"\"Map 2D points to active hexagonal bin indices.\n\n    Uses specialized logic to determine which hexagon each point falls into,\n    then maps this to an active bin index.\n\n    Parameters\n    ----------\n    points : NDArray[np.float64], shape (n_points, 2)\n        2D points to map.\n\n    Returns\n    -------\n    NDArray[np.int_], shape (n_points,)\n        Active bin indices (0 to N-1). -1 for points not in an active hexagon.\n\n    \"\"\"\n    if (\n        self.grid_offset_x_ is None\n        or self.grid_offset_y_ is None\n        or self.hex_radius_ is None\n        or self.grid_shape is None\n        or self._source_flat_to_active_id_map is None\n    ):\n        # This can happen if build() failed or was incomplete (e.g. no active bins)\n        warnings.warn(\n            \"HexagonalLayout is not fully initialized or has no active bins. \"\n            \"Cannot map points to bin indices.\",\n            RuntimeWarning,\n        )\n        return np.full(points.shape[0], -1, dtype=int)\n\n    # grid_shape is guaranteed to be tuple[int, int] for hexagonal layouts\n    assert self.grid_shape is not None and len(self.grid_shape) == 2\n    centers_shape_2d: tuple[int, int] = (self.grid_shape[0], self.grid_shape[1])\n\n    original_flat_indices = _points_to_hex_bin_ind(\n        points=points,\n        grid_offset_x=self.grid_offset_x_,\n        grid_offset_y=self.grid_offset_y_,\n        hex_radius=self.hex_radius_,\n        centers_shape=centers_shape_2d,\n    )\n    return np.array(\n        [\n            self._source_flat_to_active_id_map.get(idx, -1)\n            for idx in original_flat_indices\n        ],\n        dtype=int,\n    )\n</code></pre>"},{"location":"api/neurospatial/layout/engines/hexagonal/#neurospatial.layout.engines.hexagonal.HexagonalLayout.bin_sizes","title":"bin_sizes","text":"<pre><code>bin_sizes() -&gt; NDArray[np.float64]\n</code></pre> <p>Calculate the area of each hexagonal bin.</p> <p>All active hexagons are assumed to have the same area.</p> <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_active_bins))</code> <p>Array containing the constant area for each active hexagonal bin.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>hex_radius_</code> or <code>bin_centers</code> is not populated.</p> Source code in <code>src/neurospatial/layout/engines/hexagonal.py</code> <pre><code>def bin_sizes(self) -&gt; NDArray[np.float64]:\n    \"\"\"Calculate the area of each hexagonal bin.\n\n    All active hexagons are assumed to have the same area.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_active_bins,)\n        Array containing the constant area for each active hexagonal bin.\n\n    Raises\n    ------\n    RuntimeError\n        If `hex_radius_` or `bin_centers` is not populated.\n\n    \"\"\"\n    if self.hex_radius_ is None or self.bin_centers is None:  # pragma: no cover\n        raise RuntimeError(\"Layout not built; hex_radius_ or bin_centers missing.\")\n\n    # Area of a regular hexagon: (3 * sqrt(3) / 2) * side_length^2\n    # For pointy-top hexagons, side_length (s) is equal to hex_radius_ (R, center to vertex).\n    single_hex_area = 3.0 * np.sqrt(3.0) / 2.0 * self.hex_radius_**2.0\n    return np.full(self.bin_centers.shape[0], single_hex_area)\n</code></pre>"},{"location":"api/neurospatial/layout/engines/hexagonal/#neurospatial.layout.engines.hexagonal-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/engines/image_mask/","title":"<code>neurospatial.layout.engines.image_mask</code>","text":""},{"location":"api/neurospatial/layout/engines/image_mask/#neurospatial.layout.engines.image_mask","title":"image_mask","text":""},{"location":"api/neurospatial/layout/engines/image_mask/#neurospatial.layout.engines.image_mask-classes","title":"Classes","text":""},{"location":"api/neurospatial/layout/engines/image_mask/#neurospatial.layout.engines.image_mask.ImageMaskLayout","title":"ImageMaskLayout","text":"<pre><code>ImageMaskLayout()\n</code></pre> <p>               Bases: <code>_GridMixin</code></p> <p>2D layout derived from a boolean image mask.</p> <p>Each <code>True</code> pixel in the input <code>image_mask</code> corresponds to an active bin in the environment. The spatial scale of these pixel-bins is determined by <code>bin_size</code>. Inherits grid functionalities from <code>_GridMixin</code>.</p> <p>Initialize an ImageMaskLayout engine.</p> Source code in <code>src/neurospatial/layout/engines/image_mask.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize an ImageMaskLayout engine.\"\"\"\n    self._layout_type_tag = \"ImageMask\"\n    self._build_params_used = {}\n    self.bin_centers = np.empty((0, 2), dtype=np.float64)\n    self.connectivity = None\n    self.dimension_ranges = None\n    self.grid_edges = None\n    self.grid_shape = None\n    self.active_mask = None\n</code></pre>"},{"location":"api/neurospatial/layout/engines/image_mask/#neurospatial.layout.engines.image_mask.ImageMaskLayout-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/engines/image_mask/#neurospatial.layout.engines.image_mask.ImageMaskLayout.build","title":"build","text":"<pre><code>build(*, image_mask: NDArray[bool_], bin_size: float | tuple[float, float] = 1.0, connect_diagonal_neighbors: bool = True) -&gt; None\n</code></pre> <p>Build the layout from a 2D image mask.</p> <p>Parameters:</p> Name Type Description Default <code>image_mask</code> <code>(NDArray[bool_], shape(n_rows, n_cols))</code> <p>A 2D boolean array where <code>True</code> pixels define active bins.</p> required <code>bin_size</code> <code>Union[float, Tuple[float, float]]</code> <p>The spatial size of each pixel. If float: pixels are square (size x size). If tuple (width, height): specifies pixel_width and pixel_height.</p> <code>1.0</code> <code>connect_diagonal_neighbors</code> <code>bool</code> <p>If True, connect diagonally adjacent active pixel-bins.</p> <code>True</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>image_mask</code> is not a NumPy array.</p> <code>ValueError</code> <p>If <code>image_mask</code> is not 2D, not boolean, or <code>bin_size</code> is invalid, or if <code>image_mask</code> contains no True values or non-finite values.</p> Source code in <code>src/neurospatial/layout/engines/image_mask.py</code> <pre><code>@capture_build_params\ndef build(\n    self,\n    *,\n    image_mask: NDArray[np.bool_],  # Defines candidate pixels\n    bin_size: float | tuple[float, float] = 1.0,  # one pixel\n    connect_diagonal_neighbors: bool = True,\n) -&gt; None:\n    \"\"\"Build the layout from a 2D image mask.\n\n    Parameters\n    ----------\n    image_mask : NDArray[np.bool_], shape (n_rows, n_cols)\n        A 2D boolean array where `True` pixels define active bins.\n    bin_size : Union[float, Tuple[float, float]], default=1.0\n        The spatial size of each pixel.\n        If float: pixels are square (size x size).\n        If tuple (width, height): specifies pixel_width and pixel_height.\n    connect_diagonal_neighbors : bool, default=True\n        If True, connect diagonally adjacent active pixel-bins.\n\n    Raises\n    ------\n    TypeError\n        If `image_mask` is not a NumPy array.\n    ValueError\n        If `image_mask` is not 2D, not boolean, or `bin_size` is invalid,\n        or if `image_mask` contains no True values or non-finite values.\n\n    \"\"\"\n    if not isinstance(image_mask, np.ndarray):\n        raise TypeError(\"image_mask must be a numpy array.\")\n    if image_mask.ndim != 2:\n        raise ValueError(\"image_mask must be a 2D array.\")\n    if not np.issubdtype(image_mask.dtype, np.bool_):\n        raise ValueError(\"image_mask must be a boolean array.\")\n\n    # Validate bin_size\n    if isinstance(bin_size, tuple):\n        if any(s &lt;= 0 for s in bin_size):\n            raise ValueError(\"bin_size must be positive.\")\n    else:\n        if bin_size &lt;= 0:\n            raise ValueError(\"bin_size must be positive.\")\n    if not np.any(image_mask):\n        raise ValueError(\"image_mask must contain at least one True value.\")\n    if not np.all(np.isfinite(image_mask)):\n        raise ValueError(\"image_mask must not contain NaN or Inf values.\")\n\n    # Determine bin_sizes for x and y (units per pixel)\n    bin_size_x: float\n    bin_size_y: float\n    if isinstance(bin_size, (float, int, np.number)):\n        bin_size_x = float(bin_size)\n        bin_size_y = float(bin_size)\n    elif isinstance(bin_size, (list, tuple, np.ndarray)) and len(bin_size) == 2:\n        bin_size_x = float(bin_size[0])  # width of pixel\n        bin_size_y = float(bin_size[1])  # height of pixel\n    else:\n        raise ValueError(\n            \"bin_size for ImageMaskLayout must be a float or a 2-element sequence (width, height).\",\n        )\n\n    if bin_size_x &lt;= 0 or bin_size_y &lt;= 0:\n        raise ValueError(\"bin_size components must be positive.\")\n\n    n_rows, n_cols = image_mask.shape\n    self.grid_shape = (n_rows, n_cols)  # Note: (rows, cols) often (y_dim, x_dim)\n    y_edges = np.arange(n_rows + 1) * bin_size_y\n    x_edges = np.arange(n_cols + 1) * bin_size_x\n    self.grid_edges = (y_edges, x_edges)\n    self.dimension_ranges = (\n        (x_edges[0], x_edges[-1]),\n        (y_edges[0], y_edges[-1]),\n    )\n\n    y_centers = (np.arange(n_rows) + 0.5) * bin_size_y\n    x_centers = (np.arange(n_cols) + 0.5) * bin_size_x\n    xv, yv = np.meshgrid(\n        x_centers,\n        y_centers,\n        indexing=\"xy\",\n    )  # x is cols, y is rows\n    full_grid_bin_centers = np.stack(\n        (\n            yv.ravel(),\n            xv.ravel(),\n        ),\n        axis=1,\n    )\n\n    self.active_mask = image_mask\n    self.bin_centers = full_grid_bin_centers[self.active_mask.ravel()]\n    self.connectivity = _create_regular_grid_connectivity_graph(\n        full_grid_bin_centers=full_grid_bin_centers,\n        active_mask_nd=self.active_mask,\n        grid_shape=self.grid_shape,\n        connect_diagonal=connect_diagonal_neighbors,\n    )\n</code></pre>"},{"location":"api/neurospatial/layout/engines/image_mask/#neurospatial.layout.engines.image_mask-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/engines/masked_grid/","title":"<code>neurospatial.layout.engines.masked_grid</code>","text":""},{"location":"api/neurospatial/layout/engines/masked_grid/#neurospatial.layout.engines.masked_grid","title":"masked_grid","text":""},{"location":"api/neurospatial/layout/engines/masked_grid/#neurospatial.layout.engines.masked_grid-classes","title":"Classes","text":""},{"location":"api/neurospatial/layout/engines/masked_grid/#neurospatial.layout.engines.masked_grid.MaskedGridLayout","title":"MaskedGridLayout","text":"<pre><code>MaskedGridLayout()\n</code></pre> <p>               Bases: <code>_GridMixin</code></p> <p>Layout from a pre-defined N-D boolean mask and explicit grid edges.</p> <p>Allows for precise specification of active bins in an N-dimensional grid by providing the complete grid structure (<code>grid_edges</code>) and a mask (<code>active_mask</code>) that designates which cells of that grid are active. Inherits grid functionalities from <code>_GridMixin</code>.</p> <p>Initialize a MaskedGridLayout engine.</p> Source code in <code>src/neurospatial/layout/engines/masked_grid.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize a MaskedGridLayout engine.\"\"\"\n    self._layout_type_tag = \"MaskedGrid\"\n    self._build_params_used = {}\n    self.bin_centers = np.empty((0, 2), dtype=np.float64)\n    self.connectivity = None\n    self.dimension_ranges = None\n    self.grid_edges = None\n    self.grid_shape = None\n    self.active_mask = None\n    self.bin_size_ = None\n</code></pre>"},{"location":"api/neurospatial/layout/engines/masked_grid/#neurospatial.layout.engines.masked_grid.MaskedGridLayout-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/engines/masked_grid/#neurospatial.layout.engines.masked_grid.MaskedGridLayout.build","title":"build","text":"<pre><code>build(*, active_mask: NDArray[bool_], grid_edges: tuple[NDArray[float64], ...], connect_diagonal_neighbors: bool = True) -&gt; None\n</code></pre> <p>Build the layout from a mask and grid edges.</p> <p>Parameters:</p> Name Type Description Default <code>active_mask</code> <code>NDArray[bool_]</code> <p>N-dimensional boolean array where <code>True</code> indicates an active bin. Its shape must correspond to the number of bins defined by <code>grid_edges</code> (i.e., <code>tuple(len(e)-1 for e in grid_edges)</code>).</p> required <code>grid_edges</code> <code>Tuple[NDArray[float64], ...]</code> <p>A tuple where each element is a 1D NumPy array of bin edge positions for that dimension, defining the full grid structure.</p> required <code>connect_diagonal_neighbors</code> <code>bool</code> <p>If True, connect diagonally adjacent active grid cells.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>active_mask</code> shape does not match <code>grid_edges</code> definition, or if <code>grid_edges</code> are invalid.</p> Source code in <code>src/neurospatial/layout/engines/masked_grid.py</code> <pre><code>@capture_build_params\ndef build(\n    self,\n    *,\n    active_mask: NDArray[np.bool_],  # User's N-D definition mask\n    grid_edges: tuple[NDArray[np.float64], ...],\n    connect_diagonal_neighbors: bool = True,\n) -&gt; None:\n    \"\"\"Build the layout from a mask and grid edges.\n\n    Parameters\n    ----------\n    active_mask : NDArray[np.bool_]\n        N-dimensional boolean array where `True` indicates an active bin.\n        Its shape must correspond to the number of bins defined by `grid_edges`\n        (i.e., `tuple(len(e)-1 for e in grid_edges)`).\n    grid_edges : Tuple[NDArray[np.float64], ...]\n        A tuple where each element is a 1D NumPy array of bin edge\n        positions for that dimension, defining the full grid structure.\n    connect_diagonal_neighbors : bool, default=True\n        If True, connect diagonally adjacent active grid cells.\n\n    Raises\n    ------\n    ValueError\n        If `active_mask` shape does not match `grid_edges` definition,\n        or if `grid_edges` are invalid.\n\n    \"\"\"\n    self.active_mask = active_mask\n    self.grid_edges = grid_edges\n    self.grid_shape = tuple(len(edge) - 1 for edge in grid_edges)\n\n    if self.active_mask.shape != self.grid_shape:\n        raise ValueError(\n            f\"active_mask shape {self.active_mask.shape} must match \"\n            f\"the shape implied by grid_edges {self.grid_shape}.\",\n        )\n\n    # Create full_grid_bin_centers as (N_total_bins, N_dims) array\n    centers_per_dim = [get_centers(edge_dim) for edge_dim in self.grid_edges]\n    mesh_centers_list = np.meshgrid(*centers_per_dim, indexing=\"ij\", sparse=False)\n    full_grid_bin_centers = np.stack(\n        [c.ravel() for c in mesh_centers_list],\n        axis=-1,\n    )\n\n    self.bin_size_ = np.array(\n        [np.diff(edge_dim)[0] for edge_dim in self.grid_edges],\n        dtype=np.float64,\n    )\n\n    self.dimension_ranges = tuple(\n        (edge_dim[0], edge_dim[-1]) for edge_dim in self.grid_edges\n    )\n    self.bin_centers = full_grid_bin_centers[self.active_mask.ravel()]\n\n    self.connectivity = _create_regular_grid_connectivity_graph(\n        full_grid_bin_centers=full_grid_bin_centers,\n        active_mask_nd=self.active_mask,\n        grid_shape=self.grid_shape,\n        connect_diagonal=connect_diagonal_neighbors,\n    )\n</code></pre>"},{"location":"api/neurospatial/layout/engines/masked_grid/#neurospatial.layout.engines.masked_grid-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/engines/regular_grid/","title":"<code>neurospatial.layout.engines.regular_grid</code>","text":""},{"location":"api/neurospatial/layout/engines/regular_grid/#neurospatial.layout.engines.regular_grid","title":"regular_grid","text":""},{"location":"api/neurospatial/layout/engines/regular_grid/#neurospatial.layout.engines.regular_grid-classes","title":"Classes","text":""},{"location":"api/neurospatial/layout/engines/regular_grid/#neurospatial.layout.engines.regular_grid.RegularGridLayout","title":"RegularGridLayout","text":"<pre><code>RegularGridLayout()\n</code></pre> <p>               Bases: <code>_GridMixin</code></p> <p>Axis-aligned rectangular N-D grid layout.</p> <p>Discretizes space into a uniform N-dimensional grid. Can infer the active portion of this grid based on provided data samples using occupancy and morphological operations. Inherits grid-based functionalities from <code>_GridMixin</code>.</p> <p>Initialize a RegularGridLayout engine.</p> Source code in <code>src/neurospatial/layout/engines/regular_grid.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize a RegularGridLayout engine.\"\"\"\n    self._layout_type_tag = \"RegularGrid\"\n    self._build_params_used = {}\n    # Initialize all protocol attributes to satisfy type checkers, even if None\n    self.bin_centers = np.empty((0, 0))\n    self.connectivity = None\n    self.dimension_ranges = None\n    self.grid_edges = None\n    self.grid_shape = None\n    self.active_mask = None\n</code></pre>"},{"location":"api/neurospatial/layout/engines/regular_grid/#neurospatial.layout.engines.regular_grid.RegularGridLayout-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/engines/regular_grid/#neurospatial.layout.engines.regular_grid.RegularGridLayout.build","title":"build","text":"<pre><code>build(*, bin_size: float | Sequence[float], dimension_ranges: Sequence[tuple[float, float]] | None = None, data_samples: NDArray[float64] | None = None, add_boundary_bins: bool = False, infer_active_bins: bool = True, dilate: bool = True, fill_holes: bool = True, close_gaps: bool = True, bin_count_threshold: int = 0, connect_diagonal_neighbors: bool = True) -&gt; None\n</code></pre> <p>Build the regular N-D grid layout.</p> <p>Parameters:</p> Name Type Description Default <code>bin_size</code> <code>Union[float, Sequence[float]]</code> <p>Desired size of bins in each dimension.</p> required <code>dimension_ranges</code> <code>Optional[Sequence[Tuple[float, float]]]</code> <p>Explicit <code>[(min_d0, max_d0), ..., (min_dN-1, max_dN-1)]</code> for the grid. If None, range is inferred from <code>data_samples</code>.</p> <code>None</code> <code>data_samples</code> <code>(Optional[NDArray[float64]], shape(n_samples, n_dims))</code> <p>Data used to infer <code>dimension_ranges</code> (if not provided) and/or to infer active bins (if <code>infer_active_bins</code> is True).</p> <code>None</code> <code>add_boundary_bins</code> <code>bool</code> <p>If True, adds one bin on each side of the grid, extending the range.</p> <code>False</code> <code>infer_active_bins</code> <code>bool</code> <p>If True and <code>data_samples</code> are provided, infers active bins based on occupancy and morphological operations.</p> <code>True</code> <code>dilate</code> <code>bool</code> <p>If <code>infer_active_bins</code> is True, dilates the inferred active area.</p> <code>False</code> <code>fill_holes</code> <code>bool</code> <p>If <code>infer_active_bins</code> is True, fills holes in the inferred active area.</p> <code>False</code> <code>close_gaps</code> <code>bool</code> <p>If <code>infer_active_bins</code> is True, closes gaps in the inferred active area.</p> <code>False</code> <code>bin_count_threshold</code> <code>int</code> <p>If <code>infer_active_bins</code> is True, minimum samples in a bin to be considered initially occupied.</p> <code>0</code> <code>connect_diagonal_neighbors</code> <code>bool</code> <p>If True, connects diagonal neighbors in the connectivity graph.</p> <code>True</code> Source code in <code>src/neurospatial/layout/engines/regular_grid.py</code> <pre><code>@capture_build_params\ndef build(\n    self,\n    *,\n    bin_size: float | Sequence[float],\n    dimension_ranges: Sequence[tuple[float, float]] | None = None,\n    data_samples: NDArray[np.float64] | None = None,\n    add_boundary_bins: bool = False,\n    infer_active_bins: bool = True,\n    dilate: bool = True,\n    fill_holes: bool = True,\n    close_gaps: bool = True,\n    bin_count_threshold: int = 0,\n    connect_diagonal_neighbors: bool = True,\n) -&gt; None:\n    \"\"\"Build the regular N-D grid layout.\n\n    Parameters\n    ----------\n    bin_size : Union[float, Sequence[float]]\n        Desired size of bins in each dimension.\n    dimension_ranges : Optional[Sequence[Tuple[float, float]]], optional\n        Explicit `[(min_d0, max_d0), ..., (min_dN-1, max_dN-1)]` for the grid.\n        If None, range is inferred from `data_samples`.\n    data_samples : Optional[NDArray[np.float64]], shape (n_samples, n_dims), optional\n        Data used to infer `dimension_ranges` (if not provided) and/or to\n        infer active bins (if `infer_active_bins` is True).\n    add_boundary_bins : bool, default=False\n        If True, adds one bin on each side of the grid, extending the range.\n    infer_active_bins : bool, default=True\n        If True and `data_samples` are provided, infers active bins based\n        on occupancy and morphological operations.\n    dilate : bool, default=False\n        If `infer_active_bins` is True, dilates the inferred active area.\n    fill_holes : bool, default=False\n        If `infer_active_bins` is True, fills holes in the inferred active area.\n    close_gaps : bool, default=False\n        If `infer_active_bins` is True, closes gaps in the inferred active area.\n    bin_count_threshold : int, default=0\n        If `infer_active_bins` is True, minimum samples in a bin to be\n        considered initially occupied.\n    connect_diagonal_neighbors : bool, default=True\n        If True, connects diagonal neighbors in the connectivity graph.\n\n    \"\"\"\n\n    # --- Determine dimension_ranges if not provided ---\n    if dimension_ranges is not None:\n        self.dimension_ranges = dimension_ranges\n    else:\n        # Infer ranges from data_samples\n        if data_samples is None:\n            raise ValueError(\n                \"dimension_ranges must be provided if data_samples is None.\",\n            )\n\n        buffer_for_inference = (\n            bin_size / 2.0\n            if isinstance(bin_size, (float, int, np.number))\n            else bin_size\n        )\n        # Infer ranges from data_samples\n        self.dimension_ranges = _infer_dimension_ranges_from_samples(\n            data_samples=data_samples,\n            buffer_around_data=buffer_for_inference,\n        )\n\n    (\n        self.grid_edges,\n        full_grid_bin_centers,\n        self.grid_shape,\n    ) = _create_regular_grid(\n        data_samples=data_samples,\n        bin_size=bin_size,\n        dimension_range=self.dimension_ranges,\n        add_boundary_bins=add_boundary_bins,\n    )\n\n    if infer_active_bins and data_samples is not None:\n        self.active_mask = _infer_active_bins_from_regular_grid(\n            data_samples=data_samples,\n            edges=self.grid_edges,\n            close_gaps=close_gaps,\n            fill_holes=fill_holes,\n            dilate=dilate,\n            bin_count_threshold=bin_count_threshold,\n            boundary_exists=add_boundary_bins,\n        )\n    else:\n        # No data_samples or not inferring active bins, use all bins\n        self.active_mask = np.ones(self.grid_shape, dtype=bool)\n\n    if not np.any(self.active_mask):\n        # Build comprehensive error message with diagnostics\n        error_lines = [\"No active bins found after filtering.\"]\n        error_lines.append(\"\")  # Blank line\n\n        # Add diagnostic information\n        error_lines.append(\"Diagnostics:\")\n\n        # Show data range\n        if data_samples is not None:\n            data_clean = data_samples[~np.any(np.isnan(data_samples), axis=1)]\n            if len(data_clean) &gt; 0:\n                # Convert to Python native types for cleaner display\n                data_min = data_clean.min(axis=0).tolist()\n                data_max = data_clean.max(axis=0).tolist()\n                data_range = (\n                    data_clean.max(axis=0) - data_clean.min(axis=0)\n                ).tolist()\n                error_lines.append(\n                    f\"  Data range: {list(zip(data_min, data_max, strict=True))}\"\n                )\n                error_lines.append(f\"  Data extent: {data_range}\")\n                error_lines.append(f\"  Number of samples: {len(data_clean)}\")\n            else:\n                # All data is NaN - inform user clearly\n                error_lines.append(\"  Data samples: All NaN (no valid data)\")\n                error_lines.append(\n                    f\"  Number of samples (including NaN): {len(data_samples)}\"\n                )\n\n        # Show grid information\n        if isinstance(bin_size, (float, int, np.number)):\n            bin_size_str = f\"{bin_size}\"\n        else:\n            bin_size_str = f\"{list(bin_size)}\"\n        error_lines.append(f\"  bin_size: {bin_size_str}\")\n        error_lines.append(f\"  Grid shape: {self.grid_shape}\")\n        error_lines.append(f\"  Total bins in grid: {np.prod(self.grid_shape)}\")\n\n        # Show filtering parameters\n        error_lines.append(f\"  bin_count_threshold: {bin_count_threshold}\")\n        error_lines.append(\n            f\"  Morphological operations: dilate={dilate}, fill_holes={fill_holes}, close_gaps={close_gaps}\"\n        )\n        error_lines.append(\"\")  # Blank line\n\n        # Explain WHY this happened (common causes)\n        error_lines.append(\"Common causes:\")\n        error_lines.append(\"  1. bin_size is too large relative to your data range\")\n        error_lines.append(\n            \"  2. bin_count_threshold is too high (no bins have enough samples)\"\n        )\n        error_lines.append(\n            \"  3. Data is too sparse and morphological operations are disabled\"\n        )\n        error_lines.append(\"\")  # Blank line\n\n        # Explain HOW to fix (specific suggestions)\n        error_lines.append(\"Suggestions to fix:\")\n        error_lines.append(\"  1. Reduce bin_size to create more bins\")\n        error_lines.append(\n            \"  2. Reduce bin_count_threshold (try 0 for initial testing)\"\n        )\n        error_lines.append(\n            \"  3. Enable morphological operations (dilate=True, fill_holes=True, close_gaps=True)\"\n        )\n        error_lines.append(\n            \"  4. Check that data_samples covers the expected spatial range\"\n        )\n\n        raise ValueError(\"\\n\".join(error_lines))\n\n    self.bin_centers = full_grid_bin_centers[self.active_mask.ravel()]\n    self.connectivity = _create_regular_grid_connectivity_graph(\n        full_grid_bin_centers=full_grid_bin_centers,\n        active_mask_nd=self.active_mask,\n        grid_shape=self.grid_shape,\n        connect_diagonal=connect_diagonal_neighbors,\n    )\n</code></pre>"},{"location":"api/neurospatial/layout/engines/regular_grid/#neurospatial.layout.engines.regular_grid-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/engines/shapely_polygon/","title":"<code>neurospatial.layout.engines.shapely_polygon</code>","text":""},{"location":"api/neurospatial/layout/engines/shapely_polygon/#neurospatial.layout.engines.shapely_polygon","title":"shapely_polygon","text":""},{"location":"api/neurospatial/layout/engines/shapely_polygon/#neurospatial.layout.engines.shapely_polygon-classes","title":"Classes","text":""},{"location":"api/neurospatial/layout/engines/shapely_polygon/#neurospatial.layout.engines.shapely_polygon.ShapelyPolygonLayout","title":"ShapelyPolygonLayout","text":"<pre><code>ShapelyPolygonLayout()\n</code></pre> <p>               Bases: <code>_GridMixin</code></p> <p>2D grid layout masked by a Shapely Polygon.</p> <p>Creates a regular grid based on the polygon's bounds and specified <code>bin_size</code>. Only grid cells whose centers are contained within the polygon are considered active. Inherits grid functionalities from <code>_GridMixin</code>.</p> <p>Initialize a ShapelyPolygonLayout engine.</p> Source code in <code>src/neurospatial/layout/engines/shapely_polygon.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize a ShapelyPolygonLayout engine.\"\"\"\n    self._layout_type_tag = \"ShapelyPolygon\"\n    self._build_params_used = {}\n    self.bin_centers = np.empty((0, 2), dtype=np.float64)  # 2D Layout\n    self.connectivity = None\n    self.dimension_ranges = None\n    self.grid_edges = None\n    self.grid_shape = None\n    self.active_mask = None\n    self.polygon_definition_ = None\n</code></pre>"},{"location":"api/neurospatial/layout/engines/shapely_polygon/#neurospatial.layout.engines.shapely_polygon.ShapelyPolygonLayout-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/engines/shapely_polygon/#neurospatial.layout.engines.shapely_polygon.ShapelyPolygonLayout.build","title":"build","text":"<pre><code>build(*, polygon: Polygon, bin_size: float | Sequence[float], connect_diagonal_neighbors: bool = True) -&gt; None\n</code></pre> <p>Build the Shapely Polygon masked grid layout.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>The Shapely Polygon object that defines the boundary of the active area.</p> required <code>bin_size</code> <code>Union[float, Sequence[float]]</code> <p>The side length(s) of the grid cells. If float, cells are square (or cubic). If sequence (length 2 for 2D), specifies (width, height).</p> required <code>connect_diagonal_neighbors</code> <code>bool</code> <p>If True, connect diagonally adjacent active grid cells in the <code>connectivity</code>.</p> <code>True</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the 'shapely' package is not installed (should be caught by SHAPELY_AVAILABLE check at class definition).</p> <code>TypeError</code> <p>If <code>polygon</code> is not a Shapely Polygon.</p> Source code in <code>src/neurospatial/layout/engines/shapely_polygon.py</code> <pre><code>@capture_build_params\ndef build(\n    self,\n    *,\n    polygon: Polygon,\n    bin_size: float | Sequence[float],\n    connect_diagonal_neighbors: bool = True,\n) -&gt; None:\n    \"\"\"Build the Shapely Polygon masked grid layout.\n\n    Parameters\n    ----------\n    polygon : shapely.geometry.Polygon\n        The Shapely Polygon object that defines the boundary of the\n        active area.\n    bin_size : Union[float, Sequence[float]]\n        The side length(s) of the grid cells. If float, cells are\n        square (or cubic). If sequence (length 2 for 2D), specifies\n        (width, height).\n    connect_diagonal_neighbors : bool, default=True\n        If True, connect diagonally adjacent active grid cells in the\n        `connectivity`.\n\n    Raises\n    ------\n    RuntimeError\n        If the 'shapely' package is not installed (should be caught by\n        SHAPELY_AVAILABLE check at class definition).\n    TypeError\n        If `polygon` is not a Shapely Polygon.\n\n    \"\"\"\n    if not isinstance(polygon, Polygon):\n        raise TypeError(\"polygon must be a Shapely Polygon object.\")\n\n    self.polygon_definition_ = polygon\n    minx, miny, maxx, maxy = polygon.bounds\n    self.dimension_ranges = [(minx, maxx), (miny, maxy)]\n\n    (\n        self.grid_edges,\n        full_grid_bin_centers,\n        self.grid_shape,\n    ) = _create_regular_grid(\n        data_samples=None,\n        bin_size=bin_size,\n        dimension_range=self.dimension_ranges,\n        add_boundary_bins=False,\n    )\n\n    # 1. Intrinsic mask from Shapely\n    pts_to_check = (\n        full_grid_bin_centers[:, :2]\n        if full_grid_bin_centers.shape[0] &gt; 0\n        else np.empty((0, 2))\n    )\n    shapely_mask_flat = (\n        shapely.contains(polygon, shapely.points(pts_to_check))\n        if pts_to_check.shape[0] &gt; 0\n        else np.array([], dtype=bool)\n    )\n    self.active_mask = shapely_mask_flat.reshape(self.grid_shape)\n\n    self.bin_centers = full_grid_bin_centers[self.active_mask.ravel()]\n    self.connectivity = _create_regular_grid_connectivity_graph(\n        full_grid_bin_centers=full_grid_bin_centers,\n        active_mask_nd=self.active_mask,\n        grid_shape=self.grid_shape,\n        connect_diagonal=connect_diagonal_neighbors,\n    )\n</code></pre>"},{"location":"api/neurospatial/layout/engines/shapely_polygon/#neurospatial.layout.engines.shapely_polygon.ShapelyPolygonLayout.plot","title":"plot","text":"<pre><code>plot(ax: Axes | None = None, figsize=(7, 7), cmap: str = 'bone_r', alpha: float = 0.7, show_connectivity: bool = True, node_size: float = 20, node_color: str = 'blue') -&gt; matplotlib.axes.Axes\n</code></pre> <p>Plot the ShapelyPolygon layout.</p> <p>Displays the active grid cells and overlays the defining polygon. Inherits base grid plotting from <code>_GridMixin.plot</code> and adds polygon visualization.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Axes to plot on. If None, new figure and axes are created.</p> <code>None</code> <code>figsize</code> <code>Tuple[float, float]</code> <p>Size of the figure if <code>ax</code> is None.</p> <code>(7, 7)</code> <code>cmap</code> <code>str</code> <p>Colormap for the grid visualization.</p> <code>\"bone_r\"</code> <code>alpha</code> <code>float</code> <p>Transparency level for the grid.</p> <code>0.7</code> <code>show_connectivity</code> <code>bool</code> <p>Whether to show connections between bins.</p> <code>True</code> <code>node_size</code> <code>float</code> <p>Size of nodes in the connectivity graph.</p> <code>20</code> <code>node_color</code> <code>str</code> <p>Color of nodes in the connectivity graph.</p> <code>\"blue\"</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the layout is plotted.</p> Source code in <code>src/neurospatial/layout/engines/shapely_polygon.py</code> <pre><code>def plot(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    figsize=(7, 7),\n    cmap: str = \"bone_r\",\n    alpha: float = 0.7,\n    show_connectivity: bool = True,\n    node_size: float = 20,\n    node_color: str = \"blue\",\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot the ShapelyPolygon layout.\n\n    Displays the active grid cells and overlays the defining polygon.\n    Inherits base grid plotting from `_GridMixin.plot` and adds\n    polygon visualization.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        Axes to plot on. If None, new figure and axes are created.\n    figsize : Tuple[float, float], default=(7, 7)\n        Size of the figure if `ax` is None.\n    cmap : str, default=\"bone_r\"\n        Colormap for the grid visualization.\n    alpha : float, default=0.7\n        Transparency level for the grid.\n    show_connectivity : bool, default=True\n        Whether to show connections between bins.\n    node_size : float, default=20\n        Size of nodes in the connectivity graph.\n    node_color : str, default=\"blue\"\n        Color of nodes in the connectivity graph.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the layout is plotted.\n\n    \"\"\"\n    if (\n        self.bin_centers is None\n        or self.grid_edges is None\n        or self.active_mask is None\n        or self.grid_shape is None\n        or self.connectivity is None\n    ):\n        raise RuntimeError(\"Layout not built. Call `build` first.\")\n\n    is_2d_grid = len(self.grid_shape) == 2 and len(self.grid_edges) == 2\n\n    if is_2d_grid:\n        if ax is None:\n            _, ax = plt.subplots(figsize=figsize)\n        ax.pcolormesh(\n            self.grid_edges[0],\n            self.grid_edges[1],\n            self.active_mask.T,\n            cmap=cmap,\n            alpha=alpha,\n            shading=\"auto\",\n        )\n        ax.set_xticks(self.grid_edges[0])\n        ax.set_yticks(self.grid_edges[1])\n        ax.grid(True, ls=\"-\", lw=0.5, c=\"gray\")\n        ax.set_aspect(\"equal\")\n        ax.set_title(f\"{self._layout_type_tag} (2D Grid)\")\n        ax.set_xlabel(\"Dimension 0\")\n        ax.set_ylabel(\"Dimension 1\")\n        if self.dimension_ranges:\n            ax.set_xlim(self.dimension_ranges[0])\n            ax.set_ylim(self.dimension_ranges[1])\n\n        if show_connectivity:\n            node_position = nx.get_node_attributes(self.connectivity, \"pos\")\n            nx.draw_networkx_nodes(\n                self.connectivity,\n                node_position,\n                ax=ax,\n                node_size=node_size,\n                node_color=node_color,\n            )\n            for node_id1, node_id2 in self.connectivity.edges:\n                pos = np.stack((node_position[node_id1], node_position[node_id2]))\n                ax.plot(pos[:, 0], pos[:, 1], color=\"black\", zorder=-1)\n\n        # Plot polygon\n        poly_patch_kwargs = {\n            \"alpha\": 0.3,\n            \"fc\": \"gray\",\n            \"ec\": \"black\",\n        }\n        if hasattr(self.polygon_definition_, \"geoms\"):  # MultiPolygon\n            for geom in self.polygon_definition_.geoms:\n                if hasattr(geom, \"exterior\"):\n                    x, y = geom.exterior.xy\n                    ax.fill(x, y, **poly_patch_kwargs)\n        elif hasattr(self.polygon_definition_, \"exterior\"):  # Polygon\n            x, y = self.polygon_definition_.exterior.xy\n            ax.fill(x, y, **poly_patch_kwargs)\n\n        return ax\n    raise NotImplementedError(\n        \"Plotting for non-2D grid layouts is not implemented yet.\",\n    )\n</code></pre>"},{"location":"api/neurospatial/layout/engines/shapely_polygon/#neurospatial.layout.engines.shapely_polygon-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/engines/triangular_mesh/","title":"<code>neurospatial.layout.engines.triangular_mesh</code>","text":""},{"location":"api/neurospatial/layout/engines/triangular_mesh/#neurospatial.layout.engines.triangular_mesh","title":"triangular_mesh","text":""},{"location":"api/neurospatial/layout/engines/triangular_mesh/#neurospatial.layout.engines.triangular_mesh-classes","title":"Classes","text":""},{"location":"api/neurospatial/layout/engines/triangular_mesh/#neurospatial.layout.engines.triangular_mesh.TriangularMeshLayout","title":"TriangularMeshLayout","text":"<pre><code>TriangularMeshLayout()\n</code></pre> <p>A LayoutEngine that builds a triangular mesh over interior points (auto-generated) clipped to a boundary polygon. Each triangle whose centroid lies inside the polygon is kept as an active bin. Connectivity by shared faces.</p> Source code in <code>src/neurospatial/layout/engines/triangular_mesh.py</code> <pre><code>def __init__(self):\n    self.bin_centers = np.empty((0, 2), dtype=float)\n    self.connectivity = nx.Graph()\n    self.dimension_ranges = None\n    self.grid_edges = ()  # For non-grid layouts, this is typically empty\n    self.grid_shape = None\n    self.active_mask = None  # Will be updated in build\n    self._build_params_used = {}\n\n    self._full_delaunay_tri = None\n    self._original_simplex_to_active_idx_map = None\n    self._active_original_simplex_indices = None\n    self._boundary_polygon_stored = None\n</code></pre>"},{"location":"api/neurospatial/layout/engines/triangular_mesh/#neurospatial.layout.engines.triangular_mesh.TriangularMeshLayout-attributes","title":"Attributes","text":""},{"location":"api/neurospatial/layout/engines/triangular_mesh/#neurospatial.layout.engines.triangular_mesh.TriangularMeshLayout.is_1d","title":"is_1d  <code>property</code>","text":"<pre><code>is_1d: bool\n</code></pre> <p>Always False, as this is a 2D mesh layout.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Always False, indicating a 2D layout.</p>"},{"location":"api/neurospatial/layout/engines/triangular_mesh/#neurospatial.layout.engines.triangular_mesh.TriangularMeshLayout-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/engines/triangular_mesh/#neurospatial.layout.engines.triangular_mesh.TriangularMeshLayout.build","title":"build","text":"<pre><code>build(boundary_polygon: Polygon, point_spacing: float) -&gt; None\n</code></pre> <p>Build the triangular mesh layout.</p> <p>Parameters:</p> Name Type Description Default <code>boundary_polygon</code> <code>Polygon</code> <p>The polygon defining the boundary. Triangles with centroids outside this polygon are discarded.</p> required <code>point_spacing</code> <code>float</code> <p>Desired spacing (in same units as polygon) between generated sample points used for triangulation.</p> required Source code in <code>src/neurospatial/layout/engines/triangular_mesh.py</code> <pre><code>def build(self, boundary_polygon: Polygon, point_spacing: float) -&gt; None:\n    \"\"\"Build the triangular mesh layout.\n\n    Parameters\n    ----------\n    boundary_polygon : shapely.geometry.Polygon\n        The polygon defining the boundary. Triangles with centroids\n        outside this polygon are discarded.\n    point_spacing : float\n        Desired spacing (in same units as polygon) between generated sample points\n        used for triangulation.\n\n    \"\"\"\n    if not isinstance(boundary_polygon, Polygon):\n        raise TypeError(\"boundary_polygon must be a Shapely Polygon.\")\n    if boundary_polygon.is_empty:\n        raise ValueError(\"boundary_polygon cannot be empty.\")\n    if boundary_polygon.geom_type == \"MultiPolygon\":\n        raise ValueError(\n            \"MultiPolygon boundaries are not directly supported. \"\n            \"Please provide a single Polygon component.\",\n        )\n    if point_spacing &lt;= 0:\n        raise ValueError(f\"point_spacing must be positive, got {point_spacing}.\")\n\n    # Store build parameters.\n    # For boundary_polygon, store exterior and interior coords for better serialization.\n    # Note: This simple serialization of polygon might not capture all Shapely Polygon features perfectly.\n    boundary_exterior_coords = list(boundary_polygon.exterior.coords)\n    boundary_interior_coords_list = [\n        list(interior.coords) for interior in boundary_polygon.interiors\n    ]\n    self._build_params_used = {\n        \"boundary_exterior_coords\": boundary_exterior_coords,\n        \"boundary_interior_coords_list\": boundary_interior_coords_list,\n        \"point_spacing\": float(point_spacing),\n    }\n    self._boundary_polygon_stored = (\n        boundary_polygon  # Store the actual object for use\n    )\n\n    # 1. Generate sample points for triangulation\n    sample_points = _generate_interior_points_for_mesh(\n        boundary_polygon,\n        point_spacing,\n    )\n    if sample_points.shape[0] &lt; 3:  # Delaunay needs at least N+1 points in N-D\n        raise ValueError(\n            f\"Not enough interior sample points ({sample_points.shape[0]}) generated \"\n            \"to form any triangle. Try decreasing point_spacing or ensuring \"\n            \"the polygon is large enough relative to the spacing.\",\n        )\n    exterior_coords = _sample_polygon_boundary(boundary_polygon, point_spacing)\n    # 4) Stack the interior grid points with the boundary vertices.\n    if sample_points.size == 0:\n        sample_points = exterior_coords.copy()\n    else:\n        sample_points = np.vstack([sample_points, exterior_coords])\n\n    # 2. Perform Delaunay triangulation\n    self._full_delaunay_tri = _triangulate_points(sample_points)\n\n    # 3. Filter active simplices (triangles)\n    active_original_indices, all_centroids = _filter_active_simplices_by_centroid(\n        self._full_delaunay_tri,\n        boundary_polygon,\n    )\n    n_total_delaunay_triangles = self._full_delaunay_tri.simplices.shape[0]\n\n    if active_original_indices.size == 0:\n        raise ValueError(\n            \"No triangles found with centroids inside the boundary polygon. \"\n            \"Check boundary_polygon shape, point_spacing, or point generation strategy.\",\n        )\n\n    self._active_original_simplex_indices = active_original_indices\n\n    # 4. Create mapping from original Delaunay simplex index to active triangle index\n    self._original_simplex_to_active_idx_map = {\n        orig_idx: active_idx\n        for active_idx, orig_idx in enumerate(active_original_indices)\n    }\n\n    # 5. Populate core attributes for active triangles\n    self.bin_centers = all_centroids[active_original_indices]\n\n    # 6. Build connectivity graph for active triangles\n    self.connectivity = _build_mesh_connectivity_graph(\n        active_original_indices,\n        all_centroids,\n        self._original_simplex_to_active_idx_map,\n        self._full_delaunay_tri,\n    )\n\n    # 7. Compute dimension_ranges based on active bin centers\n    self.dimension_ranges = _compute_mesh_dimension_ranges(self.bin_centers)\n\n    # 8. Set grid-related attributes for protocol conformance\n    # The \"conceptual grid\" here is the list of all Delaunay triangles.\n    self.grid_shape = (n_total_delaunay_triangles,)\n    self.active_mask = np.zeros(n_total_delaunay_triangles, dtype=bool)\n    self.active_mask[active_original_indices] = True\n</code></pre>"},{"location":"api/neurospatial/layout/engines/triangular_mesh/#neurospatial.layout.engines.triangular_mesh.TriangularMeshLayout.point_to_bin_index","title":"point_to_bin_index","text":"<pre><code>point_to_bin_index(points: NDArray[float64]) -&gt; NDArray[np.int_]\n</code></pre> <p>Map each 2D point to an active triangle index, or -1 if outside.</p> <p>Uses Delaunay.find_simplex() \u2192 original-simplex index \u2192 active-triangle index via a fast lookup array. Then enforces that the point itself must lie inside (or on) the boundary polygon.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>(NDArray[float64], shape(n_points, 2))</code> <p>2D points to map to triangle indices.</p> required <p>Returns:</p> Type Description <code>NDArray[int_]</code> <p>Each entry is in [0..n_active-1] or -1 if outside.</p> Source code in <code>src/neurospatial/layout/engines/triangular_mesh.py</code> <pre><code>def point_to_bin_index(self, points: NDArray[np.float64]) -&gt; NDArray[np.int_]:\n    \"\"\"Map each 2D point to an active triangle index, or -1 if outside.\n\n    Uses Delaunay.find_simplex() \u2192 original-simplex index \u2192 active-triangle index via\n    a fast lookup array. Then enforces that the point itself must lie inside (or on)\n    the boundary polygon.\n\n    Parameters\n    ----------\n    points : NDArray[np.float64], shape (n_points, 2)\n        2D points to map to triangle indices.\n\n    Returns\n    -------\n    NDArray[np.int_]\n        Each entry is in [0..n_active-1] or -1 if outside.\n\n    \"\"\"\n    if (\n        self._full_delaunay_tri is None\n        or self._original_simplex_to_active_idx_map is None\n    ):\n        raise RuntimeError(\"TriangularMeshLayout is not built. Call build() first.\")\n\n    pts2d = np.atleast_2d(points).astype(np.float64, copy=False)\n    if pts2d.ndim != 2 or pts2d.shape[1] != 2:\n        raise ValueError(f\"Expected points of shape (M, 2), got {pts2d.shape}.\")\n\n    # 1) Find which Delaunay simplex each point falls into (-1 if outside hull)\n    orig_simplices = self._full_delaunay_tri.find_simplex(pts2d)\n\n    # 2) Build a 1D lookup array once, mapping original simplex idx -&gt; active idx\n    n_total = self._full_delaunay_tri.simplices.shape[0]\n    orig2active_arr = np.full(n_total, -1, dtype=int)\n    for orig_idx, active_idx in self._original_simplex_to_active_idx_map.items():\n        orig2active_arr[orig_idx] = active_idx\n\n    # 3) Initialize result array to -1\n    active_triangle_idxs = np.full(orig_simplices.shape, -1, dtype=int)\n\n    # 4) Wherever orig_simplices != -1, do a vectorized assignment\n    valid_mask = orig_simplices != -1\n    if np.any(valid_mask):\n        found_orig = orig_simplices[valid_mask]\n        active_triangle_idxs[valid_mask] = orig2active_arr[found_orig]\n\n        # 5) Now ensure each point is itself inside (or on) the boundary\n        if self._boundary_polygon_stored is not None:\n            xcoords = pts2d[valid_mask, 0]\n            ycoords = pts2d[valid_mask, 1]\n            on_or_inside = shapely.contains_xy(\n                self._boundary_polygon_stored,\n                xcoords,\n                ycoords,\n            )\n            idxs = np.flatnonzero(valid_mask)\n            for local_i, keep in enumerate(on_or_inside):\n                if not keep:\n                    active_triangle_idxs[idxs[local_i]] = -1\n\n    return active_triangle_idxs\n</code></pre>"},{"location":"api/neurospatial/layout/engines/triangular_mesh/#neurospatial.layout.engines.triangular_mesh.TriangularMeshLayout.plot","title":"plot","text":"<pre><code>plot(ax: Axes | None = None, show_triangles: bool = True, show_centroids: bool = True, show_connectivity: bool = True, show_boundary: bool = True, triangle_kwargs: dict[str, Any] | None = None, centroid_kwargs: dict[str, Any] | None = None, connectivity_kwargs: dict[str, Any] | None = None, boundary_kwargs: dict[str, Any] | None = None) -&gt; matplotlib.axes.Axes\n</code></pre> <p>Plot the triangular mesh layout.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Axes to plot on. If None, a new figure and axes are created.</p> <code>None</code> <code>show_triangles</code> <code>bool</code> <p>Whether to draw the filled active triangles. Defaults to True.</p> <code>True</code> <code>show_centroids</code> <code>bool</code> <p>Whether to draw the centroids of active triangles. Defaults to True.</p> <code>True</code> <code>show_connectivity</code> <code>bool</code> <p>Whether to draw edges of the connectivity graph. Defaults to True.</p> <code>True</code> <code>show_boundary</code> <code>bool</code> <p>Whether to draw the original boundary polygon. Defaults to True.</p> <code>True</code> <code>triangle_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments for <code>matplotlib.collections.PatchCollection</code> of triangles.</p> <code>None</code> <code>centroid_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments for <code>ax.scatter</code> plotting centroids.</p> <code>None</code> <code>connectivity_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments for plotting connectivity edges.</p> <code>None</code> <code>boundary_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments for plotting the boundary polygon.</p> <code>None</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the layout was plotted.</p> Source code in <code>src/neurospatial/layout/engines/triangular_mesh.py</code> <pre><code>def plot(\n    self,\n    ax: matplotlib.axes.Axes | None = None,\n    show_triangles: bool = True,\n    show_centroids: bool = True,\n    show_connectivity: bool = True,\n    show_boundary: bool = True,\n    triangle_kwargs: dict[str, Any] | None = None,\n    centroid_kwargs: dict[str, Any] | None = None,\n    connectivity_kwargs: dict[str, Any] | None = None,\n    boundary_kwargs: dict[str, Any] | None = None,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot the triangular mesh layout.\n\n    Parameters\n    ----------\n    ax : Optional[matplotlib.axes.Axes], optional\n        Axes to plot on. If None, a new figure and axes are created.\n    show_triangles : bool, optional\n        Whether to draw the filled active triangles. Defaults to True.\n    show_centroids : bool, optional\n        Whether to draw the centroids of active triangles. Defaults to True.\n    show_connectivity : bool, optional\n        Whether to draw edges of the connectivity graph. Defaults to True.\n    show_boundary : bool, optional\n        Whether to draw the original boundary polygon. Defaults to True.\n    triangle_kwargs : Optional[Dict[str, Any]], optional\n        Keyword arguments for `matplotlib.collections.PatchCollection` of triangles.\n    centroid_kwargs : Optional[Dict[str, Any]], optional\n        Keyword arguments for `ax.scatter` plotting centroids.\n    connectivity_kwargs : Optional[Dict[str, Any]], optional\n        Keyword arguments for plotting connectivity edges.\n    boundary_kwargs : Optional[Dict[str, Any]], optional\n        Keyword arguments for plotting the boundary polygon.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the layout was plotted.\n\n    \"\"\"\n    if (\n        self._full_delaunay_tri is None\n        or self._active_original_simplex_indices is None\n        or self.bin_centers is None\n        or self.connectivity is None\n        or self.dimension_ranges is None\n    ):\n        raise RuntimeError(\"TriangularMeshLayout is not built. Call build() first.\")\n\n    if ax is None:\n        _, ax = plt.subplots(figsize=(7, 7))  # Default figsize\n\n    # Default kwargs\n    _triangle_kwargs = {\n        \"alpha\": 0.4,\n        \"facecolor\": \"lightblue\",\n        \"edgecolor\": \"gray\",\n        \"linewidth\": 0.5,\n    }\n    if triangle_kwargs:\n        _triangle_kwargs.update(triangle_kwargs)\n\n    _centroid_kwargs = {\"color\": \"blue\", \"s\": 10, \"zorder\": 3}\n    if centroid_kwargs:\n        _centroid_kwargs.update(centroid_kwargs)\n\n    _connectivity_kwargs = {\n        \"color\": \"black\",\n        \"alpha\": 0.5,\n        \"linewidth\": 0.75,\n        \"zorder\": 2,\n    }\n    if connectivity_kwargs:\n        _connectivity_kwargs.update(connectivity_kwargs)\n\n    _boundary_kwargs = {\n        \"color\": \"black\",\n        \"linewidth\": 1.5,\n        \"linestyle\": \"--\",\n        \"zorder\": 4,\n    }\n    if boundary_kwargs:\n        _boundary_kwargs.update(boundary_kwargs)\n\n    # Plot boundary polygon\n    if show_boundary and self._boundary_polygon_stored:\n        xb, yb = self._boundary_polygon_stored.exterior.xy\n        # Use cast to work around matplotlib stub limitations\n        plot_func = cast(\"Any\", ax.plot)\n        plot_func(xb, yb, label=\"Boundary\", **_boundary_kwargs)\n        for interior in self._boundary_polygon_stored.interiors:\n            xbi, ybi = interior.xy\n            plot_func(xbi, ybi, **_boundary_kwargs)\n\n    # Plot active triangles\n    if show_triangles:\n        patches: list[MplPolygon] = []\n        mesh_points = self._full_delaunay_tri.points\n        active_simplices_vertices = mesh_points[\n            self._full_delaunay_tri.simplices[self._active_original_simplex_indices]\n        ]\n\n        for vertices in active_simplices_vertices:  # Iterate over (n_active, 3, 2)\n            patches.append(MplPolygon(vertices, closed=True))\n\n        # Use cast to work around matplotlib stub limitations\n        pc_constructor = cast(\"Any\", PatchCollection)\n        pc = pc_constructor(patches, **_triangle_kwargs)\n        ax.add_collection(pc)\n\n    # Plot centroids (which are self.bin_centers)\n    if show_centroids and self.bin_centers.shape[0] &gt; 0:\n        # Use cast to work around matplotlib stub limitations\n        scatter_func = cast(\"Any\", ax.scatter)\n        scatter_func(\n            self.bin_centers[:, 0],\n            self.bin_centers[:, 1],\n            **_centroid_kwargs,\n        )\n\n    # Plot connectivity edges\n    if show_connectivity:\n        # Use cast to work around matplotlib stub limitations\n        plot_func2 = cast(\"Any\", ax.plot)\n        for u, v in self.connectivity.edges():\n            pos_u = self.connectivity.nodes[u][\"pos\"]\n            pos_v = self.connectivity.nodes[v][\"pos\"]\n            plot_func2(\n                [pos_u[0], pos_v[0]],\n                [pos_u[1], pos_v[1]],\n                **_connectivity_kwargs,\n            )\n\n    ax.set_aspect(\"equal\", adjustable=\"box\")\n    ax.set_xlim(self.dimension_ranges[0])\n    ax.set_ylim(self.dimension_ranges[1])\n    ax.set_xlabel(\"X coordinate\")\n    ax.set_ylabel(\"Y coordinate\")\n    ax.set_title(self._layout_type_tag)\n    if (\n        show_boundary and self._boundary_polygon_stored\n    ):  # Add legend if boundary shown\n        ax.legend()\n    return ax\n</code></pre>"},{"location":"api/neurospatial/layout/engines/triangular_mesh/#neurospatial.layout.engines.triangular_mesh.TriangularMeshLayout.bin_sizes","title":"bin_sizes","text":"<pre><code>bin_sizes() -&gt; NDArray[np.float64]\n</code></pre> <p>Return the N-dimensional volume of each active N-simplex (bin).</p> <p>For 2D, this is area. For 3D, this is volume, and so on. The volume of an N-simplex with vertices v0, v1, ..., vn is calculated as: V = (1 / n!) * |det([v1-v0, v2-v0, ..., vn-v0])| where n is the number of dimensions.</p> <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>Array of N-dimensional volumes, shape (n_active_simplices,).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the layout is not built (e.g., <code>_full_delaunay_tri</code> or <code>_active_original_simplex_indices</code> is None).</p> <code>ValueError</code> <p>If the dimensionality is less than 1.</p> Source code in <code>src/neurospatial/layout/engines/triangular_mesh.py</code> <pre><code>def bin_sizes(self) -&gt; NDArray[np.float64]:\n    \"\"\"Return the N-dimensional volume of each active N-simplex (bin).\n\n    For 2D, this is area. For 3D, this is volume, and so on.\n    The volume of an N-simplex with vertices v0, v1, ..., vn is calculated as:\n    V = (1 / n!) * |det([v1-v0, v2-v0, ..., vn-v0])|\n    where n is the number of dimensions.\n\n    Returns\n    -------\n    NDArray[np.float64]\n        Array of N-dimensional volumes, shape (n_active_simplices,).\n\n    Raises\n    ------\n    RuntimeError\n        If the layout is not built (e.g., `_full_delaunay_tri` or\n        `_active_original_simplex_indices` is None).\n    ValueError\n        If the dimensionality is less than 1.\n\n    \"\"\"\n    if (\n        self._full_delaunay_tri is None\n        or self._active_original_simplex_indices is None\n    ):  # pragma: no cover\n        raise RuntimeError(\"TriangularMeshLayout is not built. Call build() first.\")\n\n    # Get the vertices of all active N-simplices\n    # .points has shape (total_points, n_dim)\n    # .simplices has shape (total_simplices, n_dim + 1)\n    all_mesh_points = self._full_delaunay_tri.points\n    active_simplices_vertex_indices = self._full_delaunay_tri.simplices[\n        self._active_original_simplex_indices\n    ]\n\n    if active_simplices_vertex_indices.shape[0] == 0:\n        return np.array([], dtype=float)  # No active simplices\n\n    # nsimplex_vertices will have shape:\n    # (num_active_simplices, num_vertices_per_simplex, n_dim)\n    nsimplex_vertices = all_mesh_points[active_simplices_vertex_indices]\n\n    n_dim = all_mesh_points.shape[1]\n\n    if n_dim == 1:\n        # For 1D simplices (line segments), volume is length\n        # Vertices are (n_active, 2, 1)\n        # v0 is (n_active, 1), v1 is (n_active, 1)\n        v0 = nsimplex_vertices[:, 0, :]  # First vertex of each simplex\n        v1 = nsimplex_vertices[:, 1, :]  # Second vertex of each simplex\n        lengths = np.abs(v1 - v0).squeeze(axis=-1)\n        return np.asarray(lengths, dtype=np.float64)\n\n    # Select one vertex from each simplex as the origin (v0)\n    # v0 will have shape (num_active_simplices, n_dim)\n    v0 = nsimplex_vertices[:, 0, :]\n\n    # Create vectors from v0 to all other vertices (v1-v0, v2-v0, ..., vn-v0)\n    # These vectors form the rows (or columns) of the matrix for the determinant.\n    # nsimplex_vertices[:, 1:, :] has shape (n_active, n_dim, n_dim)\n    # v0[:, np.newaxis, :] broadcasts v0 to match for subtraction\n    # matrix_for_determinant will have shape (n_active, n_dim, n_dim)\n    matrix_for_determinant = nsimplex_vertices[:, 1:, :] - v0[:, np.newaxis, :]\n\n    # Calculate the determinant for each simplex's matrix\n    # np.linalg.det operates on the last two axes by default.\n    determinants = np.linalg.det(matrix_for_determinant)\n\n    # Volume = abs(determinant) / n!\n    n_factorial = float(math.factorial(n_dim))\n    volumes = np.abs(determinants) / n_factorial\n\n    return np.asarray(volumes, dtype=np.float64)\n</code></pre>"},{"location":"api/neurospatial/layout/helpers/","title":"<code>neurospatial.layout.helpers</code>","text":""},{"location":"api/neurospatial/layout/helpers/#neurospatial.layout.helpers","title":"helpers","text":""},{"location":"api/neurospatial/layout/helpers/graph/","title":"<code>neurospatial.layout.helpers.graph</code>","text":""},{"location":"api/neurospatial/layout/helpers/graph/#neurospatial.layout.helpers.graph","title":"graph","text":"<p>Utility functions for graph-based (linearized track) layouts. \ud83d\udcd0</p> <p>This module provides helper functions specifically for environments where the spatial layout is defined by a graph structure that is subsequently linearized, such as an animal's track in an experiment. These functions handle:</p> <ul> <li>Discretizing a linearized graph track into 1D bins, accounting for edge   lengths and specified spacing between segments (<code>_get_graph_bins</code>).</li> <li>Creating a connectivity graph from these binned segments, where nodes   represent active 1D bin centers and edges connect adjacent bins   (<code>_create_graph_layout_connectivity_graph</code>).</li> <li>Projecting 1D linearized positions back to their corresponding N-D   coordinates on the original track graph (<code>_project_1d_to_2d</code>).</li> <li>Finding the appropriate 1D bin index for a given linear position   (<code>_find_bin_for_linear_position</code>).</li> </ul> <p>These utilities are primarily used by the <code>GraphLayout</code> engine.</p>"},{"location":"api/neurospatial/layout/helpers/graph/#neurospatial.layout.helpers.graph-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/helpers/hexagonal/","title":"<code>neurospatial.layout.helpers.hexagonal</code>","text":""},{"location":"api/neurospatial/layout/helpers/hexagonal/#neurospatial.layout.helpers.hexagonal","title":"hexagonal","text":"<p>Utility functions for creating and managing hexagonal grid layouts.</p> <p>This module provides helper functions specifically for environments that use hexagonal tiling. These functions cover: - Generation of hexagonal grid coordinates (<code>_create_hex_grid</code>). - Conversion between Cartesian and hexagonal (cube/axial) coordinate systems   (<code>_cartesian_to_fractional_cube</code>, <code>_round_fractional_cube_to_integer_axial</code>,   <code>_axial_to_offset_bin_indices</code>). - Mapping continuous 2D points to discrete hexagonal bin indices   (<code>_points_to_hex_bin_ind</code>). - Inferring active hexagonal bins based on data sample occupancy   (<code>_infer_active_bins_from_hex_grid</code>). - Determining neighbor relationships in the hexagonal grid   (<code>_get_hex_grid_neighbor_deltas</code>). - Constructing a connectivity graph for active hexagonal bins   (<code>_create_hex_connectivity_graph</code>).</p> <p>These utilities are primarily used by the <code>HexagonalLayout</code> engine.</p>"},{"location":"api/neurospatial/layout/helpers/regular_grid/","title":"<code>neurospatial.layout.helpers.regular_grid</code>","text":""},{"location":"api/neurospatial/layout/helpers/regular_grid/#neurospatial.layout.helpers.regular_grid","title":"regular_grid","text":"<p>Utility functions for creating and managing regular N-dimensional grid layouts.</p> <p>This module provides a collection of helper functions used primarily by <code>RegularGridLayout</code> and other grid-based layout engines within the <code>neurospatial</code> package. These functions handle tasks such as:</p> <ul> <li>Defining the structure (bin edges, bin centers, shape) of a regular N-D grid   based on data samples or specified dimension ranges (<code>_create_regular_grid</code>).</li> <li>Inferring which bins within this grid are \"active\" based on the density of   provided data samples, often involving morphological operations to refine   the active area (<code>_infer_active_bins_from_regular_grid</code>).</li> <li>Constructing a <code>networkx.Graph</code> that represents the connectivity between   these active grid bins, allowing for orthogonal and diagonal connections   (<code>_create_regular_grid_connectivity_graph</code>).</li> <li>Mapping continuous N-D points to their corresponding discrete bin indices   within the grid, taking into account active areas (<code>_points_to_regular_grid_bin_ind</code>).</li> </ul> <p>The module also includes functions for inferring dimensional properties from data samples, which might be shared with or used by other utility modules.</p>"},{"location":"api/neurospatial/layout/helpers/regular_grid/#neurospatial.layout.helpers.regular_grid-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/helpers/triangular_mesh/","title":"<code>neurospatial.layout.helpers.triangular_mesh</code>","text":""},{"location":"api/neurospatial/layout/helpers/triangular_mesh/#neurospatial.layout.helpers.triangular_mesh","title":"triangular_mesh","text":"<p>TriangularMeshLayout: a LayoutEngine that discretizes a 2D corridor region via a Delaunay triangulation. Instead of requiring the user to supply sample points, this layout generates a uniform grid of interior points (spaced by <code>point_spacing</code>) clipped to the provided boundary polygon. Each triangle whose centroid lies inside the polygon is kept as an active bin. Connectivity is inferred by shared faces.</p> <p>Conforms to the LayoutEngine protocol:   - Attributes:    bin_centers, connectivity, dimension_ranges,                    grid_edges, grid_shape, active_mask,                    _layout_type_tag, _build_params_used   - Properties:    is_1d   - Methods:       build(boundary_polygon, point_spacing),                    point_to_bin_index(points),                    plot(ax, ...), bin_sizes()</p>"},{"location":"api/neurospatial/layout/helpers/utils/","title":"<code>neurospatial.layout.helpers.utils</code>","text":""},{"location":"api/neurospatial/layout/helpers/utils/#neurospatial.layout.helpers.utils","title":"utils","text":"<p>General utility functions for the neurospatial package.</p> <p>This module provides helper functions used across various components of the environment definition and processing, such as calculating bin properties, inferring geometric features from data samples, plotting graphs, and computing distances.</p>"},{"location":"api/neurospatial/layout/helpers/utils/#neurospatial.layout.helpers.utils-functions","title":"Functions","text":""},{"location":"api/neurospatial/layout/helpers/utils/#neurospatial.layout.helpers.utils.get_centers","title":"get_centers","text":"<pre><code>get_centers(bin_edges: NDArray[float64]) -&gt; NDArray[np.float64]\n</code></pre> <p>Calculate the center of each bin given its edges.</p> <p>Parameters:</p> Name Type Description Default <code>bin_edges</code> <code>(NDArray[float64], shape(n_edges))</code> <p>A 1D array of sorted coordinates representing the edges that define a sequence of bins. For <code>N</code> bins, there will be <code>N+1</code> edges.</p> required <p>Returns:</p> Type Description <code>(NDArray[float64], shape(n_edges - 1))</code> <p>A 1D array containing the center coordinate of each bin.</p> Source code in <code>src/neurospatial/layout/helpers/utils.py</code> <pre><code>def get_centers(bin_edges: NDArray[np.float64]) -&gt; NDArray[np.float64]:\n    \"\"\"Calculate the center of each bin given its edges.\n\n    Parameters\n    ----------\n    bin_edges : NDArray[np.float64], shape (n_edges,)\n        A 1D array of sorted coordinates representing the edges that define\n        a sequence of bins. For `N` bins, there will be `N+1` edges.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (n_edges - 1,)\n        A 1D array containing the center coordinate of each bin.\n\n    \"\"\"\n    return bin_edges[:-1] + np.diff(bin_edges) / 2\n</code></pre>"},{"location":"api/neurospatial/layout/helpers/utils/#neurospatial.layout.helpers.utils.get_n_bins","title":"get_n_bins","text":"<pre><code>get_n_bins(data_samples: NDArray[float64], bin_size: float | Sequence[float], dimension_range: Sequence[tuple[float, float]] | None = None) -&gt; NDArray[np.int_]\n</code></pre> <p>Calculate the number of bins needed for each dimension of a dataset.</p> <p>The number of bins is determined based on the extent of the data (or a specified <code>dimension_range</code>) and the desired <code>bin_size</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_samples</code> <code>(NDArray[float64], shape(n_samples, n_dims))</code> <p>N-dimensional data samples. Used to determine the data extent if <code>dimension_range</code> is not provided. NaNs are ignored for range calculation.</p> required <code>bin_size</code> <code>Union[float, Sequence[float]]</code> <p>The desired size of the bins. If a float, this size is applied to all dimensions. If a sequence, it specifies the bin size for each dimension and its length must match <code>n_dims</code>. Must be positive.</p> required <code>dimension_range</code> <code>Optional[Sequence[Tuple[float, float]]]</code> <p>Explicit range <code>[(min_d0, max_d0), ..., (min_dN-1, max_dN-1)]</code> for each dimension. If None (default), the range is calculated from the min/max of <code>data_samples</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>(NDArray[int_], shape(n_dims))</code> <p>An array containing the calculated number of bins required for each dimension. Each value is at least 1.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>bin_size</code> is not positive or if its length (if a sequence) does not match the number of dimensions. If <code>dimension_range</code> (if provided) does not have two values (min, max) per dimension.</p> Source code in <code>src/neurospatial/layout/helpers/utils.py</code> <pre><code>def get_n_bins(\n    data_samples: NDArray[np.float64],\n    bin_size: float | Sequence[float],\n    dimension_range: Sequence[tuple[float, float]] | None = None,\n) -&gt; NDArray[np.int_]:\n    \"\"\"Calculate the number of bins needed for each dimension of a dataset.\n\n    The number of bins is determined based on the extent of the data (or a\n    specified `dimension_range`) and the desired `bin_size`.\n\n    Parameters\n    ----------\n    data_samples : NDArray[np.float64], shape (n_samples, n_dims)\n        N-dimensional data samples. Used to determine the data extent if\n        `dimension_range` is not provided. NaNs are ignored for range calculation.\n    bin_size : Union[float, Sequence[float]]\n        The desired size of the bins. If a float, this size is applied to\n        all dimensions. If a sequence, it specifies the bin size for each\n        dimension and its length must match `n_dims`. Must be positive.\n    dimension_range : Optional[Sequence[Tuple[float, float]]], optional\n        Explicit range `[(min_d0, max_d0), ..., (min_dN-1, max_dN-1)]` for\n        each dimension. If None (default), the range is calculated from\n        the min/max of `data_samples`.\n\n    Returns\n    -------\n    NDArray[np.int_], shape (n_dims,)\n        An array containing the calculated number of bins required for each\n        dimension. Each value is at least 1.\n\n    Raises\n    ------\n    ValueError\n        If `bin_size` is not positive or if its length (if a sequence)\n        does not match the number of dimensions.\n        If `dimension_range` (if provided) does not have two values (min, max)\n        per dimension.\n\n    \"\"\"\n    if dimension_range is not None:\n        # Ensure dimension_range is numpy array for consistent processing\n        pr = np.asarray(dimension_range)\n        if pr.shape[1] != 2:\n            raise ValueError(\"dimension_range must be sequence of (min, max) pairs.\")\n        extent = np.diff(pr, axis=1).squeeze(axis=1)\n    else:\n        # Ignore NaNs when calculating range from data\n        extent = np.nanmax(data_samples, axis=0) - np.nanmin(data_samples, axis=0)\n\n    # Validate and convert bin_size with helpful error messages\n    try:\n        bin_size_arr = np.asarray(bin_size, dtype=float)\n    except (TypeError, ValueError) as e:\n        # Provide helpful error message for type conversion failures\n        actual_type = type(bin_size).__name__\n        raise TypeError(\n            f\"bin_size must be a numeric value or sequence of numeric values. \"\n            f\"Got {actual_type}: {bin_size!r}\"\n        ) from e\n\n    # Check for NaN or Inf values separately\n    if np.any(np.isnan(bin_size_arr)):\n        raise ValueError(\n            f\"bin_size contains NaN (Not a Number) values (got {bin_size}). \"\n            \"bin_size must be finite numeric values.\"\n        )\n    if np.any(np.isinf(bin_size_arr)):\n        raise ValueError(\n            f\"bin_size contains infinite values (got {bin_size}). \"\n            \"bin_size must be finite numeric values.\"\n        )\n\n    # Ensure bin_size is positive\n    if np.any(bin_size_arr &lt;= 0.0):\n        raise ValueError(f\"bin_size must be positive (got {bin_size}).\")\n\n    # Calculate number of bins, ensuring at least 1 bin even if extent is 0\n    n_bins = np.ceil(extent / bin_size_arr).astype(np.int32)\n    n_bins[n_bins == 0] = 1  # Handle zero extent case\n\n    # Convert to int64 to match expected return type\n    return np.asarray(n_bins, dtype=np.int64)\n</code></pre>"},{"location":"api/neurospatial/layout/helpers/utils/#neurospatial.layout.helpers.utils.flat_to_multi_index","title":"flat_to_multi_index","text":"<pre><code>flat_to_multi_index(flat_indices: int | ndarray, grid_shape: tuple[int, ...], graph: Graph) -&gt; tuple[int | float, ...] | tuple[np.ndarray, ...]\n</code></pre> <p>Convert active-bin flat index(es) (0..N-1) to N-D grid index(es).</p> <p>Parameters:</p> Name Type Description Default <code>flat_indices</code> <code>Union[int, ndarray]</code> <p>A single active-bin flat index or an array of flat indices. These refer to row indices in the active-bin list (i.e., node IDs).</p> required <code>grid_shape</code> <code>Tuple[int, ...]</code> <p>The shape of the full N-D grid (e.g., (n_rows, n_cols) for 2D).</p> required <code>graph</code> <code>Graph</code> <p>The connectivity graph where each node ID is an active-bin ID, and node attributes include 'original_grid_nd_index' or 'source_grid_flat_index'.</p> required <p>Returns:</p> Type Description <code>Union[Tuple[Union[int, float], ...], Tuple[ndarray, ...]]</code> <ul> <li>If <code>flat_indices</code> is a single int, return a tuple of N ints or floats: the N-D index.   If conversion fails for that index, return a tuple of N <code>np.nan</code> (float) values.</li> <li>If <code>flat_indices</code> is an array of ints, return a tuple of N NumPy arrays,   each containing that coordinate for each input index. If conversion fails   for some index, its coordinate elements are <code>np.nan</code>.</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>If none of the active_flat_idx values are valid node IDs, or if <code>grid_shape</code> is invalid.</p> Source code in <code>src/neurospatial/layout/helpers/utils.py</code> <pre><code>def flat_to_multi_index(\n    flat_indices: int | np.ndarray,\n    grid_shape: tuple[int, ...],\n    graph: nx.Graph,\n) -&gt; tuple[int | float, ...] | tuple[np.ndarray, ...]:\n    \"\"\"Convert active-bin flat index(es) (0..N-1) to N-D grid index(es).\n\n    Parameters\n    ----------\n    flat_indices : Union[int, np.ndarray]\n        A single active-bin flat index or an array of flat indices. These\n        refer to row indices in the active-bin list (i.e., node IDs).\n    grid_shape : Tuple[int, ...]\n        The shape of the full N-D grid (e.g., (n_rows, n_cols) for 2D).\n    graph : nx.Graph\n        The connectivity graph where each node ID is an active-bin ID,\n        and node attributes include 'original_grid_nd_index' or\n        'source_grid_flat_index'.\n\n    Returns\n    -------\n    Union[Tuple[Union[int, float], ...], Tuple[np.ndarray, ...]]\n        - If `flat_indices` is a single int, return a tuple of N ints or floats: the N-D index.\n          If conversion fails for that index, return a tuple of N `np.nan` (float) values.\n        - If `flat_indices` is an array of ints, return a tuple of N NumPy arrays,\n          each containing that coordinate for each input index. If conversion fails\n          for some index, its coordinate elements are `np.nan`.\n\n    Raises\n    ------\n    ValueError\n        If none of the active_flat_idx values are valid node IDs, or if `grid_shape` is invalid.\n\n    \"\"\"\n    # Ensure we have a NumPy array for iteration\n    is_scalar = np.isscalar(flat_indices)\n    flat_arr = np.atleast_1d(np.asarray(flat_indices, dtype=int))\n    node_data_lookup: dict[int, dict[str, Any]] = dict(graph.nodes(data=True))\n\n    n_dims = len(grid_shape)\n    # Prepare a list to collect tuples of length n_dims\n    output_nd_list = []\n\n    for active_idx in flat_arr:\n        # Check if this node ID exists in node_data_lookup\n        if active_idx not in node_data_lookup:\n            warnings.warn(\n                f\"Active flat index {active_idx} not found in node_data_lookup. \"\n                \"Returning NaNs for this index.\",\n                UserWarning,\n            )\n            output_nd_list.append(tuple([np.nan] * n_dims))\n            continue\n\n        data = node_data_lookup[active_idx]\n\n        # If original N-D tuple is directly available, use it\n        original_index_key: str = \"original_grid_nd_index\"\n        fallback_key: str = \"source_grid_flat_index\"\n        if original_index_key in data and data[original_index_key] is not None:\n            orig_nd = data[original_index_key]\n            if not (isinstance(orig_nd, (tuple, list)) and len(orig_nd) == n_dims):\n                warnings.warn(\n                    f\"Node {active_idx} has invalid '{original_index_key}' attribute. \"\n                    \"Returning NaNs.\",\n                    UserWarning,\n                )\n                output_nd_list.append(tuple([np.nan] * n_dims))\n            else:\n                output_nd_list.append(tuple(orig_nd))\n        # Otherwise, attempt to use the fallback full-grid flat index\n        elif fallback_key in data and data[fallback_key] is not None:\n            full_flat = data[fallback_key]\n            try:\n                nd_idx = np.unravel_index(int(full_flat), grid_shape)\n                output_nd_list.append(tuple(int(x) for x in nd_idx))\n            except Exception:\n                warnings.warn(\n                    f\"Cannot unravel fallback index {full_flat} for node {active_idx}. \"\n                    \"Returning NaNs.\",\n                    UserWarning,\n                )\n                output_nd_list.append(tuple([np.nan] * n_dims))\n        else:\n            warnings.warn(\n                f\"Node {active_idx} missing both '{original_index_key}' and '{fallback_key}'. \"\n                \"Returning NaNs.\",\n                UserWarning,\n            )\n            output_nd_list.append(tuple([np.nan] * n_dims))\n\n    # Convert list of tuples into tuple of arrays\n    # e.g., output_nd_list = [(r0,c0), (r1,c1), ...] for 2D\n    # then final = (array([r0,r1,...]), array([c0,c1,...]))\n    final = tuple(\n        np.array([item[d] for item in output_nd_list], dtype=float)\n        for d in range(n_dims)\n    )\n\n    if is_scalar:\n        # Return a tuple of scalars (first element of each array)\n        # Returns tuple[int | float, ...] - int when valid, float (np.nan) when invalid\n        result_tuple = tuple(\n            int(val[0]) if not np.isnan(val[0]) else np.nan for val in final\n        )\n        return result_tuple\n    return final\n</code></pre>"},{"location":"api/neurospatial/layout/helpers/utils/#neurospatial.layout.helpers.utils.multi_index_to_flat","title":"multi_index_to_flat","text":"<pre><code>multi_index_to_flat(*nd_idx_per_dim: int | NDArray[int_], grid_shape: tuple[int, ...], active_mask: NDArray[bool_], source_flat_lookup: dict[int, int]) -&gt; int | NDArray[np.int_]\n</code></pre> <p>Convert N-D grid index(es) to active-bin flat index(es) (0..N-1).</p> <p>Parameters:</p> Name Type Description Default <code>*nd_idx_per_dim</code> <code>Union[int, ndarray]</code> <p>N separate arguments, one per dimension. Each can be an int (scalar) or a NumPy array of ints (broadcastable). Examples:   - (row, col) for a single 2D point   - (rows_array, cols_array) for multiple points Alternatively, a single argument that is a list/tuple of length N can be passed, in which case it is interpreted as:   - shape (N, n_points) or (n_points, N) or (N,) for a single N-D index.</p> <code>()</code> <code>grid_shape</code> <code>Tuple[int, ...]</code> <p>The shape of the full grid (e.g. (n_rows, n_cols) for 2D).</p> required <code>active_mask</code> <code>ndarray</code> <p>An N-D boolean mask of shape=grid_shape, where True indicates the grid cell is active. Inactive cells are not part of the state space.</p> required <code>source_flat_lookup</code> <code>Dict[int, int]</code> <p>A mapping from full-grid flat index \u2192 active-bin flat index (state ID). If a grid cell is inactive, it should not appear (or return -1).</p> required <p>Returns:</p> Type Description <code>Union[int, ndarray]</code> <ul> <li>If input implies a single grid point, returns the active-bin ID (int), or -1 if out of bounds or inactive.</li> <li>If input implies multiple grid points (arrays), returns an array of the same broadcast shape,   with each element either the active-bin ID or -1.</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of input arrays does not match len(grid_shape), or if input arrays cannot broadcast.</p> Source code in <code>src/neurospatial/layout/helpers/utils.py</code> <pre><code>def multi_index_to_flat(\n    *nd_idx_per_dim: int | NDArray[np.int_],\n    grid_shape: tuple[int, ...],\n    active_mask: NDArray[np.bool_],\n    source_flat_lookup: dict[int, int],\n) -&gt; int | NDArray[np.int_]:\n    \"\"\"Convert N-D grid index(es) to active-bin flat index(es) (0..N-1).\n\n    Parameters\n    ----------\n    *nd_idx_per_dim : Union[int, np.ndarray]\n        N separate arguments, one per dimension. Each can be an int (scalar)\n        or a NumPy array of ints (broadcastable). Examples:\n          - (row, col) for a single 2D point\n          - (rows_array, cols_array) for multiple points\n        Alternatively, a single argument that is a list/tuple of length N\n        can be passed, in which case it is interpreted as:\n          - shape (N, n_points) or (n_points, N) or (N,) for a single N-D index.\n    grid_shape : Tuple[int, ...]\n        The shape of the full grid (e.g. (n_rows, n_cols) for 2D).\n    active_mask : np.ndarray\n        An N-D boolean mask of shape=grid_shape, where True indicates the grid\n        cell is active. Inactive cells are not part of the state space.\n    source_flat_lookup : Dict[int, int]\n        A mapping from full-grid flat index \u2192 active-bin flat index (state ID).\n        If a grid cell is inactive, it should not appear (or return -1).\n\n    Returns\n    -------\n    Union[int, np.ndarray]\n        - If input implies a single grid point, returns the active-bin ID (int), or -1 if out of bounds or inactive.\n        - If input implies multiple grid points (arrays), returns an array of the same broadcast shape,\n          with each element either the active-bin ID or -1.\n\n    Raises\n    ------\n    ValueError\n        If the number of input arrays does not match len(grid_shape), or if input arrays cannot broadcast.\n\n    \"\"\"\n    # Note: The following code path is currently unreachable due to type signature\n    # (nd_idx_per_dim elements are typed as int | NDArray, not list/tuple).\n    # This code is commented out but preserved for potential future use if the\n    # signature is updated to allow list/tuple inputs.\n    # if len(nd_idx_per_dim) == 1 and isinstance(nd_idx_per_dim[0], (list, tuple)):\n    #     temp = np.asarray(nd_idx_per_dim[0])\n    #     if temp.ndim == 2 and temp.shape[0] == len(grid_shape):\n    #         nd_idx_per_dim = tuple(temp[d] for d in range(len(grid_shape)))\n    #     elif temp.ndim == 2 and temp.shape[1] == len(grid_shape):\n    #         nd_idx_per_dim = tuple(temp[:, d] for d in range(len(grid_shape)))\n    #     elif temp.ndim == 1 and temp.shape[0] == len(grid_shape):\n    #         nd_idx_per_dim = tuple(np.array([int(val)]) for val in temp)\n    #     else:\n    #         raise ValueError(\"Invalid format for single argument N-D index.\")\n\n    # Now expect len(nd_idx_per_dim) == len(grid_shape)\n    if len(nd_idx_per_dim) != len(grid_shape):\n        raise ValueError(\n            f\"Expected {len(grid_shape)} index arrays, got {len(nd_idx_per_dim)}.\",\n        )\n\n    # Convert each to a NumPy array of dtype int\n    nd_arrays = tuple(\n        np.atleast_1d(np.asarray(idx, dtype=int)) for idx in nd_idx_per_dim\n    )\n\n    # Determine the common broadcast shape\n    try:\n        common_shape = np.broadcast(*nd_arrays).shape\n    except ValueError:\n        raise ValueError(\"N-D index arrays could not be broadcast together.\") from None\n\n    # Initialize output with -1\n    flat_output = np.full(common_shape, -1, dtype=int)\n\n    # Create a mask of indices that lie within the grid bounds\n    in_bounds = np.ones(common_shape, dtype=bool)\n    for dim, arr in enumerate(nd_arrays):\n        in_bounds &amp;= (arr &gt;= 0) &amp; (arr &lt; grid_shape[dim])\n\n    if not np.any(in_bounds):\n        # No in-bounds points; return either scalar -1 or the array of -1s\n        if common_shape == (1,) and all(np.isscalar(idx) for idx in nd_idx_per_dim):\n            return -1\n        return flat_output\n\n    # Extract the valid in-bounds indices for each dimension\n    valid_nd = tuple(arr[in_bounds] for arr in nd_arrays)\n\n    # Check which of those valid N-D indices correspond to active bins\n    try:\n        active_mask_vals = active_mask[valid_nd]\n    except IndexError:\n        # If indices out of range of active_mask, treat them as inactive\n        active_mask_vals = np.zeros(len(valid_nd[0]), dtype=bool)\n\n    if not np.any(active_mask_vals):\n        # None of the in-bounds indices are active\n        if common_shape == (1,) and all(np.isscalar(idx) for idx in nd_idx_per_dim):\n            return -1\n        return flat_output\n\n    # Keep only those indices that are both in-bounds &amp; active\n    truly_active_nd = tuple(dim_arr[active_mask_vals] for dim_arr in valid_nd)\n\n    # Convert these N-D grid coords to full-grid flat indices\n    full_flat_inds = np.ravel_multi_index(truly_active_nd, grid_shape)\n\n    # Map full-grid flat indices to active-bin IDs using source_flat_lookup\n    active_ids = np.array(\n        [source_flat_lookup.get(int(ff), -1) for ff in full_flat_inds],\n        dtype=int,\n    )\n\n    # Place these active IDs back into the correct positions of the output array\n    final_mask = np.zeros(common_shape, dtype=bool)\n    final_mask[in_bounds] = active_mask_vals\n    flat_output[final_mask] = active_ids\n\n    # If this was originally scalar inputs, return a scalar\n    if common_shape == (1,) and all(np.isscalar(idx) for idx in nd_idx_per_dim):\n        return int(flat_output[0])\n    return flat_output\n</code></pre>"},{"location":"api/neurospatial/layout/helpers/utils/#neurospatial.layout.helpers.utils.find_boundary_nodes","title":"find_boundary_nodes","text":"<pre><code>find_boundary_nodes(graph: Graph, grid_shape: tuple[int, ...] | None = None, active_mask: NDArray[bool_] | None = None, layout_kind: str | None = None) -&gt; NDArray[np.int_]\n</code></pre> <p>Identify boundary nodes in a connectivity graph G.</p> <p>A node is considered \"boundary\" if:   1) For an N&gt;1 grid layout (grid_shape and active_mask provided, and      connectivity_threshold_factor is None), it lies on the edge of the      active region (i.e., at least one of its N-D neighbors is either      out of bounds or inactive).   2) Otherwise, use a degree-based heuristic:      - Compute median_degree = median(node_degree) over all nodes.      - If connectivity_threshold_factor is provided (&gt;0), threshold = factor * median_degree.        Nodes with degree &lt; threshold are boundary.      - If no factor:        \u2022 For Hexagonal (layout_kind==\"Hexagonal\") and median_degree&gt;5, threshold=5.5.        \u2022 For 1D (len(grid_shape)1 or layout_kind\"Graph\"), threshold=1.5 if max_degree&gt;=2.        \u2022 For general fallback, threshold = median_degree.        Nodes with degree &lt; threshold are boundary.   3) If no nodes found by the above and no factor given and not an N&gt;1 grid, fallback:      - Let max_degree = max(node_degree). If median_degree == max_degree, do nothing.        Else, mark nodes with degree &lt; max_degree.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>Graph</code> <p>The connectivity graph where each node ID is an active-bin ID, and node attributes include possibly 'original_grid_nd_index'.</p> required <code>grid_shape</code> <code>Tuple[int, ...]</code> <p>The shape of the full grid. Only used if len(grid_shape) &gt; 1 and active_mask is provided.</p> <code>None</code> <code>active_mask</code> <code>ndarray</code> <p>An N-D boolean mask of shape=grid_shape. True=active bin.</p> <code>None</code> <code>layout_kind</code> <code>str</code> <p>A string identifier (e.g. \"RegularGrid\", \"Hexagonal\", \"Graph\"). Used for special heuristics (e.g. hexagon degrees).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray[int_]</code> <p>Sorted array of node IDs (active-bin IDs) identified as boundary.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If G is empty or invalid parameters are provided.</p> Source code in <code>src/neurospatial/layout/helpers/utils.py</code> <pre><code>def find_boundary_nodes(\n    graph: nx.Graph,\n    grid_shape: tuple[int, ...] | None = None,\n    active_mask: NDArray[np.bool_] | None = None,\n    layout_kind: str | None = None,\n) -&gt; NDArray[np.int_]:\n    \"\"\"Identify boundary nodes in a connectivity graph G.\n\n    A node is considered \"boundary\" if:\n      1) For an N&gt;1 grid layout (grid_shape and active_mask provided, and\n         connectivity_threshold_factor is None), it lies on the edge of the\n         active region (i.e., at least one of its N-D neighbors is either\n         out of bounds or inactive).\n      2) Otherwise, use a degree-based heuristic:\n         - Compute median_degree = median(node_degree) over all nodes.\n         - If connectivity_threshold_factor is provided (&gt;0), threshold = factor * median_degree.\n           Nodes with degree &lt; threshold are boundary.\n         - If no factor:\n           \u2022 For Hexagonal (layout_kind==\"Hexagonal\") and median_degree&gt;5, threshold=5.5.\n           \u2022 For 1D (len(grid_shape)==1 or layout_kind==\"Graph\"), threshold=1.5 if max_degree&gt;=2.\n           \u2022 For general fallback, threshold = median_degree.\n           Nodes with degree &lt; threshold are boundary.\n      3) If no nodes found by the above and no factor given and not an N&gt;1 grid, fallback:\n         - Let max_degree = max(node_degree). If median_degree == max_degree, do nothing.\n           Else, mark nodes with degree &lt; max_degree.\n\n    Parameters\n    ----------\n    graph : nx.Graph\n        The connectivity graph where each node ID is an active-bin ID,\n        and node attributes include possibly 'original_grid_nd_index'.\n    grid_shape : Tuple[int, ...], optional\n        The shape of the full grid. Only used if len(grid_shape) &gt; 1 and\n        active_mask is provided.\n    active_mask : np.ndarray, optional\n        An N-D boolean mask of shape=grid_shape. True=active bin.\n    layout_kind : str, optional\n        A string identifier (e.g. \"RegularGrid\", \"Hexagonal\", \"Graph\").\n        Used for special heuristics (e.g. hexagon degrees).\n\n\n    Returns\n    -------\n    np.ndarray[np.int_]\n        Sorted array of node IDs (active-bin IDs) identified as boundary.\n\n    Raises\n    ------\n    ValueError\n        If G is empty or invalid parameters are provided.\n\n    \"\"\"\n    if graph.number_of_nodes() == 0:\n        return np.array([], dtype=int)\n\n    # Determine if we can use grid-based boundary detection\n    use_grid_method = (\n        active_mask is not None and grid_shape is not None and len(grid_shape) &gt; 1\n    )\n\n    if use_grid_method:\n        # These assertions are safe because use_grid_method checks they're not None\n        assert grid_shape is not None\n        assert active_mask is not None\n        boundary_nodes = _find_grid_boundary_nodes(graph, grid_shape, active_mask)\n    else:\n        boundary_nodes = _find_degree_based_boundary_nodes(\n            graph,\n            layout_kind,\n            grid_shape,\n        )\n\n    return np.array(sorted(set(boundary_nodes)), dtype=int)\n</code></pre>"},{"location":"api/neurospatial/layout/helpers/utils/#neurospatial.layout.helpers.utils.map_active_data_to_grid","title":"map_active_data_to_grid","text":"<pre><code>map_active_data_to_grid(grid_shape: tuple[int, ...], active_mask: NDArray[bool_], active_bin_data: NDArray[float64], fill_value: float = np.nan) -&gt; NDArray[np.float64]\n</code></pre> <p>Map a 1D array of data corresponding to active bins onto a full N-D grid.</p> <p>This is useful for visualizing data (e.g., place fields, posterior probabilities) on grid-based layouts using functions like <code>pcolormesh</code>.</p> <p>Parameters:</p> Name Type Description Default <code>active_bin_data</code> <code>(NDArray[float64], shape(n_bins))</code> <p>A 1D array of values, one for each active bin, ordered consistently with <code>self.bin_centers</code> (i.e., by active bin index 0 to <code>n_bins - 1</code>).</p> required <code>fill_value</code> <code>float</code> <p>The value to use for bins in the full grid that are not active, by default np.nan.</p> <code>nan</code> <p>Returns:</p> Type Description <code>(NDArray[float64], shape(dim0_size, dim1_size, ...))</code> <p>An N-D array with shape <code>self.grid_shape</code>. Active bin locations are filled with <code>active_bin_data</code>, others with <code>fill_value</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the environment is not grid-based (missing <code>grid_shape</code> or <code>active_mask</code>), or if <code>active_bin_data</code> has an incorrect shape or incompatible data type.</p> Source code in <code>src/neurospatial/layout/helpers/utils.py</code> <pre><code>def map_active_data_to_grid(\n    grid_shape: tuple[int, ...],\n    active_mask: NDArray[np.bool_],\n    active_bin_data: NDArray[np.float64],\n    fill_value: float = np.nan,\n) -&gt; NDArray[np.float64]:\n    \"\"\"Map a 1D array of data corresponding to active bins onto a full N-D grid.\n\n    This is useful for visualizing data (e.g., place fields, posterior\n    probabilities) on grid-based layouts using functions like `pcolormesh`.\n\n    Parameters\n    ----------\n    active_bin_data : NDArray[np.float64], shape (n_bins,)\n        A 1D array of values, one for each active bin, ordered consistently\n        with `self.bin_centers` (i.e., by active bin index 0 to `n_bins - 1`).\n    fill_value : float, optional\n        The value to use for bins in the full grid that are not active,\n        by default np.nan.\n\n    Returns\n    -------\n    NDArray[np.float64], shape (dim0_size, dim1_size, ...)\n        An N-D array with shape `self.grid_shape`. Active bin locations are\n        filled with `active_bin_data`, others with `fill_value`.\n\n    Raises\n    ------\n    ValueError\n        If the environment is not grid-based (missing `grid_shape` or\n        `active_mask`), or if `active_bin_data` has an incorrect shape\n        or incompatible data type.\n\n    \"\"\"\n    if grid_shape is None or active_mask is None:\n        raise ValueError(\n            \"This method is applicable only to grid-based environments \"\n            \"that have 'grid_shape' and 'active_mask' attributes.\",\n        )\n    if not isinstance(active_bin_data, np.ndarray) or active_bin_data.ndim != 1:\n        raise ValueError(\"active_bin_data must be a 1D NumPy array.\")\n\n    n_bins = active_mask.sum()\n    if active_bin_data.shape[0] != n_bins:\n        raise ValueError(\n            f\"Length of active_bin_data ({active_bin_data.shape[0]}) \"\n            f\"must match the number of active bins ({n_bins}).\",\n        )\n\n    # Create an array for the full grid, filled with the fill_value\n    # Ensure dtype compatibility, e.g., promote fill_value to active_bin_data.dtype\n    # or choose a suitable default like float if active_bin_data can be int.\n    dtype = np.result_type(active_bin_data.dtype, type(fill_value))\n    full_grid_data = np.full(grid_shape, fill_value, dtype=dtype)\n\n    # Place the active data into the grid using the N-D active_mask\n    full_grid_data[active_mask] = active_bin_data\n    return full_grid_data\n</code></pre>"},{"location":"api/neurospatial/regions/","title":"<code>neurospatial.regions</code>","text":""},{"location":"api/neurospatial/regions/#neurospatial.regions","title":"regions","text":""},{"location":"api/neurospatial/regions/#neurospatial.regions--regions","title":"regions","text":"<p>Immutable continuous ROI objects plus optional helpers.</p> <p>This sub-package offers:</p> <ul> <li>:class:<code>Region</code>   - an immutable, hashable ROI (point or polygon)</li> <li>:class:<code>Regions</code>  - a small <code>MutableMapping[str, Region]</code></li> <li>Lightweight import / export helpers</li> <li>A single convenience plot function (Matplotlib &amp; Shapely imported lazily)</li> </ul>"},{"location":"api/neurospatial/regions/#neurospatial.regions-classes","title":"Classes","text":""},{"location":"api/neurospatial/regions/#neurospatial.regions.Region","title":"Region  <code>dataclass</code>","text":"<pre><code>Region(name: str, kind: Kind, data: NDArray[float64] | Polygon | Point, metadata: Mapping[str, Any] = dict())\n</code></pre> <p>Immutable description of a spatial ROI.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Unique region identifier.</p> required <code>kind</code> <code>Kind</code> <p>Either <code>\"point\"</code> or <code>\"polygon\"</code>.</p> required <code>data</code> <code>NDArray[float64] | Polygon | Point</code> <p>\u2022 point \u2192 <code>np.ndarray</code> with shape <code>(n_dims,)</code> \u2022 polygon \u2192 :class:<code>shapely.geometry.Polygon</code> (always 2-D)</p> required <code>metadata</code> <code>Mapping[str, Any]</code> <p>Optional, JSON-serialisable attributes (colour, label, \u2026).</p> <code>dict()</code>"},{"location":"api/neurospatial/regions/#neurospatial.regions.Region-functions","title":"Functions","text":""},{"location":"api/neurospatial/regions/#neurospatial.regions.Region.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Export Region to a JSON-serializable dictionary.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary representation of the Region.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Export Region to a JSON-serializable dictionary.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary representation of the Region.\n\n    \"\"\"\n    if self.kind == \"point\":\n        geom = (\n            self.data.tolist()\n            if isinstance(self.data, np.ndarray)\n            else list(self.data.coords[0])\n        )\n    else:\n        geom = mapping(self.data)\n\n    return {\n        \"name\": self.name,\n        \"kind\": self.kind,\n        \"geom\": geom,\n        \"metadata\": dict(self.metadata),\n    }\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.Region.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(payload: Mapping[str, Any]) -&gt; Region\n</code></pre> <p>Create Region from dictionary representation.</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <code>Mapping[str, Any]</code> <p>Dictionary containing region data with keys: 'name', 'kind', 'geom', 'metadata'.</p> required <p>Returns:</p> Type Description <code>Region</code> <p>Reconstructed Region instance.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>@classmethod\ndef from_dict(cls, payload: Mapping[str, Any]) -&gt; Region:\n    \"\"\"Create Region from dictionary representation.\n\n    Parameters\n    ----------\n    payload : Mapping[str, Any]\n        Dictionary containing region data with keys: 'name', 'kind', 'geom', 'metadata'.\n\n    Returns\n    -------\n    Region\n        Reconstructed Region instance.\n\n    \"\"\"\n    kind_str = payload[\"kind\"]\n    if kind_str not in (\"point\", \"polygon\"):\n        raise ValueError(f\"Unknown kind {kind_str!r}\")\n    kind: Kind = kind_str\n\n    if kind == \"point\":\n        data = np.asarray(payload[\"geom\"], dtype=float)\n    else:  # kind == \"polygon\"\n        data = shape(payload[\"geom\"])\n    return cls(\n        name=payload[\"name\"],\n        kind=kind,\n        data=data,\n        metadata=payload.get(\"metadata\", {}),\n    )\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.Regions","title":"Regions","text":"<pre><code>Regions(items: Iterable[Region] | None = None)\n</code></pre> <p>               Bases: <code>MutableMapping[str, Region]</code></p> <p>A small <code>dict</code>-like container mapping name \u2192 Region.</p> <p>Provides the usual mapping API plus a few helpers (<code>add</code>, <code>remove</code>, <code>list_names</code>, <code>buffer</code>, \u2026).</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def __init__(self, items: Iterable[Region] | None = None) -&gt; None:\n    self._store: dict[str, Region] = {}\n    if items is not None:\n        for reg in items:\n            self[reg.name] = reg\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.Regions-functions","title":"Functions","text":""},{"location":"api/neurospatial/regions/#neurospatial.regions.Regions.add","title":"add","text":"<pre><code>add(name: str, *, point: PointCoords | None = None, polygon: Polygon | None = None, metadata: Mapping[str, Any] | None = None) -&gt; Region\n</code></pre> <p>Create and insert a new Region.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Unique name for the region.</p> required <code>point</code> <code>PointCoords or None</code> <p>Point coordinates or Shapely Point object. Mutually exclusive with polygon.</p> <code>None</code> <code>polygon</code> <code>Polygon or None</code> <p>Shapely Polygon object. Mutually exclusive with point.</p> <code>None</code> <code>metadata</code> <code>Mapping[str, Any] or None</code> <p>Optional metadata dictionary to attach to the region.</p> <code>None</code> <p>Returns:</p> Type Description <code>Region</code> <p>The newly created Region instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both or neither of point/polygon are specified.</p> <code>KeyError</code> <p>If name already exists in the collection.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def add(\n    self,\n    name: str,\n    *,\n    point: PointCoords | None = None,\n    polygon: Polygon | None = None,\n    metadata: Mapping[str, Any] | None = None,\n) -&gt; Region:\n    \"\"\"Create and insert a new Region.\n\n    Parameters\n    ----------\n    name : str\n        Unique name for the region.\n    point : PointCoords or None, optional\n        Point coordinates or Shapely Point object. Mutually exclusive with polygon.\n    polygon : Polygon or None, optional\n        Shapely Polygon object. Mutually exclusive with point.\n    metadata : Mapping[str, Any] or None, optional\n        Optional metadata dictionary to attach to the region.\n\n    Returns\n    -------\n    Region\n        The newly created Region instance.\n\n    Raises\n    ------\n    ValueError\n        If both or neither of point/polygon are specified.\n    KeyError\n        If name already exists in the collection.\n\n    \"\"\"\n    if (point is None) == (polygon is None):\n        raise ValueError(\"Specify **one** of 'point' or 'polygon'.\")\n    if name in self:\n        raise KeyError(f\"Duplicate region name {name!r}.\")\n\n    if point is not None:\n        # Accept either a coordinate array or a Shapely Point\n        coords = np.asarray(\n            point.coords[0] if isinstance(point, Point) else point, dtype=float\n        )\n        region = Region(name, \"point\", coords, metadata or {})\n    else:\n        region = Region(name, \"polygon\", polygon, metadata or {})\n\n    self[name] = region\n    return region\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.Regions.update_region","title":"update_region","text":"<pre><code>update_region(name: str, *, point: PointCoords | None = None, polygon: Polygon | None = None, metadata: Mapping[str, Any] | None = None) -&gt; Region\n</code></pre> <p>Update an existing Region.</p> <p>This method replaces an existing region with a new one. The region can change its type (point vs polygon) and/or data and/or metadata. Metadata is preserved from the existing region if not explicitly provided.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the region to update.</p> required <code>point</code> <code>PointCoords or None</code> <p>Point coordinates or Shapely Point object. Mutually exclusive with polygon.</p> <code>None</code> <code>polygon</code> <code>Polygon or None</code> <p>Shapely Polygon object. Mutually exclusive with point.</p> <code>None</code> <code>metadata</code> <code>Mapping[str, Any] or None</code> <p>Optional metadata dictionary to attach to the region. If None, preserves the existing region's metadata.</p> <code>None</code> <p>Returns:</p> Type Description <code>Region</code> <p>The newly created Region instance that replaced the old one.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both or neither of point/polygon are specified.</p> <code>KeyError</code> <p>If name does not exist in the collection.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neurospatial.regions import Regions\n&gt;&gt;&gt; regs = Regions()\n&gt;&gt;&gt; _ = regs.add(\"center\", point=[0.0, 0.0], metadata={\"color\": \"red\"})\n&gt;&gt;&gt; # Update coordinates while preserving metadata\n&gt;&gt;&gt; _ = regs.update_region(\"center\", point=[1.0, 1.0])\n&gt;&gt;&gt; regs[\"center\"].data\narray([1., 1.])\n&gt;&gt;&gt; regs[\"center\"].metadata[\"color\"]\n'red'\n</code></pre> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def update_region(\n    self,\n    name: str,\n    *,\n    point: PointCoords | None = None,\n    polygon: Polygon | None = None,\n    metadata: Mapping[str, Any] | None = None,\n) -&gt; Region:\n    \"\"\"Update an existing Region.\n\n    This method replaces an existing region with a new one. The region can\n    change its type (point vs polygon) and/or data and/or metadata.\n    Metadata is preserved from the existing region if not explicitly provided.\n\n    Parameters\n    ----------\n    name : str\n        Name of the region to update.\n    point : PointCoords or None, optional\n        Point coordinates or Shapely Point object. Mutually exclusive with polygon.\n    polygon : Polygon or None, optional\n        Shapely Polygon object. Mutually exclusive with point.\n    metadata : Mapping[str, Any] or None, optional\n        Optional metadata dictionary to attach to the region. If None, preserves\n        the existing region's metadata.\n\n    Returns\n    -------\n    Region\n        The newly created Region instance that replaced the old one.\n\n    Raises\n    ------\n    ValueError\n        If both or neither of point/polygon are specified.\n    KeyError\n        If name does not exist in the collection.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from neurospatial.regions import Regions\n    &gt;&gt;&gt; regs = Regions()\n    &gt;&gt;&gt; _ = regs.add(\"center\", point=[0.0, 0.0], metadata={\"color\": \"red\"})\n    &gt;&gt;&gt; # Update coordinates while preserving metadata\n    &gt;&gt;&gt; _ = regs.update_region(\"center\", point=[1.0, 1.0])\n    &gt;&gt;&gt; regs[\"center\"].data\n    array([1., 1.])\n    &gt;&gt;&gt; regs[\"center\"].metadata[\"color\"]\n    'red'\n\n    \"\"\"\n    if (point is None) == (polygon is None):\n        raise ValueError(\"Specify **one** of 'point' or 'polygon'.\")\n    if name not in self:\n        raise KeyError(\n            f\"Region {name!r} does not exist. Use add() to create new regions.\"\n        )\n\n    # Preserve existing metadata if not explicitly provided\n    old_region = self._store[name]\n    effective_metadata = metadata if metadata is not None else old_region.metadata\n\n    # Remove the old region and add the new one\n    del self._store[name]\n\n    if point is not None:\n        # Accept either a coordinate array or a Shapely Point\n        coords = np.asarray(\n            point.coords[0] if isinstance(point, Point) else point, dtype=float\n        )\n        region = Region(name, \"point\", coords, effective_metadata)\n    else:\n        region = Region(name, \"polygon\", polygon, effective_metadata)\n\n    # Use direct store access to bypass __setitem__ duplicate check\n    self._store[name] = region\n    return region\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.Regions.remove","title":"remove","text":"<pre><code>remove(name: str) -&gt; None\n</code></pre> <p>Delete a region by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of region to remove. No error if absent.</p> required Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def remove(self, name: str) -&gt; None:\n    \"\"\"Delete a region by name.\n\n    Parameters\n    ----------\n    name : str\n        Name of region to remove. No error if absent.\n\n    \"\"\"\n    self._store.pop(name, None)\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.Regions.list_names","title":"list_names","text":"<pre><code>list_names() -&gt; list[str]\n</code></pre> <p>Get list of region names in insertion order.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Region names in the order they were added.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def list_names(self) -&gt; list[str]:\n    \"\"\"Get list of region names in insertion order.\n\n    Returns\n    -------\n    list[str]\n        Region names in the order they were added.\n\n    \"\"\"\n    return list(self._store)\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.Regions.area","title":"area","text":"<pre><code>area(name: str) -&gt; float\n</code></pre> <p>Compute area of a region.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of region to query.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Area of the polygon region, or 0.0 for point regions.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def area(self, name: str) -&gt; float:\n    \"\"\"Compute area of a region.\n\n    Parameters\n    ----------\n    name : str\n        Name of region to query.\n\n    Returns\n    -------\n    float\n        Area of the polygon region, or 0.0 for point regions.\n\n    \"\"\"\n    region = self[name]\n    if region.kind == \"polygon\":\n        assert isinstance(region.data, Polygon)\n        return float(region.data.area)\n    return 0.0\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.Regions.region_center","title":"region_center","text":"<pre><code>region_center(region_name: str) -&gt; NDArray[np.float64] | None\n</code></pre> <p>Calculate the center of a specified named region.</p> <p>Parameters:</p> Name Type Description Default <code>region_name</code> <code>str</code> <p>Name of region to query.</p> required <p>Returns:</p> Type Description <code>Optional[NDArray[float64]]</code> <p>N-D coordinates of the region's center, or None if the region is empty or center cannot be determined.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If <code>region_name</code> is not present in this collection.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def region_center(self, region_name: str) -&gt; NDArray[np.float64] | None:\n    \"\"\"Calculate the center of a specified named region.\n\n    Parameters\n    ----------\n    region_name : str\n        Name of region to query.\n\n    Returns\n    -------\n    Optional[NDArray[np.float64]]\n        N-D coordinates of the region's center, or None if the region\n        is empty or center cannot be determined.\n\n    Raises\n    ------\n    KeyError\n        If `region_name` is not present in this collection.\n\n    \"\"\"\n    if region_name not in self._store:\n        raise KeyError(f\"Region '{region_name}' not found in this collection.\")\n\n    region = self._store[region_name]\n\n    if region.kind == \"point\":\n        return np.asarray(region.data, dtype=float)\n    else:  # region.kind == \"polygon\"\n        assert isinstance(region.data, Polygon)\n        return np.array(region.data.centroid.coords[0], dtype=float)\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.Regions.buffer","title":"buffer","text":"<pre><code>buffer(source: str | NDArray[float64], distance: float, new_name: str, **meta: Any) -&gt; Region\n</code></pre> <p>Create a buffered region around a point or existing region.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str or NDArray[float64]</code> <p>Region name or point coordinates to buffer around.</p> required <code>distance</code> <code>float</code> <p>Buffer distance in spatial units.</p> required <code>new_name</code> <code>str</code> <p>Name for the new buffered region.</p> required <code>**meta</code> <code>Any</code> <p>Additional metadata for the new region.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Region</code> <p>The newly created buffered region.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def buffer(\n    self,\n    source: str | NDArray[np.float64],\n    distance: float,\n    new_name: str,\n    **meta: Any,\n) -&gt; Region:\n    \"\"\"Create a buffered region around a point or existing region.\n\n    Parameters\n    ----------\n    source : str or NDArray[np.float64]\n        Region name or point coordinates to buffer around.\n    distance : float\n        Buffer distance in spatial units.\n    new_name : str\n        Name for the new buffered region.\n    **meta : Any\n        Additional metadata for the new region.\n\n    Returns\n    -------\n    Region\n        The newly created buffered region.\n\n    \"\"\"\n    # derive geometry in cm space\n    if isinstance(source, str):\n        src = self[source]\n        if src.kind == \"polygon\":\n            assert isinstance(src.data, Polygon)\n            geom = src.data\n        elif src.kind == \"point\" and src.n_dims == 2:\n            assert isinstance(src.data, np.ndarray)\n            geom = Point(src.data)\n        else:\n            raise ValueError(\"Can only buffer 2-D point or polygon regions.\")\n    else:  # raw coords\n        arr = np.asarray(source, dtype=float)\n        if arr.shape != (2,):\n            raise ValueError(\"Raw source must be shape (2,) for buffering.\")\n        geom = Point(arr)\n\n    poly = geom.buffer(distance)\n    if not isinstance(poly, Polygon):\n        raise ValueError(\"Buffer produced non-polygon geometry.\")\n\n    return self.add(new_name, polygon=poly, metadata=meta)\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.Regions.to_dataframe","title":"to_dataframe","text":"<pre><code>to_dataframe() -&gt; DataFrame\n</code></pre> <p>Convert this collection to a Pandas DataFrame. Requires Pandas to be installed.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with columns ['name', 'kind', 'data', 'metadata']. The 'data' column contains the coordinates for points or polygons.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def to_dataframe(self) -&gt; DataFrame:\n    \"\"\"Convert this collection to a Pandas DataFrame.\n    Requires Pandas to be installed.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with columns ['name', 'kind', 'data', 'metadata'].\n        The 'data' column contains the coordinates for points or polygons.\n\n    \"\"\"\n    from .io import regions_to_dataframe\n\n    return regions_to_dataframe(self)\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.Regions.to_json","title":"to_json","text":"<pre><code>to_json(path: str | Path, *, indent: int = 2) -&gt; None\n</code></pre> <p>Write collection to disk in a simple, version-tagged schema.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>Output file path for JSON data.</p> required <code>indent</code> <code>int</code> <p>Indentation level for pretty-printed JSON.</p> <code>2</code> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def to_json(self, path: str | Path, *, indent: int = 2) -&gt; None:\n    \"\"\"Write collection to disk in a simple, version-tagged schema.\n\n    Parameters\n    ----------\n    path : str or Path\n        Output file path for JSON data.\n    indent : int, default=2\n        Indentation level for pretty-printed JSON.\n\n    \"\"\"\n    payload = {\n        \"format\": self._FMT,\n        \"regions\": [r.to_dict() for r in self._store.values()],\n    }\n    output_path = Path(path)\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n    output_path.write_text(json.dumps(payload, indent=indent))\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.Regions.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(path: str | Path) -&gt; Regions\n</code></pre> <p>Load Regions from JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>Path to JSON file containing regions data.</p> required <p>Returns:</p> Type Description <code>Regions</code> <p>Loaded Regions collection.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>@classmethod\ndef from_json(cls, path: str | Path) -&gt; Regions:\n    \"\"\"Load Regions from JSON file.\n\n    Parameters\n    ----------\n    path : str or Path\n        Path to JSON file containing regions data.\n\n    Returns\n    -------\n    Regions\n        Loaded Regions collection.\n\n    \"\"\"\n    blob = json.loads(Path(path).read_text())\n    if blob.get(\"format\") != cls._FMT:\n        warnings.warn(f\"Unexpected format tag {blob.get('format')!r}\")\n    return cls(Region.from_dict(d) for d in blob[\"regions\"])\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions-functions","title":"Functions","text":""},{"location":"api/neurospatial/regions/#neurospatial.regions.load_cvat_xml","title":"load_cvat_xml","text":"<pre><code>load_cvat_xml(xml_path: str | Path, *, pixel_to_world: SpatialTransform | None = None) -&gt; Regions\n</code></pre> <p>Parse a .xml file produced by CVAT.</p> <p>Region names are generated based on their label. If a label appears multiple times within an image, a running index is appended (e.g., tumor_0, tumor_1). If a label is unique within an image, no index is added (e.g., tumor). Unlabeled shapes follow the same logic (e.g., unlabeled or unlabeled_0). Open polylines are ignored. Other shapes are converted to Regions.</p> <p>Parameters:</p> Name Type Description Default <code>xml_path</code> <code>str or Path</code> <p>Path to the CVAT XML file.</p> required <code>pixel_to_world</code> <code>SpatialTransform</code> <p>Callable mapping <code>(N,2)</code> pixel coords \u2192 <code>(N,2)</code> world coords.</p> <code>None</code> <p>Returns:</p> Type Description <code>Regions</code> <p>A collection of :class:<code>Region</code> objects.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>xml_path</code> does not exist.</p> <code>ParseError</code> <p>If <code>xml_path</code> is not a valid XML file.</p> Source code in <code>src/neurospatial/regions/io.py</code> <pre><code>def load_cvat_xml(\n    xml_path: str | Path,\n    *,\n    pixel_to_world: SpatialTransform | None = None,\n) -&gt; Regions:\n    \"\"\"Parse a *.xml* file produced by CVAT.\n\n    Region names are generated based on their label. If a label appears\n    multiple times within an image, a running index is appended (e.g., tumor_0,\n    tumor_1). If a label is unique within an image, no index is added (e.g., tumor).\n    Unlabeled shapes follow the same logic (e.g., unlabeled or unlabeled_0).\n    Open polylines are ignored. Other shapes are converted to Regions.\n\n    Parameters\n    ----------\n    xml_path : str or Path\n        Path to the CVAT XML file.\n    pixel_to_world : SpatialTransform, optional\n        Callable mapping `(N,2)` pixel coords \u2192 `(N,2)` world coords.\n\n    Returns\n    -------\n    Regions\n        A collection of :class:`Region` objects.\n\n    Raises\n    ------\n    FileNotFoundError\n        If `xml_path` does not exist.\n    ET.ParseError\n        If `xml_path` is not a valid XML file.\n\n    \"\"\"\n    path_obj = Path(xml_path)\n    if not path_obj.exists():\n        raise FileNotFoundError(f\"XML file not found: {xml_path}\")\n\n    try:\n        tree = ET.parse(path_obj)\n    except ET.ParseError as e:\n        raise ET.ParseError(f\"Error parsing XML file {xml_path}: {e}\") from e\n\n    root = tree.getroot()\n    label_colors = _get_label_colors(root)\n\n    all_regions_in_file: list[Region] = []\n    for image_idx, image in enumerate(root.findall(\"image\")):\n        image_id_str = image.get(\"id\", f\"image{image_idx}\")\n\n        # Collect all shapes from this image\n        collected_shapes_data = _collect_shapes_from_image(\n            image,\n            image_id_str,\n            pixel_to_world,\n            label_colors,\n        )\n\n        # Generate unique names and create Region objects\n        regions = _generate_region_names(collected_shapes_data, path_obj)\n        all_regions_in_file.extend(regions)\n\n    return Regions(all_regions_in_file)\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.load_labelme_json","title":"load_labelme_json","text":"<pre><code>load_labelme_json(json_path: str | Path, *, pixel_to_world: SpatialTransform | None = None, label_key: str = 'label', points_key: str = 'points') -&gt; Regions\n</code></pre> <p>Parse a .json file produced by many point-&amp;-click ROI tools.</p> <p>Parameters:</p> Name Type Description Default <code>json_path</code> <code>str or Path</code> <p>Path to the JSON file.</p> required <code>pixel_to_world</code> <code>SpatialTransform</code> <p>Callable mapping <code>(N, 2)</code> pixel coordinates \u2192 <code>(N, 2)</code> world coordinates (e.g., centimeters). If <code>None</code>, the coordinates are assumed to be in pixels.</p> <code>None</code> <code>label_key</code> <code>str</code> <p>Key in the JSON object that contains the region label. Default is \"label\".</p> <code>'label'</code> <code>points_key</code> <code>str</code> <p>Key in the JSON object that contains the list of points. Default is \"points\".</p> <code>'points'</code> <p>Returns:</p> Type Description <code>Regions</code> <p>Every polygon becomes a :class:<code>Region</code> with <code>kind=\"polygon\"</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no shapes are found in the JSON file or if a shape is missing required keys.</p> Source code in <code>src/neurospatial/regions/io.py</code> <pre><code>def load_labelme_json(\n    json_path: str | Path,\n    *,\n    pixel_to_world: SpatialTransform | None = None,\n    label_key: str = \"label\",\n    points_key: str = \"points\",\n) -&gt; Regions:\n    \"\"\"Parse a *.json* file produced by many point-&amp;-click ROI tools.\n\n    Parameters\n    ----------\n    json_path : str or Path\n        Path to the JSON file.\n    pixel_to_world : SpatialTransform, optional\n        Callable mapping `(N, 2)` **pixel** coordinates \u2192 `(N, 2)` **world**\n        coordinates (e.g., centimeters). If `None`, the coordinates are\n        assumed to be in pixels.\n    label_key : str, optional\n        Key in the JSON object that contains the region label.\n        Default is \"label\".\n    points_key : str, optional\n        Key in the JSON object that contains the list of points.\n        Default is \"points\".\n\n    Returns\n    -------\n    Regions\n        Every polygon becomes a :class:`Region` with ``kind=\"polygon\"``.\n\n    Raises\n    ------\n    ValueError\n        If no shapes are found in the JSON file or if a shape is missing\n        required keys.\n\n    \"\"\"\n    data = json.loads(Path(json_path).read_text())\n    regions_list: list[Region] = []  # Renamed to avoid conflict with Regions class\n\n    # LabelMe puts shapes in a top-level list; CVAT stores under \"shapes\"\n    shapes_data = data.get(\"shapes\", data if isinstance(data, list) else [])\n    if not isinstance(shapes_data, list):  # Ensure shapes_data is a list\n        raise ValueError(\n            f\"Expected 'shapes' to be a list, but got {type(shapes_data).__name__} in {json_path}\",\n        )\n    if not shapes_data:\n        warnings.warn(\n            f\"No shapes found in {json_path}\",\n        )  # Changed to warning, or could be error\n        return Regions([])  # Return empty Regions if no shapes\n\n    for i, obj in enumerate(shapes_data):\n        if not isinstance(obj, dict):\n            warnings.warn(f\"Shape at index {i} is not a dictionary, skipping.\")\n            continue\n\n        name = obj.get(label_key)\n        points_data = obj.get(points_key)\n\n        if name is None:\n            warnings.warn(\n                f\"Shape at index {i} is missing label (key: '{label_key}'), skipping.\",\n            )\n            continue\n        if points_data is None:\n            warnings.warn(\n                f\"Shape '{name}' (index {i}) is missing points (key: '{points_key}'), skipping.\",\n            )\n            continue\n\n        try:\n            pts_px: NDArray[np.float64] = np.asarray(points_data, dtype=float)  # (M, 2)\n            if pts_px.ndim != 2 or pts_px.shape[1] != 2:\n                warnings.warn(\n                    f\"Points for shape '{name}' (index {i}) are not in (M, 2) format, skipping.\",\n                )\n                continue\n        except ValueError as e:\n            warnings.warn(\n                f\"Could not parse points for shape '{name}' (index {i}): {e}, skipping.\",\n            )\n            continue\n\n        pts_transformed = pixel_to_world(pts_px) if pixel_to_world else pts_px\n        # Ensure polygon has at least 3 points for a valid polygon\n        if len(pts_transformed) &lt; 3:\n            warnings.warn(\n                f\"Shape '{name}' (index {i}) has fewer than 3 points after processing, skipping.\",\n            )\n            continue\n        try:\n            poly = shp.Polygon(pts_transformed)\n        except Exception as e:  # Catch potential shapely errors\n            warnings.warn(\n                f\"Could not create polygon for shape '{name}' (index {i}): {e}, skipping.\",\n            )\n            continue\n\n        regions_list.append(\n            Region(\n                name=str(name),  # Ensure name is a string\n                kind=\"polygon\",\n                data=poly,\n                metadata={\"source_json\": Path(json_path).name},\n            ),\n        )\n    return Regions(regions_list)\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.mask_to_region","title":"mask_to_region","text":"<pre><code>mask_to_region(mask_img: NDArray[bool_], *, region_name: str, pixel_to_world: SpatialTransform | None = None, approx_tol_px: float = 1.0) -&gt; Region\n</code></pre> <p>Trace the largest contour of a boolean mask into a polygon Region.</p> <ul> <li>Requires opencv-python.</li> <li>Assumes 2-D image; Y axis is not flipped - handle upstream if needed.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>mask_img</code> <code>(NDArray[bool_], shape(H, W))</code> <p>Binary mask image, where <code>True</code> indicates the region of interest.</p> required <code>region_name</code> <code>str</code> <p>Name for the resulting region.</p> required <code>pixel_to_world</code> <code>SpatialTransform</code> <p>Callable mapping (N,2) pixel coords \u2192 centimeter coords. If <code>None</code>, the coordinates are assumed to be in pixels.</p> <code>None</code> <code>approx_tol_px</code> <code>float</code> <p>Approximation tolerance for contour simplification in pixels. Default is 1.0 pixel.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Region</code> <p>A single :class:<code>Region</code> object representing the largest contour in the mask.</p> Source code in <code>src/neurospatial/regions/io.py</code> <pre><code>def mask_to_region(\n    mask_img: NDArray[np.bool_],\n    *,\n    region_name: str,\n    pixel_to_world: SpatialTransform | None = None,\n    approx_tol_px: float = 1.0,\n) -&gt; Region:\n    \"\"\"Trace the largest contour of a boolean mask into a polygon Region.\n\n    * Requires **opencv-python**.\n    * Assumes **2-D** image; Y axis is *not* flipped - handle upstream if needed.\n\n    Parameters\n    ----------\n    mask_img : NDArray[np.bool_], shape (H, W)\n        Binary mask image, where `True` indicates the region of interest.\n    region_name : str\n        Name for the resulting region.\n    pixel_to_world : SpatialTransform, optional\n        Callable mapping *(N,2)* **pixel** coords \u2192 centimeter coords.\n        If `None`, the coordinates are assumed to be in pixels.\n    approx_tol_px : float, optional\n        Approximation tolerance for contour simplification in pixels.\n        Default is 1.0 pixel.\n\n    Returns\n    -------\n    Region\n        A single :class:`Region` object representing the largest contour in the mask.\n\n    \"\"\"\n    try:\n        import cv2\n    except ImportError as exc:\n        raise RuntimeError(\"mask_to_region() needs opencv-python and shapely\") from exc\n\n    if mask_img.dtype != np.uint8:\n        mask_img = mask_img.astype(\"uint8\")\n\n    cnts, _ = cv2.findContours(\n        mask_img.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE\n    )\n    if not cnts:\n        raise ValueError(\"No contours found in mask\")\n\n    # Take the largest contour by area\n    cnt = max(cnts, key=cv2.contourArea)[:, 0, :]  # (N,2) pixels\n    cnt = cv2.approxPolyDP(cnt, approx_tol_px, True)[:, 0, :]\n\n    pts_cm = pixel_to_world(cnt.astype(np.float64)) if pixel_to_world else cnt\n    poly = shp.Polygon(pts_cm)\n\n    return Region(\n        name=region_name,\n        kind=\"polygon\",\n        data=poly,\n        metadata={\"source\": \"mask\"},\n    )\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.regions_from_json","title":"regions_from_json","text":"<pre><code>regions_from_json(path: str | Path) -&gt; Regions\n</code></pre> <p>Load the schema written by :func:<code>regions_to_json</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>Path to the JSON file containing regions.</p> required <p>Returns:</p> Type Description <code>Regions</code> <p>A collection of :class:<code>Region</code> objects representing the shapes in the JSON.</p> Source code in <code>src/neurospatial/regions/io.py</code> <pre><code>def regions_from_json(path: str | Path) -&gt; Regions:\n    \"\"\"Load the schema written by :func:`regions_to_json`.\n\n    Parameters\n    ----------\n    path : str or Path\n        Path to the JSON file containing regions.\n\n    Returns\n    -------\n    Regions\n        A collection of :class:`Region` objects representing the shapes in the JSON.\n\n    \"\"\"\n    blob = json.loads(Path(path).read_text())\n    if blob.get(\"format\") != _SCHEMA_TAG:\n        warnings.warn(\n            f\"Unrecognised format tag {blob.get('format')!r}; attempting best-effort load\",\n        )\n    return Regions(Region.from_dict(d) for d in blob[\"regions\"])\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.regions_to_json","title":"regions_to_json","text":"<pre><code>regions_to_json(regions: Regions, path: str | Path, *, indent: int = 2) -&gt; None\n</code></pre> <p>Write a list-of-dicts file that any language can read.</p> <p>Parameters:</p> Name Type Description Default <code>regions</code> <code>Regions</code> <p>Collection of regions to write.</p> required <code>path</code> <code>str or Path</code> <p>Destination file path.</p> required <code>indent</code> <code>int</code> <p>Indentation level for the JSON file. Default is 2 spaces.</p> <code>2</code> Source code in <code>src/neurospatial/regions/io.py</code> <pre><code>def regions_to_json(regions: Regions, path: str | Path, *, indent: int = 2) -&gt; None:\n    \"\"\"Write a list-of-dicts file that any language can read.\n\n    Parameters\n    ----------\n    regions : Regions\n        Collection of regions to write.\n    path : str or Path\n        Destination file path.\n    indent : int, optional\n        Indentation level for the JSON file. Default is 2 spaces.\n\n    \"\"\"\n    payload = {\n        \"format\": _SCHEMA_TAG,\n        \"regions\": [reg.to_dict() for reg in regions.values()],\n    }\n    # Ensure the parent directory exists before writing\n    output_path = Path(path)\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n    output_path.write_text(json.dumps(payload, indent=indent))\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.points_in_any_region","title":"points_in_any_region","text":"<pre><code>points_in_any_region(pts: Sequence[Sequence[float]] | NDArray[float64], regions: Regions, *, transform: SpatialTransform | None = None, point_tolerance: float = POINT_TOLERANCE) -&gt; NDArray[np.bool_]\n</code></pre> <p>Determine whether each point lies inside any of the provided Regions.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>(Union[Sequence[Sequence[float]], NDArray[float64]], shape(n_points, 2))</code> <p>Array-like of points. If <code>transform</code> is not None, coordinates are assumed to be in the input space of the transform; otherwise, they must match the coordinate space of each Region.data.</p> required <code>regions</code> <code>Regions</code> <p>A container of Region objects.</p> required <code>transform</code> <code>Optional[SpatialTransform]</code> <p>If provided, a callable that maps input coordinates to the Regions' coordinate space.</p> <code>None</code> <code>point_tolerance</code> <code>float</code> <p>Tolerance for comparing query points to point Regions.</p> <code>POINT_TOLERANCE</code> <p>Returns:</p> Name Type Description <code>mask</code> <code>(NDArray[bool_], shape(n_points))</code> <p>A boolean array where <code>mask[i]</code> is True if the i-th point is inside at least one Region.</p> Source code in <code>src/neurospatial/regions/ops.py</code> <pre><code>def points_in_any_region(\n    pts: Sequence[Sequence[float]] | NDArray[np.float64],\n    regions: Regions,\n    *,\n    transform: SpatialTransform | None = None,\n    point_tolerance: float = POINT_TOLERANCE,\n) -&gt; NDArray[np.bool_]:\n    \"\"\"Determine whether each point lies inside any of the provided Regions.\n\n    Parameters\n    ----------\n    pts : Union[Sequence[Sequence[float]], NDArray[np.float64]], shape (n_points, 2)\n        Array-like of points. If `transform` is not None, coordinates\n        are assumed to be in the input space of the transform; otherwise,\n        they must match the coordinate space of each Region.data.\n    regions : Regions\n        A container of Region objects.\n    transform : Optional[SpatialTransform], default=None\n        If provided, a callable that maps input coordinates to\n        the Regions' coordinate space.\n    point_tolerance : float, default=POINT_TOLERANCE\n        Tolerance for comparing query points to point Regions.\n\n    Returns\n    -------\n    mask : NDArray[np.bool_], shape (n_points,)\n        A boolean array where `mask[i]` is True if the i-th point\n        is inside at least one Region.\n\n    \"\"\"\n    transformed_pts = _prepare_points(pts, transform)\n    n_points = transformed_pts.shape[0]\n\n    if n_points == 0:\n        return np.array([], dtype=bool)\n    if not regions:  # No regions to check against\n        return np.zeros(n_points, dtype=bool)\n\n    overall_mask = np.zeros(n_points, dtype=bool)\n\n    for region in regions.values():\n        region_mask = _get_points_in_single_region_mask(\n            transformed_pts,\n            region,\n            point_tolerance,\n        )\n        overall_mask |= region_mask\n        if overall_mask.all():  # Early exit if all points are already covered\n            break\n    return overall_mask\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.regions_containing_points","title":"regions_containing_points","text":"<pre><code>regions_containing_points(pts: Sequence[Sequence[float]] | NDArray[float64], regions: Regions, *, transform: SpatialTransform | None = None, region_names: Sequence[str] | None = None, return_dataframe: bool = True, point_tolerance: float = POINT_TOLERANCE) -&gt; list[list[Region]] | pd.DataFrame\n</code></pre> <p>For each point, identify all Regions that contain it.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>(Union[Sequence[Sequence[float]], NDArray[float64]], shape(n_points, 2))</code> <p>Array-like of points. If <code>transform</code> is not None, these are assumed to be in the input space of the transform; otherwise, they must match the coordinate space of Region.data.</p> required <code>regions</code> <code>Regions</code> <p>A container of Region objects.</p> required <code>transform</code> <code>Optional[SpatialTransform]</code> <p>If provided, a callable that maps input coordinates to the Regions' coordinate space.</p> <code>None</code> <code>region_names</code> <code>Optional[Sequence[str]]</code> <p>If provided, only consider Regions whose <code>name</code> is in this sequence. If None, all regions in <code>regions</code> are used.</p> <code>None</code> <code>return_dataframe</code> <code>bool</code> <p>If True, return a pandas DataFrame of shape (n_points, n_selected_regions), where each column is the region name and each value is True/False. If False, return a list of lists: each sublist contains Region objects that contain the corresponding point.</p> <code>True</code> <code>point_tolerance</code> <code>float</code> <p>Tolerance for comparing query points to point Regions.</p> <code>POINT_TOLERANCE</code> <p>Returns:</p> Type Description <code>Union[List[List[Region]], pd.DataFrame], length n_points</code> <ul> <li>If <code>return_dataframe</code> is False: A list of length n_points. Each element is   a list of :class:<code>Region</code> objects that contain the corresponding point.</li> <li>If <code>return_dataframe</code> is True: A pandas DataFrame with index   range(n_points) and columns equal to selected region names.   Entry (i, col) is True if pts[i] is inside that region.</li> </ul> Notes <ul> <li>If <code>region_names</code> contains names not found in <code>regions</code>, they are silently ignored.</li> </ul> Source code in <code>src/neurospatial/regions/ops.py</code> <pre><code>def regions_containing_points(\n    pts: Sequence[Sequence[float]] | NDArray[np.float64],\n    regions: Regions,\n    *,\n    transform: SpatialTransform | None = None,\n    region_names: Sequence[str] | None = None,\n    return_dataframe: bool = True,\n    point_tolerance: float = POINT_TOLERANCE,\n) -&gt; list[list[Region]] | pd.DataFrame:\n    \"\"\"For each point, identify all Regions that contain it.\n\n    Parameters\n    ----------\n    pts : Union[Sequence[Sequence[float]], NDArray[np.float64]], shape (n_points, 2)\n        Array-like of points. If `transform` is not None, these are\n        assumed to be in the input space of the transform; otherwise,\n        they must match the coordinate space of Region.data.\n    regions : Regions\n        A container of Region objects.\n    transform : Optional[SpatialTransform], default=None\n        If provided, a callable that maps input coordinates to\n        the Regions' coordinate space.\n    region_names : Optional[Sequence[str]], default=None\n        If provided, only consider Regions whose `name` is in this sequence.\n        If None, all regions in `regions` are used.\n    return_dataframe : bool, default=True\n        If True, return a pandas DataFrame of shape (n_points, n_selected_regions),\n        where each column is the region name and each value is True/False.\n        If False, return a list of lists: each sublist contains Region objects\n        that contain the corresponding point.\n    point_tolerance : float, default=POINT_TOLERANCE\n        Tolerance for comparing query points to point Regions.\n\n    Returns\n    -------\n    Union[List[List[Region]], pd.DataFrame], length n_points\n        - If `return_dataframe` is False: A list of length n_points. Each element is\n          a list of :class:`Region` objects that contain the corresponding point.\n        - If `return_dataframe` is True: A pandas DataFrame with index\n          range(n_points) and columns equal to selected region names.\n          Entry (i, col) is True if pts[i] is inside that region.\n\n    Notes\n    -----\n    - If `region_names` contains names not found in `regions`, they are silently ignored.\n\n    \"\"\"\n    transformed_pts = _prepare_points(pts, transform)\n    n_points = transformed_pts.shape[0]\n\n    if n_points == 0:  # Handle case with no input points\n        if return_dataframe:\n            return pd.DataFrame(\n                columns=(\n                    region_names\n                    if region_names is not None\n                    else [r.name for r in regions.values()]\n                ),\n            )\n        return []\n\n    # Filter regions by name if requested\n    selected_regions: list[Region]\n    if region_names is not None:\n        # Maintain order of region_names if possible, and ensure uniqueness\n        name_set = set(region_names)\n        selected_regions = [\n            regions[name]\n            for name in region_names\n            if name in regions and name in name_set\n        ]\n    else:\n        selected_regions = list(regions.values())\n\n    if not selected_regions and return_dataframe:  # No regions to form columns\n        return pd.DataFrame(index=np.arange(n_points))\n\n    if return_dataframe:\n        # Initialize a DataFrame with shape (n_points, len(selected_regions))\n        # Using list comprehension for column names ensures they match selected_regions order\n        df_columns = [reg.name for reg in selected_regions]\n        df = pd.DataFrame(\n            index=np.arange(n_points),\n            columns=df_columns,\n            dtype=bool,\n        )\n        for reg in selected_regions:\n            df[reg.name] = _get_points_in_single_region_mask(\n                transformed_pts,\n                reg,\n                point_tolerance,\n            )\n        return df\n    # Build list of lists of Region objects\n    output: list[list[Region]] = [[] for _ in range(n_points)]\n    for region in selected_regions:\n        point_mask = _get_points_in_single_region_mask(\n            transformed_pts,\n            region,\n            point_tolerance,\n        )\n        # Iterate through points that are in the current region\n        for i in np.flatnonzero(point_mask):\n            output[i].append(region.name)\n    return output\n</code></pre>"},{"location":"api/neurospatial/regions/#neurospatial.regions.plot_regions","title":"plot_regions","text":"<pre><code>plot_regions(regions: Regions, *, ax: Axes | None = None, region_names: Sequence[str] | None = None, default_kwargs: Mapping[str, Any] | None = None, world_to_pixel: SpatialTransform | None = None, add_legend: bool = True, **per_region_kwargs: Mapping[str, Any]) -&gt; None\n</code></pre> <p>Draw a subset (or all) regions onto ax.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>Destination Axes.</p> <code>None</code> <code>regions</code> <code>Regions</code> <p>Collection to draw.</p> required <code>region_names</code> <code>optional list or tuple</code> <p>If given, plot only these names; otherwise plot all.</p> <code>None</code> <code>default_kwargs</code> <code>dict</code> <p>Plot kwargs applied to every region (unless overridden).</p> <code>None</code> <code>world_to_pixel</code> <code>SpatialTransform</code> <p>If supplied, coordinates are mapped through this transform before plotting - handy for overlaying cm-space polygons on pixel-space video frames.</p> <code>None</code> <code>**per_region_kwargs</code> <code>Mapping[str, Any]</code> <p>Per-region overrides::</p> <pre><code>plot_regions(ax, regs, Stem={\"alpha\": 0.1}, Reward={\"edgecolor\": \"red\"})\n</code></pre> <code>{}</code> <p>Returns:</p> Type Description <code>None</code> <p>Modifies the provided axes in place.</p> Notes <ul> <li>Points \u2192 <code>ax.scatter</code></li> <li>Polygons \u2192 <code>matplotlib.patches.PathPatch</code></li> <li>Legend labels default to the region name.</li> </ul> Source code in <code>src/neurospatial/regions/plot.py</code> <pre><code>def plot_regions(\n    regions: Regions,\n    *,\n    ax: matplotlib.axes.Axes | None = None,\n    region_names: Sequence[str] | None = None,\n    default_kwargs: Mapping[str, Any] | None = None,\n    world_to_pixel: SpatialTransform | None = None,\n    add_legend: bool = True,\n    **per_region_kwargs: Mapping[str, Any],\n) -&gt; None:\n    \"\"\"Draw a subset (or all) regions onto *ax*.\n\n    Parameters\n    ----------\n    ax : matplotlib.axes.Axes\n        Destination Axes.\n    regions : Regions\n        Collection to draw.\n    region_names : optional list or tuple\n        If given, plot only these names; otherwise plot *all*.\n    default_kwargs : dict, optional\n        Plot kwargs applied to every region (unless overridden).\n    world_to_pixel : SpatialTransform, optional\n        If supplied, coordinates are mapped **through** this transform\n        *before* plotting - handy for overlaying cm-space polygons on\n        pixel-space video frames.\n    **per_region_kwargs\n        Per-region overrides::\n\n            plot_regions(ax, regs, Stem={\"alpha\": 0.1}, Reward={\"edgecolor\": \"red\"})\n\n    Returns\n    -------\n    None\n        Modifies the provided axes in place.\n\n    Notes\n    -----\n    * Points \u2192 `ax.scatter`\n    * Polygons \u2192 `matplotlib.patches.PathPatch`\n    * Legend labels default to the region name.\n\n    \"\"\"\n    try:\n        import shapely.geometry as _shp\n    except ModuleNotFoundError:  # polygon plotting will warn later if needed\n        _shp = None\n\n    if region_names is None:\n        region_names = tuple(regions.keys())\n\n    if not region_names:\n        return  # nothing to draw\n\n    if ax is None:\n        ax = plt.gca()\n\n    for name in region_names:\n        if name not in regions:\n            warnings.warn(f\"plot_regions: '{name}' not in collection; skipping.\")\n            continue\n\n        reg: Region = regions[name]\n\n        # base \u2192 per-region kw \u2192 metadata \u2192 kwargs passed in call\n        opts: dict[str, Any] = dict(default_kwargs or {})\n        opts.update(reg.metadata.get(\"plot_kwargs\", {}))\n        opts.update(per_region_kwargs.get(name, {}))\n\n        label = opts.pop(\"label\", name)  # legend label\n        alpha = opts.pop(\"alpha\", 0.5)\n\n        # optional coordinate transform\n        def _map(pts: NDArray[np.float64]) -&gt; NDArray[np.float64]:\n            return world_to_pixel(pts) if world_to_pixel else pts\n\n        # ---- draw according to kind ---------------------------------\n        if reg.kind == \"point\":\n            xy = _map(np.asarray(reg.data, dtype=float))\n            ax.scatter(\n                xy[0],\n                xy[1],\n                marker=opts.pop(\"marker\", \"x\"),\n                s=opts.pop(\"s\", 100),\n                alpha=alpha,\n                label=label,\n                **opts,\n            )\n\n        elif reg.kind == \"polygon\":\n            if _shp is None:\n                warnings.warn(f\"Can't draw polygon '{name}': shapely not installed.\")\n                continue\n\n            # Narrow type to Polygon\n            from shapely.geometry import Polygon\n\n            poly = reg.data  # already shapely.Polygon\n            if not isinstance(poly, Polygon):\n                warnings.warn(f\"Region '{name}' data is not a Polygon; skipping.\")\n                continue\n\n            # exterior + (optional) holes  \u2192 Path\n            def _ring_to_path(r):\n                pts = _map(np.asarray(r.coords)[:, :2])\n                return MplPath(pts)\n\n            path = MplPath.make_compound_path(\n                _ring_to_path(poly.exterior),\n                *[_ring_to_path(i) for i in poly.interiors],\n            )\n\n            patch = PathPatch(\n                path,\n                label=label,\n                facecolor=opts.pop(\"facecolor\", opts.pop(\"color\", None)),\n                alpha=alpha,\n                **opts,\n            )\n            ax.add_patch(patch)\n        else:\n            # This shouldn't happen with Literal['point', 'polygon'] type\n            raise ValueError(f\"Unknown region kind '{reg.kind}' for '{name}'.\")\n\n    # add a legend if *any* labels were produced\n    handles, labels = ax.get_legend_handles_labels()\n    if handles and add_legend:\n        ax.legend(handles, labels, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n    ax.autoscale(enable=True, axis=\"both\", tight=True)\n</code></pre>"},{"location":"api/neurospatial/regions/core/","title":"<code>neurospatial.regions.core</code>","text":""},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core","title":"core","text":""},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core--regionscorepy","title":"regions/core.py","text":"<p>Pure data layer for continuous regions of interest (ROIs).</p>"},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core-classes","title":"Classes","text":""},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core.Region","title":"Region  <code>dataclass</code>","text":"<pre><code>Region(name: str, kind: Kind, data: NDArray[float64] | Polygon | Point, metadata: Mapping[str, Any] = dict())\n</code></pre> <p>Immutable description of a spatial ROI.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Unique region identifier.</p> required <code>kind</code> <code>Kind</code> <p>Either <code>\"point\"</code> or <code>\"polygon\"</code>.</p> required <code>data</code> <code>NDArray[float64] | Polygon | Point</code> <p>\u2022 point \u2192 <code>np.ndarray</code> with shape <code>(n_dims,)</code> \u2022 polygon \u2192 :class:<code>shapely.geometry.Polygon</code> (always 2-D)</p> required <code>metadata</code> <code>Mapping[str, Any]</code> <p>Optional, JSON-serialisable attributes (colour, label, \u2026).</p> <code>dict()</code>"},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core.Region-functions","title":"Functions","text":""},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core.Region.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Export Region to a JSON-serializable dictionary.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary representation of the Region.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Export Region to a JSON-serializable dictionary.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary representation of the Region.\n\n    \"\"\"\n    if self.kind == \"point\":\n        geom = (\n            self.data.tolist()\n            if isinstance(self.data, np.ndarray)\n            else list(self.data.coords[0])\n        )\n    else:\n        geom = mapping(self.data)\n\n    return {\n        \"name\": self.name,\n        \"kind\": self.kind,\n        \"geom\": geom,\n        \"metadata\": dict(self.metadata),\n    }\n</code></pre>"},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core.Region.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(payload: Mapping[str, Any]) -&gt; Region\n</code></pre> <p>Create Region from dictionary representation.</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <code>Mapping[str, Any]</code> <p>Dictionary containing region data with keys: 'name', 'kind', 'geom', 'metadata'.</p> required <p>Returns:</p> Type Description <code>Region</code> <p>Reconstructed Region instance.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>@classmethod\ndef from_dict(cls, payload: Mapping[str, Any]) -&gt; Region:\n    \"\"\"Create Region from dictionary representation.\n\n    Parameters\n    ----------\n    payload : Mapping[str, Any]\n        Dictionary containing region data with keys: 'name', 'kind', 'geom', 'metadata'.\n\n    Returns\n    -------\n    Region\n        Reconstructed Region instance.\n\n    \"\"\"\n    kind_str = payload[\"kind\"]\n    if kind_str not in (\"point\", \"polygon\"):\n        raise ValueError(f\"Unknown kind {kind_str!r}\")\n    kind: Kind = kind_str\n\n    if kind == \"point\":\n        data = np.asarray(payload[\"geom\"], dtype=float)\n    else:  # kind == \"polygon\"\n        data = shape(payload[\"geom\"])\n    return cls(\n        name=payload[\"name\"],\n        kind=kind,\n        data=data,\n        metadata=payload.get(\"metadata\", {}),\n    )\n</code></pre>"},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core.Regions","title":"Regions","text":"<pre><code>Regions(items: Iterable[Region] | None = None)\n</code></pre> <p>               Bases: <code>MutableMapping[str, Region]</code></p> <p>A small <code>dict</code>-like container mapping name \u2192 Region.</p> <p>Provides the usual mapping API plus a few helpers (<code>add</code>, <code>remove</code>, <code>list_names</code>, <code>buffer</code>, \u2026).</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def __init__(self, items: Iterable[Region] | None = None) -&gt; None:\n    self._store: dict[str, Region] = {}\n    if items is not None:\n        for reg in items:\n            self[reg.name] = reg\n</code></pre>"},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core.Regions-functions","title":"Functions","text":""},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core.Regions.add","title":"add","text":"<pre><code>add(name: str, *, point: PointCoords | None = None, polygon: Polygon | None = None, metadata: Mapping[str, Any] | None = None) -&gt; Region\n</code></pre> <p>Create and insert a new Region.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Unique name for the region.</p> required <code>point</code> <code>PointCoords or None</code> <p>Point coordinates or Shapely Point object. Mutually exclusive with polygon.</p> <code>None</code> <code>polygon</code> <code>Polygon or None</code> <p>Shapely Polygon object. Mutually exclusive with point.</p> <code>None</code> <code>metadata</code> <code>Mapping[str, Any] or None</code> <p>Optional metadata dictionary to attach to the region.</p> <code>None</code> <p>Returns:</p> Type Description <code>Region</code> <p>The newly created Region instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both or neither of point/polygon are specified.</p> <code>KeyError</code> <p>If name already exists in the collection.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def add(\n    self,\n    name: str,\n    *,\n    point: PointCoords | None = None,\n    polygon: Polygon | None = None,\n    metadata: Mapping[str, Any] | None = None,\n) -&gt; Region:\n    \"\"\"Create and insert a new Region.\n\n    Parameters\n    ----------\n    name : str\n        Unique name for the region.\n    point : PointCoords or None, optional\n        Point coordinates or Shapely Point object. Mutually exclusive with polygon.\n    polygon : Polygon or None, optional\n        Shapely Polygon object. Mutually exclusive with point.\n    metadata : Mapping[str, Any] or None, optional\n        Optional metadata dictionary to attach to the region.\n\n    Returns\n    -------\n    Region\n        The newly created Region instance.\n\n    Raises\n    ------\n    ValueError\n        If both or neither of point/polygon are specified.\n    KeyError\n        If name already exists in the collection.\n\n    \"\"\"\n    if (point is None) == (polygon is None):\n        raise ValueError(\"Specify **one** of 'point' or 'polygon'.\")\n    if name in self:\n        raise KeyError(f\"Duplicate region name {name!r}.\")\n\n    if point is not None:\n        # Accept either a coordinate array or a Shapely Point\n        coords = np.asarray(\n            point.coords[0] if isinstance(point, Point) else point, dtype=float\n        )\n        region = Region(name, \"point\", coords, metadata or {})\n    else:\n        region = Region(name, \"polygon\", polygon, metadata or {})\n\n    self[name] = region\n    return region\n</code></pre>"},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core.Regions.update_region","title":"update_region","text":"<pre><code>update_region(name: str, *, point: PointCoords | None = None, polygon: Polygon | None = None, metadata: Mapping[str, Any] | None = None) -&gt; Region\n</code></pre> <p>Update an existing Region.</p> <p>This method replaces an existing region with a new one. The region can change its type (point vs polygon) and/or data and/or metadata. Metadata is preserved from the existing region if not explicitly provided.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the region to update.</p> required <code>point</code> <code>PointCoords or None</code> <p>Point coordinates or Shapely Point object. Mutually exclusive with polygon.</p> <code>None</code> <code>polygon</code> <code>Polygon or None</code> <p>Shapely Polygon object. Mutually exclusive with point.</p> <code>None</code> <code>metadata</code> <code>Mapping[str, Any] or None</code> <p>Optional metadata dictionary to attach to the region. If None, preserves the existing region's metadata.</p> <code>None</code> <p>Returns:</p> Type Description <code>Region</code> <p>The newly created Region instance that replaced the old one.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both or neither of point/polygon are specified.</p> <code>KeyError</code> <p>If name does not exist in the collection.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neurospatial.regions import Regions\n&gt;&gt;&gt; regs = Regions()\n&gt;&gt;&gt; _ = regs.add(\"center\", point=[0.0, 0.0], metadata={\"color\": \"red\"})\n&gt;&gt;&gt; # Update coordinates while preserving metadata\n&gt;&gt;&gt; _ = regs.update_region(\"center\", point=[1.0, 1.0])\n&gt;&gt;&gt; regs[\"center\"].data\narray([1., 1.])\n&gt;&gt;&gt; regs[\"center\"].metadata[\"color\"]\n'red'\n</code></pre> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def update_region(\n    self,\n    name: str,\n    *,\n    point: PointCoords | None = None,\n    polygon: Polygon | None = None,\n    metadata: Mapping[str, Any] | None = None,\n) -&gt; Region:\n    \"\"\"Update an existing Region.\n\n    This method replaces an existing region with a new one. The region can\n    change its type (point vs polygon) and/or data and/or metadata.\n    Metadata is preserved from the existing region if not explicitly provided.\n\n    Parameters\n    ----------\n    name : str\n        Name of the region to update.\n    point : PointCoords or None, optional\n        Point coordinates or Shapely Point object. Mutually exclusive with polygon.\n    polygon : Polygon or None, optional\n        Shapely Polygon object. Mutually exclusive with point.\n    metadata : Mapping[str, Any] or None, optional\n        Optional metadata dictionary to attach to the region. If None, preserves\n        the existing region's metadata.\n\n    Returns\n    -------\n    Region\n        The newly created Region instance that replaced the old one.\n\n    Raises\n    ------\n    ValueError\n        If both or neither of point/polygon are specified.\n    KeyError\n        If name does not exist in the collection.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from neurospatial.regions import Regions\n    &gt;&gt;&gt; regs = Regions()\n    &gt;&gt;&gt; _ = regs.add(\"center\", point=[0.0, 0.0], metadata={\"color\": \"red\"})\n    &gt;&gt;&gt; # Update coordinates while preserving metadata\n    &gt;&gt;&gt; _ = regs.update_region(\"center\", point=[1.0, 1.0])\n    &gt;&gt;&gt; regs[\"center\"].data\n    array([1., 1.])\n    &gt;&gt;&gt; regs[\"center\"].metadata[\"color\"]\n    'red'\n\n    \"\"\"\n    if (point is None) == (polygon is None):\n        raise ValueError(\"Specify **one** of 'point' or 'polygon'.\")\n    if name not in self:\n        raise KeyError(\n            f\"Region {name!r} does not exist. Use add() to create new regions.\"\n        )\n\n    # Preserve existing metadata if not explicitly provided\n    old_region = self._store[name]\n    effective_metadata = metadata if metadata is not None else old_region.metadata\n\n    # Remove the old region and add the new one\n    del self._store[name]\n\n    if point is not None:\n        # Accept either a coordinate array or a Shapely Point\n        coords = np.asarray(\n            point.coords[0] if isinstance(point, Point) else point, dtype=float\n        )\n        region = Region(name, \"point\", coords, effective_metadata)\n    else:\n        region = Region(name, \"polygon\", polygon, effective_metadata)\n\n    # Use direct store access to bypass __setitem__ duplicate check\n    self._store[name] = region\n    return region\n</code></pre>"},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core.Regions.remove","title":"remove","text":"<pre><code>remove(name: str) -&gt; None\n</code></pre> <p>Delete a region by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of region to remove. No error if absent.</p> required Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def remove(self, name: str) -&gt; None:\n    \"\"\"Delete a region by name.\n\n    Parameters\n    ----------\n    name : str\n        Name of region to remove. No error if absent.\n\n    \"\"\"\n    self._store.pop(name, None)\n</code></pre>"},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core.Regions.list_names","title":"list_names","text":"<pre><code>list_names() -&gt; list[str]\n</code></pre> <p>Get list of region names in insertion order.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Region names in the order they were added.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def list_names(self) -&gt; list[str]:\n    \"\"\"Get list of region names in insertion order.\n\n    Returns\n    -------\n    list[str]\n        Region names in the order they were added.\n\n    \"\"\"\n    return list(self._store)\n</code></pre>"},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core.Regions.area","title":"area","text":"<pre><code>area(name: str) -&gt; float\n</code></pre> <p>Compute area of a region.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of region to query.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Area of the polygon region, or 0.0 for point regions.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def area(self, name: str) -&gt; float:\n    \"\"\"Compute area of a region.\n\n    Parameters\n    ----------\n    name : str\n        Name of region to query.\n\n    Returns\n    -------\n    float\n        Area of the polygon region, or 0.0 for point regions.\n\n    \"\"\"\n    region = self[name]\n    if region.kind == \"polygon\":\n        assert isinstance(region.data, Polygon)\n        return float(region.data.area)\n    return 0.0\n</code></pre>"},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core.Regions.region_center","title":"region_center","text":"<pre><code>region_center(region_name: str) -&gt; NDArray[np.float64] | None\n</code></pre> <p>Calculate the center of a specified named region.</p> <p>Parameters:</p> Name Type Description Default <code>region_name</code> <code>str</code> <p>Name of region to query.</p> required <p>Returns:</p> Type Description <code>Optional[NDArray[float64]]</code> <p>N-D coordinates of the region's center, or None if the region is empty or center cannot be determined.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If <code>region_name</code> is not present in this collection.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def region_center(self, region_name: str) -&gt; NDArray[np.float64] | None:\n    \"\"\"Calculate the center of a specified named region.\n\n    Parameters\n    ----------\n    region_name : str\n        Name of region to query.\n\n    Returns\n    -------\n    Optional[NDArray[np.float64]]\n        N-D coordinates of the region's center, or None if the region\n        is empty or center cannot be determined.\n\n    Raises\n    ------\n    KeyError\n        If `region_name` is not present in this collection.\n\n    \"\"\"\n    if region_name not in self._store:\n        raise KeyError(f\"Region '{region_name}' not found in this collection.\")\n\n    region = self._store[region_name]\n\n    if region.kind == \"point\":\n        return np.asarray(region.data, dtype=float)\n    else:  # region.kind == \"polygon\"\n        assert isinstance(region.data, Polygon)\n        return np.array(region.data.centroid.coords[0], dtype=float)\n</code></pre>"},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core.Regions.buffer","title":"buffer","text":"<pre><code>buffer(source: str | NDArray[float64], distance: float, new_name: str, **meta: Any) -&gt; Region\n</code></pre> <p>Create a buffered region around a point or existing region.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str or NDArray[float64]</code> <p>Region name or point coordinates to buffer around.</p> required <code>distance</code> <code>float</code> <p>Buffer distance in spatial units.</p> required <code>new_name</code> <code>str</code> <p>Name for the new buffered region.</p> required <code>**meta</code> <code>Any</code> <p>Additional metadata for the new region.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Region</code> <p>The newly created buffered region.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def buffer(\n    self,\n    source: str | NDArray[np.float64],\n    distance: float,\n    new_name: str,\n    **meta: Any,\n) -&gt; Region:\n    \"\"\"Create a buffered region around a point or existing region.\n\n    Parameters\n    ----------\n    source : str or NDArray[np.float64]\n        Region name or point coordinates to buffer around.\n    distance : float\n        Buffer distance in spatial units.\n    new_name : str\n        Name for the new buffered region.\n    **meta : Any\n        Additional metadata for the new region.\n\n    Returns\n    -------\n    Region\n        The newly created buffered region.\n\n    \"\"\"\n    # derive geometry in cm space\n    if isinstance(source, str):\n        src = self[source]\n        if src.kind == \"polygon\":\n            assert isinstance(src.data, Polygon)\n            geom = src.data\n        elif src.kind == \"point\" and src.n_dims == 2:\n            assert isinstance(src.data, np.ndarray)\n            geom = Point(src.data)\n        else:\n            raise ValueError(\"Can only buffer 2-D point or polygon regions.\")\n    else:  # raw coords\n        arr = np.asarray(source, dtype=float)\n        if arr.shape != (2,):\n            raise ValueError(\"Raw source must be shape (2,) for buffering.\")\n        geom = Point(arr)\n\n    poly = geom.buffer(distance)\n    if not isinstance(poly, Polygon):\n        raise ValueError(\"Buffer produced non-polygon geometry.\")\n\n    return self.add(new_name, polygon=poly, metadata=meta)\n</code></pre>"},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core.Regions.to_dataframe","title":"to_dataframe","text":"<pre><code>to_dataframe() -&gt; DataFrame\n</code></pre> <p>Convert this collection to a Pandas DataFrame. Requires Pandas to be installed.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with columns ['name', 'kind', 'data', 'metadata']. The 'data' column contains the coordinates for points or polygons.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def to_dataframe(self) -&gt; DataFrame:\n    \"\"\"Convert this collection to a Pandas DataFrame.\n    Requires Pandas to be installed.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with columns ['name', 'kind', 'data', 'metadata'].\n        The 'data' column contains the coordinates for points or polygons.\n\n    \"\"\"\n    from .io import regions_to_dataframe\n\n    return regions_to_dataframe(self)\n</code></pre>"},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core.Regions.to_json","title":"to_json","text":"<pre><code>to_json(path: str | Path, *, indent: int = 2) -&gt; None\n</code></pre> <p>Write collection to disk in a simple, version-tagged schema.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>Output file path for JSON data.</p> required <code>indent</code> <code>int</code> <p>Indentation level for pretty-printed JSON.</p> <code>2</code> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>def to_json(self, path: str | Path, *, indent: int = 2) -&gt; None:\n    \"\"\"Write collection to disk in a simple, version-tagged schema.\n\n    Parameters\n    ----------\n    path : str or Path\n        Output file path for JSON data.\n    indent : int, default=2\n        Indentation level for pretty-printed JSON.\n\n    \"\"\"\n    payload = {\n        \"format\": self._FMT,\n        \"regions\": [r.to_dict() for r in self._store.values()],\n    }\n    output_path = Path(path)\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n    output_path.write_text(json.dumps(payload, indent=indent))\n</code></pre>"},{"location":"api/neurospatial/regions/core/#neurospatial.regions.core.Regions.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(path: str | Path) -&gt; Regions\n</code></pre> <p>Load Regions from JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>Path to JSON file containing regions data.</p> required <p>Returns:</p> Type Description <code>Regions</code> <p>Loaded Regions collection.</p> Source code in <code>src/neurospatial/regions/core.py</code> <pre><code>@classmethod\ndef from_json(cls, path: str | Path) -&gt; Regions:\n    \"\"\"Load Regions from JSON file.\n\n    Parameters\n    ----------\n    path : str or Path\n        Path to JSON file containing regions data.\n\n    Returns\n    -------\n    Regions\n        Loaded Regions collection.\n\n    \"\"\"\n    blob = json.loads(Path(path).read_text())\n    if blob.get(\"format\") != cls._FMT:\n        warnings.warn(f\"Unexpected format tag {blob.get('format')!r}\")\n    return cls(Region.from_dict(d) for d in blob[\"regions\"])\n</code></pre>"},{"location":"api/neurospatial/regions/io/","title":"<code>neurospatial.regions.io</code>","text":""},{"location":"api/neurospatial/regions/io/#neurospatial.regions.io","title":"io","text":""},{"location":"api/neurospatial/regions/io/#neurospatial.regions.io--regionsiopy","title":"regions/io.py","text":"<p>Helper functions for importing continuous ROIs (<code>Region</code> / <code>Regions</code>) from common labelling formats and exporting them to a shareable JSON schema.</p>"},{"location":"api/neurospatial/regions/io/#neurospatial.regions.io-classes","title":"Classes","text":""},{"location":"api/neurospatial/regions/io/#neurospatial.regions.io-functions","title":"Functions","text":""},{"location":"api/neurospatial/regions/io/#neurospatial.regions.io.regions_to_json","title":"regions_to_json","text":"<pre><code>regions_to_json(regions: Regions, path: str | Path, *, indent: int = 2) -&gt; None\n</code></pre> <p>Write a list-of-dicts file that any language can read.</p> <p>Parameters:</p> Name Type Description Default <code>regions</code> <code>Regions</code> <p>Collection of regions to write.</p> required <code>path</code> <code>str or Path</code> <p>Destination file path.</p> required <code>indent</code> <code>int</code> <p>Indentation level for the JSON file. Default is 2 spaces.</p> <code>2</code> Source code in <code>src/neurospatial/regions/io.py</code> <pre><code>def regions_to_json(regions: Regions, path: str | Path, *, indent: int = 2) -&gt; None:\n    \"\"\"Write a list-of-dicts file that any language can read.\n\n    Parameters\n    ----------\n    regions : Regions\n        Collection of regions to write.\n    path : str or Path\n        Destination file path.\n    indent : int, optional\n        Indentation level for the JSON file. Default is 2 spaces.\n\n    \"\"\"\n    payload = {\n        \"format\": _SCHEMA_TAG,\n        \"regions\": [reg.to_dict() for reg in regions.values()],\n    }\n    # Ensure the parent directory exists before writing\n    output_path = Path(path)\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n    output_path.write_text(json.dumps(payload, indent=indent))\n</code></pre>"},{"location":"api/neurospatial/regions/io/#neurospatial.regions.io.regions_from_json","title":"regions_from_json","text":"<pre><code>regions_from_json(path: str | Path) -&gt; Regions\n</code></pre> <p>Load the schema written by :func:<code>regions_to_json</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>Path to the JSON file containing regions.</p> required <p>Returns:</p> Type Description <code>Regions</code> <p>A collection of :class:<code>Region</code> objects representing the shapes in the JSON.</p> Source code in <code>src/neurospatial/regions/io.py</code> <pre><code>def regions_from_json(path: str | Path) -&gt; Regions:\n    \"\"\"Load the schema written by :func:`regions_to_json`.\n\n    Parameters\n    ----------\n    path : str or Path\n        Path to the JSON file containing regions.\n\n    Returns\n    -------\n    Regions\n        A collection of :class:`Region` objects representing the shapes in the JSON.\n\n    \"\"\"\n    blob = json.loads(Path(path).read_text())\n    if blob.get(\"format\") != _SCHEMA_TAG:\n        warnings.warn(\n            f\"Unrecognised format tag {blob.get('format')!r}; attempting best-effort load\",\n        )\n    return Regions(Region.from_dict(d) for d in blob[\"regions\"])\n</code></pre>"},{"location":"api/neurospatial/regions/io/#neurospatial.regions.io.load_labelme_json","title":"load_labelme_json","text":"<pre><code>load_labelme_json(json_path: str | Path, *, pixel_to_world: SpatialTransform | None = None, label_key: str = 'label', points_key: str = 'points') -&gt; Regions\n</code></pre> <p>Parse a .json file produced by many point-&amp;-click ROI tools.</p> <p>Parameters:</p> Name Type Description Default <code>json_path</code> <code>str or Path</code> <p>Path to the JSON file.</p> required <code>pixel_to_world</code> <code>SpatialTransform</code> <p>Callable mapping <code>(N, 2)</code> pixel coordinates \u2192 <code>(N, 2)</code> world coordinates (e.g., centimeters). If <code>None</code>, the coordinates are assumed to be in pixels.</p> <code>None</code> <code>label_key</code> <code>str</code> <p>Key in the JSON object that contains the region label. Default is \"label\".</p> <code>'label'</code> <code>points_key</code> <code>str</code> <p>Key in the JSON object that contains the list of points. Default is \"points\".</p> <code>'points'</code> <p>Returns:</p> Type Description <code>Regions</code> <p>Every polygon becomes a :class:<code>Region</code> with <code>kind=\"polygon\"</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no shapes are found in the JSON file or if a shape is missing required keys.</p> Source code in <code>src/neurospatial/regions/io.py</code> <pre><code>def load_labelme_json(\n    json_path: str | Path,\n    *,\n    pixel_to_world: SpatialTransform | None = None,\n    label_key: str = \"label\",\n    points_key: str = \"points\",\n) -&gt; Regions:\n    \"\"\"Parse a *.json* file produced by many point-&amp;-click ROI tools.\n\n    Parameters\n    ----------\n    json_path : str or Path\n        Path to the JSON file.\n    pixel_to_world : SpatialTransform, optional\n        Callable mapping `(N, 2)` **pixel** coordinates \u2192 `(N, 2)` **world**\n        coordinates (e.g., centimeters). If `None`, the coordinates are\n        assumed to be in pixels.\n    label_key : str, optional\n        Key in the JSON object that contains the region label.\n        Default is \"label\".\n    points_key : str, optional\n        Key in the JSON object that contains the list of points.\n        Default is \"points\".\n\n    Returns\n    -------\n    Regions\n        Every polygon becomes a :class:`Region` with ``kind=\"polygon\"``.\n\n    Raises\n    ------\n    ValueError\n        If no shapes are found in the JSON file or if a shape is missing\n        required keys.\n\n    \"\"\"\n    data = json.loads(Path(json_path).read_text())\n    regions_list: list[Region] = []  # Renamed to avoid conflict with Regions class\n\n    # LabelMe puts shapes in a top-level list; CVAT stores under \"shapes\"\n    shapes_data = data.get(\"shapes\", data if isinstance(data, list) else [])\n    if not isinstance(shapes_data, list):  # Ensure shapes_data is a list\n        raise ValueError(\n            f\"Expected 'shapes' to be a list, but got {type(shapes_data).__name__} in {json_path}\",\n        )\n    if not shapes_data:\n        warnings.warn(\n            f\"No shapes found in {json_path}\",\n        )  # Changed to warning, or could be error\n        return Regions([])  # Return empty Regions if no shapes\n\n    for i, obj in enumerate(shapes_data):\n        if not isinstance(obj, dict):\n            warnings.warn(f\"Shape at index {i} is not a dictionary, skipping.\")\n            continue\n\n        name = obj.get(label_key)\n        points_data = obj.get(points_key)\n\n        if name is None:\n            warnings.warn(\n                f\"Shape at index {i} is missing label (key: '{label_key}'), skipping.\",\n            )\n            continue\n        if points_data is None:\n            warnings.warn(\n                f\"Shape '{name}' (index {i}) is missing points (key: '{points_key}'), skipping.\",\n            )\n            continue\n\n        try:\n            pts_px: NDArray[np.float64] = np.asarray(points_data, dtype=float)  # (M, 2)\n            if pts_px.ndim != 2 or pts_px.shape[1] != 2:\n                warnings.warn(\n                    f\"Points for shape '{name}' (index {i}) are not in (M, 2) format, skipping.\",\n                )\n                continue\n        except ValueError as e:\n            warnings.warn(\n                f\"Could not parse points for shape '{name}' (index {i}): {e}, skipping.\",\n            )\n            continue\n\n        pts_transformed = pixel_to_world(pts_px) if pixel_to_world else pts_px\n        # Ensure polygon has at least 3 points for a valid polygon\n        if len(pts_transformed) &lt; 3:\n            warnings.warn(\n                f\"Shape '{name}' (index {i}) has fewer than 3 points after processing, skipping.\",\n            )\n            continue\n        try:\n            poly = shp.Polygon(pts_transformed)\n        except Exception as e:  # Catch potential shapely errors\n            warnings.warn(\n                f\"Could not create polygon for shape '{name}' (index {i}): {e}, skipping.\",\n            )\n            continue\n\n        regions_list.append(\n            Region(\n                name=str(name),  # Ensure name is a string\n                kind=\"polygon\",\n                data=poly,\n                metadata={\"source_json\": Path(json_path).name},\n            ),\n        )\n    return Regions(regions_list)\n</code></pre>"},{"location":"api/neurospatial/regions/io/#neurospatial.regions.io.load_cvat_xml","title":"load_cvat_xml","text":"<pre><code>load_cvat_xml(xml_path: str | Path, *, pixel_to_world: SpatialTransform | None = None) -&gt; Regions\n</code></pre> <p>Parse a .xml file produced by CVAT.</p> <p>Region names are generated based on their label. If a label appears multiple times within an image, a running index is appended (e.g., tumor_0, tumor_1). If a label is unique within an image, no index is added (e.g., tumor). Unlabeled shapes follow the same logic (e.g., unlabeled or unlabeled_0). Open polylines are ignored. Other shapes are converted to Regions.</p> <p>Parameters:</p> Name Type Description Default <code>xml_path</code> <code>str or Path</code> <p>Path to the CVAT XML file.</p> required <code>pixel_to_world</code> <code>SpatialTransform</code> <p>Callable mapping <code>(N,2)</code> pixel coords \u2192 <code>(N,2)</code> world coords.</p> <code>None</code> <p>Returns:</p> Type Description <code>Regions</code> <p>A collection of :class:<code>Region</code> objects.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>xml_path</code> does not exist.</p> <code>ParseError</code> <p>If <code>xml_path</code> is not a valid XML file.</p> Source code in <code>src/neurospatial/regions/io.py</code> <pre><code>def load_cvat_xml(\n    xml_path: str | Path,\n    *,\n    pixel_to_world: SpatialTransform | None = None,\n) -&gt; Regions:\n    \"\"\"Parse a *.xml* file produced by CVAT.\n\n    Region names are generated based on their label. If a label appears\n    multiple times within an image, a running index is appended (e.g., tumor_0,\n    tumor_1). If a label is unique within an image, no index is added (e.g., tumor).\n    Unlabeled shapes follow the same logic (e.g., unlabeled or unlabeled_0).\n    Open polylines are ignored. Other shapes are converted to Regions.\n\n    Parameters\n    ----------\n    xml_path : str or Path\n        Path to the CVAT XML file.\n    pixel_to_world : SpatialTransform, optional\n        Callable mapping `(N,2)` pixel coords \u2192 `(N,2)` world coords.\n\n    Returns\n    -------\n    Regions\n        A collection of :class:`Region` objects.\n\n    Raises\n    ------\n    FileNotFoundError\n        If `xml_path` does not exist.\n    ET.ParseError\n        If `xml_path` is not a valid XML file.\n\n    \"\"\"\n    path_obj = Path(xml_path)\n    if not path_obj.exists():\n        raise FileNotFoundError(f\"XML file not found: {xml_path}\")\n\n    try:\n        tree = ET.parse(path_obj)\n    except ET.ParseError as e:\n        raise ET.ParseError(f\"Error parsing XML file {xml_path}: {e}\") from e\n\n    root = tree.getroot()\n    label_colors = _get_label_colors(root)\n\n    all_regions_in_file: list[Region] = []\n    for image_idx, image in enumerate(root.findall(\"image\")):\n        image_id_str = image.get(\"id\", f\"image{image_idx}\")\n\n        # Collect all shapes from this image\n        collected_shapes_data = _collect_shapes_from_image(\n            image,\n            image_id_str,\n            pixel_to_world,\n            label_colors,\n        )\n\n        # Generate unique names and create Region objects\n        regions = _generate_region_names(collected_shapes_data, path_obj)\n        all_regions_in_file.extend(regions)\n\n    return Regions(all_regions_in_file)\n</code></pre>"},{"location":"api/neurospatial/regions/io/#neurospatial.regions.io.mask_to_region","title":"mask_to_region","text":"<pre><code>mask_to_region(mask_img: NDArray[bool_], *, region_name: str, pixel_to_world: SpatialTransform | None = None, approx_tol_px: float = 1.0) -&gt; Region\n</code></pre> <p>Trace the largest contour of a boolean mask into a polygon Region.</p> <ul> <li>Requires opencv-python.</li> <li>Assumes 2-D image; Y axis is not flipped - handle upstream if needed.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>mask_img</code> <code>(NDArray[bool_], shape(H, W))</code> <p>Binary mask image, where <code>True</code> indicates the region of interest.</p> required <code>region_name</code> <code>str</code> <p>Name for the resulting region.</p> required <code>pixel_to_world</code> <code>SpatialTransform</code> <p>Callable mapping (N,2) pixel coords \u2192 centimeter coords. If <code>None</code>, the coordinates are assumed to be in pixels.</p> <code>None</code> <code>approx_tol_px</code> <code>float</code> <p>Approximation tolerance for contour simplification in pixels. Default is 1.0 pixel.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Region</code> <p>A single :class:<code>Region</code> object representing the largest contour in the mask.</p> Source code in <code>src/neurospatial/regions/io.py</code> <pre><code>def mask_to_region(\n    mask_img: NDArray[np.bool_],\n    *,\n    region_name: str,\n    pixel_to_world: SpatialTransform | None = None,\n    approx_tol_px: float = 1.0,\n) -&gt; Region:\n    \"\"\"Trace the largest contour of a boolean mask into a polygon Region.\n\n    * Requires **opencv-python**.\n    * Assumes **2-D** image; Y axis is *not* flipped - handle upstream if needed.\n\n    Parameters\n    ----------\n    mask_img : NDArray[np.bool_], shape (H, W)\n        Binary mask image, where `True` indicates the region of interest.\n    region_name : str\n        Name for the resulting region.\n    pixel_to_world : SpatialTransform, optional\n        Callable mapping *(N,2)* **pixel** coords \u2192 centimeter coords.\n        If `None`, the coordinates are assumed to be in pixels.\n    approx_tol_px : float, optional\n        Approximation tolerance for contour simplification in pixels.\n        Default is 1.0 pixel.\n\n    Returns\n    -------\n    Region\n        A single :class:`Region` object representing the largest contour in the mask.\n\n    \"\"\"\n    try:\n        import cv2\n    except ImportError as exc:\n        raise RuntimeError(\"mask_to_region() needs opencv-python and shapely\") from exc\n\n    if mask_img.dtype != np.uint8:\n        mask_img = mask_img.astype(\"uint8\")\n\n    cnts, _ = cv2.findContours(\n        mask_img.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE\n    )\n    if not cnts:\n        raise ValueError(\"No contours found in mask\")\n\n    # Take the largest contour by area\n    cnt = max(cnts, key=cv2.contourArea)[:, 0, :]  # (N,2) pixels\n    cnt = cv2.approxPolyDP(cnt, approx_tol_px, True)[:, 0, :]\n\n    pts_cm = pixel_to_world(cnt.astype(np.float64)) if pixel_to_world else cnt\n    poly = shp.Polygon(pts_cm)\n\n    return Region(\n        name=region_name,\n        kind=\"polygon\",\n        data=poly,\n        metadata={\"source\": \"mask\"},\n    )\n</code></pre>"},{"location":"api/neurospatial/regions/io/#neurospatial.regions.io.regions_to_dataframe","title":"regions_to_dataframe","text":"<pre><code>regions_to_dataframe(regions: Regions) -&gt; pd.DataFrame\n</code></pre> <p>Return a pandas DataFrame summary.</p> <p>Parameters:</p> Name Type Description Default <code>regions</code> <code>Regions</code> <p>Collection of regions to summarize.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame with columns for region name, kind, area, and metadata.</p> Source code in <code>src/neurospatial/regions/io.py</code> <pre><code>def regions_to_dataframe(regions: Regions) -&gt; pd.DataFrame:\n    \"\"\"Return a *pandas* DataFrame summary.\n\n    Parameters\n    ----------\n    regions : Regions\n        Collection of regions to summarize.\n\n    Returns\n    -------\n    pd.DataFrame\n        A DataFrame with columns for region name, kind, area, and metadata.\n\n    \"\"\"\n    records: list[Mapping[str, Any]] = []\n    for reg in regions.values():\n        rec = reg.to_dict()\n        if reg.kind == \"polygon\":\n            assert isinstance(reg.data, Polygon)\n            rec[\"area\"] = float(reg.data.area)\n        else:\n            rec[\"area\"] = 0.0\n        records.append(rec)\n\n    return pd.DataFrame.from_records(records)\n</code></pre>"},{"location":"api/neurospatial/regions/ops/","title":"<code>neurospatial.regions.ops</code>","text":""},{"location":"api/neurospatial/regions/ops/#neurospatial.regions.ops","title":"ops","text":"<p>ops.py</p> <p>Operations for querying point-in-region membership using Shapely and NumPy.</p> <p>This module provides fast, vectorized functions to determine whether one or more 2D points lie inside polygonal (or point) Regions. It leverages Shapely's vectorized predicates for bulk point-in-polygon tests and returns either a boolean mask of \u201cinside any region\u201d or, for each point, the list of Regions that contain it. Additionally, users can request a DataFrame representation where each column is a region and each row corresponds to a point, indicating membership as booleans. Users can also limit the query to a subset of regions by name.</p> <p>The key functions are:</p> <ul> <li>points_in_any_region:  Given an (n, 2) array of points, returns an (n,) boolean   array indicating whether each point is inside at least one Region.</li> <li>regions_containing_points:  Given an (n, 2) array of points, either returns, for each   point, the list of Region objects that contain it, or a pandas DataFrame of shape   (n, m) where m is the number of selected regions and values are booleans.</li> </ul> <p>Both functions accept an optional <code>transform</code> that maps pixel-space coordinates to the Regions' coordinate space via a SpatialTransform with a <code>.forward()</code> method.</p> <p>Examples:</p> <p>Example usage (conceptual):</p> <p>.. code-block:: python</p> <pre><code>from pathlib import Path\nimport numpy as np\nfrom neurospatial.regions.io import load_labelme_json\nfrom neurospatial.transforms import SpatialTransform\nfrom neurospatial.regions.ops import points_in_any_region, regions_containing_points\n\ntransform = SpatialTransform(...)  # pixel\u2192world transform\nrois = load_labelme_json(Path(\"annotations.json\"), transform=transform)\npts_pixel = np.random.rand(1000, 2) * 512\nmask = points_in_any_region(pts_pixel, rois, transform=transform)\nmatches = regions_containing_points(\n    pts_pixel,\n    rois,\n    transform=transform,\n    include_boundary=True,\n    region_names=[\"regionA\", \"regionB\"],\n    return_dataframe=True,\n)\n</code></pre>"},{"location":"api/neurospatial/regions/ops/#neurospatial.regions.ops-classes","title":"Classes","text":""},{"location":"api/neurospatial/regions/ops/#neurospatial.regions.ops-functions","title":"Functions","text":""},{"location":"api/neurospatial/regions/ops/#neurospatial.regions.ops.points_in_any_region","title":"points_in_any_region","text":"<pre><code>points_in_any_region(pts: Sequence[Sequence[float]] | NDArray[float64], regions: Regions, *, transform: SpatialTransform | None = None, point_tolerance: float = POINT_TOLERANCE) -&gt; NDArray[np.bool_]\n</code></pre> <p>Determine whether each point lies inside any of the provided Regions.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>(Union[Sequence[Sequence[float]], NDArray[float64]], shape(n_points, 2))</code> <p>Array-like of points. If <code>transform</code> is not None, coordinates are assumed to be in the input space of the transform; otherwise, they must match the coordinate space of each Region.data.</p> required <code>regions</code> <code>Regions</code> <p>A container of Region objects.</p> required <code>transform</code> <code>Optional[SpatialTransform]</code> <p>If provided, a callable that maps input coordinates to the Regions' coordinate space.</p> <code>None</code> <code>point_tolerance</code> <code>float</code> <p>Tolerance for comparing query points to point Regions.</p> <code>POINT_TOLERANCE</code> <p>Returns:</p> Name Type Description <code>mask</code> <code>(NDArray[bool_], shape(n_points))</code> <p>A boolean array where <code>mask[i]</code> is True if the i-th point is inside at least one Region.</p> Source code in <code>src/neurospatial/regions/ops.py</code> <pre><code>def points_in_any_region(\n    pts: Sequence[Sequence[float]] | NDArray[np.float64],\n    regions: Regions,\n    *,\n    transform: SpatialTransform | None = None,\n    point_tolerance: float = POINT_TOLERANCE,\n) -&gt; NDArray[np.bool_]:\n    \"\"\"Determine whether each point lies inside any of the provided Regions.\n\n    Parameters\n    ----------\n    pts : Union[Sequence[Sequence[float]], NDArray[np.float64]], shape (n_points, 2)\n        Array-like of points. If `transform` is not None, coordinates\n        are assumed to be in the input space of the transform; otherwise,\n        they must match the coordinate space of each Region.data.\n    regions : Regions\n        A container of Region objects.\n    transform : Optional[SpatialTransform], default=None\n        If provided, a callable that maps input coordinates to\n        the Regions' coordinate space.\n    point_tolerance : float, default=POINT_TOLERANCE\n        Tolerance for comparing query points to point Regions.\n\n    Returns\n    -------\n    mask : NDArray[np.bool_], shape (n_points,)\n        A boolean array where `mask[i]` is True if the i-th point\n        is inside at least one Region.\n\n    \"\"\"\n    transformed_pts = _prepare_points(pts, transform)\n    n_points = transformed_pts.shape[0]\n\n    if n_points == 0:\n        return np.array([], dtype=bool)\n    if not regions:  # No regions to check against\n        return np.zeros(n_points, dtype=bool)\n\n    overall_mask = np.zeros(n_points, dtype=bool)\n\n    for region in regions.values():\n        region_mask = _get_points_in_single_region_mask(\n            transformed_pts,\n            region,\n            point_tolerance,\n        )\n        overall_mask |= region_mask\n        if overall_mask.all():  # Early exit if all points are already covered\n            break\n    return overall_mask\n</code></pre>"},{"location":"api/neurospatial/regions/ops/#neurospatial.regions.ops.regions_containing_points","title":"regions_containing_points","text":"<pre><code>regions_containing_points(pts: Sequence[Sequence[float]] | NDArray[float64], regions: Regions, *, transform: SpatialTransform | None = None, region_names: Sequence[str] | None = None, return_dataframe: bool = True, point_tolerance: float = POINT_TOLERANCE) -&gt; list[list[Region]] | pd.DataFrame\n</code></pre> <p>For each point, identify all Regions that contain it.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>(Union[Sequence[Sequence[float]], NDArray[float64]], shape(n_points, 2))</code> <p>Array-like of points. If <code>transform</code> is not None, these are assumed to be in the input space of the transform; otherwise, they must match the coordinate space of Region.data.</p> required <code>regions</code> <code>Regions</code> <p>A container of Region objects.</p> required <code>transform</code> <code>Optional[SpatialTransform]</code> <p>If provided, a callable that maps input coordinates to the Regions' coordinate space.</p> <code>None</code> <code>region_names</code> <code>Optional[Sequence[str]]</code> <p>If provided, only consider Regions whose <code>name</code> is in this sequence. If None, all regions in <code>regions</code> are used.</p> <code>None</code> <code>return_dataframe</code> <code>bool</code> <p>If True, return a pandas DataFrame of shape (n_points, n_selected_regions), where each column is the region name and each value is True/False. If False, return a list of lists: each sublist contains Region objects that contain the corresponding point.</p> <code>True</code> <code>point_tolerance</code> <code>float</code> <p>Tolerance for comparing query points to point Regions.</p> <code>POINT_TOLERANCE</code> <p>Returns:</p> Type Description <code>Union[List[List[Region]], pd.DataFrame], length n_points</code> <ul> <li>If <code>return_dataframe</code> is False: A list of length n_points. Each element is   a list of :class:<code>Region</code> objects that contain the corresponding point.</li> <li>If <code>return_dataframe</code> is True: A pandas DataFrame with index   range(n_points) and columns equal to selected region names.   Entry (i, col) is True if pts[i] is inside that region.</li> </ul> Notes <ul> <li>If <code>region_names</code> contains names not found in <code>regions</code>, they are silently ignored.</li> </ul> Source code in <code>src/neurospatial/regions/ops.py</code> <pre><code>def regions_containing_points(\n    pts: Sequence[Sequence[float]] | NDArray[np.float64],\n    regions: Regions,\n    *,\n    transform: SpatialTransform | None = None,\n    region_names: Sequence[str] | None = None,\n    return_dataframe: bool = True,\n    point_tolerance: float = POINT_TOLERANCE,\n) -&gt; list[list[Region]] | pd.DataFrame:\n    \"\"\"For each point, identify all Regions that contain it.\n\n    Parameters\n    ----------\n    pts : Union[Sequence[Sequence[float]], NDArray[np.float64]], shape (n_points, 2)\n        Array-like of points. If `transform` is not None, these are\n        assumed to be in the input space of the transform; otherwise,\n        they must match the coordinate space of Region.data.\n    regions : Regions\n        A container of Region objects.\n    transform : Optional[SpatialTransform], default=None\n        If provided, a callable that maps input coordinates to\n        the Regions' coordinate space.\n    region_names : Optional[Sequence[str]], default=None\n        If provided, only consider Regions whose `name` is in this sequence.\n        If None, all regions in `regions` are used.\n    return_dataframe : bool, default=True\n        If True, return a pandas DataFrame of shape (n_points, n_selected_regions),\n        where each column is the region name and each value is True/False.\n        If False, return a list of lists: each sublist contains Region objects\n        that contain the corresponding point.\n    point_tolerance : float, default=POINT_TOLERANCE\n        Tolerance for comparing query points to point Regions.\n\n    Returns\n    -------\n    Union[List[List[Region]], pd.DataFrame], length n_points\n        - If `return_dataframe` is False: A list of length n_points. Each element is\n          a list of :class:`Region` objects that contain the corresponding point.\n        - If `return_dataframe` is True: A pandas DataFrame with index\n          range(n_points) and columns equal to selected region names.\n          Entry (i, col) is True if pts[i] is inside that region.\n\n    Notes\n    -----\n    - If `region_names` contains names not found in `regions`, they are silently ignored.\n\n    \"\"\"\n    transformed_pts = _prepare_points(pts, transform)\n    n_points = transformed_pts.shape[0]\n\n    if n_points == 0:  # Handle case with no input points\n        if return_dataframe:\n            return pd.DataFrame(\n                columns=(\n                    region_names\n                    if region_names is not None\n                    else [r.name for r in regions.values()]\n                ),\n            )\n        return []\n\n    # Filter regions by name if requested\n    selected_regions: list[Region]\n    if region_names is not None:\n        # Maintain order of region_names if possible, and ensure uniqueness\n        name_set = set(region_names)\n        selected_regions = [\n            regions[name]\n            for name in region_names\n            if name in regions and name in name_set\n        ]\n    else:\n        selected_regions = list(regions.values())\n\n    if not selected_regions and return_dataframe:  # No regions to form columns\n        return pd.DataFrame(index=np.arange(n_points))\n\n    if return_dataframe:\n        # Initialize a DataFrame with shape (n_points, len(selected_regions))\n        # Using list comprehension for column names ensures they match selected_regions order\n        df_columns = [reg.name for reg in selected_regions]\n        df = pd.DataFrame(\n            index=np.arange(n_points),\n            columns=df_columns,\n            dtype=bool,\n        )\n        for reg in selected_regions:\n            df[reg.name] = _get_points_in_single_region_mask(\n                transformed_pts,\n                reg,\n                point_tolerance,\n            )\n        return df\n    # Build list of lists of Region objects\n    output: list[list[Region]] = [[] for _ in range(n_points)]\n    for region in selected_regions:\n        point_mask = _get_points_in_single_region_mask(\n            transformed_pts,\n            region,\n            point_tolerance,\n        )\n        # Iterate through points that are in the current region\n        for i in np.flatnonzero(point_mask):\n            output[i].append(region.name)\n    return output\n</code></pre>"},{"location":"api/neurospatial/regions/plot/","title":"<code>neurospatial.regions.plot</code>","text":""},{"location":"api/neurospatial/regions/plot/#neurospatial.regions.plot","title":"plot","text":""},{"location":"api/neurospatial/regions/plot/#neurospatial.regions.plot--regionsplotpy","title":"regions/plot.py","text":"<p>Lightweight helpers for visualising continuous ROIs that live in a :class:<code>regions.core.Regions</code> collection.</p> <p>You only pay the import cost of matplotlib and shapely the moment you call :func:<code>plot_regions</code>.</p>"},{"location":"api/neurospatial/regions/plot/#neurospatial.regions.plot-classes","title":"Classes","text":""},{"location":"api/neurospatial/regions/plot/#neurospatial.regions.plot-functions","title":"Functions","text":""},{"location":"api/neurospatial/regions/plot/#neurospatial.regions.plot.plot_regions","title":"plot_regions","text":"<pre><code>plot_regions(regions: Regions, *, ax: Axes | None = None, region_names: Sequence[str] | None = None, default_kwargs: Mapping[str, Any] | None = None, world_to_pixel: SpatialTransform | None = None, add_legend: bool = True, **per_region_kwargs: Mapping[str, Any]) -&gt; None\n</code></pre> <p>Draw a subset (or all) regions onto ax.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>Destination Axes.</p> <code>None</code> <code>regions</code> <code>Regions</code> <p>Collection to draw.</p> required <code>region_names</code> <code>optional list or tuple</code> <p>If given, plot only these names; otherwise plot all.</p> <code>None</code> <code>default_kwargs</code> <code>dict</code> <p>Plot kwargs applied to every region (unless overridden).</p> <code>None</code> <code>world_to_pixel</code> <code>SpatialTransform</code> <p>If supplied, coordinates are mapped through this transform before plotting - handy for overlaying cm-space polygons on pixel-space video frames.</p> <code>None</code> <code>**per_region_kwargs</code> <code>Mapping[str, Any]</code> <p>Per-region overrides::</p> <pre><code>plot_regions(ax, regs, Stem={\"alpha\": 0.1}, Reward={\"edgecolor\": \"red\"})\n</code></pre> <code>{}</code> <p>Returns:</p> Type Description <code>None</code> <p>Modifies the provided axes in place.</p> Notes <ul> <li>Points \u2192 <code>ax.scatter</code></li> <li>Polygons \u2192 <code>matplotlib.patches.PathPatch</code></li> <li>Legend labels default to the region name.</li> </ul> Source code in <code>src/neurospatial/regions/plot.py</code> <pre><code>def plot_regions(\n    regions: Regions,\n    *,\n    ax: matplotlib.axes.Axes | None = None,\n    region_names: Sequence[str] | None = None,\n    default_kwargs: Mapping[str, Any] | None = None,\n    world_to_pixel: SpatialTransform | None = None,\n    add_legend: bool = True,\n    **per_region_kwargs: Mapping[str, Any],\n) -&gt; None:\n    \"\"\"Draw a subset (or all) regions onto *ax*.\n\n    Parameters\n    ----------\n    ax : matplotlib.axes.Axes\n        Destination Axes.\n    regions : Regions\n        Collection to draw.\n    region_names : optional list or tuple\n        If given, plot only these names; otherwise plot *all*.\n    default_kwargs : dict, optional\n        Plot kwargs applied to every region (unless overridden).\n    world_to_pixel : SpatialTransform, optional\n        If supplied, coordinates are mapped **through** this transform\n        *before* plotting - handy for overlaying cm-space polygons on\n        pixel-space video frames.\n    **per_region_kwargs\n        Per-region overrides::\n\n            plot_regions(ax, regs, Stem={\"alpha\": 0.1}, Reward={\"edgecolor\": \"red\"})\n\n    Returns\n    -------\n    None\n        Modifies the provided axes in place.\n\n    Notes\n    -----\n    * Points \u2192 `ax.scatter`\n    * Polygons \u2192 `matplotlib.patches.PathPatch`\n    * Legend labels default to the region name.\n\n    \"\"\"\n    try:\n        import shapely.geometry as _shp\n    except ModuleNotFoundError:  # polygon plotting will warn later if needed\n        _shp = None\n\n    if region_names is None:\n        region_names = tuple(regions.keys())\n\n    if not region_names:\n        return  # nothing to draw\n\n    if ax is None:\n        ax = plt.gca()\n\n    for name in region_names:\n        if name not in regions:\n            warnings.warn(f\"plot_regions: '{name}' not in collection; skipping.\")\n            continue\n\n        reg: Region = regions[name]\n\n        # base \u2192 per-region kw \u2192 metadata \u2192 kwargs passed in call\n        opts: dict[str, Any] = dict(default_kwargs or {})\n        opts.update(reg.metadata.get(\"plot_kwargs\", {}))\n        opts.update(per_region_kwargs.get(name, {}))\n\n        label = opts.pop(\"label\", name)  # legend label\n        alpha = opts.pop(\"alpha\", 0.5)\n\n        # optional coordinate transform\n        def _map(pts: NDArray[np.float64]) -&gt; NDArray[np.float64]:\n            return world_to_pixel(pts) if world_to_pixel else pts\n\n        # ---- draw according to kind ---------------------------------\n        if reg.kind == \"point\":\n            xy = _map(np.asarray(reg.data, dtype=float))\n            ax.scatter(\n                xy[0],\n                xy[1],\n                marker=opts.pop(\"marker\", \"x\"),\n                s=opts.pop(\"s\", 100),\n                alpha=alpha,\n                label=label,\n                **opts,\n            )\n\n        elif reg.kind == \"polygon\":\n            if _shp is None:\n                warnings.warn(f\"Can't draw polygon '{name}': shapely not installed.\")\n                continue\n\n            # Narrow type to Polygon\n            from shapely.geometry import Polygon\n\n            poly = reg.data  # already shapely.Polygon\n            if not isinstance(poly, Polygon):\n                warnings.warn(f\"Region '{name}' data is not a Polygon; skipping.\")\n                continue\n\n            # exterior + (optional) holes  \u2192 Path\n            def _ring_to_path(r):\n                pts = _map(np.asarray(r.coords)[:, :2])\n                return MplPath(pts)\n\n            path = MplPath.make_compound_path(\n                _ring_to_path(poly.exterior),\n                *[_ring_to_path(i) for i in poly.interiors],\n            )\n\n            patch = PathPatch(\n                path,\n                label=label,\n                facecolor=opts.pop(\"facecolor\", opts.pop(\"color\", None)),\n                alpha=alpha,\n                **opts,\n            )\n            ax.add_patch(patch)\n        else:\n            # This shouldn't happen with Literal['point', 'polygon'] type\n            raise ValueError(f\"Unknown region kind '{reg.kind}' for '{name}'.\")\n\n    # add a legend if *any* labels were produced\n    handles, labels = ax.get_legend_handles_labels()\n    if handles and add_legend:\n        ax.legend(handles, labels, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n    ax.autoscale(enable=True, axis=\"both\", tight=True)\n</code></pre>"},{"location":"examples/","title":"Examples","text":"<p>Real-world examples demonstrating neurospatial's capabilities through interactive Jupyter notebooks.</p>"},{"location":"examples/#available-notebooks","title":"Available Notebooks","text":""},{"location":"examples/#1-introduction-basics","title":"1. Introduction &amp; Basics","text":"<p>Get started with neurospatial basics:</p> <ul> <li>Creating environments from data</li> <li>Basic spatial queries</li> <li>Visualizing environments</li> <li>Understanding bin centers and connectivity</li> </ul> <p>Open notebook: 01_introduction_basics.ipynb | Recommended for: First-time users</p>"},{"location":"examples/#2-layout-engines","title":"2. Layout Engines","text":"<p>Explore different discretization strategies:</p> <ul> <li>Regular grids</li> <li>Hexagonal tessellations</li> <li>Triangular meshes</li> <li>Comparing layout engines</li> </ul> <p>Open notebook: 02_layout_engines.ipynb | Recommended for: Understanding spatial discretization options</p>"},{"location":"examples/#3-morphological-operations","title":"3. Morphological Operations","text":"<p>Master automatic active bin detection:</p> <ul> <li>Dilation and closing operations</li> <li>Filling holes</li> <li>Thresholding strategies</li> <li>Handling sparse data</li> </ul> <p>Open notebook: 03_morphological_operations.ipynb | Recommended for: Working with real experimental data</p>"},{"location":"examples/#4-regions-of-interest","title":"4. Regions of Interest","text":"<p>Define and manage spatial regions:</p> <ul> <li>Creating point and polygon regions</li> <li>Region operations (buffering, area calculation)</li> <li>Using regions in analysis</li> <li>Region serialization</li> </ul> <p>Open notebook: 04_regions_of_interest.ipynb | Recommended for: Defining experimental zones and ROIs</p>"},{"location":"examples/#5-track-linearization","title":"5. Track Linearization","text":"<p>Work with maze and track experiments:</p> <ul> <li>Creating 1D linearized environments</li> <li>Converting between 2D and 1D coordinates</li> <li>T-maze and plus maze examples</li> <li>Sequential analysis</li> </ul> <p>Open notebook: 05_track_linearization.ipynb | Recommended for: Track-based experiments</p>"},{"location":"examples/#6-composite-environments","title":"6. Composite Environments","text":"<p>Merge multiple environments:</p> <ul> <li>Creating composite environments</li> <li>Automatic bridge inference</li> <li>Multi-arena experiments</li> <li>Cross-environment queries</li> </ul> <p>Open notebook: 06_composite_environments.ipynb | Recommended for: Multi-environment studies</p>"},{"location":"examples/#7-advanced-operations","title":"7. Advanced Operations","text":"<p>Advanced features and techniques:</p> <ul> <li>Custom spatial queries</li> <li>Graph operations</li> <li>Performance optimization</li> <li>Edge cases and troubleshooting</li> </ul> <p>Open notebook: 07_advanced_operations.ipynb | Recommended for: Power users</p>"},{"location":"examples/#8-complete-workflow","title":"8. Complete Workflow","text":"<p>End-to-end analysis example:</p> <ul> <li>Loading experimental data</li> <li>Environment setup</li> <li>Computing spatial statistics</li> <li>Visualization and export</li> </ul> <p>Open notebook: 08_complete_workflow.ipynb | Recommended for: Seeing it all together</p>"},{"location":"examples/#viewing-on-github","title":"Viewing on GitHub","text":"<p>All example notebooks are available on GitHub with rendered outputs:</p> <p>View examples on GitHub</p>"},{"location":"examples/#running-examples","title":"Running Examples","text":"<p>To run the examples locally:</p> <pre><code># Clone the repository\ngit clone https://github.com/edeno/neurospatial.git\ncd neurospatial\n\n# Install with dependencies\nuv sync\n\n# Start Jupyter\nuv run jupyter notebook examples/\n</code></pre>"},{"location":"examples/#contributing-examples","title":"Contributing Examples","text":"<p>Have a useful example? We welcome contributions! See the Contributing Guide for details.</p> <p>For Documentation Contributors</p> <p>The notebooks displayed here are automatically synced from the <code>examples/</code> directory.</p> <p>To update notebooks in the documentation:</p> <ol> <li>Edit notebooks in the <code>examples/</code> directory (repository root)</li> <li>Run <code>uv run python docs/sync_notebooks.py</code> before building docs</li> <li>The GitHub Actions workflow automatically syncs notebooks on deployment</li> </ol> <p>Do not edit <code>.ipynb</code> files directly in <code>docs/examples/</code> - they will be overwritten.</p>"},{"location":"examples/01_introduction_basics/","title":"Introduction to neurospatial: The Basics","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom neurospatial import Environment\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Configure matplotlib\nplt.rcParams[\"figure.figsize\"] = (10, 8)\nplt.rcParams[\"font.size\"] = 11\n</pre> import matplotlib.pyplot as plt import numpy as np  from neurospatial import Environment  # Set random seed for reproducibility np.random.seed(42)  # Configure matplotlib plt.rcParams[\"figure.figsize\"] = (10, 8) plt.rcParams[\"font.size\"] = 11 In\u00a0[2]: Copied! <pre># Simulate an animal's trajectory through a 100x100 cm open field\n# We'll create a random walk with some drift to make it realistic\n\nn_timepoints = 5000  # About 5 minutes at 20 Hz sampling\nposition_2d = np.zeros((n_timepoints, 2))\nposition_2d[0] = [50, 50]  # Start at center\n\n# Random walk with drift toward center (animals tend to avoid edges)\nfor t in range(1, n_timepoints):\n    # Random movement\n    step = np.random.randn(2) * 2.0  # 2 cm standard deviation\n\n    # Gentle drift toward center\n    center_pull = (50 - position_2d[t - 1]) * 0.01\n\n    # Update position\n    position_2d[t] = position_2d[t - 1] + step + center_pull\n\n    # Enforce boundaries (bounce off walls)\n    position_2d[t] = np.clip(position_2d[t], 5, 95)\n\nprint(f\"Generated {n_timepoints} position samples\")\nprint(f\"Position data shape: {position_2d.shape}\")\nprint(f\"X range: [{position_2d[:, 0].min():.1f}, {position_2d[:, 0].max():.1f}] cm\")\nprint(f\"Y range: [{position_2d[:, 1].min():.1f}, {position_2d[:, 1].max():.1f}] cm\")\n</pre> # Simulate an animal's trajectory through a 100x100 cm open field # We'll create a random walk with some drift to make it realistic  n_timepoints = 5000  # About 5 minutes at 20 Hz sampling position_2d = np.zeros((n_timepoints, 2)) position_2d[0] = [50, 50]  # Start at center  # Random walk with drift toward center (animals tend to avoid edges) for t in range(1, n_timepoints):     # Random movement     step = np.random.randn(2) * 2.0  # 2 cm standard deviation      # Gentle drift toward center     center_pull = (50 - position_2d[t - 1]) * 0.01      # Update position     position_2d[t] = position_2d[t - 1] + step + center_pull      # Enforce boundaries (bounce off walls)     position_2d[t] = np.clip(position_2d[t], 5, 95)  print(f\"Generated {n_timepoints} position samples\") print(f\"Position data shape: {position_2d.shape}\") print(f\"X range: [{position_2d[:, 0].min():.1f}, {position_2d[:, 0].max():.1f}] cm\") print(f\"Y range: [{position_2d[:, 1].min():.1f}, {position_2d[:, 1].max():.1f}] cm\") <pre>Generated 5000 position samples\nPosition data shape: (5000, 2)\nX range: [10.4, 95.0] cm\nY range: [5.4, 90.0] cm\n</pre> <p>Let's visualize the trajectory:</p> In\u00a0[3]: Copied! <pre>fig, ax = plt.subplots(figsize=(8, 8))\n\n# Plot trajectory (color by time)\nscatter = ax.scatter(\n    position_2d[:, 0],\n    position_2d[:, 1],\n    c=np.arange(n_timepoints),\n    cmap=\"viridis\",\n    s=1,\n    alpha=0.5,\n)\n\n# Mark start and end\nax.plot(position_2d[0, 0], position_2d[0, 1], \"go\", markersize=10, label=\"Start\")\nax.plot(position_2d[-1, 0], position_2d[-1, 1], \"ro\", markersize=10, label=\"End\")\n\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(\"Animal Trajectory in Open Field\")\nax.set_aspect(\"equal\")\nax.legend()\nplt.colorbar(scatter, ax=ax, label=\"Time (samples)\")\nplt.tight_layout()\nplt.show()\n</pre> fig, ax = plt.subplots(figsize=(8, 8))  # Plot trajectory (color by time) scatter = ax.scatter(     position_2d[:, 0],     position_2d[:, 1],     c=np.arange(n_timepoints),     cmap=\"viridis\",     s=1,     alpha=0.5, )  # Mark start and end ax.plot(position_2d[0, 0], position_2d[0, 1], \"go\", markersize=10, label=\"Start\") ax.plot(position_2d[-1, 0], position_2d[-1, 1], \"ro\", markersize=10, label=\"End\")  ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(\"Animal Trajectory in Open Field\") ax.set_aspect(\"equal\") ax.legend() plt.colorbar(scatter, ax=ax, label=\"Time (samples)\") plt.tight_layout() plt.show() In\u00a0[4]: Copied! <pre># Create environment with 5 cm bins\nenv = Environment.from_samples(\n    data_samples=position_2d,\n    bin_size=5.0,  # 5 cm bins\n    name=\"OpenFieldExample\",\n)\n\nprint(env.info())\n</pre> # Create environment with 5 cm bins env = Environment.from_samples(     data_samples=position_2d,     bin_size=5.0,  # 5 cm bins     name=\"OpenFieldExample\", )  print(env.info()) <pre>Environment Information\n=======================\n\nName: OpenFieldExample\nLayout Type: RegularGrid\nDimensions: 2\nNumber of Bins: 211\n\nSpatial Extent:\n  Dimension 0: [7.91, 97.50] (range: 89.59)\n  Dimension 1: [2.94, 92.50] (range: 89.57)\n\nBin Sizes:\n  Dimension 0: 4.98\n  Dimension 1: 4.98\n\nRegions: None\n\n</pre> <p>Let's break down what we see in the info output:</p> <ul> <li>Name: The label we gave our environment</li> <li>Layout type: <code>RegularGrid</code> (the default grid-based discretization)</li> <li>Dimensions: 2D (x and y coordinates)</li> <li>Total bins: The maximum possible number of bins (grid size)</li> <li>Active bins: Bins that contain data samples</li> <li>Dimension ranges: The spatial extent in each dimension</li> </ul> In\u00a0[5]: Copied! <pre># Environment properties\nprint(f\"Number of bins: {env.n_bins}\")\nprint(f\"Number of dimensions: {env.n_dims}\")\nprint(f\"Grid shape: {env.grid_shape}\")\nprint(f\"Bin centers shape: {env.bin_centers.shape}\")\nprint(\"\\nDimension ranges:\")\nfor dim, (min_val, max_val) in enumerate(env.dimension_ranges):\n    print(f\"  Dim {dim}: [{min_val:.1f}, {max_val:.1f}] cm\")\n</pre> # Environment properties print(f\"Number of bins: {env.n_bins}\") print(f\"Number of dimensions: {env.n_dims}\") print(f\"Grid shape: {env.grid_shape}\") print(f\"Bin centers shape: {env.bin_centers.shape}\") print(\"\\nDimension ranges:\") for dim, (min_val, max_val) in enumerate(env.dimension_ranges):     print(f\"  Dim {dim}: [{min_val:.1f}, {max_val:.1f}] cm\") <pre>Number of bins: 211\nNumber of dimensions: 2\nGrid shape: (18, 18)\nBin centers shape: (211, 2)\n\nDimension ranges:\n  Dim 0: [7.9, 97.5] cm\n  Dim 1: [2.9, 92.5] cm\n</pre> In\u00a0[6]: Copied! <pre>fig, ax = plt.subplots(figsize=(10, 10))\nenv.plot(ax=ax, show_connectivity=True)\nax.set_title(\"Discretized Environment (5 cm bins)\")\nplt.tight_layout()\nplt.show()\n</pre> fig, ax = plt.subplots(figsize=(10, 10)) env.plot(ax=ax, show_connectivity=True) ax.set_title(\"Discretized Environment (5 cm bins)\") plt.tight_layout() plt.show() <p>What you're seeing:</p> <ul> <li>Blue dots: Active bin centers (areas the animal visited)</li> <li>Gray lines: Connectivity between neighboring bins</li> <li>The grid structure with 5 cm spacing</li> </ul> In\u00a0[7]: Copied! <pre># Map all position samples to bin indices\nbin_indices = env.bin_at(position_2d)\n\nprint(f\"Bin indices shape: {bin_indices.shape}\")\nprint(f\"Example: position {position_2d[0]} -&gt; bin {bin_indices[0]}\")\nprint(f\"\\nUnique bins visited: {len(np.unique(bin_indices[bin_indices &gt;= 0]))}\")\nprint(f\"Samples outside active bins: {np.sum(bin_indices &lt; 0)}\")\n</pre> # Map all position samples to bin indices bin_indices = env.bin_at(position_2d)  print(f\"Bin indices shape: {bin_indices.shape}\") print(f\"Example: position {position_2d[0]} -&gt; bin {bin_indices[0]}\") print(f\"\\nUnique bins visited: {len(np.unique(bin_indices[bin_indices &gt;= 0]))}\") print(f\"Samples outside active bins: {np.sum(bin_indices &lt; 0)}\") <pre>Bin indices shape: (5000,)\nExample: position [50. 50.] -&gt; bin 116\n\nUnique bins visited: 211\nSamples outside active bins: 0\n</pre> <p>Important: <code>bin_at()</code> returns <code>-1</code> for points outside active bins or environment bounds.</p> In\u00a0[8]: Copied! <pre># Count samples per bin (occupancy)\noccupancy = np.bincount(bin_indices[bin_indices &gt;= 0], minlength=env.n_bins)\n\nprint(f\"Occupancy array shape: {occupancy.shape}\")\nprint(f\"Total samples: {occupancy.sum()}\")\nprint(f\"Mean samples per active bin: {occupancy[occupancy &gt; 0].mean():.1f}\")\nprint(f\"Max samples in any bin: {occupancy.max()}\")\n</pre> # Count samples per bin (occupancy) occupancy = np.bincount(bin_indices[bin_indices &gt;= 0], minlength=env.n_bins)  print(f\"Occupancy array shape: {occupancy.shape}\") print(f\"Total samples: {occupancy.sum()}\") print(f\"Mean samples per active bin: {occupancy[occupancy &gt; 0].mean():.1f}\") print(f\"Max samples in any bin: {occupancy.max()}\") <pre>Occupancy array shape: (211,)\nTotal samples: 5000\nMean samples per active bin: 23.7\nMax samples in any bin: 108\n</pre> <p>Let's visualize the occupancy map:</p> In\u00a0[9]: Copied! <pre>fig, ax = plt.subplots(figsize=(10, 9))\n\n# Create occupancy map\nscatter = ax.scatter(\n    env.bin_centers[:, 0],\n    env.bin_centers[:, 1],\n    c=occupancy,\n    s=200,\n    cmap=\"hot\",\n    marker=\"s\",  # Square markers\n    edgecolors=\"none\",\n)\n\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(\"Occupancy Map (samples per bin)\")\nax.set_aspect(\"equal\")\nplt.colorbar(scatter, ax=ax, label=\"Samples\")\nplt.tight_layout()\nplt.show()\n</pre> fig, ax = plt.subplots(figsize=(10, 9))  # Create occupancy map scatter = ax.scatter(     env.bin_centers[:, 0],     env.bin_centers[:, 1],     c=occupancy,     s=200,     cmap=\"hot\",     marker=\"s\",  # Square markers     edgecolors=\"none\", )  ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(\"Occupancy Map (samples per bin)\") ax.set_aspect(\"equal\") plt.colorbar(scatter, ax=ax, label=\"Samples\") plt.tight_layout() plt.show() In\u00a0[10]: Copied! <pre># Test some points\ntest_points = np.array(\n    [\n        [50.0, 50.0],  # Center - should be in\n        [10.0, 10.0],  # Corner - should be in\n        [0.0, 0.0],  # Far corner - might be out\n        [150.0, 50.0],  # Outside bounds - definitely out\n    ]\n)\n\nis_contained = env.contains(test_points)\n\nfor point, contained in zip(test_points, is_contained, strict=False):\n    status = \"\u2713 IN\" if contained else \"\u2717 OUT\"\n    print(f\"Point {point}: {status}\")\n</pre> # Test some points test_points = np.array(     [         [50.0, 50.0],  # Center - should be in         [10.0, 10.0],  # Corner - should be in         [0.0, 0.0],  # Far corner - might be out         [150.0, 50.0],  # Outside bounds - definitely out     ] )  is_contained = env.contains(test_points)  for point, contained in zip(test_points, is_contained, strict=False):     status = \"\u2713 IN\" if contained else \"\u2717 OUT\"     print(f\"Point {point}: {status}\") <pre>Point [50. 50.]: \u2713 IN\nPoint [10. 10.]: \u2717 OUT\nPoint [0. 0.]: \u2717 OUT\nPoint [150.  50.]: \u2717 OUT\n</pre> In\u00a0[11]: Copied! <pre># Pick a bin near the center\ncenter_point = np.array([[50.0, 50.0]])\ncenter_bin = env.bin_at(center_point)[0]\n\n# Find its neighbors\nneighbor_bins = env.neighbors(center_bin)\n\nprint(f\"Bin {center_bin} at position {env.bin_centers[center_bin]}\")\nprint(f\"has {len(neighbor_bins)} neighbors:\")\nfor neighbor in neighbor_bins:\n    print(f\"  Bin {neighbor} at position {env.bin_centers[neighbor]}\")\n</pre> # Pick a bin near the center center_point = np.array([[50.0, 50.0]]) center_bin = env.bin_at(center_point)[0]  # Find its neighbors neighbor_bins = env.neighbors(center_bin)  print(f\"Bin {center_bin} at position {env.bin_centers[center_bin]}\") print(f\"has {len(neighbor_bins)} neighbors:\") for neighbor in neighbor_bins:     print(f\"  Bin {neighbor} at position {env.bin_centers[neighbor]}\") <pre>Bin 116 at position [50.21485687 50.20964522]\nhas 8 neighbors:\n  Bin 98 at position [45.23747339 45.23373964]\n  Bin 99 at position [45.23747339 50.20964522]\n  Bin 100 at position [45.23747339 55.18555079]\n  Bin 115 at position [50.21485687 45.23373964]\n  Bin 117 at position [50.21485687 55.18555079]\n  Bin 130 at position [55.19224036 45.23373964]\n  Bin 131 at position [55.19224036 50.20964522]\n  Bin 132 at position [55.19224036 55.18555079]\n</pre> <p>Let's visualize the neighborhood:</p> In\u00a0[12]: Copied! <pre>fig, ax = plt.subplots(figsize=(8, 8))\n\n# Plot all bins\nax.scatter(\n    env.bin_centers[:, 0],\n    env.bin_centers[:, 1],\n    c=\"lightgray\",\n    s=100,\n    alpha=0.3,\n    label=\"Other bins\",\n)\n\n# Highlight the center bin\nax.scatter(\n    env.bin_centers[center_bin, 0],\n    env.bin_centers[center_bin, 1],\n    c=\"red\",\n    s=300,\n    marker=\"*\",\n    edgecolors=\"black\",\n    linewidth=2,\n    label=f\"Center bin {center_bin}\",\n    zorder=10,\n)\n\n# Highlight neighbors\nneighbor_positions = env.bin_centers[neighbor_bins]\nax.scatter(\n    neighbor_positions[:, 0],\n    neighbor_positions[:, 1],\n    c=\"blue\",\n    s=200,\n    alpha=0.7,\n    edgecolors=\"black\",\n    linewidth=1,\n    label=f\"Neighbors ({len(neighbor_bins)})\",\n)\n\n# Draw edges to neighbors\ncenter_pos = env.bin_centers[center_bin]\nfor neighbor_pos in neighbor_positions:\n    ax.plot(\n        [center_pos[0], neighbor_pos[0]],\n        [center_pos[1], neighbor_pos[1]],\n        \"b-\",\n        alpha=0.3,\n        linewidth=2,\n    )\n\nax.set_xlim(center_pos[0] - 15, center_pos[0] + 15)\nax.set_ylim(center_pos[1] - 15, center_pos[1] + 15)\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(\"Bin Neighborhood Example\")\nax.set_aspect(\"equal\")\nax.legend(loc=\"upper right\")\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n</pre> fig, ax = plt.subplots(figsize=(8, 8))  # Plot all bins ax.scatter(     env.bin_centers[:, 0],     env.bin_centers[:, 1],     c=\"lightgray\",     s=100,     alpha=0.3,     label=\"Other bins\", )  # Highlight the center bin ax.scatter(     env.bin_centers[center_bin, 0],     env.bin_centers[center_bin, 1],     c=\"red\",     s=300,     marker=\"*\",     edgecolors=\"black\",     linewidth=2,     label=f\"Center bin {center_bin}\",     zorder=10, )  # Highlight neighbors neighbor_positions = env.bin_centers[neighbor_bins] ax.scatter(     neighbor_positions[:, 0],     neighbor_positions[:, 1],     c=\"blue\",     s=200,     alpha=0.7,     edgecolors=\"black\",     linewidth=1,     label=f\"Neighbors ({len(neighbor_bins)})\", )  # Draw edges to neighbors center_pos = env.bin_centers[center_bin] for neighbor_pos in neighbor_positions:     ax.plot(         [center_pos[0], neighbor_pos[0]],         [center_pos[1], neighbor_pos[1]],         \"b-\",         alpha=0.3,         linewidth=2,     )  ax.set_xlim(center_pos[0] - 15, center_pos[0] + 15) ax.set_ylim(center_pos[1] - 15, center_pos[1] + 15) ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(\"Bin Neighborhood Example\") ax.set_aspect(\"equal\") ax.legend(loc=\"upper right\") ax.grid(True, alpha=0.3) plt.tight_layout() plt.show() In\u00a0[13]: Copied! <pre># Create environments with different bin sizes\nbin_sizes = [2.5, 5.0, 10.0]  # cm\nenvs = {}\n\nfor bin_size in bin_sizes:\n    envs[bin_size] = Environment.from_samples(\n        data_samples=position_2d, bin_size=bin_size, name=f\"OpenField_{bin_size}cm\"\n    )\n    print(f\"\\nBin size = {bin_size} cm:\")\n    print(f\"  Total bins: {envs[bin_size].n_bins}\")\n    print(f\"  Grid shape: {envs[bin_size].grid_shape}\")\n</pre> # Create environments with different bin sizes bin_sizes = [2.5, 5.0, 10.0]  # cm envs = {}  for bin_size in bin_sizes:     envs[bin_size] = Environment.from_samples(         data_samples=position_2d, bin_size=bin_size, name=f\"OpenField_{bin_size}cm\"     )     print(f\"\\nBin size = {bin_size} cm:\")     print(f\"  Total bins: {envs[bin_size].n_bins}\")     print(f\"  Grid shape: {envs[bin_size].grid_shape}\") <pre>\nBin size = 2.5 cm:\n  Total bins: 684\n  Grid shape: (35, 35)\n\nBin size = 5.0 cm:\n  Total bins: 211\n  Grid shape: (18, 18)\n\nBin size = 10.0 cm:\n  Total bins: 75\n  Grid shape: (10, 10)\n</pre> In\u00a0[14]: Copied! <pre># Visualize the three environments\nfig, axes = plt.subplots(1, 3, figsize=(18, 6))\n\nfor ax, bin_size in zip(axes, bin_sizes, strict=False):\n    envs[bin_size].plot(ax=ax, show_connectivity=True)\n    ax.set_title(f\"Bin size = {bin_size} cm\\n({envs[bin_size].n_bins} bins)\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Visualize the three environments fig, axes = plt.subplots(1, 3, figsize=(18, 6))  for ax, bin_size in zip(axes, bin_sizes, strict=False):     envs[bin_size].plot(ax=ax, show_connectivity=True)     ax.set_title(f\"Bin size = {bin_size} cm\\n({envs[bin_size].n_bins} bins)\")  plt.tight_layout() plt.show() <p>What to notice:</p> <ul> <li>2.5 cm bins: High resolution, but many bins with few samples</li> <li>5 cm bins: Good balance for most analyses</li> <li>10 cm bins: Lower resolution, but each bin has more samples</li> </ul> <p>Rule of thumb: Choose bin_size so each bin gets at least 10-20 samples for stable estimates.</p> In\u00a0[15]: Copied! <pre># This will fail!\ntry:\n    bad_env = Environment.from_samples(\n        data_samples=position_2d,\n        bin_size=200.0,  # 200 cm - way too large!\n        name=\"TooBig\",\n    )\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n    print(\"\\nSolution: Use a smaller bin_size!\")\n</pre> # This will fail! try:     bad_env = Environment.from_samples(         data_samples=position_2d,         bin_size=200.0,  # 200 cm - way too large!         name=\"TooBig\",     ) except ValueError as e:     print(f\"Error: {e}\")     print(\"\\nSolution: Use a smaller bin_size!\") In\u00a0[16]: Copied! <pre># Example: data in centimeters, but you think it's in meters\n# A 0.05 cm bin would be way too small!\n\nprint(\"If your data is in centimeters, use bin_size in centimeters (e.g., 5.0)\")\nprint(\"If your data is in meters, use bin_size in meters (e.g., 0.05)\")\nprint(\"If your data is in pixels, use bin_size in pixels (e.g., 10)\")\n</pre> # Example: data in centimeters, but you think it's in meters # A 0.05 cm bin would be way too small!  print(\"If your data is in centimeters, use bin_size in centimeters (e.g., 5.0)\") print(\"If your data is in meters, use bin_size in meters (e.g., 0.05)\") print(\"If your data is in pixels, use bin_size in pixels (e.g., 10)\") <pre>If your data is in centimeters, use bin_size in centimeters (e.g., 5.0)\nIf your data is in meters, use bin_size in meters (e.g., 0.05)\nIf your data is in pixels, use bin_size in pixels (e.g., 10)\n</pre> In\u00a0[17]: Copied! <pre># \u2717 WRONG - Don't do this!\n# env = Environment()  # This won't work!\n\n# \u2713 CORRECT - Use factory methods\nenv_correct = Environment.from_samples(data_samples=position_2d, bin_size=5.0)\nprint(\"Always use factory methods like from_samples()!\")\n</pre> # \u2717 WRONG - Don't do this! # env = Environment()  # This won't work!  # \u2713 CORRECT - Use factory methods env_correct = Environment.from_samples(data_samples=position_2d, bin_size=5.0) print(\"Always use factory methods like from_samples()!\") <pre>Always use factory methods like from_samples()!\n</pre>"},{"location":"examples/01_introduction_basics/#introduction-to-neurospatial-the-basics","title":"Introduction to neurospatial: The Basics\u00b6","text":""},{"location":"examples/01_introduction_basics/#learning-objectives","title":"Learning Objectives\u00b6","text":"<p>By the end of this notebook, you will be able to:</p> <ul> <li>Understand what spatial discretization is and why it matters for neuroscience</li> <li>Create your first environment from position data</li> <li>Understand the concepts of bins, bin_size, and active bins</li> <li>Perform basic spatial queries: <code>bin_at()</code>, <code>contains()</code>, <code>neighbors()</code></li> <li>Visualize environments using <code>plot()</code></li> <li>Avoid common pitfalls when choosing bin_size</li> </ul> <p>Estimated time: 15-20 minutes</p>"},{"location":"examples/01_introduction_basics/#what-is-spatial-discretization","title":"What is Spatial Discretization?\u00b6","text":"<p>In neuroscience experiments, we often track an animal's position continuously through space. For example:</p> <ul> <li>A rat exploring an open field</li> <li>A mouse running on a linear track</li> <li>A human navigating a virtual environment</li> </ul> <p>To analyze neural activity in relation to position, we need to discretize continuous space into distinct bins (also called spatial bins or nodes). Think of it like creating a grid overlay on your environment.</p> <p>Why discretize?</p> <ul> <li>Compute spatial firing rate maps (place fields)</li> <li>Calculate occupancy-normalized neural activity</li> <li>Perform spatial statistics and decoding</li> <li>Identify regions of interest</li> </ul> <p>The <code>neurospatial</code> library makes spatial discretization easy and flexible!</p>"},{"location":"examples/01_introduction_basics/#setup","title":"Setup\u00b6","text":"<p>First, let's import the necessary libraries:</p>"},{"location":"examples/01_introduction_basics/#creating-synthetic-position-data","title":"Creating Synthetic Position Data\u00b6","text":"<p>Let's simulate position data from an animal exploring a 100 cm \u00d7 100 cm open field. This represents what you might get from a tracking system like Optitrack, DeepLabCut, or similar.</p>"},{"location":"examples/01_introduction_basics/#creating-your-first-environment","title":"Creating Your First Environment\u00b6","text":"<p>Now let's discretize this continuous trajectory into bins! The most common way to create an environment is using <code>Environment.from_samples()</code>, which automatically infers the spatial extent from your data.</p> <p>Key parameter: <code>bin_size</code></p> <ul> <li>This controls how finely we divide up space</li> <li>Units match your data (here: centimeters)</li> <li>Typical values: 2-5 cm for rodent experiments</li> <li>Trade-off: smaller bins = more spatial resolution, but fewer samples per bin</li> </ul>"},{"location":"examples/01_introduction_basics/#understanding-active-vs-inactive-bins","title":"Understanding Active vs Inactive Bins\u00b6","text":"<p>By default, <code>from_samples()</code> infers which bins are \"active\" based on whether they contain data. This is important for:</p> <ul> <li>Ignoring walls and obstacles</li> <li>Focusing analysis on visited areas</li> <li>Avoiding division by zero in occupancy normalization</li> </ul> <p>Let's explore the environment properties:</p>"},{"location":"examples/01_introduction_basics/#visualizing-the-environment","title":"Visualizing the Environment\u00b6","text":"<p>The <code>plot()</code> method gives us a quick visualization of our discretized environment:</p>"},{"location":"examples/01_introduction_basics/#basic-spatial-queries","title":"Basic Spatial Queries\u00b6","text":"<p>Now let's explore the core operations you'll use for spatial analysis.</p>"},{"location":"examples/01_introduction_basics/#1-mapping-points-to-bins-bin_at","title":"1. Mapping Points to Bins: <code>bin_at()</code>\u00b6","text":"<p>This is probably the most common operation\u2014mapping continuous positions to discrete bin indices:</p>"},{"location":"examples/01_introduction_basics/#2-computing-occupancy","title":"2. Computing Occupancy\u00b6","text":"<p>Let's use bin indices to compute how much time was spent in each bin:</p>"},{"location":"examples/01_introduction_basics/#3-checking-if-points-are-in-environment-contains","title":"3. Checking if Points are in Environment: <code>contains()</code>\u00b6","text":"<p>Sometimes you need to know if points are within the active environment:</p>"},{"location":"examples/01_introduction_basics/#4-finding-neighbors-neighbors","title":"4. Finding Neighbors: <code>neighbors()</code>\u00b6","text":"<p>The connectivity graph tells us which bins are adjacent to each other:</p>"},{"location":"examples/01_introduction_basics/#the-impact-of-bin_size","title":"The Impact of bin_size\u00b6","text":"<p>Choosing the right <code>bin_size</code> is crucial! Let's compare three different bin sizes to see the trade-offs:</p>"},{"location":"examples/01_introduction_basics/#common-pitfalls-and-how-to-avoid-them","title":"Common Pitfalls and How to Avoid Them\u00b6","text":""},{"location":"examples/01_introduction_basics/#pitfall-1-bin_size-is-too-large","title":"Pitfall 1: bin_size is too large\u00b6","text":"<p>If bin_size is larger than your environment, you'll get an error:</p>"},{"location":"examples/01_introduction_basics/#pitfall-2-unit-mismatch","title":"Pitfall 2: Unit mismatch\u00b6","text":"<p>Make sure your <code>bin_size</code> units match your data units!</p>"},{"location":"examples/01_introduction_basics/#pitfall-3-not-using-factory-methods","title":"Pitfall 3: Not using factory methods\u00b6","text":"<p>Always use factory methods like <code>from_samples()</code>, never call <code>Environment()</code> directly:</p>"},{"location":"examples/01_introduction_basics/#key-takeaways","title":"Key Takeaways\u00b6","text":"<p>Congratulations! You now know the basics of neurospatial. Here's what you learned:</p> <ol> <li>Spatial discretization converts continuous position data into discrete bins for analysis</li> <li><code>Environment.from_samples()</code> is the main way to create environments from data</li> <li><code>bin_size</code> controls the resolution of your spatial grid (units must match your data)</li> <li>Active bins are bins that contain data samples</li> <li>Core operations:<ul> <li><code>bin_at(points)</code> - Map positions to bin indices</li> <li><code>contains(points)</code> - Check if points are in the environment</li> <li><code>neighbors(bin_idx)</code> - Find adjacent bins</li> <li><code>plot()</code> - Visualize the environment</li> </ul> </li> <li>Choose bin_size wisely - balance resolution vs samples per bin</li> </ol>"},{"location":"examples/01_introduction_basics/#next-steps","title":"Next Steps\u00b6","text":"<p>In the next notebook (02_layout_engines.ipynb), you'll learn about:</p> <ul> <li>Different layout engines (hexagonal, polygon-bounded, etc.)</li> <li>When to use each layout type</li> <li>Comparing connectivity patterns</li> </ul>"},{"location":"examples/01_introduction_basics/#exercises-optional","title":"Exercises (Optional)\u00b6","text":"<p>Try these on your own to reinforce your learning:</p> <ol> <li>Create an environment with 3 cm bins and compute the occupancy</li> <li>Find the 5 most visited bins and plot them</li> <li>Calculate the percentage of time spent in the center (50\u00b120 cm square)</li> <li>Create environments with different bin sizes and compare the number of active bins</li> </ol>"},{"location":"examples/02_layout_engines/","title":"Layout Engines: Choosing the Right Spatial Discretization","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nfrom shapely.geometry import Point, Polygon\n\nfrom neurospatial import Environment\n\nnp.random.seed(42)\nplt.rcParams[\"figure.figsize\"] = (12, 10)\n</pre> import matplotlib.pyplot as plt import numpy as np from shapely.geometry import Point, Polygon  from neurospatial import Environment  np.random.seed(42) plt.rcParams[\"figure.figsize\"] = (12, 10) In\u00a0[2]: Copied! <pre># Generate sample data for a square arena\nn_samples = 2000\nsquare_data = np.random.uniform(0, 50, size=(n_samples, 2))\n\n# Create regular grid environment\nenv_regular = Environment.from_samples(\n    data_samples=square_data, bin_size=5.0, name=\"RegularGrid\"\n)\n\nprint(\"Regular Grid Environment:\")\nprint(f\"  Layout type: {env_regular.layout._layout_type_tag}\")\nprint(f\"  Number of bins: {env_regular.n_bins}\")\nprint(f\"  Grid shape: {env_regular.grid_shape}\")\n</pre> # Generate sample data for a square arena n_samples = 2000 square_data = np.random.uniform(0, 50, size=(n_samples, 2))  # Create regular grid environment env_regular = Environment.from_samples(     data_samples=square_data, bin_size=5.0, name=\"RegularGrid\" )  print(\"Regular Grid Environment:\") print(f\"  Layout type: {env_regular.layout._layout_type_tag}\") print(f\"  Number of bins: {env_regular.n_bins}\") print(f\"  Grid shape: {env_regular.grid_shape}\") <pre>Regular Grid Environment:\n  Layout type: RegularGrid\n  Number of bins: 121\n  Grid shape: (11, 11)\n</pre> In\u00a0[3]: Copied! <pre># Orthogonal neighbors only (4-connectivity in 2D)\nenv_orthogonal = Environment.from_samples(\n    data_samples=square_data,\n    bin_size=5.0,\n    connect_diagonal_neighbors=False,\n    name=\"Orthogonal\",\n)\n\n# Include diagonal neighbors (8-connectivity in 2D)\nenv_diagonal = Environment.from_samples(\n    data_samples=square_data,\n    bin_size=5.0,\n    connect_diagonal_neighbors=True,\n    name=\"Diagonal\",\n)\n\n# Compare number of edges\nprint(f\"Orthogonal connectivity: {env_orthogonal.connectivity.number_of_edges()} edges\")\nprint(f\"Diagonal connectivity: {env_diagonal.connectivity.number_of_edges()} edges\")\n</pre> # Orthogonal neighbors only (4-connectivity in 2D) env_orthogonal = Environment.from_samples(     data_samples=square_data,     bin_size=5.0,     connect_diagonal_neighbors=False,     name=\"Orthogonal\", )  # Include diagonal neighbors (8-connectivity in 2D) env_diagonal = Environment.from_samples(     data_samples=square_data,     bin_size=5.0,     connect_diagonal_neighbors=True,     name=\"Diagonal\", )  # Compare number of edges print(f\"Orthogonal connectivity: {env_orthogonal.connectivity.number_of_edges()} edges\") print(f\"Diagonal connectivity: {env_diagonal.connectivity.number_of_edges()} edges\") <pre>Orthogonal connectivity: 220 edges\nDiagonal connectivity: 420 edges\n</pre> In\u00a0[4]: Copied! <pre># Visualize the difference\nfig, axes = plt.subplots(1, 2, figsize=(16, 8))\n\n# Zoom in on a small region to see connectivity\nfor ax, env, title in zip(\n    axes,\n    [env_orthogonal, env_diagonal],\n    [\"Orthogonal (4-connectivity)\", \"Diagonal (8-connectivity)\"],\n    strict=False,\n):\n    env.plot(ax=ax, show_connectivity=True)\n    ax.set_xlim(20, 35)\n    ax.set_ylim(20, 35)\n    ax.set_title(title)\n\nplt.tight_layout()\nplt.show()\n</pre> # Visualize the difference fig, axes = plt.subplots(1, 2, figsize=(16, 8))  # Zoom in on a small region to see connectivity for ax, env, title in zip(     axes,     [env_orthogonal, env_diagonal],     [\"Orthogonal (4-connectivity)\", \"Diagonal (8-connectivity)\"],     strict=False, ):     env.plot(ax=ax, show_connectivity=True)     ax.set_xlim(20, 35)     ax.set_ylim(20, 35)     ax.set_title(title)  plt.tight_layout() plt.show() <p>When to use each:</p> <ul> <li>Orthogonal: Simpler, matches cardinal directions, faster computation</li> <li>Diagonal: More realistic for free movement, shorter path distances</li> </ul> In\u00a0[5]: Copied! <pre># Create hexagonal environment\nenv_hex = Environment.from_samples(\n    data_samples=square_data,\n    layout_kind=\"Hexagonal\",  # Specify layout type\n    bin_size=5.0,  # This is the hexagon width (flat-to-flat distance)\n    name=\"Hexagonal\",\n)\n\nprint(\"Hexagonal Environment:\")\nprint(f\"  Layout type: {env_hex.layout._layout_type_tag}\")\nprint(f\"  Number of bins: {env_hex.n_bins}\")\nprint(f\"  Number of edges: {env_hex.connectivity.number_of_edges()}\")\n</pre> # Create hexagonal environment env_hex = Environment.from_samples(     data_samples=square_data,     layout_kind=\"Hexagonal\",  # Specify layout type     bin_size=5.0,  # This is the hexagon width (flat-to-flat distance)     name=\"Hexagonal\", )  print(\"Hexagonal Environment:\") print(f\"  Layout type: {env_hex.layout._layout_type_tag}\") print(f\"  Number of bins: {env_hex.n_bins}\") print(f\"  Number of edges: {env_hex.connectivity.number_of_edges()}\") <pre>Hexagonal Environment:\n  Layout type: Hexagonal\n  Number of bins: 134\n  Number of edges: 355\n</pre> In\u00a0[6]: Copied! <pre># Compare regular grid vs hexagonal\nfig, axes = plt.subplots(1, 2, figsize=(16, 8))\n\nenv_regular.plot(ax=axes[0], show_connectivity=True)\naxes[0].set_title(f\"Regular Grid ({env_regular.n_bins} bins)\")\naxes[0].set_xlim(15, 35)\naxes[0].set_ylim(15, 35)\n\nenv_hex.plot(ax=axes[1], show_connectivity=True)\naxes[1].set_title(f\"Hexagonal ({env_hex.n_bins} bins)\")\naxes[1].set_xlim(15, 35)\naxes[1].set_ylim(15, 35)\n\nplt.tight_layout()\nplt.show()\n</pre> # Compare regular grid vs hexagonal fig, axes = plt.subplots(1, 2, figsize=(16, 8))  env_regular.plot(ax=axes[0], show_connectivity=True) axes[0].set_title(f\"Regular Grid ({env_regular.n_bins} bins)\") axes[0].set_xlim(15, 35) axes[0].set_ylim(15, 35)  env_hex.plot(ax=axes[1], show_connectivity=True) axes[1].set_title(f\"Hexagonal ({env_hex.n_bins} bins)\") axes[1].set_xlim(15, 35) axes[1].set_ylim(15, 35)  plt.tight_layout() plt.show() In\u00a0[7]: Copied! <pre>def analyze_neighbor_distances(env, name):\n    \"\"\"Compute statistics about neighbor distances.\"\"\"\n    distances = []\n    for _, _, data in env.connectivity.edges(data=True):\n        distances.append(data[\"distance\"])\n\n    distances = np.array(distances)\n    print(f\"\\n{name}:\")\n    print(f\"  Mean distance: {distances.mean():.3f} cm\")\n    print(f\"  Std distance: {distances.std():.3f} cm\")\n    print(f\"  Min distance: {distances.min():.3f} cm\")\n    print(f\"  Max distance: {distances.max():.3f} cm\")\n    print(f\"  Coefficient of variation: {distances.std() / distances.mean():.3f}\")\n    return distances\n\n\nregular_distances = analyze_neighbor_distances(env_diagonal, \"Regular Grid (diagonal)\")\nhex_distances = analyze_neighbor_distances(env_hex, \"Hexagonal\")\n</pre> def analyze_neighbor_distances(env, name):     \"\"\"Compute statistics about neighbor distances.\"\"\"     distances = []     for _, _, data in env.connectivity.edges(data=True):         distances.append(data[\"distance\"])      distances = np.array(distances)     print(f\"\\n{name}:\")     print(f\"  Mean distance: {distances.mean():.3f} cm\")     print(f\"  Std distance: {distances.std():.3f} cm\")     print(f\"  Min distance: {distances.min():.3f} cm\")     print(f\"  Max distance: {distances.max():.3f} cm\")     print(f\"  Coefficient of variation: {distances.std() / distances.mean():.3f}\")     return distances   regular_distances = analyze_neighbor_distances(env_diagonal, \"Regular Grid (diagonal)\") hex_distances = analyze_neighbor_distances(env_hex, \"Hexagonal\") <pre>\nRegular Grid (diagonal):\n  Mean distance: 5.980 cm\n  Std distance: 1.033 cm\n  Min distance: 4.992 cm\n  Max distance: 7.064 cm\n  Coefficient of variation: 0.173\n\nHexagonal:\n  Mean distance: 5.000 cm\n  Std distance: 0.000 cm\n  Min distance: 5.000 cm\n  Max distance: 5.000 cm\n  Coefficient of variation: 0.000\n</pre> In\u00a0[8]: Copied! <pre># Plot distance distributions\nfig, ax = plt.subplots(figsize=(10, 6))\n\n\n# Use explicit bins to handle uniform hexagonal data\n# For uniform data (single value), use fewer bins; for varied data, use 20\ndef get_bins_and_range(distances):\n    \"\"\"Determine appropriate bins and range for histogram.\"\"\"\n    min_val = distances.min()\n    max_val = distances.max()\n\n    # If all values are the same, create a narrow range around that value\n    if np.isclose(min_val, max_val):\n        range_val = (min_val - 0.01, max_val + 0.01)\n        return 3, range_val  # Use just 3 bins for uniform data\n    else:\n        # For varied data, use 20 bins\n        range_val = (min_val, max_val)\n        return 20, range_val\n\n\nregular_bins, regular_range = get_bins_and_range(regular_distances)\nhex_bins, hex_range = get_bins_and_range(hex_distances)\n\nax.hist(\n    regular_distances,\n    bins=regular_bins,\n    alpha=0.6,\n    label=\"Regular Grid\",\n    density=True,\n    range=regular_range,\n)\nax.hist(\n    hex_distances,\n    bins=hex_bins,\n    alpha=0.6,\n    label=\"Hexagonal\",\n    density=True,\n    range=hex_range,\n)\n\nax.set_xlabel(\"Edge Distance (cm)\")\nax.set_ylabel(\"Density\")\nax.set_title(\"Distribution of Neighbor Distances\")\nax.legend()\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n</pre> # Plot distance distributions fig, ax = plt.subplots(figsize=(10, 6))   # Use explicit bins to handle uniform hexagonal data # For uniform data (single value), use fewer bins; for varied data, use 20 def get_bins_and_range(distances):     \"\"\"Determine appropriate bins and range for histogram.\"\"\"     min_val = distances.min()     max_val = distances.max()      # If all values are the same, create a narrow range around that value     if np.isclose(min_val, max_val):         range_val = (min_val - 0.01, max_val + 0.01)         return 3, range_val  # Use just 3 bins for uniform data     else:         # For varied data, use 20 bins         range_val = (min_val, max_val)         return 20, range_val   regular_bins, regular_range = get_bins_and_range(regular_distances) hex_bins, hex_range = get_bins_and_range(hex_distances)  ax.hist(     regular_distances,     bins=regular_bins,     alpha=0.6,     label=\"Regular Grid\",     density=True,     range=regular_range, ) ax.hist(     hex_distances,     bins=hex_bins,     alpha=0.6,     label=\"Hexagonal\",     density=True,     range=hex_range, )  ax.set_xlabel(\"Edge Distance (cm)\") ax.set_ylabel(\"Density\") ax.set_title(\"Distribution of Neighbor Distances\") ax.legend() ax.grid(True, alpha=0.3) plt.tight_layout() plt.show() <p>Key insight: Hexagonal layouts have a single peak (uniform distances), while regular grids have two peaks (orthogonal vs diagonal distances).</p> In\u00a0[9]: Copied! <pre># Define a circular arena (50 cm diameter)\ncenter = Point(50, 50)\nradius = 25.0\ncircle = center.buffer(radius)\n\n# Create environment bounded by circle\nenv_circle = Environment.from_polygon(\n    polygon=circle, bin_size=3.0, name=\"CircularArena\"\n)\n\nprint(\"Circular Arena:\")\nprint(f\"  Radius: {radius} cm\")\nprint(f\"  Active bins: {env_circle.n_bins}\")\nprint(f\"  Grid shape: {env_circle.grid_shape}\")\n</pre> # Define a circular arena (50 cm diameter) center = Point(50, 50) radius = 25.0 circle = center.buffer(radius)  # Create environment bounded by circle env_circle = Environment.from_polygon(     polygon=circle, bin_size=3.0, name=\"CircularArena\" )  print(\"Circular Arena:\") print(f\"  Radius: {radius} cm\") print(f\"  Active bins: {env_circle.n_bins}\") print(f\"  Grid shape: {env_circle.grid_shape}\") <pre>Circular Arena:\n  Radius: 25.0 cm\n  Active bins: 225\n  Grid shape: (17, 17)\n</pre> In\u00a0[10]: Copied! <pre># Visualize\nfig, ax = plt.subplots(figsize=(10, 10))\nenv_circle.plot(ax=ax, show_connectivity=True)\nax.set_title(\"Circular Arena (25 cm radius)\")\nax.set_aspect(\"equal\")\nplt.tight_layout()\nplt.show()\n</pre> # Visualize fig, ax = plt.subplots(figsize=(10, 10)) env_circle.plot(ax=ax, show_connectivity=True) ax.set_title(\"Circular Arena (25 cm radius)\") ax.set_aspect(\"equal\") plt.tight_layout() plt.show() In\u00a0[11]: Copied! <pre># Define a T-maze shape\nt_maze_coords = [\n    # Horizontal bar (top of T)\n    (0, 40),\n    (60, 40),\n    (60, 50),\n    (0, 50),\n    (0, 40),  # Close at junction\n    # Vertical bar (stem of T)\n    (25, 40),\n    (25, 0),\n    (35, 0),\n    (35, 40),\n    # Close back at junction\n    (25, 40),\n]\n\n# Create proper polygon\nt_maze_polygon = Polygon(\n    [\n        (0, 40),\n        (0, 50),\n        (25, 50),\n        (25, 60),\n        (35, 60),\n        (35, 50),\n        (60, 50),\n        (60, 40),\n        (35, 40),\n        (35, 0),\n        (25, 0),\n        (25, 40),\n    ]\n)\n\nenv_tmaze = Environment.from_polygon(polygon=t_maze_polygon, bin_size=3.0, name=\"TMaze\")\n\nprint(\"T-Maze Environment:\")\nprint(f\"  Active bins: {env_tmaze.n_bins}\")\n</pre> # Define a T-maze shape t_maze_coords = [     # Horizontal bar (top of T)     (0, 40),     (60, 40),     (60, 50),     (0, 50),     (0, 40),  # Close at junction     # Vertical bar (stem of T)     (25, 40),     (25, 0),     (35, 0),     (35, 40),     # Close back at junction     (25, 40), ]  # Create proper polygon t_maze_polygon = Polygon(     [         (0, 40),         (0, 50),         (25, 50),         (25, 60),         (35, 60),         (35, 50),         (60, 50),         (60, 40),         (35, 40),         (35, 0),         (25, 0),         (25, 40),     ] )  env_tmaze = Environment.from_polygon(polygon=t_maze_polygon, bin_size=3.0, name=\"TMaze\")  print(\"T-Maze Environment:\") print(f\"  Active bins: {env_tmaze.n_bins}\") <pre>T-Maze Environment:\n  Active bins: 144\n</pre> In\u00a0[12]: Copied! <pre>fig, ax = plt.subplots(figsize=(8, 10))\nenv_tmaze.plot(ax=ax, show_connectivity=True)\nax.set_title(\"T-Maze Environment\")\nax.set_aspect(\"equal\")\nplt.tight_layout()\nplt.show()\n</pre> fig, ax = plt.subplots(figsize=(8, 10)) env_tmaze.plot(ax=ax, show_connectivity=True) ax.set_title(\"T-Maze Environment\") ax.set_aspect(\"equal\") plt.tight_layout() plt.show() In\u00a0[13]: Copied! <pre># Generate data inside a circle\nn_samples = 2000\nangles = np.random.uniform(0, 2 * np.pi, n_samples)\nradii = (\n    np.sqrt(np.random.uniform(0, 1, n_samples)) * 23\n)  # sqrt for uniform distribution\ncircle_data = np.column_stack(\n    [50 + radii * np.cos(angles), 50 + radii * np.sin(angles)]\n)\n\n# Create with different layouts\ncircle_polygon = Point(50, 50).buffer(25)\n\nenvs_comparison = {\n    \"Regular Grid\\n(from_samples)\": Environment.from_samples(\n        data_samples=circle_data, bin_size=4.0, name=\"Regular\"\n    ),\n    \"Regular Grid\\n(from_polygon)\": Environment.from_polygon(\n        polygon=circle_polygon, bin_size=4.0, name=\"RegularPoly\"\n    ),\n    \"Hexagonal\\n(from_samples)\": Environment.from_samples(\n        data_samples=circle_data,\n        layout_kind=\"Hexagonal\",\n        bin_size=4.0,\n        name=\"HexSamples\",\n    ),\n}\n</pre> # Generate data inside a circle n_samples = 2000 angles = np.random.uniform(0, 2 * np.pi, n_samples) radii = (     np.sqrt(np.random.uniform(0, 1, n_samples)) * 23 )  # sqrt for uniform distribution circle_data = np.column_stack(     [50 + radii * np.cos(angles), 50 + radii * np.sin(angles)] )  # Create with different layouts circle_polygon = Point(50, 50).buffer(25)  envs_comparison = {     \"Regular Grid\\n(from_samples)\": Environment.from_samples(         data_samples=circle_data, bin_size=4.0, name=\"Regular\"     ),     \"Regular Grid\\n(from_polygon)\": Environment.from_polygon(         polygon=circle_polygon, bin_size=4.0, name=\"RegularPoly\"     ),     \"Hexagonal\\n(from_samples)\": Environment.from_samples(         data_samples=circle_data,         layout_kind=\"Hexagonal\",         bin_size=4.0,         name=\"HexSamples\",     ), } In\u00a0[14]: Copied! <pre># Plot comparison\nfig, axes = plt.subplots(1, 3, figsize=(18, 6))\n\nfor ax, (title, env) in zip(axes, envs_comparison.items(), strict=False):\n    env.plot(ax=ax, show_connectivity=True)\n    ax.set_title(f\"{title}\\n{env.n_bins} bins\")\n    ax.set_aspect(\"equal\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Plot comparison fig, axes = plt.subplots(1, 3, figsize=(18, 6))  for ax, (title, env) in zip(axes, envs_comparison.items(), strict=False):     env.plot(ax=ax, show_connectivity=True)     ax.set_title(f\"{title}\\n{env.n_bins} bins\")     ax.set_aspect(\"equal\")  plt.tight_layout() plt.show() In\u00a0[15]: Copied! <pre># Regular grid parameters\nenv1 = Environment.from_samples(\n    data_samples=square_data,\n    bin_size=5.0,  # Size of bins\n    connect_diagonal_neighbors=True,  # Include diagonal connections\n    infer_active_bins=True,  # Auto-detect active bins\n    bin_count_threshold=1,  # Min samples per active bin\n    name=\"FullyConfigured\",\n)\n\n# Hexagonal parameters\nenv2 = Environment.from_samples(\n    data_samples=square_data,\n    layout_kind=\"Hexagonal\",\n    bin_size=5.0,  # Hexagon width (flat-to-flat)\n    infer_active_bins=True,\n    name=\"HexConfigured\",\n)\n\n# Polygon parameters (from_polygon always uses RegularGrid layout)\nenv3 = Environment.from_polygon(\n    polygon=circle_polygon,\n    bin_size=5.0,\n    connect_diagonal_neighbors=True,\n    name=\"PolyConfigured\",\n)\n\nprint(\"All environments created successfully!\")\n</pre> # Regular grid parameters env1 = Environment.from_samples(     data_samples=square_data,     bin_size=5.0,  # Size of bins     connect_diagonal_neighbors=True,  # Include diagonal connections     infer_active_bins=True,  # Auto-detect active bins     bin_count_threshold=1,  # Min samples per active bin     name=\"FullyConfigured\", )  # Hexagonal parameters env2 = Environment.from_samples(     data_samples=square_data,     layout_kind=\"Hexagonal\",     bin_size=5.0,  # Hexagon width (flat-to-flat)     infer_active_bins=True,     name=\"HexConfigured\", )  # Polygon parameters (from_polygon always uses RegularGrid layout) env3 = Environment.from_polygon(     polygon=circle_polygon,     bin_size=5.0,     connect_diagonal_neighbors=True,     name=\"PolyConfigured\", )  print(\"All environments created successfully!\") <pre>All environments created successfully!\n</pre>"},{"location":"examples/02_layout_engines/#layout-engines-choosing-the-right-spatial-discretization","title":"Layout Engines: Choosing the Right Spatial Discretization\u00b6","text":""},{"location":"examples/02_layout_engines/#learning-objectives","title":"Learning Objectives\u00b6","text":"<p>By the end of this notebook, you will be able to:</p> <ul> <li>Understand the different layout engines available in neurospatial</li> <li>Choose the appropriate layout for your experimental setup</li> <li>Create environments with regular grids, hexagonal tessellations, and polygon boundaries</li> <li>Compare connectivity patterns across different layouts</li> <li>Understand the trade-offs between different discretization strategies</li> </ul> <p>Estimated time: 20-25 minutes</p>"},{"location":"examples/02_layout_engines/#what-are-layout-engines","title":"What Are Layout Engines?\u00b6","text":"<p>A layout engine defines how continuous space is discretized into bins. Different experimental setups benefit from different discretization strategies:</p> <ul> <li>RegularGridLayout: Standard rectangular grids (most common)</li> <li>HexagonalLayout: Hexagonal tessellations (uniform neighbor distances)</li> <li>ShapelyPolygonLayout: Grid bounded by arbitrary polygons (circular arenas, complex shapes)</li> <li>MaskedGridLayout: Grids with explicit active/inactive regions</li> <li>ImageMaskLayout: Binary image-based layouts</li> <li>TriangularMeshLayout: Triangular tessellations</li> <li>GraphLayout: 1D linearized tracks (covered in notebook 05)</li> </ul> <p>You typically don't interact with layout engines directly\u2014factory methods like <code>from_samples()</code> handle them for you!</p>"},{"location":"examples/02_layout_engines/#setup","title":"Setup\u00b6","text":""},{"location":"examples/02_layout_engines/#1-regular-grid-layout-default","title":"1. Regular Grid Layout (Default)\u00b6","text":"<p>This is the standard rectangular grid you've already seen in notebook 01. It's the default layout for <code>from_samples()</code>.</p>"},{"location":"examples/02_layout_engines/#connectivity-orthogonal-vs-diagonal","title":"Connectivity: Orthogonal vs Diagonal\u00b6","text":"<p>Regular grids support two connectivity patterns:</p>"},{"location":"examples/02_layout_engines/#2-hexagonal-layout","title":"2. Hexagonal Layout\u00b6","text":"<p>Hexagonal tessellations have a key advantage: all neighbors are equidistant from the center bin. This creates more uniform spatial sampling.</p>"},{"location":"examples/02_layout_engines/#neighbor-distance-analysis","title":"Neighbor Distance Analysis\u00b6","text":"<p>Let's verify that hexagonal layouts have more uniform neighbor distances:</p>"},{"location":"examples/02_layout_engines/#3-polygon-bounded-layouts","title":"3. Polygon-Bounded Layouts\u00b6","text":"<p>Real experiments often use circular arenas, water mazes, or other non-rectangular environments. Polygon-bounded layouts let you specify an exact boundary.</p>"},{"location":"examples/02_layout_engines/#example-1-circular-arena","title":"Example 1: Circular Arena\u00b6","text":"<p>A common experimental setup in rodent neuroscience:</p>"},{"location":"examples/02_layout_engines/#example-2-complex-polygon-shape","title":"Example 2: Complex Polygon Shape\u00b6","text":"<p>You can define arbitrary polygons for complex environments:</p>"},{"location":"examples/02_layout_engines/#4-comparing-all-layouts-side-by-side","title":"4. Comparing All Layouts Side-by-Side\u00b6","text":"<p>Let's create the same circular arena with different layout types:</p>"},{"location":"examples/02_layout_engines/#5-when-to-use-each-layout","title":"5. When to Use Each Layout\u00b6","text":"<p>Here's a decision guide:</p> Layout Best For Advantages Disadvantages Regular Grid Most applications, rectangular arenas Simple, intuitive, fast Non-uniform neighbor distances (with diagonal) Hexagonal Isotropic analysis, grid cells Uniform neighbor distances, natural for some patterns Slightly more complex, can't tile rectangles perfectly Polygon-bounded Circular arenas, water mazes, custom shapes Exact boundaries, matches physical setup Requires polygon definition Graph (next notebook) Linear tracks, mazes, 1D analysis True 1D representation, handles complex track geometry Only for track-like environments <p>Default recommendation: Start with regular grid (<code>from_samples()</code>). It works for 95% of use cases!</p>"},{"location":"examples/02_layout_engines/#6-layout-parameters-summary","title":"6. Layout Parameters Summary\u00b6","text":"<p>Key parameters that affect layout creation:</p>"},{"location":"examples/02_layout_engines/#key-takeaways","title":"Key Takeaways\u00b6","text":"<ol> <li>Layout engines define how space is discretized into bins</li> <li>Regular grids are the default and work for most applications</li> <li>Hexagonal layouts provide uniform neighbor distances</li> <li>Polygon-bounded layouts match physical arena boundaries (circles, custom shapes)</li> <li>Connectivity patterns (orthogonal vs diagonal) affect path distances and computation</li> <li>Choose layouts based on:<ul> <li>Physical arena shape</li> <li>Analysis requirements (isotropy, path distances)</li> <li>Computational considerations</li> </ul> </li> </ol>"},{"location":"examples/02_layout_engines/#next-steps","title":"Next Steps\u00b6","text":"<p>In the next notebook (03_morphological_operations.ipynb), you'll learn:</p> <ul> <li>How to handle sparse or patchy data</li> <li>Morphological operations: dilate, fill_holes, close_gaps</li> <li>Controlling active bin inference</li> <li>Dealing with noisy position tracking</li> </ul>"},{"location":"examples/02_layout_engines/#exercises-optional","title":"Exercises (Optional)\u00b6","text":"<ol> <li>Create a hexagonal environment for a circular arena and compare bin count with regular grid</li> <li>Design a custom polygon for a figure-8 maze</li> <li>Compare shortest path distances between two points using orthogonal vs diagonal connectivity</li> <li>Calculate the average number of neighbors per bin for each layout type</li> </ol>"},{"location":"examples/03_morphological_operations/","title":"Morphological Operations: Handling Sparse and Patchy Data","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom neurospatial import Environment\n\nnp.random.seed(42)\nplt.rcParams[\"figure.figsize\"] = (12, 10)\nplt.rcParams[\"font.size\"] = 11\n</pre> import matplotlib.pyplot as plt import numpy as np  from neurospatial import Environment  np.random.seed(42) plt.rcParams[\"figure.figsize\"] = (12, 10) plt.rcParams[\"font.size\"] = 11 In\u00a0[2]: Copied! <pre>def create_sparse_trajectory(n_samples=3000, seed=42):\n    \"\"\"\n    Create sparse position data with realistic biases.\n\n    Simulates an animal that:\n    - Prefers to stay near walls (thigmotaxis)\n    - Has occasional tracking failures\n    - Makes quick runs across the center\n\n    Parameters\n    ----------\n    n_samples : int\n        Number of position samples to generate.\n    seed : int\n        Random seed for reproducibility.\n\n    Returns\n    -------\n    position : ndarray, shape (n_samples, 2)\n        2D position data in cm.\n    \"\"\"\n    np.random.seed(seed)\n    position = np.zeros((n_samples, 2))\n    position[0] = [10, 10]  # Start in corner\n\n    # Create biased random walk\n    for t in range(1, n_samples):\n        # Strong preference for edges\n        if np.random.rand() &lt; 0.7:  # 70% of time, move along edges\n            # Move along walls\n            if (\n                position[t - 1, 0] &lt; 15 or position[t - 1, 0] &gt; 85\n            ):  # Near vertical walls\n                step = [np.random.randn() * 0.5, np.random.randn() * 3.0]\n            elif (\n                position[t - 1, 1] &lt; 15 or position[t - 1, 1] &gt; 85\n            ):  # Near horizontal walls\n                step = [np.random.randn() * 3.0, np.random.randn() * 0.5]\n            else:\n                step = np.random.randn(2) * 2.0\n        else:  # Occasional center crossing\n            step = np.random.randn(2) * 5.0\n\n        position[t] = position[t - 1] + step\n        position[t] = np.clip(position[t], 5, 95)\n\n    # Add some tracking failures (NaN regions that get filtered out)\n    tracking_failures = np.random.choice(\n        n_samples, size=int(n_samples * 0.05), replace=False\n    )\n\n    # Remove tracked failures\n    position = np.delete(position, tracking_failures, axis=0)\n\n    return position\n\n\nsparse_data = create_sparse_trajectory(n_samples=3000)\nprint(f\"Generated {len(sparse_data)} position samples\")\nprint(f\"X range: [{sparse_data[:, 0].min():.1f}, {sparse_data[:, 0].max():.1f}] cm\")\nprint(f\"Y range: [{sparse_data[:, 1].min():.1f}, {sparse_data[:, 1].max():.1f}] cm\")\n</pre> def create_sparse_trajectory(n_samples=3000, seed=42):     \"\"\"     Create sparse position data with realistic biases.      Simulates an animal that:     - Prefers to stay near walls (thigmotaxis)     - Has occasional tracking failures     - Makes quick runs across the center      Parameters     ----------     n_samples : int         Number of position samples to generate.     seed : int         Random seed for reproducibility.      Returns     -------     position : ndarray, shape (n_samples, 2)         2D position data in cm.     \"\"\"     np.random.seed(seed)     position = np.zeros((n_samples, 2))     position[0] = [10, 10]  # Start in corner      # Create biased random walk     for t in range(1, n_samples):         # Strong preference for edges         if np.random.rand() &lt; 0.7:  # 70% of time, move along edges             # Move along walls             if (                 position[t - 1, 0] &lt; 15 or position[t - 1, 0] &gt; 85             ):  # Near vertical walls                 step = [np.random.randn() * 0.5, np.random.randn() * 3.0]             elif (                 position[t - 1, 1] &lt; 15 or position[t - 1, 1] &gt; 85             ):  # Near horizontal walls                 step = [np.random.randn() * 3.0, np.random.randn() * 0.5]             else:                 step = np.random.randn(2) * 2.0         else:  # Occasional center crossing             step = np.random.randn(2) * 5.0          position[t] = position[t - 1] + step         position[t] = np.clip(position[t], 5, 95)      # Add some tracking failures (NaN regions that get filtered out)     tracking_failures = np.random.choice(         n_samples, size=int(n_samples * 0.05), replace=False     )      # Remove tracked failures     position = np.delete(position, tracking_failures, axis=0)      return position   sparse_data = create_sparse_trajectory(n_samples=3000) print(f\"Generated {len(sparse_data)} position samples\") print(f\"X range: [{sparse_data[:, 0].min():.1f}, {sparse_data[:, 0].max():.1f}] cm\") print(f\"Y range: [{sparse_data[:, 1].min():.1f}, {sparse_data[:, 1].max():.1f}] cm\") <pre>Generated 2850 position samples\nX range: [5.0, 95.0] cm\nY range: [5.0, 95.0] cm\n</pre> In\u00a0[3]: Copied! <pre># Visualize the sparse trajectory\nfig, ax = plt.subplots(figsize=(10, 10))\n\nscatter = ax.scatter(\n    sparse_data[:, 0],\n    sparse_data[:, 1],\n    c=np.arange(len(sparse_data)),\n    cmap=\"viridis\",\n    s=2,\n    alpha=0.5,\n)\n\nax.plot(sparse_data[0, 0], sparse_data[0, 1], \"go\", markersize=12, label=\"Start\")\nax.plot(sparse_data[-1, 0], sparse_data[-1, 1], \"ro\", markersize=12, label=\"End\")\n\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(\"Sparse Trajectory (wall-preferring animal)\")\nax.set_aspect(\"equal\")\nax.legend()\nplt.colorbar(scatter, ax=ax, label=\"Time (samples)\")\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nNotice: Animal spends most time near walls, rarely visits center\")\n</pre> # Visualize the sparse trajectory fig, ax = plt.subplots(figsize=(10, 10))  scatter = ax.scatter(     sparse_data[:, 0],     sparse_data[:, 1],     c=np.arange(len(sparse_data)),     cmap=\"viridis\",     s=2,     alpha=0.5, )  ax.plot(sparse_data[0, 0], sparse_data[0, 1], \"go\", markersize=12, label=\"Start\") ax.plot(sparse_data[-1, 0], sparse_data[-1, 1], \"ro\", markersize=12, label=\"End\")  ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(\"Sparse Trajectory (wall-preferring animal)\") ax.set_aspect(\"equal\") ax.legend() plt.colorbar(scatter, ax=ax, label=\"Time (samples)\") plt.tight_layout() plt.show()  print(\"\\nNotice: Animal spends most time near walls, rarely visits center\") <pre>\nNotice: Animal spends most time near walls, rarely visits center\n</pre> In\u00a0[4]: Copied! <pre># Create environment with default settings\nenv_default = Environment.from_samples(\n    data_samples=sparse_data, bin_size=5.0, name=\"Default_Sparse\"\n)\n\nprint(env_default.info())\n</pre> # Create environment with default settings env_default = Environment.from_samples(     data_samples=sparse_data, bin_size=5.0, name=\"Default_Sparse\" )  print(env_default.info()) <pre>Environment Information\n=======================\n\nName: Default_Sparse\nLayout Type: RegularGrid\nDimensions: 2\nNumber of Bins: 270\n\nSpatial Extent:\n  Dimension 0: [2.50, 97.50] (range: 95.00)\n  Dimension 1: [2.50, 97.50] (range: 95.00)\n\nBin Sizes:\n  Dimension 0: 5.00\n  Dimension 1: 5.00\n\nRegions: None\n\n</pre> In\u00a0[5]: Copied! <pre># Visualize the fragmented environment\nfig, ax = plt.subplots(figsize=(10, 10))\nenv_default.plot(ax=ax, show_connectivity=True)\nax.set_title(f\"Default Environment (Fragmented)\\n{env_default.n_bins} active bins\")\nax.set_aspect(\"equal\")\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nProblem: Environment is fragmented!\")\nprint(\"- Center bins are missing (animal rarely visited)\")\nprint(\"- Cannot compute paths through the center\")\nprint(\"- Spatial analysis will be limited to edges only\")\n</pre> # Visualize the fragmented environment fig, ax = plt.subplots(figsize=(10, 10)) env_default.plot(ax=ax, show_connectivity=True) ax.set_title(f\"Default Environment (Fragmented)\\n{env_default.n_bins} active bins\") ax.set_aspect(\"equal\") plt.tight_layout() plt.show()  print(\"\\nProblem: Environment is fragmented!\") print(\"- Center bins are missing (animal rarely visited)\") print(\"- Cannot compute paths through the center\") print(\"- Spatial analysis will be limited to edges only\") <pre>\nProblem: Environment is fragmented!\n- Center bins are missing (animal rarely visited)\n- Cannot compute paths through the center\n- Spatial analysis will be limited to edges only\n</pre> In\u00a0[6]: Copied! <pre>import networkx as nx\n\n# Check if environment is connected\nis_connected = nx.is_connected(env_default.connectivity)\nprint(f\"Is environment connected? {is_connected}\")\n\nif not is_connected:\n    # Find connected components\n    components = list(nx.connected_components(env_default.connectivity))\n    print(f\"\\nNumber of disconnected components: {len(components)}\")\n    print(f\"Largest component size: {len(max(components, key=len))} bins\")\n    print(f\"Smallest component size: {len(min(components, key=len))} bins\")\n\n    # Try to find a path from corner to corner (will fail if disconnected)\n    try:\n        corner1 = env_default.bin_at([[10, 10]])[0]\n        corner2 = env_default.bin_at([[90, 90]])[0]\n        path = env_default.shortest_path(corner1, corner2)\n        print(f\"\\nPath from corner to corner: {len(path)} bins\")\n    except nx.NetworkXNoPath:\n        print(\"\\nNo path exists between opposite corners!\")\n</pre> import networkx as nx  # Check if environment is connected is_connected = nx.is_connected(env_default.connectivity) print(f\"Is environment connected? {is_connected}\")  if not is_connected:     # Find connected components     components = list(nx.connected_components(env_default.connectivity))     print(f\"\\nNumber of disconnected components: {len(components)}\")     print(f\"Largest component size: {len(max(components, key=len))} bins\")     print(f\"Smallest component size: {len(min(components, key=len))} bins\")      # Try to find a path from corner to corner (will fail if disconnected)     try:         corner1 = env_default.bin_at([[10, 10]])[0]         corner2 = env_default.bin_at([[90, 90]])[0]         path = env_default.shortest_path(corner1, corner2)         print(f\"\\nPath from corner to corner: {len(path)} bins\")     except nx.NetworkXNoPath:         print(\"\\nNo path exists between opposite corners!\") <pre>Is environment connected? True\n</pre> In\u00a0[7]: Copied! <pre># Create environment with dilation\nenv_dilated = Environment.from_samples(\n    data_samples=sparse_data,\n    bin_size=5.0,\n    dilate=True,  # Enable dilation\n    name=\"Dilated\",\n)\n\nprint(env_dilated.info())\nprint(f\"\\nBins added by dilation: {env_dilated.n_bins - env_default.n_bins}\")\n</pre> # Create environment with dilation env_dilated = Environment.from_samples(     data_samples=sparse_data,     bin_size=5.0,     dilate=True,  # Enable dilation     name=\"Dilated\", )  print(env_dilated.info()) print(f\"\\nBins added by dilation: {env_dilated.n_bins - env_default.n_bins}\") <pre>Environment Information\n=======================\n\nName: Dilated\nLayout Type: RegularGrid\nDimensions: 2\nNumber of Bins: 315\n\nSpatial Extent:\n  Dimension 0: [2.50, 97.50] (range: 95.00)\n  Dimension 1: [2.50, 97.50] (range: 95.00)\n\nBin Sizes:\n  Dimension 0: 5.00\n  Dimension 1: 5.00\n\nRegions: None\n\n\nBins added by dilation: 45\n</pre> In\u00a0[8]: Copied! <pre># Compare default vs dilated\nfig, axes = plt.subplots(1, 2, figsize=(18, 8))\n\nenv_default.plot(ax=axes[0], show_connectivity=True)\naxes[0].set_title(f\"Default\\n{env_default.n_bins} bins\")\naxes[0].set_aspect(\"equal\")\n\nenv_dilated.plot(ax=axes[1], show_connectivity=True)\naxes[1].set_title(f\"With Dilation\\n{env_dilated.n_bins} bins\")\naxes[1].set_aspect(\"equal\")\n\nplt.tight_layout()\nplt.show()\n\n# Check connectivity\nis_connected = nx.is_connected(env_dilated.connectivity)\nprint(f\"\\nIs dilated environment connected? {is_connected}\")\n</pre> # Compare default vs dilated fig, axes = plt.subplots(1, 2, figsize=(18, 8))  env_default.plot(ax=axes[0], show_connectivity=True) axes[0].set_title(f\"Default\\n{env_default.n_bins} bins\") axes[0].set_aspect(\"equal\")  env_dilated.plot(ax=axes[1], show_connectivity=True) axes[1].set_title(f\"With Dilation\\n{env_dilated.n_bins} bins\") axes[1].set_aspect(\"equal\")  plt.tight_layout() plt.show()  # Check connectivity is_connected = nx.is_connected(env_dilated.connectivity) print(f\"\\nIs dilated environment connected? {is_connected}\") <pre>\nIs dilated environment connected? True\n</pre> In\u00a0[9]: Copied! <pre># Create environment with hole filling\nenv_filled = Environment.from_samples(\n    data_samples=sparse_data,\n    bin_size=5.0,\n    fill_holes=True,  # Enable hole filling\n    name=\"Filled\",\n)\n\nprint(env_filled.info())\nprint(f\"\\nBins added by fill_holes: {env_filled.n_bins - env_default.n_bins}\")\n</pre> # Create environment with hole filling env_filled = Environment.from_samples(     data_samples=sparse_data,     bin_size=5.0,     fill_holes=True,  # Enable hole filling     name=\"Filled\", )  print(env_filled.info()) print(f\"\\nBins added by fill_holes: {env_filled.n_bins - env_default.n_bins}\") <pre>Environment Information\n=======================\n\nName: Filled\nLayout Type: RegularGrid\nDimensions: 2\nNumber of Bins: 279\n\nSpatial Extent:\n  Dimension 0: [2.50, 97.50] (range: 95.00)\n  Dimension 1: [2.50, 97.50] (range: 95.00)\n\nBin Sizes:\n  Dimension 0: 5.00\n  Dimension 1: 5.00\n\nRegions: None\n\n\nBins added by fill_holes: 9\n</pre> In\u00a0[10]: Copied! <pre># Create environment with gap closing\nenv_closed = Environment.from_samples(\n    data_samples=sparse_data,\n    bin_size=5.0,\n    close_gaps=True,  # Enable closing\n    name=\"Closed\",\n)\n\nprint(env_closed.info())\nprint(\n    f\"\\nBins after close_gaps: {env_closed.n_bins} (compare to {env_default.n_bins} default)\"\n)\n</pre> # Create environment with gap closing env_closed = Environment.from_samples(     data_samples=sparse_data,     bin_size=5.0,     close_gaps=True,  # Enable closing     name=\"Closed\", )  print(env_closed.info()) print(     f\"\\nBins after close_gaps: {env_closed.n_bins} (compare to {env_default.n_bins} default)\" ) <pre>Environment Information\n=======================\n\nName: Closed\nLayout Type: RegularGrid\nDimensions: 2\nNumber of Bins: 225\n\nSpatial Extent:\n  Dimension 0: [2.50, 97.50] (range: 95.00)\n  Dimension 1: [2.50, 97.50] (range: 95.00)\n\nBin Sizes:\n  Dimension 0: 5.00\n  Dimension 1: 5.00\n\nRegions: None\n\n\nBins after close_gaps: 225 (compare to 270 default)\n</pre> In\u00a0[11]: Copied! <pre># Combine all operations\nenv_combined = Environment.from_samples(\n    data_samples=sparse_data,\n    bin_size=5.0,\n    dilate=True,\n    fill_holes=True,\n    close_gaps=True,\n    name=\"Combined\",\n)\n\nprint(env_combined.info())\n</pre> # Combine all operations env_combined = Environment.from_samples(     data_samples=sparse_data,     bin_size=5.0,     dilate=True,     fill_holes=True,     close_gaps=True,     name=\"Combined\", )  print(env_combined.info()) <pre>Environment Information\n=======================\n\nName: Combined\nLayout Type: RegularGrid\nDimensions: 2\nNumber of Bins: 311\n\nSpatial Extent:\n  Dimension 0: [2.50, 97.50] (range: 95.00)\n  Dimension 1: [2.50, 97.50] (range: 95.00)\n\nBin Sizes:\n  Dimension 0: 5.00\n  Dimension 1: 5.00\n\nRegions: None\n\n</pre> In\u00a0[12]: Copied! <pre># Compare all approaches\nfig, axes = plt.subplots(2, 2, figsize=(16, 16))\naxes = axes.ravel()\n\nenvs = [\n    (env_default, \"Default (No operations)\"),\n    (env_dilated, \"Dilate only\"),\n    (env_filled, \"Fill holes only\"),\n    (env_combined, \"All operations combined\"),\n]\n\nfor ax, (env, title) in zip(axes, envs, strict=False):\n    env.plot(ax=ax, show_connectivity=True)\n\n    # Check connectivity\n    is_connected = nx.is_connected(env.connectivity)\n    status = \"\u2713 Connected\" if is_connected else \"\u2717 Disconnected\"\n\n    ax.set_title(f\"{title}\\n{env.n_bins} bins - {status}\")\n    ax.set_aspect(\"equal\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Compare all approaches fig, axes = plt.subplots(2, 2, figsize=(16, 16)) axes = axes.ravel()  envs = [     (env_default, \"Default (No operations)\"),     (env_dilated, \"Dilate only\"),     (env_filled, \"Fill holes only\"),     (env_combined, \"All operations combined\"), ]  for ax, (env, title) in zip(axes, envs, strict=False):     env.plot(ax=ax, show_connectivity=True)      # Check connectivity     is_connected = nx.is_connected(env.connectivity)     status = \"\u2713 Connected\" if is_connected else \"\u2717 Disconnected\"      ax.set_title(f\"{title}\\n{env.n_bins} bins - {status}\")     ax.set_aspect(\"equal\")  plt.tight_layout() plt.show() In\u00a0[13]: Copied! <pre># Compare different thresholds\nthresholds = [1, 5, 10]\nenv_thresholds = {}\n\nfor thresh in thresholds:\n    env = Environment.from_samples(\n        data_samples=sparse_data,\n        bin_size=5.0,\n        bin_count_threshold=thresh,\n        name=f\"Threshold_{thresh}\",\n    )\n    env_thresholds[thresh] = env\n    print(f\"Threshold = {thresh}: {env.n_bins} active bins\")\n</pre> # Compare different thresholds thresholds = [1, 5, 10] env_thresholds = {}  for thresh in thresholds:     env = Environment.from_samples(         data_samples=sparse_data,         bin_size=5.0,         bin_count_threshold=thresh,         name=f\"Threshold_{thresh}\",     )     env_thresholds[thresh] = env     print(f\"Threshold = {thresh}: {env.n_bins} active bins\") <pre>Threshold = 1: 248 active bins\nThreshold = 5: 172 active bins\nThreshold = 10: 100 active bins\n</pre> In\u00a0[14]: Copied! <pre># Visualize threshold effects\nfig, axes = plt.subplots(1, 3, figsize=(18, 6))\n\nfor ax, thresh in zip(axes, thresholds, strict=False):\n    env_thresholds[thresh].plot(ax=ax, show_connectivity=True)\n    ax.set_title(f\"Threshold = {thresh}\\n{env_thresholds[thresh].n_bins} bins\")\n    ax.set_aspect(\"equal\")\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nHigher thresholds remove bins with sparse sampling\")\nprint(\"Use this to focus on well-sampled regions only\")\n</pre> # Visualize threshold effects fig, axes = plt.subplots(1, 3, figsize=(18, 6))  for ax, thresh in zip(axes, thresholds, strict=False):     env_thresholds[thresh].plot(ax=ax, show_connectivity=True)     ax.set_title(f\"Threshold = {thresh}\\n{env_thresholds[thresh].n_bins} bins\")     ax.set_aspect(\"equal\")  plt.tight_layout() plt.show()  print(\"\\nHigher thresholds remove bins with sparse sampling\") print(\"Use this to focus on well-sampled regions only\") <pre>\nHigher thresholds remove bins with sparse sampling\nUse this to focus on well-sampled regions only\n</pre> In\u00a0[15]: Copied! <pre># Simulate neural spiking data correlated with position\ndef generate_place_cell_spikes(position, preferred_location, field_size=15.0):\n    \"\"\"\n    Generate spikes from a place cell with a preferred location.\n\n    Parameters\n    ----------\n    position : ndarray, shape (n_samples, 2)\n        Position trajectory.\n    preferred_location : array-like, shape (2,)\n        Center of place field.\n    field_size : float\n        Spatial scale of place field.\n\n    Returns\n    -------\n    spike_counts : ndarray, shape (n_samples,)\n        Number of spikes at each timepoint.\n    \"\"\"\n    distances = np.linalg.norm(position - preferred_location, axis=1)\n    firing_rate = 20.0 * np.exp(\n        -(distances**2) / (2 * field_size**2)\n    )  # Gaussian place field\n\n    # Poisson spiking\n    dt = 0.05  # 50 ms bins\n    spike_counts = np.random.poisson(firing_rate * dt)\n    return spike_counts\n\n\n# Create place cell centered in the arena\nplace_field_center = np.array([50.0, 50.0])\nspikes = generate_place_cell_spikes(sparse_data, place_field_center, field_size=20.0)\n\nprint(f\"Generated {spikes.sum()} total spikes\")\nprint(f\"Mean firing rate: {spikes.mean() / 0.05:.2f} Hz\")\n</pre> # Simulate neural spiking data correlated with position def generate_place_cell_spikes(position, preferred_location, field_size=15.0):     \"\"\"     Generate spikes from a place cell with a preferred location.      Parameters     ----------     position : ndarray, shape (n_samples, 2)         Position trajectory.     preferred_location : array-like, shape (2,)         Center of place field.     field_size : float         Spatial scale of place field.      Returns     -------     spike_counts : ndarray, shape (n_samples,)         Number of spikes at each timepoint.     \"\"\"     distances = np.linalg.norm(position - preferred_location, axis=1)     firing_rate = 20.0 * np.exp(         -(distances**2) / (2 * field_size**2)     )  # Gaussian place field      # Poisson spiking     dt = 0.05  # 50 ms bins     spike_counts = np.random.poisson(firing_rate * dt)     return spike_counts   # Create place cell centered in the arena place_field_center = np.array([50.0, 50.0]) spikes = generate_place_cell_spikes(sparse_data, place_field_center, field_size=20.0)  print(f\"Generated {spikes.sum()} total spikes\") print(f\"Mean firing rate: {spikes.mean() / 0.05:.2f} Hz\") <pre>Generated 421 total spikes\nMean firing rate: 2.95 Hz\n</pre> In\u00a0[16]: Copied! <pre># Map spikes to bins\nbin_indices = env_default.bin_at(sparse_data)\n\n# Count spikes per bin\nspike_counts_per_bin = np.bincount(\n    bin_indices[bin_indices &gt;= 0],\n    weights=spikes[bin_indices &gt;= 0],\n    minlength=env_default.n_bins,\n)\n\n# Count occupancy per bin (in seconds)\noccupancy_per_bin = (\n    np.bincount(bin_indices[bin_indices &gt;= 0], minlength=env_default.n_bins) * 0.05\n)  # 50 ms per sample\n\n# Compute firing rate (spikes / seconds)\n# Add small epsilon to avoid division by zero\nfiring_rate_map = np.divide(\n    spike_counts_per_bin,\n    occupancy_per_bin,\n    where=occupancy_per_bin &gt; 0,\n    out=np.zeros_like(spike_counts_per_bin, dtype=float),\n)\n\nprint(\n    f\"Bins with valid firing rates: {np.sum(firing_rate_map &gt; 0)} / {env_default.n_bins}\"\n)\nprint(f\"Peak firing rate: {firing_rate_map.max():.2f} Hz\")\nprint(\"\\nProblem: Center bins have no data (firing rate = 0)\")\n</pre> # Map spikes to bins bin_indices = env_default.bin_at(sparse_data)  # Count spikes per bin spike_counts_per_bin = np.bincount(     bin_indices[bin_indices &gt;= 0],     weights=spikes[bin_indices &gt;= 0],     minlength=env_default.n_bins, )  # Count occupancy per bin (in seconds) occupancy_per_bin = (     np.bincount(bin_indices[bin_indices &gt;= 0], minlength=env_default.n_bins) * 0.05 )  # 50 ms per sample  # Compute firing rate (spikes / seconds) # Add small epsilon to avoid division by zero firing_rate_map = np.divide(     spike_counts_per_bin,     occupancy_per_bin,     where=occupancy_per_bin &gt; 0,     out=np.zeros_like(spike_counts_per_bin, dtype=float), )  print(     f\"Bins with valid firing rates: {np.sum(firing_rate_map &gt; 0)} / {env_default.n_bins}\" ) print(f\"Peak firing rate: {firing_rate_map.max():.2f} Hz\") print(\"\\nProblem: Center bins have no data (firing rate = 0)\") <pre>Bins with valid firing rates: 162 / 270\nPeak firing rate: 40.00 Hz\n\nProblem: Center bins have no data (firing rate = 0)\n</pre> In\u00a0[17]: Copied! <pre># Visualize problematic firing rate map\nfig, ax = plt.subplots(figsize=(10, 10))\n\n# Only plot bins with data\nactive_bins = firing_rate_map &gt; 0\nscatter = ax.scatter(\n    env_default.bin_centers[active_bins, 0],\n    env_default.bin_centers[active_bins, 1],\n    c=firing_rate_map[active_bins],\n    s=300,\n    cmap=\"hot\",\n    marker=\"s\",\n    edgecolors=\"black\",\n    linewidth=0.5,\n)\n\n# Mark true place field center\nax.plot(\n    place_field_center[0],\n    place_field_center[1],\n    \"c*\",\n    markersize=30,\n    markeredgecolor=\"blue\",\n    markeredgewidth=2,\n    label=\"True place field center\",\n)\n\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(\"Firing Rate Map (Fragmented Environment)\\nMissing center bins!\")\nax.set_aspect(\"equal\")\nax.legend()\nplt.colorbar(scatter, ax=ax, label=\"Firing Rate (Hz)\")\nplt.tight_layout()\nplt.show()\n</pre> # Visualize problematic firing rate map fig, ax = plt.subplots(figsize=(10, 10))  # Only plot bins with data active_bins = firing_rate_map &gt; 0 scatter = ax.scatter(     env_default.bin_centers[active_bins, 0],     env_default.bin_centers[active_bins, 1],     c=firing_rate_map[active_bins],     s=300,     cmap=\"hot\",     marker=\"s\",     edgecolors=\"black\",     linewidth=0.5, )  # Mark true place field center ax.plot(     place_field_center[0],     place_field_center[1],     \"c*\",     markersize=30,     markeredgecolor=\"blue\",     markeredgewidth=2,     label=\"True place field center\", )  ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(\"Firing Rate Map (Fragmented Environment)\\nMissing center bins!\") ax.set_aspect(\"equal\") ax.legend() plt.colorbar(scatter, ax=ax, label=\"Firing Rate (Hz)\") plt.tight_layout() plt.show() In\u00a0[18]: Copied! <pre># Create fixed environment\nenv_fixed = Environment.from_samples(\n    data_samples=sparse_data, bin_size=5.0, dilate=True, fill_holes=True, name=\"Fixed\"\n)\n\nprint(f\"Fixed environment: {env_fixed.n_bins} bins\")\nprint(f\"Is connected: {nx.is_connected(env_fixed.connectivity)}\")\n\n# Recompute firing rate map\nbin_indices_fixed = env_fixed.bin_at(sparse_data)\n\nspike_counts_per_bin_fixed = np.bincount(\n    bin_indices_fixed[bin_indices_fixed &gt;= 0],\n    weights=spikes[bin_indices_fixed &gt;= 0],\n    minlength=env_fixed.n_bins,\n)\n\noccupancy_per_bin_fixed = (\n    np.bincount(bin_indices_fixed[bin_indices_fixed &gt;= 0], minlength=env_fixed.n_bins)\n    * 0.05\n)\n\nfiring_rate_map_fixed = np.divide(\n    spike_counts_per_bin_fixed,\n    occupancy_per_bin_fixed,\n    where=occupancy_per_bin_fixed &gt; 0,\n    out=np.zeros_like(spike_counts_per_bin_fixed, dtype=float),\n)\n\nprint(\n    f\"\\nBins with valid firing rates: {np.sum(firing_rate_map_fixed &gt; 0)} / {env_fixed.n_bins}\"\n)\n</pre> # Create fixed environment env_fixed = Environment.from_samples(     data_samples=sparse_data, bin_size=5.0, dilate=True, fill_holes=True, name=\"Fixed\" )  print(f\"Fixed environment: {env_fixed.n_bins} bins\") print(f\"Is connected: {nx.is_connected(env_fixed.connectivity)}\")  # Recompute firing rate map bin_indices_fixed = env_fixed.bin_at(sparse_data)  spike_counts_per_bin_fixed = np.bincount(     bin_indices_fixed[bin_indices_fixed &gt;= 0],     weights=spikes[bin_indices_fixed &gt;= 0],     minlength=env_fixed.n_bins, )  occupancy_per_bin_fixed = (     np.bincount(bin_indices_fixed[bin_indices_fixed &gt;= 0], minlength=env_fixed.n_bins)     * 0.05 )  firing_rate_map_fixed = np.divide(     spike_counts_per_bin_fixed,     occupancy_per_bin_fixed,     where=occupancy_per_bin_fixed &gt; 0,     out=np.zeros_like(spike_counts_per_bin_fixed, dtype=float), )  print(     f\"\\nBins with valid firing rates: {np.sum(firing_rate_map_fixed &gt; 0)} / {env_fixed.n_bins}\" ) <pre>Fixed environment: 315 bins\nIs connected: True\n\nBins with valid firing rates: 162 / 315\n</pre> In\u00a0[19]: Copied! <pre># Visualize fixed firing rate map\nfig, axes = plt.subplots(1, 2, figsize=(18, 8))\n\n# Before\nactive_bins = firing_rate_map &gt; 0\nscatter1 = axes[0].scatter(\n    env_default.bin_centers[active_bins, 0],\n    env_default.bin_centers[active_bins, 1],\n    c=firing_rate_map[active_bins],\n    s=300,\n    cmap=\"hot\",\n    vmin=0,\n    vmax=firing_rate_map.max(),\n    marker=\"s\",\n    edgecolors=\"black\",\n    linewidth=0.5,\n)\naxes[0].plot(\n    place_field_center[0],\n    place_field_center[1],\n    \"c*\",\n    markersize=30,\n    markeredgecolor=\"blue\",\n    markeredgewidth=2,\n)\naxes[0].set_title(\"Before: Fragmented\")\naxes[0].set_aspect(\"equal\")\naxes[0].set_xlabel(\"X position (cm)\")\naxes[0].set_ylabel(\"Y position (cm)\")\n\n# After\nactive_bins_fixed = firing_rate_map_fixed &gt; 0\nscatter2 = axes[1].scatter(\n    env_fixed.bin_centers[active_bins_fixed, 0],\n    env_fixed.bin_centers[active_bins_fixed, 1],\n    c=firing_rate_map_fixed[active_bins_fixed],\n    s=300,\n    cmap=\"hot\",\n    vmin=0,\n    vmax=firing_rate_map.max(),\n    marker=\"s\",\n    edgecolors=\"black\",\n    linewidth=0.5,\n)\naxes[1].plot(\n    place_field_center[0],\n    place_field_center[1],\n    \"c*\",\n    markersize=30,\n    markeredgecolor=\"blue\",\n    markeredgewidth=2,\n    label=\"True place field center\",\n)\naxes[1].set_title(\"After: Connected with morphological ops\")\naxes[1].set_aspect(\"equal\")\naxes[1].set_xlabel(\"X position (cm)\")\naxes[1].set_ylabel(\"Y position (cm)\")\naxes[1].legend()\n\nplt.colorbar(scatter2, ax=axes[1], label=\"Firing Rate (Hz)\")\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nFixed! Now we can see the complete place field\")\n</pre> # Visualize fixed firing rate map fig, axes = plt.subplots(1, 2, figsize=(18, 8))  # Before active_bins = firing_rate_map &gt; 0 scatter1 = axes[0].scatter(     env_default.bin_centers[active_bins, 0],     env_default.bin_centers[active_bins, 1],     c=firing_rate_map[active_bins],     s=300,     cmap=\"hot\",     vmin=0,     vmax=firing_rate_map.max(),     marker=\"s\",     edgecolors=\"black\",     linewidth=0.5, ) axes[0].plot(     place_field_center[0],     place_field_center[1],     \"c*\",     markersize=30,     markeredgecolor=\"blue\",     markeredgewidth=2, ) axes[0].set_title(\"Before: Fragmented\") axes[0].set_aspect(\"equal\") axes[0].set_xlabel(\"X position (cm)\") axes[0].set_ylabel(\"Y position (cm)\")  # After active_bins_fixed = firing_rate_map_fixed &gt; 0 scatter2 = axes[1].scatter(     env_fixed.bin_centers[active_bins_fixed, 0],     env_fixed.bin_centers[active_bins_fixed, 1],     c=firing_rate_map_fixed[active_bins_fixed],     s=300,     cmap=\"hot\",     vmin=0,     vmax=firing_rate_map.max(),     marker=\"s\",     edgecolors=\"black\",     linewidth=0.5, ) axes[1].plot(     place_field_center[0],     place_field_center[1],     \"c*\",     markersize=30,     markeredgecolor=\"blue\",     markeredgewidth=2,     label=\"True place field center\", ) axes[1].set_title(\"After: Connected with morphological ops\") axes[1].set_aspect(\"equal\") axes[1].set_xlabel(\"X position (cm)\") axes[1].set_ylabel(\"Y position (cm)\") axes[1].legend()  plt.colorbar(scatter2, ax=axes[1], label=\"Firing Rate (Hz)\") plt.tight_layout() plt.show()  print(\"\\nFixed! Now we can see the complete place field\") <pre>\nFixed! Now we can see the complete place field\n</pre> In\u00a0[20]: Copied! <pre># Multiple rounds of dilation\nenv_over_dilated = Environment.from_samples(\n    data_samples=sparse_data, bin_size=5.0, dilate=True, name=\"OverDilated\"\n)\n\n# Apply dilation multiple times manually (not recommended!)\n# This is just for demonstration\nprint(\"Warning: Don't dilate multiple times unless you have a good reason!\")\nprint(\"Morphological operations should be used conservatively.\")\n</pre> # Multiple rounds of dilation env_over_dilated = Environment.from_samples(     data_samples=sparse_data, bin_size=5.0, dilate=True, name=\"OverDilated\" )  # Apply dilation multiple times manually (not recommended!) # This is just for demonstration print(\"Warning: Don't dilate multiple times unless you have a good reason!\") print(\"Morphological operations should be used conservatively.\") <pre>Warning: Don't dilate multiple times unless you have a good reason!\nMorphological operations should be used conservatively.\n</pre> In\u00a0[21]: Copied! <pre>def check_environment_quality(env):\n    \"\"\"\n    Diagnostic function to check environment quality.\n\n    Parameters\n    ----------\n    env : Environment\n        Environment to check.\n    \"\"\"\n    print(f\"Environment: {env.name}\")\n    print(f\"  Total bins: {env.n_bins}\")\n    print(f\"  Total edges: {env.connectivity.number_of_edges()}\")\n\n    is_connected = nx.is_connected(env.connectivity)\n    print(f\"  Connected: {is_connected}\")\n\n    if not is_connected:\n        components = list(nx.connected_components(env.connectivity))\n        print(f\"  WARNING: {len(components)} disconnected components!\")\n        print(f\"  Largest component: {len(max(components, key=len))} bins\")\n\n    print()\n\n\n# Check all our environments\ncheck_environment_quality(env_default)\ncheck_environment_quality(env_fixed)\n</pre> def check_environment_quality(env):     \"\"\"     Diagnostic function to check environment quality.      Parameters     ----------     env : Environment         Environment to check.     \"\"\"     print(f\"Environment: {env.name}\")     print(f\"  Total bins: {env.n_bins}\")     print(f\"  Total edges: {env.connectivity.number_of_edges()}\")      is_connected = nx.is_connected(env.connectivity)     print(f\"  Connected: {is_connected}\")      if not is_connected:         components = list(nx.connected_components(env.connectivity))         print(f\"  WARNING: {len(components)} disconnected components!\")         print(f\"  Largest component: {len(max(components, key=len))} bins\")      print()   # Check all our environments check_environment_quality(env_default) check_environment_quality(env_fixed) <pre>Environment: Default_Sparse\n  Total bins: 270\n  Total edges: 912\n  Connected: True\n\nEnvironment: Fixed\n  Total bins: 315\n  Total edges: 1128\n  Connected: True\n\n</pre>"},{"location":"examples/03_morphological_operations/#morphological-operations-handling-sparse-and-patchy-data","title":"Morphological Operations: Handling Sparse and Patchy Data\u00b6","text":""},{"location":"examples/03_morphological_operations/#learning-objectives","title":"Learning Objectives\u00b6","text":"<p>By the end of this notebook, you will be able to:</p> <ul> <li>Understand why sparse data creates problems for spatial analysis</li> <li>Use morphological operations (dilate, fill_holes, close_gaps) to improve connectivity</li> <li>Control active bin inference with <code>bin_count_threshold</code></li> <li>Diagnose and fix common issues with real-world position tracking data</li> <li>Make informed decisions about when to use morphological operations</li> </ul> <p>Estimated time: 20-30 minutes</p>"},{"location":"examples/03_morphological_operations/#the-problem-real-data-is-messy","title":"The Problem: Real Data is Messy\u00b6","text":"<p>In notebook 01, we worked with clean, uniformly sampled position data. But real experimental data is often:</p> <ul> <li>Sparse: Animals don't visit all locations equally</li> <li>Patchy: Tracking can fail briefly, creating gaps</li> <li>Biased: Animals prefer certain regions (edges, corners, goal locations)</li> <li>Noisy: Position estimates can be inaccurate or have outliers</li> </ul> <p>These issues can fragment your environment into disconnected regions, making spatial analysis difficult or impossible.</p> <p>This notebook shows you how to handle these challenges!</p>"},{"location":"examples/03_morphological_operations/#setup","title":"Setup\u00b6","text":""},{"location":"examples/03_morphological_operations/#creating-realistic-sparse-data","title":"Creating Realistic Sparse Data\u00b6","text":"<p>Let's simulate what real position tracking often looks like: an animal that prefers certain regions and avoids others.</p>"},{"location":"examples/03_morphological_operations/#problem-1-fragmented-environment","title":"Problem 1: Fragmented Environment\u00b6","text":"<p>What happens when we create an environment from this sparse data using default settings?</p>"},{"location":"examples/03_morphological_operations/#checking-connectivity","title":"Checking Connectivity\u00b6","text":"<p>Let's verify that the environment is indeed disconnected:</p>"},{"location":"examples/03_morphological_operations/#solution-1-morphological-dilation","title":"Solution 1: Morphological Dilation\u00b6","text":"<p>Dilation expands active regions by adding neighboring bins. This fills small gaps and connects nearby fragments.</p> <p>Think of it like inflating the active region slightly.</p>"},{"location":"examples/03_morphological_operations/#solution-2-filling-holes","title":"Solution 2: Filling Holes\u00b6","text":"<p>Fill holes fills in completely enclosed inactive regions. This is useful when an animal briefly crosses an area but doesn't sample it well enough to activate all bins.</p>"},{"location":"examples/03_morphological_operations/#solution-3-closing-gaps","title":"Solution 3: Closing Gaps\u00b6","text":"<p>Close gaps performs dilation followed by erosion (shrinking). This connects nearby regions while preserving the overall shape better than dilation alone.</p> <p>Think of it as: expand -&gt; connect -&gt; shrink back to original size.</p>"},{"location":"examples/03_morphological_operations/#combining-multiple-operations","title":"Combining Multiple Operations\u00b6","text":"<p>For very sparse data, you can combine multiple morphological operations:</p>"},{"location":"examples/03_morphological_operations/#solution-4-adjusting-bin_count_threshold","title":"Solution 4: Adjusting bin_count_threshold\u00b6","text":"<p>By default, a bin needs at least 1 sample to be considered active. You can adjust this threshold to:</p> <ul> <li>Lower threshold (&lt; 1): Include bins with sparse sampling</li> <li>Higher threshold (&gt; 1): Require more samples for robust estimates</li> </ul> <p>Note: <code>bin_count_threshold</code> is applied BEFORE morphological operations.</p>"},{"location":"examples/03_morphological_operations/#practical-example-fixing-a-real-analysis-pipeline","title":"Practical Example: Fixing a Real Analysis Pipeline\u00b6","text":"<p>Let's simulate a complete analysis workflow where sparse data causes problems, then fix it.</p>"},{"location":"examples/03_morphological_operations/#problem-computing-spatial-firing-rate-map","title":"Problem: Computing Spatial Firing Rate Map\u00b6","text":"<p>With the fragmented default environment, we can't compute rates for center bins:</p>"},{"location":"examples/03_morphological_operations/#solution-use-morphological-operations","title":"Solution: Use Morphological Operations\u00b6","text":"<p>Now let's fix this by creating a properly connected environment:</p>"},{"location":"examples/03_morphological_operations/#when-to-use-each-operation","title":"When to Use Each Operation\u00b6","text":"<p>Here's a decision guide:</p> Operation Use When Effect Caution dilate Sparse sampling, need connectivity Expands active regions by 1 bin Adds bins where animal never went fill_holes Animal crosses regions quickly Fills enclosed gaps Only affects interior holes close_gaps Need to connect nearby fragments Connects then shrinks Better shape preservation than dilate bin_count_threshold Very sparse data or need robust estimates Removes bins with few samples May fragment more <p>General recommendation:</p> <ol> <li>Start without morphological operations</li> <li>Check if environment is connected (use <code>networkx.is_connected()</code>)</li> <li>If fragmented, try <code>dilate=True</code> first</li> <li>If still fragmented, add <code>fill_holes=True</code></li> <li>Only use higher <code>bin_count_threshold</code> if you need very robust estimates</li> </ol>"},{"location":"examples/03_morphological_operations/#common-pitfalls","title":"Common Pitfalls\u00b6","text":""},{"location":"examples/03_morphological_operations/#pitfall-1-over-dilation","title":"Pitfall 1: Over-dilation\u00b6","text":"<p>Too much dilation can create bins far from actual data:</p>"},{"location":"examples/03_morphological_operations/#pitfall-2-wrong-operation-order","title":"Pitfall 2: Wrong operation order\u00b6","text":"<p>Operations are applied in this order:</p> <ol> <li>bin_count_threshold (determines initial active bins)</li> <li>dilate</li> <li>fill_holes</li> <li>close_gaps</li> </ol> <p>This order matters for the final result!</p>"},{"location":"examples/03_morphological_operations/#pitfall-3-forgetting-to-check-connectivity","title":"Pitfall 3: Forgetting to check connectivity\u00b6","text":"<p>Always verify your environment is connected before computing spatial paths or distances:</p>"},{"location":"examples/03_morphological_operations/#pitfall-4-not-considering-the-trade-off","title":"Pitfall 4: Not considering the trade-off\u00b6","text":"<p>Morphological operations make connectivity better but:</p> <ul> <li>Add bins where the animal never went</li> <li>Can't compute occupancy-normalized rates for these bins</li> <li>May artificially smooth spatial patterns</li> </ul> <p>Best practice: Use morphological operations to establish connectivity, but mark these bins in your analysis and interpret carefully.</p>"},{"location":"examples/03_morphological_operations/#key-takeaways","title":"Key Takeaways\u00b6","text":"<ol> <li>Real data is sparse - Animals don't sample uniformly, tracking can fail</li> <li>Fragmentation breaks analyses - Disconnected environments can't compute paths or distances</li> <li>Morphological operations fix connectivity:<ul> <li><code>dilate=True</code> - Expand active regions</li> <li><code>fill_holes=True</code> - Fill enclosed gaps</li> <li><code>close_gaps=True</code> - Connect nearby fragments</li> </ul> </li> <li>bin_count_threshold - Control minimum samples needed per bin</li> <li>Always check connectivity - Use <code>networkx.is_connected()</code> to verify</li> <li>Trade-offs exist - More connectivity = more artificial bins</li> <li>Use conservatively - Start minimal, add operations only if needed</li> </ol>"},{"location":"examples/03_morphological_operations/#next-steps","title":"Next Steps\u00b6","text":"<p>In the next notebook (04_regions_of_interest.ipynb), you'll learn:</p> <ul> <li>How to define named regions (goal locations, reward zones)</li> <li>Point vs polygon regions</li> <li>Querying spatial relationships</li> <li>Saving and loading region definitions</li> </ul>"},{"location":"examples/03_morphological_operations/#exercises-optional","title":"Exercises (Optional)\u00b6","text":"<ol> <li>Create extremely sparse data (remove 90% of samples) and find the minimal morphological operations needed</li> <li>Compare firing rate maps with and without morphological operations</li> <li>Find the optimal <code>bin_count_threshold</code> that gives you a connected environment</li> <li>Create a diagnostic function that recommends which operations to use</li> </ol>"},{"location":"examples/04_regions_of_interest/","title":"Regions of Interest: Defining and Managing Spatial Regions","text":"In\u00a0[1]: Copied! <pre>import os\nimport tempfile\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import Polygon as MPLPolygon\nfrom shapely.geometry import Point, Polygon\n\nfrom neurospatial import Environment\nfrom neurospatial.regions import Regions\n\nnp.random.seed(42)\nplt.rcParams[\"figure.figsize\"] = (12, 10)\nplt.rcParams[\"font.size\"] = 11\n</pre> import os import tempfile from pathlib import Path  import matplotlib.pyplot as plt import numpy as np from matplotlib.patches import Polygon as MPLPolygon from shapely.geometry import Point, Polygon  from neurospatial import Environment from neurospatial.regions import Regions  np.random.seed(42) plt.rcParams[\"figure.figsize\"] = (12, 10) plt.rcParams[\"font.size\"] = 11 In\u00a0[2]: Copied! <pre># Create circular water maze (120 cm diameter)\nmaze_center = Point(60, 60)\nmaze_radius = 60.0\nmaze_boundary = maze_center.buffer(maze_radius)\n\n# Generate position data - animal searching for platform\nn_samples = 2000\n\n# Start from random edge locations (simulating starting positions)\nstart_angles = np.random.choice([0, 90, 180, 270], size=n_samples)\nangles = np.deg2rad(start_angles + np.random.randn(n_samples) * 10)\n\n# Create trajectory that gradually moves toward platform location (SW quadrant)\nposition_data = np.zeros((n_samples, 2))\nposition_data[0] = [\n    60 + maze_radius * 0.9 * np.cos(angles[0]),\n    60 + maze_radius * 0.9 * np.sin(angles[0]),\n]\n\nplatform_location = np.array([30.0, 30.0])  # SW quadrant\n\nfor t in range(1, n_samples):\n    # Random walk with bias toward platform\n    to_platform = platform_location - position_data[t - 1]\n    distance_to_platform = np.linalg.norm(to_platform)\n\n    if distance_to_platform &gt; 10:  # If far from platform\n        # Weak attraction to platform + noise\n        step = to_platform * 0.05 + np.random.randn(2) * 3.0\n    else:  # Near platform - circle around it\n        step = np.random.randn(2) * 1.0\n\n    position_data[t] = position_data[t - 1] + step\n\n    # Enforce circular boundary\n    dist_from_center = np.linalg.norm(position_data[t] - np.array([60, 60]))\n    if dist_from_center &gt; maze_radius:\n        # Bounce off wall\n        direction = (position_data[t] - np.array([60, 60])) / dist_from_center\n        position_data[t] = np.array([60, 60]) + direction * (maze_radius - 1)\n\nprint(f\"Generated {len(position_data)} position samples\")\nprint(f\"Arena: {maze_radius * 2:.0f} cm diameter circular water maze\")\n</pre> # Create circular water maze (120 cm diameter) maze_center = Point(60, 60) maze_radius = 60.0 maze_boundary = maze_center.buffer(maze_radius)  # Generate position data - animal searching for platform n_samples = 2000  # Start from random edge locations (simulating starting positions) start_angles = np.random.choice([0, 90, 180, 270], size=n_samples) angles = np.deg2rad(start_angles + np.random.randn(n_samples) * 10)  # Create trajectory that gradually moves toward platform location (SW quadrant) position_data = np.zeros((n_samples, 2)) position_data[0] = [     60 + maze_radius * 0.9 * np.cos(angles[0]),     60 + maze_radius * 0.9 * np.sin(angles[0]), ]  platform_location = np.array([30.0, 30.0])  # SW quadrant  for t in range(1, n_samples):     # Random walk with bias toward platform     to_platform = platform_location - position_data[t - 1]     distance_to_platform = np.linalg.norm(to_platform)      if distance_to_platform &gt; 10:  # If far from platform         # Weak attraction to platform + noise         step = to_platform * 0.05 + np.random.randn(2) * 3.0     else:  # Near platform - circle around it         step = np.random.randn(2) * 1.0      position_data[t] = position_data[t - 1] + step      # Enforce circular boundary     dist_from_center = np.linalg.norm(position_data[t] - np.array([60, 60]))     if dist_from_center &gt; maze_radius:         # Bounce off wall         direction = (position_data[t] - np.array([60, 60])) / dist_from_center         position_data[t] = np.array([60, 60]) + direction * (maze_radius - 1)  print(f\"Generated {len(position_data)} position samples\") print(f\"Arena: {maze_radius * 2:.0f} cm diameter circular water maze\") <pre>Generated 2000 position samples\nArena: 120 cm diameter circular water maze\n</pre> In\u00a0[3]: Copied! <pre># Create environment\nenv = Environment.from_polygon(polygon=maze_boundary, bin_size=6.0, name=\"WaterMaze\")\n\nprint(env.info())\n</pre> # Create environment env = Environment.from_polygon(polygon=maze_boundary, bin_size=6.0, name=\"WaterMaze\")  print(env.info()) <pre>Environment Information\n=======================\n\nName: WaterMaze\nLayout Type: ShapelyPolygon\nDimensions: 2\nNumber of Bins: 316\n\nSpatial Extent:\n  Dimension 0: [0.00, 120.00] (range: 120.00)\n  Dimension 1: [0.00, 120.00] (range: 120.00)\n\nBin Sizes:\n  Dimension 0: 6.00\n  Dimension 1: 6.00\n\nRegions: None\n\n</pre> In\u00a0[4]: Copied! <pre># Visualize trajectory\nfig, ax = plt.subplots(figsize=(10, 10))\n\n# Plot environment\nenv.plot(ax=ax, show_connectivity=False)\n\n# Plot trajectory\nax.plot(\n    position_data[:, 0],\n    position_data[:, 1],\n    \"gray\",\n    alpha=0.3,\n    linewidth=0.5,\n    label=\"Trajectory\",\n)\nax.scatter(\n    position_data[:, 0],\n    position_data[:, 1],\n    c=np.arange(len(position_data)),\n    cmap=\"viridis\",\n    s=1,\n    alpha=0.5,\n)\n\n# Mark start and end\nax.plot(\n    position_data[0, 0],\n    position_data[0, 1],\n    \"go\",\n    markersize=15,\n    label=\"Start\",\n    markeredgecolor=\"black\",\n    markeredgewidth=2,\n)\nax.plot(\n    position_data[-1, 0],\n    position_data[-1, 1],\n    \"ro\",\n    markersize=15,\n    label=\"End\",\n    markeredgecolor=\"black\",\n    markeredgewidth=2,\n)\n\nax.set_title(\"Water Maze Trajectory\")\nax.set_aspect(\"equal\")\nax.legend()\nplt.tight_layout()\nplt.show()\n</pre> # Visualize trajectory fig, ax = plt.subplots(figsize=(10, 10))  # Plot environment env.plot(ax=ax, show_connectivity=False)  # Plot trajectory ax.plot(     position_data[:, 0],     position_data[:, 1],     \"gray\",     alpha=0.3,     linewidth=0.5,     label=\"Trajectory\", ) ax.scatter(     position_data[:, 0],     position_data[:, 1],     c=np.arange(len(position_data)),     cmap=\"viridis\",     s=1,     alpha=0.5, )  # Mark start and end ax.plot(     position_data[0, 0],     position_data[0, 1],     \"go\",     markersize=15,     label=\"Start\",     markeredgecolor=\"black\",     markeredgewidth=2, ) ax.plot(     position_data[-1, 0],     position_data[-1, 1],     \"ro\",     markersize=15,     label=\"End\",     markeredgecolor=\"black\",     markeredgewidth=2, )  ax.set_title(\"Water Maze Trajectory\") ax.set_aspect(\"equal\") ax.legend() plt.tight_layout() plt.show() In\u00a0[5]: Copied! <pre># Add the platform region\nenv.regions.add(\"platform\", point=platform_location, metadata={\"color\": \"red\"})\n\n# Check what regions exist\nprint(f\"Regions in environment: {list(env.regions.keys())}\")\nprint(f\"Number of regions: {len(env.regions)}\")\n\n# Access a specific region\nplatform = env.regions[\"platform\"]\nprint(f\"\\nPlatform region: {platform}\")\n</pre> # Add the platform region env.regions.add(\"platform\", point=platform_location, metadata={\"color\": \"red\"})  # Check what regions exist print(f\"Regions in environment: {list(env.regions.keys())}\") print(f\"Number of regions: {len(env.regions)}\")  # Access a specific region platform = env.regions[\"platform\"] print(f\"\\nPlatform region: {platform}\") <pre>Regions in environment: ['platform']\nNumber of regions: 1\n\nPlatform region: platform\n</pre> In\u00a0[6]: Copied! <pre># Define start positions around the edge\nstart_positions = {\n    \"start_north\": np.array([60.0, 110.0]),\n    \"start_east\": np.array([110.0, 60.0]),\n    \"start_south\": np.array([60.0, 10.0]),\n    \"start_west\": np.array([10.0, 60.0]),\n}\n\n# Add all start positions\nfor name, point in start_positions.items():\n    env.regions.add(name, point=point, metadata={\"color\": \"green\"})\n\nprint(f\"Total regions: {len(env.regions)}\")\nprint(f\"Region names: {list(env.regions.keys())}\")\n</pre> # Define start positions around the edge start_positions = {     \"start_north\": np.array([60.0, 110.0]),     \"start_east\": np.array([110.0, 60.0]),     \"start_south\": np.array([60.0, 10.0]),     \"start_west\": np.array([10.0, 60.0]), }  # Add all start positions for name, point in start_positions.items():     env.regions.add(name, point=point, metadata={\"color\": \"green\"})  print(f\"Total regions: {len(env.regions)}\") print(f\"Region names: {list(env.regions.keys())}\") <pre>Total regions: 5\nRegion names: ['platform', 'start_north', 'start_east', 'start_south', 'start_west']\n</pre> In\u00a0[7]: Copied! <pre># Plot environment with regions\nfig, ax = plt.subplots(figsize=(11, 11))\n\n# Plot environment\nenv.plot(ax=ax, show_connectivity=False)\n\n# Plot regions\nfor region_name, region in env.regions.items():\n    if region.kind == \"point\":\n        marker = \"*\" if \"platform\" in region_name else \"o\"\n        size = 400 if \"platform\" in region_name else 250\n        color = region.metadata.get(\"color\", \"blue\") if region.metadata else \"blue\"\n        ax.scatter(\n            region.data[0],\n            region.data[1],\n            c=color,\n            s=size,\n            marker=marker,\n            edgecolors=\"black\",\n            linewidth=2,\n            label=region_name,\n            zorder=10,\n        )\n        # Add text label\n        ax.text(\n            region.data[0],\n            region.data[1] - 8,\n            region_name.replace(\"_\", \"\\n\"),\n            ha=\"center\",\n            fontsize=9,\n            fontweight=\"bold\",\n        )\n\nax.set_title(\"Water Maze with Regions of Interest\")\nax.set_aspect(\"equal\")\nax.legend(loc=\"upper left\", fontsize=9)\nplt.tight_layout()\nplt.show()\n</pre> # Plot environment with regions fig, ax = plt.subplots(figsize=(11, 11))  # Plot environment env.plot(ax=ax, show_connectivity=False)  # Plot regions for region_name, region in env.regions.items():     if region.kind == \"point\":         marker = \"*\" if \"platform\" in region_name else \"o\"         size = 400 if \"platform\" in region_name else 250         color = region.metadata.get(\"color\", \"blue\") if region.metadata else \"blue\"         ax.scatter(             region.data[0],             region.data[1],             c=color,             s=size,             marker=marker,             edgecolors=\"black\",             linewidth=2,             label=region_name,             zorder=10,         )         # Add text label         ax.text(             region.data[0],             region.data[1] - 8,             region_name.replace(\"_\", \"\\n\"),             ha=\"center\",             fontsize=9,             fontweight=\"bold\",         )  ax.set_title(\"Water Maze with Regions of Interest\") ax.set_aspect(\"equal\") ax.legend(loc=\"upper left\", fontsize=9) plt.tight_layout() plt.show() In\u00a0[8]: Copied! <pre># Define quadrants as simple box polygons\nnw_quadrant = Polygon([(60, 60), (60, 120), (0, 120), (0, 60), (60, 60)])\nne_quadrant = Polygon([(60, 60), (120, 60), (120, 120), (60, 120), (60, 60)])\nsw_quadrant = Polygon([(60, 60), (0, 60), (0, 0), (60, 0), (60, 60)])\nse_quadrant = Polygon([(60, 60), (60, 0), (120, 0), (120, 60), (60, 60)])\n\n# Intersect with maze boundary to get actual quadrants\nnw_zone = maze_boundary.intersection(nw_quadrant)\nne_zone = maze_boundary.intersection(ne_quadrant)\nsw_zone = maze_boundary.intersection(sw_quadrant)\nse_zone = maze_boundary.intersection(se_quadrant)\n\n# Add quadrant regions\nenv.regions.add(\"quadrant_NW\", polygon=nw_zone, metadata={\"color\": \"lightblue\"})\nenv.regions.add(\"quadrant_NE\", polygon=ne_zone, metadata={\"color\": \"lightgreen\"})\nenv.regions.add(\"quadrant_SW\", polygon=sw_zone, metadata={\"color\": \"lightcoral\"})\nenv.regions.add(\"quadrant_SE\", polygon=se_zone, metadata={\"color\": \"lightyellow\"})\n\nprint(f\"Total regions: {len(env.regions)}\")\nprint(\n    f\"Polygon regions: {[name for name, r in env.regions.items() if r.kind == 'polygon']}\"\n)\n</pre> # Define quadrants as simple box polygons nw_quadrant = Polygon([(60, 60), (60, 120), (0, 120), (0, 60), (60, 60)]) ne_quadrant = Polygon([(60, 60), (120, 60), (120, 120), (60, 120), (60, 60)]) sw_quadrant = Polygon([(60, 60), (0, 60), (0, 0), (60, 0), (60, 60)]) se_quadrant = Polygon([(60, 60), (60, 0), (120, 0), (120, 60), (60, 60)])  # Intersect with maze boundary to get actual quadrants nw_zone = maze_boundary.intersection(nw_quadrant) ne_zone = maze_boundary.intersection(ne_quadrant) sw_zone = maze_boundary.intersection(sw_quadrant) se_zone = maze_boundary.intersection(se_quadrant)  # Add quadrant regions env.regions.add(\"quadrant_NW\", polygon=nw_zone, metadata={\"color\": \"lightblue\"}) env.regions.add(\"quadrant_NE\", polygon=ne_zone, metadata={\"color\": \"lightgreen\"}) env.regions.add(\"quadrant_SW\", polygon=sw_zone, metadata={\"color\": \"lightcoral\"}) env.regions.add(\"quadrant_SE\", polygon=se_zone, metadata={\"color\": \"lightyellow\"})  print(f\"Total regions: {len(env.regions)}\") print(     f\"Polygon regions: {[name for name, r in env.regions.items() if r.kind == 'polygon']}\" ) <pre>Total regions: 9\nPolygon regions: ['quadrant_NW', 'quadrant_NE', 'quadrant_SW', 'quadrant_SE']\n</pre> In\u00a0[9]: Copied! <pre># Visualize quadrants\nfig, ax = plt.subplots(figsize=(11, 11))\n\n# Plot environment\nenv.plot(ax=ax, show_connectivity=False)\n\n# Plot polygon regions first\nfor region_name, region in env.regions.items():\n    if region.kind == \"polygon\" and region.data.geom_type == \"Polygon\":\n        coords = np.array(region.data.exterior.coords)\n        color = (\n            region.metadata.get(\"color\", \"lightblue\")\n            if region.metadata\n            else \"lightblue\"\n        )\n        patch = MPLPolygon(\n            coords,\n            facecolor=color,\n            alpha=0.3,\n            edgecolor=\"black\",\n            linewidth=2,\n            label=region_name,\n        )\n        ax.add_patch(patch)\n\n# Plot point regions on top\nfor region_name, region in env.regions.items():\n    if region.kind == \"point\":\n        marker = \"*\" if \"platform\" in region_name else \"o\"\n        size = 400 if \"platform\" in region_name else 250\n        color = region.metadata.get(\"color\", \"blue\") if region.metadata else \"blue\"\n        ax.scatter(\n            region.data[0],\n            region.data[1],\n            c=color,\n            s=size,\n            marker=marker,\n            edgecolors=\"black\",\n            linewidth=2,\n            zorder=10,\n        )\n\nax.set_title(\"Water Maze with Quadrants\")\nax.set_aspect(\"equal\")\nax.legend(loc=\"upper left\", fontsize=8, ncol=2)\nplt.tight_layout()\nplt.show()\n</pre> # Visualize quadrants fig, ax = plt.subplots(figsize=(11, 11))  # Plot environment env.plot(ax=ax, show_connectivity=False)  # Plot polygon regions first for region_name, region in env.regions.items():     if region.kind == \"polygon\" and region.data.geom_type == \"Polygon\":         coords = np.array(region.data.exterior.coords)         color = (             region.metadata.get(\"color\", \"lightblue\")             if region.metadata             else \"lightblue\"         )         patch = MPLPolygon(             coords,             facecolor=color,             alpha=0.3,             edgecolor=\"black\",             linewidth=2,             label=region_name,         )         ax.add_patch(patch)  # Plot point regions on top for region_name, region in env.regions.items():     if region.kind == \"point\":         marker = \"*\" if \"platform\" in region_name else \"o\"         size = 400 if \"platform\" in region_name else 250         color = region.metadata.get(\"color\", \"blue\") if region.metadata else \"blue\"         ax.scatter(             region.data[0],             region.data[1],             c=color,             s=size,             marker=marker,             edgecolors=\"black\",             linewidth=2,             zorder=10,         )  ax.set_title(\"Water Maze with Quadrants\") ax.set_aspect(\"equal\") ax.legend(loc=\"upper left\", fontsize=8, ncol=2) plt.tight_layout() plt.show() In\u00a0[10]: Copied! <pre># Get bins in target quadrant\ntarget_quadrant = env.regions[\"quadrant_SW\"]\n\n# Find which bins are in this region\nbins_in_target = []\nfor bin_idx in range(env.n_bins):\n    bin_center = env.bin_centers[bin_idx]\n    point = Point(bin_center[0], bin_center[1])\n    if target_quadrant.data.contains(point):\n        bins_in_target.append(bin_idx)\n\nprint(f\"Bins in target quadrant (SW): {len(bins_in_target)} / {env.n_bins} total\")\nprint(f\"Percentage: {len(bins_in_target) / env.n_bins * 100:.1f}%\")\n</pre> # Get bins in target quadrant target_quadrant = env.regions[\"quadrant_SW\"]  # Find which bins are in this region bins_in_target = [] for bin_idx in range(env.n_bins):     bin_center = env.bin_centers[bin_idx]     point = Point(bin_center[0], bin_center[1])     if target_quadrant.data.contains(point):         bins_in_target.append(bin_idx)  print(f\"Bins in target quadrant (SW): {len(bins_in_target)} / {env.n_bins} total\") print(f\"Percentage: {len(bins_in_target) / env.n_bins * 100:.1f}%\") <pre>Bins in target quadrant (SW): 79 / 316 total\nPercentage: 25.0%\n</pre> In\u00a0[11]: Copied! <pre># Compute time in each quadrant\ndt = 0.05  # 50 ms per sample\n\nquadrant_names = [\"quadrant_NW\", \"quadrant_NE\", \"quadrant_SW\", \"quadrant_SE\"]\ntime_in_zone = {}\n\nfor quad_name in quadrant_names:\n    quad_polygon = env.regions[quad_name].data\n\n    # Check which samples are in this quadrant\n    samples_in_quad = 0\n    for pos in position_data:\n        point = Point(pos[0], pos[1])\n        if quad_polygon.contains(point):\n            samples_in_quad += 1\n\n    time_in_zone[quad_name] = samples_in_quad * dt\n    print(\n        f\"{quad_name}: {time_in_zone[quad_name]:.1f} seconds ({samples_in_quad} samples)\"\n    )\n\ntotal_time = sum(time_in_zone.values())\nprint(f\"\\nTotal time: {total_time:.1f} seconds\")\n\n# Check if animal learned\ntarget_time = time_in_zone[\"quadrant_SW\"]\ntarget_percentage = target_time / total_time * 100\nprint(f\"\\nTime in target quadrant: {target_percentage:.1f}%\")\nprint(\"Chance level: 25%\")\nif target_percentage &gt; 35:\n    print(\"Result: Animal shows spatial memory!\")\nelse:\n    print(\"Result: No clear preference yet\")\n</pre> # Compute time in each quadrant dt = 0.05  # 50 ms per sample  quadrant_names = [\"quadrant_NW\", \"quadrant_NE\", \"quadrant_SW\", \"quadrant_SE\"] time_in_zone = {}  for quad_name in quadrant_names:     quad_polygon = env.regions[quad_name].data      # Check which samples are in this quadrant     samples_in_quad = 0     for pos in position_data:         point = Point(pos[0], pos[1])         if quad_polygon.contains(point):             samples_in_quad += 1      time_in_zone[quad_name] = samples_in_quad * dt     print(         f\"{quad_name}: {time_in_zone[quad_name]:.1f} seconds ({samples_in_quad} samples)\"     )  total_time = sum(time_in_zone.values()) print(f\"\\nTotal time: {total_time:.1f} seconds\")  # Check if animal learned target_time = time_in_zone[\"quadrant_SW\"] target_percentage = target_time / total_time * 100 print(f\"\\nTime in target quadrant: {target_percentage:.1f}%\") print(\"Chance level: 25%\") if target_percentage &gt; 35:     print(\"Result: Animal shows spatial memory!\") else:     print(\"Result: No clear preference yet\") <pre>quadrant_NW: 0.0 seconds (0 samples)\nquadrant_NE: 0.0 seconds (0 samples)\nquadrant_SW: 100.0 seconds (2000 samples)\nquadrant_SE: 0.0 seconds (0 samples)\n\nTotal time: 100.0 seconds\n\nTime in target quadrant: 100.0%\nChance level: 25%\nResult: Animal shows spatial memory!\n</pre> In\u00a0[12]: Copied! <pre># Visualize time in zone\nfig, ax = plt.subplots(figsize=(10, 6))\n\ncolors = [\"lightblue\", \"lightgreen\", \"lightcoral\", \"lightyellow\"]\nquadrant_labels = [\"NW\", \"NE\", \"SW (Target)\", \"SE\"]\ntimes = [time_in_zone[name] for name in quadrant_names]\n\nbars = ax.bar(quadrant_labels, times, color=colors, edgecolor=\"black\", linewidth=2)\n\n# Add chance level line\nax.axhline(\n    total_time / 4, color=\"red\", linestyle=\"--\", linewidth=2, label=\"Chance (25%)\"\n)\n\nax.set_ylabel(\"Time (seconds)\")\nax.set_title(\"Time Spent in Each Quadrant\")\nax.legend()\nax.grid(axis=\"y\", alpha=0.3)\n\n# Add percentage labels on bars\nfor bar, time in zip(bars, times, strict=False):\n    height = bar.get_height()\n    ax.text(\n        bar.get_x() + bar.get_width() / 2.0,\n        height,\n        f\"{time / total_time * 100:.1f}%\",\n        ha=\"center\",\n        va=\"bottom\",\n        fontweight=\"bold\",\n    )\n\nplt.tight_layout()\nplt.show()\n</pre> # Visualize time in zone fig, ax = plt.subplots(figsize=(10, 6))  colors = [\"lightblue\", \"lightgreen\", \"lightcoral\", \"lightyellow\"] quadrant_labels = [\"NW\", \"NE\", \"SW (Target)\", \"SE\"] times = [time_in_zone[name] for name in quadrant_names]  bars = ax.bar(quadrant_labels, times, color=colors, edgecolor=\"black\", linewidth=2)  # Add chance level line ax.axhline(     total_time / 4, color=\"red\", linestyle=\"--\", linewidth=2, label=\"Chance (25%)\" )  ax.set_ylabel(\"Time (seconds)\") ax.set_title(\"Time Spent in Each Quadrant\") ax.legend() ax.grid(axis=\"y\", alpha=0.3)  # Add percentage labels on bars for bar, time in zip(bars, times, strict=False):     height = bar.get_height()     ax.text(         bar.get_x() + bar.get_width() / 2.0,         height,         f\"{time / total_time * 100:.1f}%\",         ha=\"center\",         va=\"bottom\",         fontweight=\"bold\",     )  plt.tight_layout() plt.show() In\u00a0[13]: Copied! <pre># Compute distance from each bin to platform\nplatform_point = env.regions[\"platform\"].data\n\ndistances_to_platform = np.zeros(env.n_bins)\nfor bin_idx in range(env.n_bins):\n    bin_center = env.bin_centers[bin_idx]\n    distances_to_platform[bin_idx] = np.linalg.norm(bin_center - platform_point)\n\nprint(f\"Min distance to platform: {distances_to_platform.min():.1f} cm\")\nprint(f\"Max distance to platform: {distances_to_platform.max():.1f} cm\")\nprint(f\"Mean distance to platform: {distances_to_platform.mean():.1f} cm\")\n</pre> # Compute distance from each bin to platform platform_point = env.regions[\"platform\"].data  distances_to_platform = np.zeros(env.n_bins) for bin_idx in range(env.n_bins):     bin_center = env.bin_centers[bin_idx]     distances_to_platform[bin_idx] = np.linalg.norm(bin_center - platform_point)  print(f\"Min distance to platform: {distances_to_platform.min():.1f} cm\") print(f\"Max distance to platform: {distances_to_platform.max():.1f} cm\") print(f\"Mean distance to platform: {distances_to_platform.mean():.1f} cm\") <pre>Min distance to platform: 4.2 cm\nMax distance to platform: 101.9 cm\nMean distance to platform: 54.6 cm\n</pre> In\u00a0[14]: Copied! <pre># Visualize distance map\nfig, ax = plt.subplots(figsize=(11, 10))\n\nscatter = ax.scatter(\n    env.bin_centers[:, 0],\n    env.bin_centers[:, 1],\n    c=distances_to_platform,\n    s=200,\n    cmap=\"viridis_r\",\n    marker=\"s\",\n    edgecolors=\"black\",\n    linewidth=0.5,\n)\n\nax.scatter(\n    platform_point[0],\n    platform_point[1],\n    c=\"red\",\n    s=400,\n    marker=\"*\",\n    edgecolors=\"black\",\n    linewidth=2,\n    label=\"Platform\",\n    zorder=10,\n)\n\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(\"Distance to Platform from Each Bin\")\nax.set_aspect(\"equal\")\nax.legend()\nplt.colorbar(scatter, ax=ax, label=\"Distance (cm)\")\nplt.tight_layout()\nplt.show()\n</pre> # Visualize distance map fig, ax = plt.subplots(figsize=(11, 10))  scatter = ax.scatter(     env.bin_centers[:, 0],     env.bin_centers[:, 1],     c=distances_to_platform,     s=200,     cmap=\"viridis_r\",     marker=\"s\",     edgecolors=\"black\",     linewidth=0.5, )  ax.scatter(     platform_point[0],     platform_point[1],     c=\"red\",     s=400,     marker=\"*\",     edgecolors=\"black\",     linewidth=2,     label=\"Platform\",     zorder=10, )  ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(\"Distance to Platform from Each Bin\") ax.set_aspect(\"equal\") ax.legend() plt.colorbar(scatter, ax=ax, label=\"Distance (cm)\") plt.tight_layout() plt.show() In\u00a0[15]: Copied! <pre># Get center of target quadrant\ntarget_center = env.regions.region_center(\"quadrant_SW\")\nprint(f\"Center of SW quadrant: {target_center}\")\nprint(f\"Platform location: {platform_point}\")\nprint(f\"Distance: {np.linalg.norm(target_center - platform_point):.1f} cm\")\n</pre> # Get center of target quadrant target_center = env.regions.region_center(\"quadrant_SW\") print(f\"Center of SW quadrant: {target_center}\") print(f\"Platform location: {platform_point}\") print(f\"Distance: {np.linalg.norm(target_center - platform_point):.1f} cm\") <pre>Center of SW quadrant: [34.55566547 34.55566547]\nPlatform location: [30. 30.]\nDistance: 6.4 cm\n</pre> In\u00a0[16]: Copied! <pre># Compute area of each quadrant\nfor quad_name in quadrant_names:\n    area = env.regions.area(quad_name)\n    print(f\"{quad_name}: {area:.0f} cm\u00b2\")\n\nareas = [env.regions.area(name) for name in quadrant_names]\nprint(f\"\\nMean quadrant area: {np.mean(areas):.0f} cm\u00b2\")\n</pre> # Compute area of each quadrant for quad_name in quadrant_names:     area = env.regions.area(quad_name)     print(f\"{quad_name}: {area:.0f} cm\u00b2\")  areas = [env.regions.area(name) for name in quadrant_names] print(f\"\\nMean quadrant area: {np.mean(areas):.0f} cm\u00b2\") <pre>quadrant_NW: 2823 cm\u00b2\nquadrant_NE: 2823 cm\u00b2\nquadrant_SW: 2823 cm\u00b2\nquadrant_SE: 2823 cm\u00b2\n\nMean quadrant area: 2823 cm\u00b2\n</pre> In\u00a0[17]: Copied! <pre># Create platform zone\nplatform_zone = env.regions.buffer(\"platform\", distance=10.0, new_name=\"platform_zone\")\nprint(f\"Platform zone area: {platform_zone.data.area:.0f} cm\u00b2\")\n</pre> # Create platform zone platform_zone = env.regions.buffer(\"platform\", distance=10.0, new_name=\"platform_zone\") print(f\"Platform zone area: {platform_zone.data.area:.0f} cm\u00b2\") <pre>Platform zone area: 314 cm\u00b2\n</pre> In\u00a0[18]: Copied! <pre># Create temporary file path\ntemp_fd, temp_path = tempfile.mkstemp(suffix=\".json\")\nos.close(temp_fd)  # Close the file descriptor\n\n# Save regions\nenv.regions.to_json(temp_path)\nprint(f\"Regions saved to: {temp_path}\")\n\n# Load regions\nloaded_regions = Regions.from_json(temp_path)\nprint(f\"Loaded {len(loaded_regions)} regions\")\n\nPath(temp_path).unlink()\n</pre> # Create temporary file path temp_fd, temp_path = tempfile.mkstemp(suffix=\".json\") os.close(temp_fd)  # Close the file descriptor  # Save regions env.regions.to_json(temp_path) print(f\"Regions saved to: {temp_path}\")  # Load regions loaded_regions = Regions.from_json(temp_path) print(f\"Loaded {len(loaded_regions)} regions\")  Path(temp_path).unlink() <pre>Regions saved to: /var/folders/86/m147b4k17lddvs_xsw0mj2zw0000gn/T/tmppheqe8ai.json\nLoaded 10 regions\n</pre> In\u00a0[19]: Copied! <pre># Regions are immutable - demonstrating the correct approach\n# Note: Regions are immutable - can't modify .data directly\n# Must use update_region() to modify\n\nenv.regions.update_region(\"platform\", point=np.array([50, 50]))\nprint(\"Updated platform location successfully using update_region()\")\n</pre> # Regions are immutable - demonstrating the correct approach # Note: Regions are immutable - can't modify .data directly # Must use update_region() to modify  env.regions.update_region(\"platform\", point=np.array([50, 50])) print(\"Updated platform location successfully using update_region()\") <pre>Updated platform location successfully using update_region()\n</pre> In\u00a0[20]: Copied! <pre># Cannot overwrite existing regions - must use update_region() or delete first\n# Correct approach: use update_region()\nenv.regions.update_region(\"platform\", point=np.array([50, 50]))\nprint(\"Updated region successfully using update_region()\")\n</pre> # Cannot overwrite existing regions - must use update_region() or delete first # Correct approach: use update_region() env.regions.update_region(\"platform\", point=np.array([50, 50])) print(\"Updated region successfully using update_region()\") <pre>Updated region successfully using update_region()\n</pre>"},{"location":"examples/04_regions_of_interest/#regions-of-interest-defining-and-managing-spatial-regions","title":"Regions of Interest: Defining and Managing Spatial Regions\u00b6","text":""},{"location":"examples/04_regions_of_interest/#learning-objectives","title":"Learning Objectives\u00b6","text":"<p>By the end of this notebook, you will be able to:</p> <ul> <li>Define named regions of interest (ROIs) as points or polygons</li> <li>Add, remove, and update regions in an environment</li> <li>Query spatial relationships (bins in regions, distances to regions)</li> <li>Use regions for behavioral analysis (time in zone, entries/exits)</li> <li>Save and load region definitions with JSON serialization</li> <li>Visualize regions overlaid on environments</li> </ul> <p>Estimated time: 20-25 minutes</p>"},{"location":"examples/04_regions_of_interest/#why-regions-of-interest","title":"Why Regions of Interest?\u00b6","text":"<p>In spatial navigation experiments, certain locations have special meaning:</p> <ul> <li>Goal locations: Reward sites, escape platforms, target zones</li> <li>Start locations: Where trials begin</li> <li>Context zones: Different areas with distinct features</li> <li>Object locations: Novel or familiar object positions</li> <li>Danger zones: Shock zones, predator areas</li> </ul> <p>The <code>neurospatial</code> library lets you define these regions and use them for analysis:</p> <ul> <li>Mark important locations</li> <li>Compute behavioral metrics (time in zone, approaches)</li> <li>Visualize task structure</li> <li>Share experimental designs</li> </ul> <p>Regions are immutable and serializable - perfect for reproducible science!</p>"},{"location":"examples/04_regions_of_interest/#setup","title":"Setup\u00b6","text":""},{"location":"examples/04_regions_of_interest/#creating-an-example-environment","title":"Creating an Example Environment\u00b6","text":"<p>Let's create a Morris water maze environment - a classic spatial memory task where rodents learn to find a hidden platform.</p>"},{"location":"examples/04_regions_of_interest/#creating-regions-point-regions","title":"Creating Regions: Point Regions\u00b6","text":"<p>A point region represents a specific location. Let's define the platform location:</p>"},{"location":"examples/04_regions_of_interest/#adding-regions-to-environment","title":"Adding Regions to Environment\u00b6","text":"<p>Environments have a <code>regions</code> attribute that works like a dictionary:</p>"},{"location":"examples/04_regions_of_interest/#adding-multiple-regions","title":"Adding Multiple Regions\u00b6","text":"<p>Let's add start locations in each cardinal direction:</p>"},{"location":"examples/04_regions_of_interest/#visualizing-regions","title":"Visualizing Regions\u00b6","text":""},{"location":"examples/04_regions_of_interest/#creating-regions-polygon-regions","title":"Creating Regions: Polygon Regions\u00b6","text":"<p>Polygon regions define areas (zones) rather than points. Let's define quadrants of the maze:</p>"},{"location":"examples/04_regions_of_interest/#querying-regions","title":"Querying Regions\u00b6","text":"<p>Now let's use regions for analysis!</p>"},{"location":"examples/04_regions_of_interest/#finding-bins-in-a-region","title":"Finding Bins in a Region\u00b6","text":""},{"location":"examples/04_regions_of_interest/#computing-time-in-zone","title":"Computing Time in Zone\u00b6","text":"<p>A key behavioral metric: how much time did the animal spend in each quadrant?</p>"},{"location":"examples/04_regions_of_interest/#distance-to-region","title":"Distance to Region\u00b6","text":"<p>Compute distances from all bins to a specific region:</p>"},{"location":"examples/04_regions_of_interest/#region-operations","title":"Region Operations\u00b6","text":"<p>Regions support several useful operations:</p>"},{"location":"examples/04_regions_of_interest/#getting-region-center","title":"Getting Region Center\u00b6","text":""},{"location":"examples/04_regions_of_interest/#computing-region-area","title":"Computing Region Area\u00b6","text":""},{"location":"examples/04_regions_of_interest/#buffering-regions","title":"Buffering Regions\u00b6","text":""},{"location":"examples/04_regions_of_interest/#saving-and-loading-regions","title":"Saving and Loading Regions\u00b6","text":""},{"location":"examples/04_regions_of_interest/#common-pitfalls","title":"Common Pitfalls\u00b6","text":""},{"location":"examples/04_regions_of_interest/#pitfall-1-trying-to-modify-immutable-regions","title":"Pitfall 1: Trying to modify immutable regions\u00b6","text":""},{"location":"examples/04_regions_of_interest/#pitfall-2-trying-to-overwrite-existing-regions","title":"Pitfall 2: Trying to overwrite existing regions\u00b6","text":""},{"location":"examples/04_regions_of_interest/#key-takeaways","title":"Key Takeaways\u00b6","text":"<ol> <li>Regions define important locations - platforms, goals, zones</li> <li>Two region types: Point regions and Polygon regions</li> <li>Use for behavioral analysis: Time in zone, distance to goal</li> <li>Regions are immutable - use <code>update_region()</code> to modify</li> <li>Dictionary-like interface: <code>add()</code>, <code>remove()</code>, <code>keys()</code></li> <li>Serialization support - save/load from JSON</li> <li>Operations: <code>buffer()</code>, <code>area()</code>, <code>region_center()</code></li> </ol>"},{"location":"examples/04_regions_of_interest/#next-steps","title":"Next Steps\u00b6","text":"<p>In the next notebook (05_track_linearization.ipynb), you'll learn:</p> <ul> <li>1D linearized tracks with GraphLayout</li> <li>Converting between N-D and linear coordinates</li> <li>Plus maze analysis example</li> </ul>"},{"location":"examples/04_regions_of_interest/#exercises-optional","title":"Exercises (Optional)\u00b6","text":"<ol> <li>Define regions for a radial arm maze</li> <li>Compute average latency to first platform zone entry</li> <li>Create heatmap of bins visited before reaching platform</li> <li>Design a T-maze with choice zones</li> </ol>"},{"location":"examples/05_track_linearization/","title":"Track Linearization: Working with 1D Environments","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport networkx as nx\nimport numpy as np\n\nfrom neurospatial import Environment\n\nnp.random.seed(42)\nplt.rcParams[\"figure.figsize\"] = (14, 10)\nplt.rcParams[\"font.size\"] = 11\n</pre> import matplotlib.pyplot as plt import networkx as nx import numpy as np  from neurospatial import Environment  np.random.seed(42) plt.rcParams[\"figure.figsize\"] = (14, 10) plt.rcParams[\"font.size\"] = 11 In\u00a0[2]: Copied! <pre># Create position data for a linear track (back and forth)\ntrack_length = 100.0  # cm\nn_laps = 5\nsamples_per_lap = 200\nn_samples = n_laps * samples_per_lap\n\n# Position along track (oscillates back and forth)\nt = np.linspace(0, n_laps * 2 * np.pi, n_samples)\nx_position = (np.sin(t) + 1) * 50  # Oscillates between 0 and 100\n\n# Y position is constant (straight track at y=0)\ny_position = np.zeros_like(x_position)\n\n# Add small noise\ny_position += np.random.randn(n_samples) * 0.5\n\nlinear_track_data = np.column_stack([x_position, y_position])\n\nprint(f\"Generated {n_samples} samples for linear track\")\nprint(\n    f\"Track extent: X=[{x_position.min():.1f}, {x_position.max():.1f}], Y=[{y_position.min():.1f}, {y_position.max():.1f}]\"\n)\n</pre> # Create position data for a linear track (back and forth) track_length = 100.0  # cm n_laps = 5 samples_per_lap = 200 n_samples = n_laps * samples_per_lap  # Position along track (oscillates back and forth) t = np.linspace(0, n_laps * 2 * np.pi, n_samples) x_position = (np.sin(t) + 1) * 50  # Oscillates between 0 and 100  # Y position is constant (straight track at y=0) y_position = np.zeros_like(x_position)  # Add small noise y_position += np.random.randn(n_samples) * 0.5  linear_track_data = np.column_stack([x_position, y_position])  print(f\"Generated {n_samples} samples for linear track\") print(     f\"Track extent: X=[{x_position.min():.1f}, {x_position.max():.1f}], Y=[{y_position.min():.1f}, {y_position.max():.1f}]\" ) <pre>Generated 1000 samples for linear track\nTrack extent: X=[0.0, 100.0], Y=[-1.6, 1.9]\n</pre> In\u00a0[3]: Copied! <pre># Visualize the trajectory\nfig, ax = plt.subplots(figsize=(14, 4))\n\nscatter = ax.scatter(\n    linear_track_data[:, 0],\n    linear_track_data[:, 1],\n    c=np.arange(n_samples),\n    cmap=\"viridis\",\n    s=10,\n    alpha=0.6,\n)\n\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(\"Linear Track Trajectory (5 laps, back and forth)\")\nax.set_aspect(\"equal\")\nplt.colorbar(scatter, ax=ax, label=\"Time (samples)\")\nplt.tight_layout()\nplt.show()\n</pre> # Visualize the trajectory fig, ax = plt.subplots(figsize=(14, 4))  scatter = ax.scatter(     linear_track_data[:, 0],     linear_track_data[:, 1],     c=np.arange(n_samples),     cmap=\"viridis\",     s=10,     alpha=0.6, )  ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(\"Linear Track Trajectory (5 laps, back and forth)\") ax.set_aspect(\"equal\") plt.colorbar(scatter, ax=ax, label=\"Time (samples)\") plt.tight_layout() plt.show() In\u00a0[4]: Copied! <pre># For a linear track, create a simple graph with two nodes (endpoints) and one edge\nlinear_track_graph = nx.Graph()\nlinear_track_graph.add_node(0, pos=(0.0, 0.0))\nlinear_track_graph.add_node(1, pos=(100.0, 0.0))\nlinear_track_graph.add_edge(0, 1, edge_id=0)\n\n# Add distance attribute to edge (required by GraphLayout)\nfor u, v in linear_track_graph.edges():\n    pos_u = np.array(linear_track_graph.nodes[u][\"pos\"])\n    pos_v = np.array(linear_track_graph.nodes[v][\"pos\"])\n    linear_track_graph.edges[u, v][\"distance\"] = np.linalg.norm(pos_v - pos_u)\n\n# Define edge order (list of edges to traverse)\nedge_order = [(0, 1)]\n\n# Create 1D linearized environment\nenv_1d = Environment.from_graph(\n    graph=linear_track_graph,\n    edge_order=edge_order,\n    edge_spacing=0.0,  # No spacing between edges for single edge\n    bin_size=5.0,  # 5 cm bins along track\n    name=\"LinearTrack\",\n)\n\nprint(\"1D Environment Created!\")\nprint(f\"Is 1D: {env_1d.is_1d}\")\nprint(f\"Number of bins: {env_1d.n_bins}\")\nprint(f\"Layout type: {env_1d.layout._layout_type_tag}\")\n</pre> # For a linear track, create a simple graph with two nodes (endpoints) and one edge linear_track_graph = nx.Graph() linear_track_graph.add_node(0, pos=(0.0, 0.0)) linear_track_graph.add_node(1, pos=(100.0, 0.0)) linear_track_graph.add_edge(0, 1, edge_id=0)  # Add distance attribute to edge (required by GraphLayout) for u, v in linear_track_graph.edges():     pos_u = np.array(linear_track_graph.nodes[u][\"pos\"])     pos_v = np.array(linear_track_graph.nodes[v][\"pos\"])     linear_track_graph.edges[u, v][\"distance\"] = np.linalg.norm(pos_v - pos_u)  # Define edge order (list of edges to traverse) edge_order = [(0, 1)]  # Create 1D linearized environment env_1d = Environment.from_graph(     graph=linear_track_graph,     edge_order=edge_order,     edge_spacing=0.0,  # No spacing between edges for single edge     bin_size=5.0,  # 5 cm bins along track     name=\"LinearTrack\", )  print(\"1D Environment Created!\") print(f\"Is 1D: {env_1d.is_1d}\") print(f\"Number of bins: {env_1d.n_bins}\") print(f\"Layout type: {env_1d.layout._layout_type_tag}\") <pre>1D Environment Created!\nIs 1D: True\nNumber of bins: 20\nLayout type: Graph\n</pre> In\u00a0[5]: Copied! <pre>if env_1d is not None:\n    # Visualize the 1D environment\n    fig, ax = plt.subplots(figsize=(14, 6))\n\n    env_1d.plot(ax=ax, show_connectivity=True)\n\n    ax.set_title(\"1D Linearized Environment\")\n    plt.tight_layout()\n    plt.show()\n\n    print(f\"\\nBin centers shape: {env_1d.bin_centers.shape}\")\n    print(f\"Dimension ranges: {env_1d.dimension_ranges}\")\nelse:\n    print(\"Skipping visualization (track-linearization not available)\")\n</pre> if env_1d is not None:     # Visualize the 1D environment     fig, ax = plt.subplots(figsize=(14, 6))      env_1d.plot(ax=ax, show_connectivity=True)      ax.set_title(\"1D Linearized Environment\")     plt.tight_layout()     plt.show()      print(f\"\\nBin centers shape: {env_1d.bin_centers.shape}\")     print(f\"Dimension ranges: {env_1d.dimension_ranges}\") else:     print(\"Skipping visualization (track-linearization not available)\") <pre>\nBin centers shape: (20, 2)\nDimension ranges: ((np.float64(2.5), np.float64(97.5)), (np.float64(0.0), np.float64(0.0)))\n</pre> In\u00a0[6]: Copied! <pre>if env_1d is not None and env_1d.is_1d:\n    # Map trajectory to linear position\n    linear_positions = env_1d.to_linear(linear_track_data)\n\n    print(f\"Linear positions shape: {linear_positions.shape}\")\n    print(\n        f\"Linear position range: [{linear_positions.min():.1f}, {linear_positions.max():.1f}]\"\n    )\n\n    # Show how same X position maps to different linear positions\n    mid_track_x = 50.0\n    mid_indices = np.where(np.abs(linear_track_data[:, 0] - mid_track_x) &lt; 1.0)[0][:10]\n\n    print(f\"\\nSame X position ({mid_track_x} cm) at different times:\")\n    for idx in mid_indices[:5]:\n        print(\n            f\"  Time {idx}: 2D pos = {linear_track_data[idx]}, Linear pos = {linear_positions[idx]:.1f}\"\n        )\nelse:\n    print(\"Skipping coordinate conversion (track-linearization not available)\")\n</pre> if env_1d is not None and env_1d.is_1d:     # Map trajectory to linear position     linear_positions = env_1d.to_linear(linear_track_data)      print(f\"Linear positions shape: {linear_positions.shape}\")     print(         f\"Linear position range: [{linear_positions.min():.1f}, {linear_positions.max():.1f}]\"     )      # Show how same X position maps to different linear positions     mid_track_x = 50.0     mid_indices = np.where(np.abs(linear_track_data[:, 0] - mid_track_x) &lt; 1.0)[0][:10]      print(f\"\\nSame X position ({mid_track_x} cm) at different times:\")     for idx in mid_indices[:5]:         print(             f\"  Time {idx}: 2D pos = {linear_track_data[idx]}, Linear pos = {linear_positions[idx]:.1f}\"         ) else:     print(\"Skipping coordinate conversion (track-linearization not available)\") <pre>Linear positions shape: (1000,)\nLinear position range: [0.0, 100.0]\n\nSame X position (50.0 cm) at different times:\n  Time 0: 2D pos = [50.          0.24835708], Linear pos = 50.0\n  Time 100: 2D pos = [49.84276339 -0.70768537], Linear pos = 49.8\n  Time 200: 2D pos = [50.31447167  0.17889368], Linear pos = 50.3\n  Time 300: 2D pos = [49.52829639 -0.41449751], Linear pos = 49.5\n  Time 399: 2D pos = [49.05663476  0.61890816], Linear pos = 49.1\n</pre> In\u00a0[7]: Copied! <pre>if env_1d is not None and env_1d.is_1d:\n    # Visualize linear position over time\n    fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n\n    # Top: 2D X position over time\n    axes[0].plot(linear_track_data[:, 0], linewidth=2)\n    axes[0].set_ylabel(\"X Position (cm)\")\n    axes[0].set_title(\"2D Spatial Position Over Time\")\n    axes[0].grid(True, alpha=0.3)\n    axes[0].axhline(50, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Middle of track\")\n    axes[0].legend()\n\n    # Bottom: 1D linear position over time\n    axes[1].plot(linear_positions, linewidth=2, color=\"orange\")\n    axes[1].set_xlabel(\"Time (samples)\")\n    axes[1].set_ylabel(\"Linear Position\")\n    axes[1].set_title(\"1D Linearized Position Over Time (trajectory-aware)\")\n    axes[1].grid(True, alpha=0.3)\n\n    plt.tight_layout()\n    plt.show()\n\n    print(\"\\nKey insight: Linear position continuously increases,\")\n    print(\"even when X position oscillates back and forth!\")\nelse:\n    print(\"Skipping visualization (track-linearization not available)\")\n</pre> if env_1d is not None and env_1d.is_1d:     # Visualize linear position over time     fig, axes = plt.subplots(2, 1, figsize=(14, 8))      # Top: 2D X position over time     axes[0].plot(linear_track_data[:, 0], linewidth=2)     axes[0].set_ylabel(\"X Position (cm)\")     axes[0].set_title(\"2D Spatial Position Over Time\")     axes[0].grid(True, alpha=0.3)     axes[0].axhline(50, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Middle of track\")     axes[0].legend()      # Bottom: 1D linear position over time     axes[1].plot(linear_positions, linewidth=2, color=\"orange\")     axes[1].set_xlabel(\"Time (samples)\")     axes[1].set_ylabel(\"Linear Position\")     axes[1].set_title(\"1D Linearized Position Over Time (trajectory-aware)\")     axes[1].grid(True, alpha=0.3)      plt.tight_layout()     plt.show()      print(\"\\nKey insight: Linear position continuously increases,\")     print(\"even when X position oscillates back and forth!\") else:     print(\"Skipping visualization (track-linearization not available)\") <pre>\nKey insight: Linear position continuously increases,\neven when X position oscillates back and forth!\n</pre> In\u00a0[8]: Copied! <pre># Create plus maze structure\n# Center at (50, 50), arms extend 40 cm in each direction\n\ncenter = np.array([50.0, 50.0])\narm_length = 40.0\n\n# Define arm endpoints\nnorth_end = center + np.array([0, arm_length])\neast_end = center + np.array([arm_length, 0])\nsouth_end = center + np.array([0, -arm_length])\nwest_end = center + np.array([-arm_length, 0])\n\n# Generate trajectory: start at south, go to center, explore arms\ntrajectory_segments = [\n    # Start at south arm\n    (south_end, center),\n    # Go to north arm and back\n    (center, north_end),\n    (north_end, center),\n    # Go to east arm and back\n    (center, east_end),\n    (east_end, center),\n    # Go to west arm and back\n    (center, west_end),\n    (west_end, center),\n    # Return to south\n    (center, south_end),\n]\n\n\n# Create smooth trajectory\ndef create_smooth_segment(start, end, n_points=100):\n    \"\"\"Create smooth trajectory between two points.\"\"\"\n    alphas = np.linspace(0, 1, n_points)\n    points = np.outer(1 - alphas, start) + np.outer(alphas, end)\n    # Add small noise\n    points += np.random.randn(n_points, 2) * 0.5\n    return points\n\n\nplus_maze_data = []\nfor start, end in trajectory_segments:\n    segment = create_smooth_segment(start, end, n_points=100)\n    plus_maze_data.append(segment)\n\nplus_maze_data = np.vstack(plus_maze_data)\n\nprint(f\"Generated {len(plus_maze_data)} samples for plus maze\")\nprint(\"Trajectory visits all 4 arms\")\n</pre> # Create plus maze structure # Center at (50, 50), arms extend 40 cm in each direction  center = np.array([50.0, 50.0]) arm_length = 40.0  # Define arm endpoints north_end = center + np.array([0, arm_length]) east_end = center + np.array([arm_length, 0]) south_end = center + np.array([0, -arm_length]) west_end = center + np.array([-arm_length, 0])  # Generate trajectory: start at south, go to center, explore arms trajectory_segments = [     # Start at south arm     (south_end, center),     # Go to north arm and back     (center, north_end),     (north_end, center),     # Go to east arm and back     (center, east_end),     (east_end, center),     # Go to west arm and back     (center, west_end),     (west_end, center),     # Return to south     (center, south_end), ]   # Create smooth trajectory def create_smooth_segment(start, end, n_points=100):     \"\"\"Create smooth trajectory between two points.\"\"\"     alphas = np.linspace(0, 1, n_points)     points = np.outer(1 - alphas, start) + np.outer(alphas, end)     # Add small noise     points += np.random.randn(n_points, 2) * 0.5     return points   plus_maze_data = [] for start, end in trajectory_segments:     segment = create_smooth_segment(start, end, n_points=100)     plus_maze_data.append(segment)  plus_maze_data = np.vstack(plus_maze_data)  print(f\"Generated {len(plus_maze_data)} samples for plus maze\") print(\"Trajectory visits all 4 arms\") <pre>Generated 800 samples for plus maze\nTrajectory visits all 4 arms\n</pre> In\u00a0[9]: Copied! <pre># Visualize plus maze trajectory\nfig, ax = plt.subplots(figsize=(10, 10))\n\n# Draw maze structure\nax.plot(\n    [center[0], north_end[0]],\n    [center[1], north_end[1]],\n    \"k-\",\n    linewidth=8,\n    alpha=0.3,\n    label=\"Track structure\",\n)\nax.plot(\n    [center[0], south_end[0]], [center[1], south_end[1]], \"k-\", linewidth=8, alpha=0.3\n)\nax.plot(\n    [west_end[0], east_end[0]], [center[1], center[1]], \"k-\", linewidth=8, alpha=0.3\n)\n\n# Plot trajectory\nscatter = ax.scatter(\n    plus_maze_data[:, 0],\n    plus_maze_data[:, 1],\n    c=np.arange(len(plus_maze_data)),\n    cmap=\"viridis\",\n    s=20,\n    alpha=0.6,\n)\n\n# Mark center and arm endpoints\nax.plot(center[0], center[1], \"r*\", markersize=25, label=\"Center\")\nax.plot(north_end[0], north_end[1], \"go\", markersize=15, label=\"North arm\")\nax.plot(south_end[0], south_end[1], \"bo\", markersize=15, label=\"South arm\")\nax.plot(east_end[0], east_end[1], \"mo\", markersize=15, label=\"East arm\")\nax.plot(west_end[0], west_end[1], \"co\", markersize=15, label=\"West arm\")\n\n# Mark start\nax.plot(\n    plus_maze_data[0, 0],\n    plus_maze_data[0, 1],\n    \"ks\",\n    markersize=20,\n    label=\"Start\",\n    markeredgewidth=2,\n    markerfacecolor=\"yellow\",\n)\n\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(\"Plus Maze Trajectory\")\nax.set_aspect(\"equal\")\nax.legend(loc=\"upper left\", fontsize=9)\nax.grid(True, alpha=0.3)\nplt.colorbar(scatter, ax=ax, label=\"Time (samples)\")\nplt.tight_layout()\nplt.show()\n</pre> # Visualize plus maze trajectory fig, ax = plt.subplots(figsize=(10, 10))  # Draw maze structure ax.plot(     [center[0], north_end[0]],     [center[1], north_end[1]],     \"k-\",     linewidth=8,     alpha=0.3,     label=\"Track structure\", ) ax.plot(     [center[0], south_end[0]], [center[1], south_end[1]], \"k-\", linewidth=8, alpha=0.3 ) ax.plot(     [west_end[0], east_end[0]], [center[1], center[1]], \"k-\", linewidth=8, alpha=0.3 )  # Plot trajectory scatter = ax.scatter(     plus_maze_data[:, 0],     plus_maze_data[:, 1],     c=np.arange(len(plus_maze_data)),     cmap=\"viridis\",     s=20,     alpha=0.6, )  # Mark center and arm endpoints ax.plot(center[0], center[1], \"r*\", markersize=25, label=\"Center\") ax.plot(north_end[0], north_end[1], \"go\", markersize=15, label=\"North arm\") ax.plot(south_end[0], south_end[1], \"bo\", markersize=15, label=\"South arm\") ax.plot(east_end[0], east_end[1], \"mo\", markersize=15, label=\"East arm\") ax.plot(west_end[0], west_end[1], \"co\", markersize=15, label=\"West arm\")  # Mark start ax.plot(     plus_maze_data[0, 0],     plus_maze_data[0, 1],     \"ks\",     markersize=20,     label=\"Start\",     markeredgewidth=2,     markerfacecolor=\"yellow\", )  ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(\"Plus Maze Trajectory\") ax.set_aspect(\"equal\") ax.legend(loc=\"upper left\", fontsize=9) ax.grid(True, alpha=0.3) plt.colorbar(scatter, ax=ax, label=\"Time (samples)\") plt.tight_layout() plt.show() In\u00a0[10]: Copied! <pre># Define track graph structure\n# Nodes are named locations, edges are track segments\n\ntrack_graph = nx.Graph()\n\n# Add nodes with 2D positions\ntrack_graph.add_node(\"center\", pos=center)\ntrack_graph.add_node(\"north\", pos=north_end)\ntrack_graph.add_node(\"south\", pos=south_end)\ntrack_graph.add_node(\"east\", pos=east_end)\ntrack_graph.add_node(\"west\", pos=west_end)\n\n# Add edges (track segments) with sequential edge_ids\ntrack_graph.add_edge(\"center\", \"north\", edge_id=0)\ntrack_graph.add_edge(\"center\", \"south\", edge_id=1)\ntrack_graph.add_edge(\"center\", \"east\", edge_id=2)\ntrack_graph.add_edge(\"center\", \"west\", edge_id=3)\n\n# Add distance attributes to edges (required by GraphLayout)\nfor u, v in track_graph.edges():\n    pos_u = np.array(track_graph.nodes[u][\"pos\"])\n    pos_v = np.array(track_graph.nodes[v][\"pos\"])\n    track_graph.edges[u, v][\"distance\"] = np.linalg.norm(pos_v - pos_u)\n\nprint(\n    f\"Track graph: {track_graph.number_of_nodes()} nodes, {track_graph.number_of_edges()} edges\"\n)\nprint(f\"Nodes: {list(track_graph.nodes())}\")\n</pre> # Define track graph structure # Nodes are named locations, edges are track segments  track_graph = nx.Graph()  # Add nodes with 2D positions track_graph.add_node(\"center\", pos=center) track_graph.add_node(\"north\", pos=north_end) track_graph.add_node(\"south\", pos=south_end) track_graph.add_node(\"east\", pos=east_end) track_graph.add_node(\"west\", pos=west_end)  # Add edges (track segments) with sequential edge_ids track_graph.add_edge(\"center\", \"north\", edge_id=0) track_graph.add_edge(\"center\", \"south\", edge_id=1) track_graph.add_edge(\"center\", \"east\", edge_id=2) track_graph.add_edge(\"center\", \"west\", edge_id=3)  # Add distance attributes to edges (required by GraphLayout) for u, v in track_graph.edges():     pos_u = np.array(track_graph.nodes[u][\"pos\"])     pos_v = np.array(track_graph.nodes[v][\"pos\"])     track_graph.edges[u, v][\"distance\"] = np.linalg.norm(pos_v - pos_u)  print(     f\"Track graph: {track_graph.number_of_nodes()} nodes, {track_graph.number_of_edges()} edges\" ) print(f\"Nodes: {list(track_graph.nodes())}\") <pre>Track graph: 5 nodes, 4 edges\nNodes: ['center', 'north', 'south', 'east', 'west']\n</pre> In\u00a0[11]: Copied! <pre># Define edge order for plus maze (order in which edges are traversed)\n# For a plus maze, we traverse all 4 arms from the center\nplus_maze_edge_order = [\n    (\"center\", \"north\"),\n    (\"center\", \"south\"),\n    (\"center\", \"east\"),\n    (\"center\", \"west\"),\n]\n\n# Create 1D environment for plus maze\nenv_plus = Environment.from_graph(\n    graph=track_graph,\n    edge_order=plus_maze_edge_order,\n    edge_spacing=0.0,  # No spacing between edges\n    bin_size=5.0,\n    name=\"PlusMaze\",\n)\n\nprint(\"Plus Maze 1D Environment Created!\")\nprint(env_plus.info())\n</pre> # Define edge order for plus maze (order in which edges are traversed) # For a plus maze, we traverse all 4 arms from the center plus_maze_edge_order = [     (\"center\", \"north\"),     (\"center\", \"south\"),     (\"center\", \"east\"),     (\"center\", \"west\"), ]  # Create 1D environment for plus maze env_plus = Environment.from_graph(     graph=track_graph,     edge_order=plus_maze_edge_order,     edge_spacing=0.0,  # No spacing between edges     bin_size=5.0,     name=\"PlusMaze\", )  print(\"Plus Maze 1D Environment Created!\") print(env_plus.info()) <pre>Plus Maze 1D Environment Created!\nEnvironment Information\n=======================\n\nName: PlusMaze\nLayout Type: Graph\nDimensions: 2\nNumber of Bins: 32\n\nSpatial Extent:\n  Dimension 0: [12.50, 87.50] (range: 75.00)\n  Dimension 1: [12.50, 87.50] (range: 75.00)\n\nBin Sizes:\n  Dimension 0: 5.00\n\nRegions: None\n\nLinearization: Available (1D environment)\n\n</pre> In\u00a0[12]: Copied! <pre># Visualize the linearized plus maze\nfig, ax = plt.subplots(figsize=(12, 10))\n\nenv_plus.plot(ax=ax, show_connectivity=True)\n\nax.set_title(\"Plus Maze - 1D Linearized Representation\")\nax.set_aspect(\"equal\")\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nNote: Center appears multiple times in linearization!\")\nprint(\"This captures the different trajectories through the center.\")\n</pre> # Visualize the linearized plus maze fig, ax = plt.subplots(figsize=(12, 10))  env_plus.plot(ax=ax, show_connectivity=True)  ax.set_title(\"Plus Maze - 1D Linearized Representation\") ax.set_aspect(\"equal\") plt.tight_layout() plt.show()  print(\"\\nNote: Center appears multiple times in linearization!\") print(\"This captures the different trajectories through the center.\") <pre>\nNote: Center appears multiple times in linearization!\nThis captures the different trajectories through the center.\n</pre> In\u00a0[13]: Copied! <pre># Simulate a place cell that fires on the north arm only\ndef simulate_trajectory_specific_cell(\n    position_data, arm_start, arm_end, field_size=10.0\n):\n    \"\"\"\n    Simulate a neuron that fires only when moving toward a specific arm.\n\n    Parameters\n    ----------\n    position_data : ndarray, shape (n_samples, 2)\n        Position trajectory.\n    arm_start : array-like, shape (2,)\n        Start of arm (center).\n    arm_end : array-like, shape (2,)\n        End of arm.\n    field_size : float\n        Spatial scale of place field.\n\n    Returns\n    -------\n    spike_counts : ndarray, shape (n_samples,)\n        Spikes at each position.\n    \"\"\"\n    # Check if position is on the arm and moving in correct direction\n    arm_direction = arm_end - arm_start\n    arm_direction = arm_direction / np.linalg.norm(arm_direction)\n\n    # Field center is 2/3 along the arm\n    field_center = arm_start + 0.67 * (arm_end - arm_start)\n\n    spike_counts = np.zeros(len(position_data))\n\n    for i in range(1, len(position_data)):\n        # Distance to field center\n        distance = np.linalg.norm(position_data[i] - field_center)\n\n        # Movement direction\n        movement = position_data[i] - position_data[i - 1]\n        if np.linalg.norm(movement) &gt; 0.1:\n            movement_dir = movement / np.linalg.norm(movement)\n\n            # Check if moving toward arm end\n            alignment = np.dot(movement_dir, arm_direction)\n\n            if alignment &gt; 0.5 and distance &lt; field_size:\n                # Fire based on distance\n                firing_rate = 30.0 * np.exp(-(distance**2) / (2 * field_size**2))\n                spike_counts[i] = np.random.poisson(firing_rate * 0.05)\n\n    return spike_counts\n\n\n# Simulate a cell that fires only when going TO north arm (not returning)\nnorth_cell_spikes = simulate_trajectory_specific_cell(\n    plus_maze_data, center, north_end, field_size=15.0\n)\n\nprint(f\"Generated {north_cell_spikes.sum()} spikes\")\nprint(f\"Mean firing rate: {north_cell_spikes.mean() / 0.05:.2f} Hz\")\n</pre> # Simulate a place cell that fires on the north arm only def simulate_trajectory_specific_cell(     position_data, arm_start, arm_end, field_size=10.0 ):     \"\"\"     Simulate a neuron that fires only when moving toward a specific arm.      Parameters     ----------     position_data : ndarray, shape (n_samples, 2)         Position trajectory.     arm_start : array-like, shape (2,)         Start of arm (center).     arm_end : array-like, shape (2,)         End of arm.     field_size : float         Spatial scale of place field.      Returns     -------     spike_counts : ndarray, shape (n_samples,)         Spikes at each position.     \"\"\"     # Check if position is on the arm and moving in correct direction     arm_direction = arm_end - arm_start     arm_direction = arm_direction / np.linalg.norm(arm_direction)      # Field center is 2/3 along the arm     field_center = arm_start + 0.67 * (arm_end - arm_start)      spike_counts = np.zeros(len(position_data))      for i in range(1, len(position_data)):         # Distance to field center         distance = np.linalg.norm(position_data[i] - field_center)          # Movement direction         movement = position_data[i] - position_data[i - 1]         if np.linalg.norm(movement) &gt; 0.1:             movement_dir = movement / np.linalg.norm(movement)              # Check if moving toward arm end             alignment = np.dot(movement_dir, arm_direction)              if alignment &gt; 0.5 and distance &lt; field_size:                 # Fire based on distance                 firing_rate = 30.0 * np.exp(-(distance**2) / (2 * field_size**2))                 spike_counts[i] = np.random.poisson(firing_rate * 0.05)      return spike_counts   # Simulate a cell that fires only when going TO north arm (not returning) north_cell_spikes = simulate_trajectory_specific_cell(     plus_maze_data, center, north_end, field_size=15.0 )  print(f\"Generated {north_cell_spikes.sum()} spikes\") print(f\"Mean firing rate: {north_cell_spikes.mean() / 0.05:.2f} Hz\") <pre>Generated 70.0 spikes\nMean firing rate: 1.75 Hz\n</pre> In\u00a0[14]: Copied! <pre># Visualize spikes on 2D trajectory\nfig, ax = plt.subplots(figsize=(10, 10))\n\n# Draw maze structure\nax.plot(\n    [center[0], north_end[0]], [center[1], north_end[1]], \"k-\", linewidth=8, alpha=0.2\n)\nax.plot(\n    [center[0], south_end[0]], [center[1], south_end[1]], \"k-\", linewidth=8, alpha=0.2\n)\nax.plot(\n    [west_end[0], east_end[0]], [center[1], center[1]], \"k-\", linewidth=8, alpha=0.2\n)\n\n# Plot trajectory\nax.plot(plus_maze_data[:, 0], plus_maze_data[:, 1], \"gray\", alpha=0.3, linewidth=1)\n\n# Highlight spike locations\nspike_indices = np.where(north_cell_spikes &gt; 0)[0]\nspike_positions = plus_maze_data[spike_indices]\n\nax.scatter(\n    spike_positions[:, 0],\n    spike_positions[:, 1],\n    c=\"red\",\n    s=100,\n    alpha=0.8,\n    marker=\"o\",\n    edgecolors=\"black\",\n    linewidth=1,\n    label=f\"Spikes (n={len(spike_indices)})\",\n)\n\nax.plot(center[0], center[1], \"k*\", markersize=20, label=\"Center\")\nax.plot(north_end[0], north_end[1], \"go\", markersize=15, label=\"North arm\")\n\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(\"Trajectory-Specific Cell: Fires on North Arm (outbound only)\")\nax.set_aspect(\"equal\")\nax.legend()\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nNotice: Cell fires specifically when animal moves toward north arm\")\nprint(\"But NOT when returning from north arm through the same physical space!\")\n</pre> # Visualize spikes on 2D trajectory fig, ax = plt.subplots(figsize=(10, 10))  # Draw maze structure ax.plot(     [center[0], north_end[0]], [center[1], north_end[1]], \"k-\", linewidth=8, alpha=0.2 ) ax.plot(     [center[0], south_end[0]], [center[1], south_end[1]], \"k-\", linewidth=8, alpha=0.2 ) ax.plot(     [west_end[0], east_end[0]], [center[1], center[1]], \"k-\", linewidth=8, alpha=0.2 )  # Plot trajectory ax.plot(plus_maze_data[:, 0], plus_maze_data[:, 1], \"gray\", alpha=0.3, linewidth=1)  # Highlight spike locations spike_indices = np.where(north_cell_spikes &gt; 0)[0] spike_positions = plus_maze_data[spike_indices]  ax.scatter(     spike_positions[:, 0],     spike_positions[:, 1],     c=\"red\",     s=100,     alpha=0.8,     marker=\"o\",     edgecolors=\"black\",     linewidth=1,     label=f\"Spikes (n={len(spike_indices)})\", )  ax.plot(center[0], center[1], \"k*\", markersize=20, label=\"Center\") ax.plot(north_end[0], north_end[1], \"go\", markersize=15, label=\"North arm\")  ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(\"Trajectory-Specific Cell: Fires on North Arm (outbound only)\") ax.set_aspect(\"equal\") ax.legend() ax.grid(True, alpha=0.3) plt.tight_layout() plt.show()  print(\"\\nNotice: Cell fires specifically when animal moves toward north arm\") print(\"But NOT when returning from north arm through the same physical space!\") <pre>\nNotice: Cell fires specifically when animal moves toward north arm\nBut NOT when returning from north arm through the same physical space!\n</pre> In\u00a0[15]: Copied! <pre># Create 2D environment (wrong for this analysis!)\nenv_2d = Environment.from_samples(\n    data_samples=plus_maze_data, bin_size=8.0, name=\"PlusMaze2D\"\n)\n\n# Map to bins\nbin_indices_2d = env_2d.bin_at(plus_maze_data)\n\n# Compute firing rate\nspike_counts_per_bin = np.bincount(\n    bin_indices_2d[bin_indices_2d &gt;= 0],\n    weights=north_cell_spikes[bin_indices_2d &gt;= 0],\n    minlength=env_2d.n_bins,\n)\n\noccupancy_per_bin = (\n    np.bincount(bin_indices_2d[bin_indices_2d &gt;= 0], minlength=env_2d.n_bins) * 0.05\n)\n\nfiring_rate_2d = np.divide(\n    spike_counts_per_bin,\n    occupancy_per_bin,\n    where=occupancy_per_bin &gt; 0,\n    out=np.zeros_like(spike_counts_per_bin, dtype=float),\n)\n\nprint(f\"2D firing rate map: {env_2d.n_bins} bins\")\nprint(f\"Peak firing rate: {firing_rate_2d.max():.2f} Hz\")\n</pre> # Create 2D environment (wrong for this analysis!) env_2d = Environment.from_samples(     data_samples=plus_maze_data, bin_size=8.0, name=\"PlusMaze2D\" )  # Map to bins bin_indices_2d = env_2d.bin_at(plus_maze_data)  # Compute firing rate spike_counts_per_bin = np.bincount(     bin_indices_2d[bin_indices_2d &gt;= 0],     weights=north_cell_spikes[bin_indices_2d &gt;= 0],     minlength=env_2d.n_bins, )  occupancy_per_bin = (     np.bincount(bin_indices_2d[bin_indices_2d &gt;= 0], minlength=env_2d.n_bins) * 0.05 )  firing_rate_2d = np.divide(     spike_counts_per_bin,     occupancy_per_bin,     where=occupancy_per_bin &gt; 0,     out=np.zeros_like(spike_counts_per_bin, dtype=float), )  print(f\"2D firing rate map: {env_2d.n_bins} bins\") print(f\"Peak firing rate: {firing_rate_2d.max():.2f} Hz\") <pre>2D firing rate map: 44 bins\nPeak firing rate: 18.46 Hz\n</pre> In\u00a0[16]: Copied! <pre># Visualize 2D firing rate (problematic)\nfig, ax = plt.subplots(figsize=(10, 10))\n\n# Plot firing rate\nactive_bins = firing_rate_2d &gt; 0\nscatter = ax.scatter(\n    env_2d.bin_centers[active_bins, 0],\n    env_2d.bin_centers[active_bins, 1],\n    c=firing_rate_2d[active_bins],\n    s=400,\n    cmap=\"hot\",\n    marker=\"s\",\n    edgecolors=\"black\",\n    linewidth=1,\n)\n\n# Draw maze structure\nax.plot(\n    [center[0], north_end[0]], [center[1], north_end[1]], \"b-\", linewidth=3, alpha=0.3\n)\nax.plot(\n    [center[0], south_end[0]], [center[1], south_end[1]], \"b-\", linewidth=3, alpha=0.3\n)\nax.plot(\n    [west_end[0], east_end[0]], [center[1], center[1]], \"b-\", linewidth=3, alpha=0.3\n)\n\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(\"2D Firing Rate Map (WRONG: averages over trajectories!)\")\nax.set_aspect(\"equal\")\nplt.colorbar(scatter, ax=ax, label=\"Firing Rate (Hz)\")\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nProblem: 2D map averages over outbound and inbound journeys\")\nprint(\"Result: Diluted place field, lost trajectory information\")\n</pre> # Visualize 2D firing rate (problematic) fig, ax = plt.subplots(figsize=(10, 10))  # Plot firing rate active_bins = firing_rate_2d &gt; 0 scatter = ax.scatter(     env_2d.bin_centers[active_bins, 0],     env_2d.bin_centers[active_bins, 1],     c=firing_rate_2d[active_bins],     s=400,     cmap=\"hot\",     marker=\"s\",     edgecolors=\"black\",     linewidth=1, )  # Draw maze structure ax.plot(     [center[0], north_end[0]], [center[1], north_end[1]], \"b-\", linewidth=3, alpha=0.3 ) ax.plot(     [center[0], south_end[0]], [center[1], south_end[1]], \"b-\", linewidth=3, alpha=0.3 ) ax.plot(     [west_end[0], east_end[0]], [center[1], center[1]], \"b-\", linewidth=3, alpha=0.3 )  ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(\"2D Firing Rate Map (WRONG: averages over trajectories!)\") ax.set_aspect(\"equal\") plt.colorbar(scatter, ax=ax, label=\"Firing Rate (Hz)\") plt.tight_layout() plt.show()  print(\"\\nProblem: 2D map averages over outbound and inbound journeys\") print(\"Result: Diluted place field, lost trajectory information\") <pre>\nProblem: 2D map averages over outbound and inbound journeys\nResult: Diluted place field, lost trajectory information\n</pre> In\u00a0[17]: Copied! <pre>if env_plus is not None and env_plus.is_1d:\n    # Map to 1D bins\n    bin_indices_1d = env_plus.bin_at(plus_maze_data)\n\n    # Compute firing rate in 1D\n    spike_counts_per_bin_1d = np.bincount(\n        bin_indices_1d[bin_indices_1d &gt;= 0],\n        weights=north_cell_spikes[bin_indices_1d &gt;= 0],\n        minlength=env_plus.n_bins,\n    )\n\n    occupancy_per_bin_1d = (\n        np.bincount(bin_indices_1d[bin_indices_1d &gt;= 0], minlength=env_plus.n_bins)\n        * 0.05\n    )\n\n    firing_rate_1d = np.divide(\n        spike_counts_per_bin_1d,\n        occupancy_per_bin_1d,\n        where=occupancy_per_bin_1d &gt; 0,\n        out=np.zeros_like(spike_counts_per_bin_1d, dtype=float),\n    )\n\n    print(f\"1D firing rate map: {env_plus.n_bins} bins\")\n    print(f\"Peak firing rate: {firing_rate_1d.max():.2f} Hz\")\n    print(\"\\nNotice: Peak rate is higher (not diluted by averaging)\")\nelse:\n    print(\"Skipping 1D analysis (track-linearization not available)\")\n</pre> if env_plus is not None and env_plus.is_1d:     # Map to 1D bins     bin_indices_1d = env_plus.bin_at(plus_maze_data)      # Compute firing rate in 1D     spike_counts_per_bin_1d = np.bincount(         bin_indices_1d[bin_indices_1d &gt;= 0],         weights=north_cell_spikes[bin_indices_1d &gt;= 0],         minlength=env_plus.n_bins,     )      occupancy_per_bin_1d = (         np.bincount(bin_indices_1d[bin_indices_1d &gt;= 0], minlength=env_plus.n_bins)         * 0.05     )      firing_rate_1d = np.divide(         spike_counts_per_bin_1d,         occupancy_per_bin_1d,         where=occupancy_per_bin_1d &gt; 0,         out=np.zeros_like(spike_counts_per_bin_1d, dtype=float),     )      print(f\"1D firing rate map: {env_plus.n_bins} bins\")     print(f\"Peak firing rate: {firing_rate_1d.max():.2f} Hz\")     print(\"\\nNotice: Peak rate is higher (not diluted by averaging)\") else:     print(\"Skipping 1D analysis (track-linearization not available)\") <pre>1D firing rate map: 32 bins\nPeak firing rate: 13.60 Hz\n\nNotice: Peak rate is higher (not diluted by averaging)\n</pre> In\u00a0[18]: Copied! <pre>if env_plus is not None and env_plus.is_1d:\n    # Visualize 1D firing rate\n    fig, ax = plt.subplots(figsize=(14, 5))\n\n    # Get linear positions\n    linear_pos = env_plus.to_linear(plus_maze_data)\n\n    # Plot firing rate as function of linear position\n    bin_linear_positions = np.arange(env_plus.n_bins)\n\n    ax.bar(\n        bin_linear_positions,\n        firing_rate_1d,\n        width=1.0,\n        color=\"red\",\n        alpha=0.7,\n        edgecolor=\"black\",\n        linewidth=1,\n    )\n\n    ax.set_xlabel(\"Linear Position (bin index)\")\n    ax.set_ylabel(\"Firing Rate (Hz)\")\n    ax.set_title(\"1D Linearized Firing Rate (CORRECT: preserves trajectory)\")\n    ax.grid(axis=\"y\", alpha=0.3)\n\n    plt.tight_layout()\n    plt.show()\n\n    print(\"\\nSuccess: Clear, localized place field on north arm\")\n    print(\"Outbound and inbound trajectories are separated!\")\nelse:\n    print(\"Skipping visualization (track-linearization not available)\")\n</pre> if env_plus is not None and env_plus.is_1d:     # Visualize 1D firing rate     fig, ax = plt.subplots(figsize=(14, 5))      # Get linear positions     linear_pos = env_plus.to_linear(plus_maze_data)      # Plot firing rate as function of linear position     bin_linear_positions = np.arange(env_plus.n_bins)      ax.bar(         bin_linear_positions,         firing_rate_1d,         width=1.0,         color=\"red\",         alpha=0.7,         edgecolor=\"black\",         linewidth=1,     )      ax.set_xlabel(\"Linear Position (bin index)\")     ax.set_ylabel(\"Firing Rate (Hz)\")     ax.set_title(\"1D Linearized Firing Rate (CORRECT: preserves trajectory)\")     ax.grid(axis=\"y\", alpha=0.3)      plt.tight_layout()     plt.show()      print(\"\\nSuccess: Clear, localized place field on north arm\")     print(\"Outbound and inbound trajectories are separated!\") else:     print(\"Skipping visualization (track-linearization not available)\") <pre>\nSuccess: Clear, localized place field on north arm\nOutbound and inbound trajectories are separated!\n</pre> In\u00a0[19]: Copied! <pre># Always check before calling linearization methods!\n\n\ndef safe_linearize(env, position):\n    \"\"\"\n    Safely convert to linear position.\n\n    Parameters\n    ----------\n    env : Environment\n        Environment instance.\n    position : ndarray\n        Position data.\n\n    Returns\n    -------\n    linear_position : ndarray or None\n        Linear position if 1D, None otherwise.\n    \"\"\"\n    if env.is_1d:\n        return env.to_linear(position)\n    else:\n        print(f\"Warning: {env.name} is not 1D (is {env.n_dims}D)\")\n        print(\"Use bin_at() instead for spatial binning\")\n        return None\n\n\n# Test\nprint(\"Testing 2D environment:\")\nresult = safe_linearize(env_2d, plus_maze_data[:10])\n\nif env_plus is not None:\n    print(\"\\nTesting 1D environment:\")\n    result = safe_linearize(env_plus, plus_maze_data[:10])\n    print(f\"Linear positions: {result}\")\n</pre> # Always check before calling linearization methods!   def safe_linearize(env, position):     \"\"\"     Safely convert to linear position.      Parameters     ----------     env : Environment         Environment instance.     position : ndarray         Position data.      Returns     -------     linear_position : ndarray or None         Linear position if 1D, None otherwise.     \"\"\"     if env.is_1d:         return env.to_linear(position)     else:         print(f\"Warning: {env.name} is not 1D (is {env.n_dims}D)\")         print(\"Use bin_at() instead for spatial binning\")         return None   # Test print(\"Testing 2D environment:\") result = safe_linearize(env_2d, plus_maze_data[:10])  if env_plus is not None:     print(\"\\nTesting 1D environment:\")     result = safe_linearize(env_plus, plus_maze_data[:10])     print(f\"Linear positions: {result}\") <pre>Testing 2D environment:\nWarning: PlusMaze2D is not 1D (is 2D)\nUse bin_at() instead for spatial binning\n\nTesting 1D environment:\nLinear positions: [79.53768316 79.91942798 78.9951765  78.47029289 78.65145599 77.88099818\n 77.92035148 77.07276178 77.00961968 76.15155339]\n</pre> In\u00a0[20]: Copied! <pre># \u2717 WRONG - Don't call to_linear() on non-1D environments\ntry:\n    linear = env_2d.to_linear(plus_maze_data[:10])\nexcept TypeError as e:\n    print(f\"Error: {e}\")\n    print(\"\\nAlways check env.is_1d before calling to_linear()!\")\n\n# \u2713 CORRECT\nif env_2d.is_1d:\n    linear = env_2d.to_linear(plus_maze_data[:10])\nelse:\n    print(\"Using spatial binning instead\")\n    bins = env_2d.bin_at(plus_maze_data[:10])\n</pre> # \u2717 WRONG - Don't call to_linear() on non-1D environments try:     linear = env_2d.to_linear(plus_maze_data[:10]) except TypeError as e:     print(f\"Error: {e}\")     print(\"\\nAlways check env.is_1d before calling to_linear()!\")  # \u2713 CORRECT if env_2d.is_1d:     linear = env_2d.to_linear(plus_maze_data[:10]) else:     print(\"Using spatial binning instead\")     bins = env_2d.bin_at(plus_maze_data[:10]) <pre>Error: Linearized coordinate only for GraphLayout environments.\n\nAlways check env.is_1d before calling to_linear()!\nUsing spatial binning instead\n</pre>"},{"location":"examples/05_track_linearization/#track-linearization-working-with-1d-environments","title":"Track Linearization: Working with 1D Environments\u00b6","text":""},{"location":"examples/05_track_linearization/#learning-objectives","title":"Learning Objectives\u00b6","text":"<p>By the end of this notebook, you will be able to:</p> <ul> <li>Understand when and why to use 1D linearization</li> <li>Create linearized track environments with GraphLayout</li> <li>Convert between N-D position coordinates and 1D linear position</li> <li>Work with complex maze structures (plus maze, figure-8)</li> <li>Understand the difference between 1D and N-D environments</li> <li>Use linearization for trajectory-dependent neural analysis</li> </ul> <p>Estimated time: 25-30 minutes</p>"},{"location":"examples/05_track_linearization/#why-1d-linearization","title":"Why 1D Linearization?\u00b6","text":"<p>Many experiments use track-based environments where movement is constrained to specific paths:</p> <ul> <li>Linear tracks: Simple back-and-forth running</li> <li>W-tracks / Z-tracks: Alternation tasks</li> <li>Plus mazes: Four-arm radial structures</li> <li>Figure-8 mazes: Continuous alternation</li> <li>T-mazes: Left/right choice tasks</li> </ul> <p>For these environments, linearization maps 2D positions onto a 1D track coordinate. This is essential for:</p> <ul> <li>Trajectory-dependent analysis: Distinguish left vs right journeys on the same physical location</li> <li>Place field analysis: Better capture spatially-tuned neurons on tracks</li> <li>Sequence detection: Identify replay and theta sequences</li> <li>Directional coding: Separate opposing movement directions</li> </ul> <p>The <code>GraphLayout</code> engine handles this automatically!</p>"},{"location":"examples/05_track_linearization/#setup","title":"Setup\u00b6","text":""},{"location":"examples/05_track_linearization/#example-1-simple-linear-track","title":"Example 1: Simple Linear Track\u00b6","text":"<p>Let's start with the simplest case: a straight linear track.</p>"},{"location":"examples/05_track_linearization/#creating-a-linearized-environment","title":"Creating a Linearized Environment\u00b6","text":"<p>To create a 1D linearized environment, use <code>Environment.from_graph()</code>. This requires the <code>track-linearization</code> package.</p> <p>Note: The <code>from_graph()</code> method automatically handles track linearization for you.</p>"},{"location":"examples/05_track_linearization/#understanding-1d-vs-2d-environments","title":"Understanding 1D vs 2D Environments\u00b6","text":"<p>The key difference:</p> <ul> <li>2D/N-D Environment: Bins represent regions in physical space</li> <li>1D Environment: Bins represent positions along a trajectory</li> </ul> <p>Critical insight: On a linear track, the same physical location (e.g., X=50 cm) is visited twice per lap (going left vs going right). A 1D linearized environment gives these different bin indices based on trajectory!</p>"},{"location":"examples/05_track_linearization/#converting-between-n-d-and-linear-coordinates","title":"Converting Between N-D and Linear Coordinates\u00b6","text":"<p>1D environments provide special methods:</p> <ul> <li><code>to_linear(nd_position)</code>: Convert 2D position \u2192 1D linear coordinate</li> <li><code>linear_to_nd(linear_position)</code>: Convert 1D coordinate \u2192 2D position</li> </ul> <p>These methods consider trajectory, not just spatial location!</p>"},{"location":"examples/05_track_linearization/#example-2-plus-maze","title":"Example 2: Plus Maze\u00b6","text":"<p>Now let's look at a more complex structure: a plus maze with four arms.</p>"},{"location":"examples/05_track_linearization/#creating-plus-maze-environment-with-graph","title":"Creating Plus Maze Environment with Graph\u00b6","text":"<p>For complex mazes, you can provide an explicit track graph structure:</p>"},{"location":"examples/05_track_linearization/#why-linearization-matters-neural-analysis-example","title":"Why Linearization Matters: Neural Analysis Example\u00b6","text":"<p>Let's demonstrate why linearization is crucial for neural analysis on tracks.</p>"},{"location":"examples/05_track_linearization/#problem-2d-analysis-misses-trajectory-dependence","title":"Problem: 2D Analysis Misses Trajectory Dependence\u00b6","text":"<p>If we compute a firing rate map in 2D space, we lose the trajectory information:</p>"},{"location":"examples/05_track_linearization/#solution-1d-linearization-preserves-trajectory","title":"Solution: 1D Linearization Preserves Trajectory\u00b6","text":"<p>Now let's see how 1D linearization handles this correctly:</p>"},{"location":"examples/05_track_linearization/#when-to-use-1d-vs-n-d-environments","title":"When to Use 1D vs N-D Environments\u00b6","text":"Use 1D (GraphLayout) Use N-D (GridLayout) Linear tracks Open field arenas Mazes with defined paths Water mazes Track-based tasks Free exploration Trajectory-dependent analysis Purely spatial analysis Sequence detection Grid cell analysis Theta sequences, replay Head direction independence <p>Key question: Does your analysis care about the trajectory/history, or just current location?</p> <ul> <li>Trajectory matters \u2192 Use 1D linearization</li> <li>Location only \u2192 Use N-D grids</li> </ul>"},{"location":"examples/05_track_linearization/#checking-if-environment-is-1d","title":"Checking if Environment is 1D\u00b6","text":""},{"location":"examples/05_track_linearization/#common-pitfalls","title":"Common Pitfalls\u00b6","text":""},{"location":"examples/05_track_linearization/#pitfall-1-calling-linearization-methods-on-n-d-environments","title":"Pitfall 1: Calling linearization methods on N-D environments\u00b6","text":""},{"location":"examples/05_track_linearization/#pitfall-2-using-2d-environments-for-trajectory-dependent-analysis","title":"Pitfall 2: Using 2D environments for trajectory-dependent analysis\u00b6","text":"<p>As we saw, this averages over different trajectories and loses information!</p>"},{"location":"examples/05_track_linearization/#pitfall-3-not-providing-track_graph-for-complex-mazes","title":"Pitfall 3: Not providing track_graph for complex mazes\u00b6","text":"<p>For simple tracks, auto-inference works. For complex mazes with branches, provide an explicit graph structure to ensure correct topology.</p>"},{"location":"examples/05_track_linearization/#pitfall-4-forgetting-that-linearization-is-trajectory-dependent","title":"Pitfall 4: Forgetting that linearization is trajectory-dependent\u00b6","text":"<p>The same physical location maps to different linear positions depending on trajectory! This is a feature, not a bug.</p>"},{"location":"examples/05_track_linearization/#key-takeaways","title":"Key Takeaways\u00b6","text":"<ol> <li>1D linearization maps 2D/3D positions onto a 1D track coordinate</li> <li>GraphLayout creates 1D linearized environments (requires <code>track-linearization</code>)</li> <li>Use <code>from_graph()</code> factory method with position data and optional track structure</li> <li>Trajectory-aware: Same physical location \u2192 different linear positions based on path</li> <li>Essential for track tasks: Plus mazes, T-mazes, linear tracks, figure-8s</li> <li>Check <code>env.is_1d</code> before calling linearization methods</li> <li>Methods:<ul> <li><code>to_linear(nd_position)</code> - Convert to 1D</li> <li><code>linear_to_nd(linear_position)</code> - Convert back to N-D</li> </ul> </li> <li>Benefits: Trajectory-dependent analysis, sequence detection, better place fields</li> </ol>"},{"location":"examples/05_track_linearization/#next-steps","title":"Next Steps\u00b6","text":"<p>You've completed the core tutorial series! You now know:</p> <ol> <li>\u2713 Basics (notebook 01) - Creating environments, spatial queries</li> <li>\u2713 Layout engines (notebook 02) - Regular, hexagonal, polygon-bounded</li> <li>\u2713 Morphological operations (notebook 03) - Handling sparse data</li> <li>\u2713 Regions (notebook 04) - Defining and analyzing zones</li> <li>\u2713 Linearization (notebook 05) - 1D track analysis</li> </ol> <p>Advanced topics to explore:</p> <ul> <li>CompositeEnvironment (merging multiple environments)</li> <li>Alignment and transformations (mapping between environments)</li> <li>Custom layout engines (specialized discretizations)</li> <li>Integration with neural data pipelines</li> </ul> <p>Check the documentation and examples directory for more!</p>"},{"location":"examples/05_track_linearization/#exercises-optional","title":"Exercises (Optional)\u00b6","text":"<ol> <li>Create a figure-8 maze with explicit track graph</li> <li>Simulate a place cell that fires on one arm but not others</li> <li>Compare 2D vs 1D occupancy normalization for the same cell</li> <li>Create a W-track environment and analyze directional place fields</li> </ol>"},{"location":"examples/06_composite_environments/","title":"Composite Environments: Merging Multiple Spaces","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport networkx as nx\nimport numpy as np\nfrom shapely.geometry import Point\n\nfrom neurospatial import Environment\nfrom neurospatial.composite import CompositeEnvironment\n\nnp.random.seed(42)\nplt.rcParams[\"figure.figsize\"] = (14, 10)\nplt.rcParams[\"font.size\"] = 11\n</pre> import matplotlib.pyplot as plt import networkx as nx import numpy as np from shapely.geometry import Point  from neurospatial import Environment from neurospatial.composite import CompositeEnvironment  np.random.seed(42) plt.rcParams[\"figure.figsize\"] = (14, 10) plt.rcParams[\"font.size\"] = 11 In\u00a0[2]: Copied! <pre># Room 1: 50x50 cm square arena\n# Simulate exploration with clustering in center\nn_samples_room1 = 2000\nroom1_data = np.random.randn(n_samples_room1, 2) * 8 + np.array([25, 25])\nroom1_data = np.clip(room1_data, 5, 45)\n\nenv_room1 = Environment.from_samples(\n    data_samples=room1_data, bin_size=4.0, name=\"Room1\"\n)\n\n# Room 2: Different location, 40x60 cm rectangular arena\nn_samples_room2 = 1500\nroom2_data = np.random.uniform(low=[60, 10], high=[95, 65], size=(n_samples_room2, 2))\n\nenv_room2 = Environment.from_samples(\n    data_samples=room2_data, bin_size=4.0, name=\"Room2\"\n)\n\nprint(f\"Room 1: {env_room1.n_bins} bins, range {env_room1.dimension_ranges}\")\nprint(f\"Room 2: {env_room2.n_bins} bins, range {env_room2.dimension_ranges}\")\n</pre> # Room 1: 50x50 cm square arena # Simulate exploration with clustering in center n_samples_room1 = 2000 room1_data = np.random.randn(n_samples_room1, 2) * 8 + np.array([25, 25]) room1_data = np.clip(room1_data, 5, 45)  env_room1 = Environment.from_samples(     data_samples=room1_data, bin_size=4.0, name=\"Room1\" )  # Room 2: Different location, 40x60 cm rectangular arena n_samples_room2 = 1500 room2_data = np.random.uniform(low=[60, 10], high=[95, 65], size=(n_samples_room2, 2))  env_room2 = Environment.from_samples(     data_samples=room2_data, bin_size=4.0, name=\"Room2\" )  print(f\"Room 1: {env_room1.n_bins} bins, range {env_room1.dimension_ranges}\") print(f\"Room 2: {env_room2.n_bins} bins, range {env_room2.dimension_ranges}\") <pre>Room 1: 109 bins, range ((np.float64(3.0), np.float64(47.0)), (np.float64(3.0), np.float64(47.0)))\nRoom 2: 150 bins, range ((np.float64(58.02763288826266), np.float64(96.97726051652701)), (np.float64(8.0132552576824), np.float64(66.97033745828202)))\n</pre> In\u00a0[3]: Copied! <pre># Visualize the two rooms separately\nfig, axes = plt.subplots(1, 2, figsize=(16, 7))\n\nenv_room1.plot(ax=axes[0], show_connectivity=True)\naxes[0].set_title(f\"Room 1 ({env_room1.n_bins} bins)\")\naxes[0].set_aspect(\"equal\")\n\nenv_room2.plot(ax=axes[1], show_connectivity=True)\naxes[1].set_title(f\"Room 2 ({env_room2.n_bins} bins)\")\naxes[1].set_aspect(\"equal\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Visualize the two rooms separately fig, axes = plt.subplots(1, 2, figsize=(16, 7))  env_room1.plot(ax=axes[0], show_connectivity=True) axes[0].set_title(f\"Room 1 ({env_room1.n_bins} bins)\") axes[0].set_aspect(\"equal\")  env_room2.plot(ax=axes[1], show_connectivity=True) axes[1].set_title(f\"Room 2 ({env_room2.n_bins} bins)\") axes[1].set_aspect(\"equal\")  plt.tight_layout() plt.show() In\u00a0[4]: Copied! <pre># Create composite environment with automatic bridge inference\ncomposite_env = CompositeEnvironment(\n    subenvs=[env_room1, env_room2],\n    auto_bridge=True,  # Automatically connect nearest bins\n    max_mnn_distance=None,  # No distance limit (we'll explore this later)\n)\n\nprint(\"Composite Environment Created!\")\nprint(f\"  Total bins: {composite_env.n_bins}\")\nprint(f\"  Sub-environments: {len(composite_env._subenvs_info)}\")\nprint(f\"  Bridge edges: {len(composite_env._bridge_list)}\")\nprint(f\"  Total edges: {composite_env.connectivity.number_of_edges()}\")\n</pre> # Create composite environment with automatic bridge inference composite_env = CompositeEnvironment(     subenvs=[env_room1, env_room2],     auto_bridge=True,  # Automatically connect nearest bins     max_mnn_distance=None,  # No distance limit (we'll explore this later) )  print(\"Composite Environment Created!\") print(f\"  Total bins: {composite_env.n_bins}\") print(f\"  Sub-environments: {len(composite_env._subenvs_info)}\") print(f\"  Bridge edges: {len(composite_env._bridge_list)}\") print(f\"  Total edges: {composite_env.connectivity.number_of_edges()}\") <pre>Composite Environment Created!\n  Total bins: 259\n  Sub-environments: 2\n  Bridge edges: 8\n  Total edges: 904\n</pre> In\u00a0[5]: Copied! <pre># Examine the bridges in detail\nprint(f\"\\nBridge Details ({len(composite_env._bridge_list)} total):\")\nfor i, ((i_env, i_bin), (j_env, j_bin), distance) in enumerate(\n    composite_env._bridge_list[:5]\n):  # Show first 5\n    # Get composite bin indices\n    bin1 = composite_env._subenvs_info[i_env][\"start_idx\"] + i_bin\n    bin2 = composite_env._subenvs_info[j_env][\"start_idx\"] + j_bin\n    pos1 = composite_env.bin_centers[bin1]\n    pos2 = composite_env.bin_centers[bin2]\n    print(\n        f\"  Bridge {i}: Bin {bin1} {pos1} \u2194 Bin {bin2} {pos2}, distance={distance:.2f} cm\"\n    )\n</pre> # Examine the bridges in detail print(f\"\\nBridge Details ({len(composite_env._bridge_list)} total):\") for i, ((i_env, i_bin), (j_env, j_bin), distance) in enumerate(     composite_env._bridge_list[:5] ):  # Show first 5     # Get composite bin indices     bin1 = composite_env._subenvs_info[i_env][\"start_idx\"] + i_bin     bin2 = composite_env._subenvs_info[j_env][\"start_idx\"] + j_bin     pos1 = composite_env.bin_centers[bin1]     pos2 = composite_env.bin_centers[bin2]     print(         f\"  Bridge {i}: Bin {bin1} {pos1} \u2194 Bin {bin2} {pos2}, distance={distance:.2f} cm\"     ) <pre>\nBridge Details (8 total):\n  Bridge 0: Bin 101 [45.  9.] \u2194 Bin 109 [59.97511427  9.97849133], distance=15.01 cm\n  Bridge 1: Bin 102 [45. 13.] \u2194 Bin 110 [59.97511427 13.90896348], distance=15.00 cm\n  Bridge 2: Bin 103 [45. 17.] \u2194 Bin 111 [59.97511427 17.83943562], distance=15.00 cm\n  Bridge 3: Bin 104 [45. 21.] \u2194 Bin 112 [59.97511427 21.76990777], distance=14.99 cm\n  Bridge 4: Bin 105 [45. 25.] \u2194 Bin 113 [59.97511427 25.70037992], distance=14.99 cm\n</pre> In\u00a0[6]: Copied! <pre># Visualize the composite with bridges highlighted\nfig, ax = plt.subplots(figsize=(14, 10))\n\n# Plot all bins\nax.scatter(\n    composite_env.bin_centers[:, 0],\n    composite_env.bin_centers[:, 1],\n    c=\"lightblue\",\n    s=100,\n    alpha=0.6,\n    label=\"Bins\",\n)\n\n# Convert bridge list to set of edges for fast lookup\nbridge_edges = set()\nfor (i_env, i_bin), (j_env, j_bin), _ in composite_env._bridge_list:\n    bin1 = composite_env._subenvs_info[i_env][\"start_idx\"] + i_bin\n    bin2 = composite_env._subenvs_info[j_env][\"start_idx\"] + j_bin\n    bridge_edges.add((min(bin1, bin2), max(bin1, bin2)))\n\n# Draw regular edges (within environments) in gray\nfor edge in composite_env.connectivity.edges():\n    edge_key = (min(edge[0], edge[1]), max(edge[0], edge[1]))\n    if edge_key not in bridge_edges:\n        pos1 = composite_env.bin_centers[edge[0]]\n        pos2 = composite_env.bin_centers[edge[1]]\n        ax.plot(\n            [pos1[0], pos2[0]], [pos1[1], pos2[1]], \"gray\", alpha=0.1, linewidth=0.5\n        )\n\n# Highlight bridge edges in red\nfor i, ((i_env, i_bin), (j_env, j_bin), _) in enumerate(composite_env._bridge_list):\n    bin1 = composite_env._subenvs_info[i_env][\"start_idx\"] + i_bin\n    bin2 = composite_env._subenvs_info[j_env][\"start_idx\"] + j_bin\n    pos1 = composite_env.bin_centers[bin1]\n    pos2 = composite_env.bin_centers[bin2]\n    ax.plot(\n        [pos1[0], pos2[0]],\n        [pos1[1], pos2[1]],\n        \"r-\",\n        linewidth=2.5,\n        alpha=0.8,\n        label=\"Bridge\" if i == 0 else \"\",\n    )\n\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(f\"Composite Environment with {len(composite_env._bridge_list)} Bridges\")\nax.legend()\nax.set_aspect(\"equal\")\nplt.tight_layout()\nplt.show()\n</pre> # Visualize the composite with bridges highlighted fig, ax = plt.subplots(figsize=(14, 10))  # Plot all bins ax.scatter(     composite_env.bin_centers[:, 0],     composite_env.bin_centers[:, 1],     c=\"lightblue\",     s=100,     alpha=0.6,     label=\"Bins\", )  # Convert bridge list to set of edges for fast lookup bridge_edges = set() for (i_env, i_bin), (j_env, j_bin), _ in composite_env._bridge_list:     bin1 = composite_env._subenvs_info[i_env][\"start_idx\"] + i_bin     bin2 = composite_env._subenvs_info[j_env][\"start_idx\"] + j_bin     bridge_edges.add((min(bin1, bin2), max(bin1, bin2)))  # Draw regular edges (within environments) in gray for edge in composite_env.connectivity.edges():     edge_key = (min(edge[0], edge[1]), max(edge[0], edge[1]))     if edge_key not in bridge_edges:         pos1 = composite_env.bin_centers[edge[0]]         pos2 = composite_env.bin_centers[edge[1]]         ax.plot(             [pos1[0], pos2[0]], [pos1[1], pos2[1]], \"gray\", alpha=0.1, linewidth=0.5         )  # Highlight bridge edges in red for i, ((i_env, i_bin), (j_env, j_bin), _) in enumerate(composite_env._bridge_list):     bin1 = composite_env._subenvs_info[i_env][\"start_idx\"] + i_bin     bin2 = composite_env._subenvs_info[j_env][\"start_idx\"] + j_bin     pos1 = composite_env.bin_centers[bin1]     pos2 = composite_env.bin_centers[bin2]     ax.plot(         [pos1[0], pos2[0]],         [pos1[1], pos2[1]],         \"r-\",         linewidth=2.5,         alpha=0.8,         label=\"Bridge\" if i == 0 else \"\",     )  ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(f\"Composite Environment with {len(composite_env._bridge_list)} Bridges\") ax.legend() ax.set_aspect(\"equal\") plt.tight_layout() plt.show() In\u00a0[7]: Copied! <pre># Test points in different rooms\ntest_points = np.array(\n    [\n        [25.0, 25.0],  # Center of Room 1\n        [75.0, 40.0],  # Center of Room 2\n        [50.0, 50.0],  # Between rooms (outside both)\n    ]\n)\n\n# Map to bins\nbin_indices = composite_env.bin_at(test_points)\nis_contained = composite_env.contains(test_points)\n\nprint(\"\\nSpatial Queries:\")\nfor _i, (point, bin_idx, contained) in enumerate(\n    zip(test_points, bin_indices, is_contained, strict=False)\n):\n    status = \"\u2713 IN\" if contained else \"\u2717 OUT\"\n    print(f\"  Point {point}: bin={bin_idx}, {status}\")\n</pre> # Test points in different rooms test_points = np.array(     [         [25.0, 25.0],  # Center of Room 1         [75.0, 40.0],  # Center of Room 2         [50.0, 50.0],  # Between rooms (outside both)     ] )  # Map to bins bin_indices = composite_env.bin_at(test_points) is_contained = composite_env.contains(test_points)  print(\"\\nSpatial Queries:\") for _i, (point, bin_idx, contained) in enumerate(     zip(test_points, bin_indices, is_contained, strict=False) ):     status = \"\u2713 IN\" if contained else \"\u2717 OUT\"     print(f\"  Point {point}: bin={bin_idx}, {status}\") <pre>\nSpatial Queries:\n  Point [25. 25.]: bin=53, \u2713 IN\n  Point [75. 40.]: bin=177, \u2713 IN\n  Point [50. 50.]: bin=-1, \u2717 OUT\n</pre> In\u00a0[8]: Copied! <pre># Calculate distance between rooms\n# Pick a bin from each room\npoint_room1 = np.array([25.0, 25.0])\npoint_room2 = np.array([75.0, 40.0])\n\n# Geodesic distance (along the graph, through bridges)\ngeodesic_dist = composite_env.distance_between(point_room1, point_room2)\n\n# Euclidean distance (straight line)\neuclidean_dist = np.linalg.norm(point_room1 - point_room2)\n\nprint(\"\\nDistance from Room 1 center to Room 2 center:\")\nprint(f\"  Euclidean (straight line): {euclidean_dist:.2f} cm\")\nprint(f\"  Geodesic (through graph): {geodesic_dist:.2f} cm\")\nprint(f\"  Difference: {geodesic_dist - euclidean_dist:.2f} cm\")\nprint(\"\\nNote: Geodesic is longer because it follows the connectivity graph.\")\n</pre> # Calculate distance between rooms # Pick a bin from each room point_room1 = np.array([25.0, 25.0]) point_room2 = np.array([75.0, 40.0])  # Geodesic distance (along the graph, through bridges) geodesic_dist = composite_env.distance_between(point_room1, point_room2)  # Euclidean distance (straight line) euclidean_dist = np.linalg.norm(point_room1 - point_room2)  print(\"\\nDistance from Room 1 center to Room 2 center:\") print(f\"  Euclidean (straight line): {euclidean_dist:.2f} cm\") print(f\"  Geodesic (through graph): {geodesic_dist:.2f} cm\") print(f\"  Difference: {geodesic_dist - euclidean_dist:.2f} cm\") print(\"\\nNote: Geodesic is longer because it follows the connectivity graph.\") <pre>\nDistance from Room 1 center to Room 2 center:\n  Euclidean (straight line): 52.20 cm\n  Geodesic (through graph): 57.13 cm\n  Difference: 4.92 cm\n\nNote: Geodesic is longer because it follows the connectivity graph.\n</pre> In\u00a0[9]: Copied! <pre># Create three separate circular arenas at different locations\ndef create_circular_arena(\n    center_x, center_y, radius=15, n_samples=800, bin_size=3.0, name=\"Arena\"\n):\n    \"\"\"Create a circular arena environment.\"\"\"\n    # Generate samples inside circle\n    angles = np.random.uniform(0, 2 * np.pi, n_samples)\n    radii = np.sqrt(np.random.uniform(0, 1, n_samples)) * (radius - 2)\n    np.column_stack(\n        [center_x + radii * np.cos(angles), center_y + radii * np.sin(angles)]\n    )\n\n    # Create environment\n    circle_polygon = Point(center_x, center_y).buffer(radius)\n    return Environment.from_polygon(\n        polygon=circle_polygon, bin_size=bin_size, name=name\n    )\n\n\n# Create three arenas in a line\narena_a = create_circular_arena(20, 50, radius=15, name=\"Arena_A\")\narena_b = create_circular_arena(60, 50, radius=15, name=\"Arena_B\")\narena_c = create_circular_arena(100, 50, radius=15, name=\"Arena_C\")\n\nprint(f\"Arena A: {arena_a.n_bins} bins\")\nprint(f\"Arena B: {arena_b.n_bins} bins\")\nprint(f\"Arena C: {arena_c.n_bins} bins\")\n</pre> # Create three separate circular arenas at different locations def create_circular_arena(     center_x, center_y, radius=15, n_samples=800, bin_size=3.0, name=\"Arena\" ):     \"\"\"Create a circular arena environment.\"\"\"     # Generate samples inside circle     angles = np.random.uniform(0, 2 * np.pi, n_samples)     radii = np.sqrt(np.random.uniform(0, 1, n_samples)) * (radius - 2)     np.column_stack(         [center_x + radii * np.cos(angles), center_y + radii * np.sin(angles)]     )      # Create environment     circle_polygon = Point(center_x, center_y).buffer(radius)     return Environment.from_polygon(         polygon=circle_polygon, bin_size=bin_size, name=name     )   # Create three arenas in a line arena_a = create_circular_arena(20, 50, radius=15, name=\"Arena_A\") arena_b = create_circular_arena(60, 50, radius=15, name=\"Arena_B\") arena_c = create_circular_arena(100, 50, radius=15, name=\"Arena_C\")  print(f\"Arena A: {arena_a.n_bins} bins\") print(f\"Arena B: {arena_b.n_bins} bins\") print(f\"Arena C: {arena_c.n_bins} bins\") <pre>Arena A: 80 bins\nArena B: 80 bins\nArena C: 80 bins\n</pre> In\u00a0[10]: Copied! <pre># Compare different bridge distance thresholds\ncomposites = {\n    \"No limit\": CompositeEnvironment(\n        subenvs=[arena_a, arena_b, arena_c], auto_bridge=True, max_mnn_distance=None\n    ),\n    \"Within 15 cm\": CompositeEnvironment(\n        subenvs=[arena_a, arena_b, arena_c], auto_bridge=True, max_mnn_distance=15.0\n    ),\n    \"Within 8 cm\": CompositeEnvironment(\n        subenvs=[arena_a, arena_b, arena_c], auto_bridge=True, max_mnn_distance=8.0\n    ),\n    \"No bridges\": CompositeEnvironment(\n        subenvs=[arena_a, arena_b, arena_c],\n        auto_bridge=False,  # Disable automatic bridging\n    ),\n}\n\nprint(\"Bridge counts with different thresholds:\")\nfor name, comp_env in composites.items():\n    print(f\"  {name:15s}: {len(comp_env._bridge_list):3d} bridges\")\n</pre> # Compare different bridge distance thresholds composites = {     \"No limit\": CompositeEnvironment(         subenvs=[arena_a, arena_b, arena_c], auto_bridge=True, max_mnn_distance=None     ),     \"Within 15 cm\": CompositeEnvironment(         subenvs=[arena_a, arena_b, arena_c], auto_bridge=True, max_mnn_distance=15.0     ),     \"Within 8 cm\": CompositeEnvironment(         subenvs=[arena_a, arena_b, arena_c], auto_bridge=True, max_mnn_distance=8.0     ),     \"No bridges\": CompositeEnvironment(         subenvs=[arena_a, arena_b, arena_c],         auto_bridge=False,  # Disable automatic bridging     ), }  print(\"Bridge counts with different thresholds:\") for name, comp_env in composites.items():     print(f\"  {name:15s}: {len(comp_env._bridge_list):3d} bridges\") <pre>Bridge counts with different thresholds:\n  No limit       :  12 bridges\n  Within 15 cm   :   8 bridges\n  Within 8 cm    :   0 bridges\n  No bridges     :   0 bridges\n</pre> In\u00a0[11]: Copied! <pre># Visualize the difference\nfig, axes = plt.subplots(2, 2, figsize=(18, 14))\naxes = axes.flatten()\n\nfor ax, (title, comp_env) in zip(axes, composites.items(), strict=False):\n    # Plot bins\n    ax.scatter(\n        comp_env.bin_centers[:, 0],\n        comp_env.bin_centers[:, 1],\n        c=\"lightblue\",\n        s=80,\n        alpha=0.6,\n    )\n\n    # Convert bridge list to set of edges for fast lookup\n    bridge_edges_set = set()\n    for (i_env, i_bin), (j_env, j_bin), _ in comp_env._bridge_list:\n        bin1 = comp_env._subenvs_info[i_env][\"start_idx\"] + i_bin\n        bin2 = comp_env._subenvs_info[j_env][\"start_idx\"] + j_bin\n        bridge_edges_set.add((min(bin1, bin2), max(bin1, bin2)))\n\n    # Draw regular edges\n    for edge in comp_env.connectivity.edges():\n        edge_key = (min(edge[0], edge[1]), max(edge[0], edge[1]))\n        if edge_key not in bridge_edges_set:\n            pos1 = comp_env.bin_centers[edge[0]]\n            pos2 = comp_env.bin_centers[edge[1]]\n            ax.plot(\n                [pos1[0], pos2[0]],\n                [pos1[1], pos2[1]],\n                \"gray\",\n                alpha=0.15,\n                linewidth=0.5,\n            )\n\n    # Draw bridges\n    for (i_env, i_bin), (j_env, j_bin), _ in comp_env._bridge_list:\n        bin1 = comp_env._subenvs_info[i_env][\"start_idx\"] + i_bin\n        bin2 = comp_env._subenvs_info[j_env][\"start_idx\"] + j_bin\n        pos1 = comp_env.bin_centers[bin1]\n        pos2 = comp_env.bin_centers[bin2]\n        ax.plot([pos1[0], pos2[0]], [pos1[1], pos2[1]], \"r-\", linewidth=2.5, alpha=0.8)\n\n    ax.set_title(f\"{title}\\n{len(comp_env._bridge_list)} bridges\")\n    ax.set_xlabel(\"X position (cm)\")\n    ax.set_ylabel(\"Y position (cm)\")\n    ax.set_aspect(\"equal\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Visualize the difference fig, axes = plt.subplots(2, 2, figsize=(18, 14)) axes = axes.flatten()  for ax, (title, comp_env) in zip(axes, composites.items(), strict=False):     # Plot bins     ax.scatter(         comp_env.bin_centers[:, 0],         comp_env.bin_centers[:, 1],         c=\"lightblue\",         s=80,         alpha=0.6,     )      # Convert bridge list to set of edges for fast lookup     bridge_edges_set = set()     for (i_env, i_bin), (j_env, j_bin), _ in comp_env._bridge_list:         bin1 = comp_env._subenvs_info[i_env][\"start_idx\"] + i_bin         bin2 = comp_env._subenvs_info[j_env][\"start_idx\"] + j_bin         bridge_edges_set.add((min(bin1, bin2), max(bin1, bin2)))      # Draw regular edges     for edge in comp_env.connectivity.edges():         edge_key = (min(edge[0], edge[1]), max(edge[0], edge[1]))         if edge_key not in bridge_edges_set:             pos1 = comp_env.bin_centers[edge[0]]             pos2 = comp_env.bin_centers[edge[1]]             ax.plot(                 [pos1[0], pos2[0]],                 [pos1[1], pos2[1]],                 \"gray\",                 alpha=0.15,                 linewidth=0.5,             )      # Draw bridges     for (i_env, i_bin), (j_env, j_bin), _ in comp_env._bridge_list:         bin1 = comp_env._subenvs_info[i_env][\"start_idx\"] + i_bin         bin2 = comp_env._subenvs_info[j_env][\"start_idx\"] + j_bin         pos1 = comp_env.bin_centers[bin1]         pos2 = comp_env.bin_centers[bin2]         ax.plot([pos1[0], pos2[0]], [pos1[1], pos2[1]], \"r-\", linewidth=2.5, alpha=0.8)      ax.set_title(f\"{title}\\n{len(comp_env._bridge_list)} bridges\")     ax.set_xlabel(\"X position (cm)\")     ax.set_ylabel(\"Y position (cm)\")     ax.set_aspect(\"equal\")  plt.tight_layout() plt.show() <p>Key observations:</p> <ul> <li>No limit: All arenas connect (A-B, B-C, A-C)</li> <li>15 cm threshold: Only adjacent arenas connect (A-B, B-C)</li> <li>8 cm threshold: Only very close bins connect</li> <li>No bridges: Completely disconnected sub-environments</li> </ul> In\u00a0[12]: Copied! <pre># Create T-maze compartments\n# Start box (bottom)\nstart_box_data = np.random.uniform(low=[45, 0], high=[55, 30], size=(600, 2))\nenv_start = Environment.from_samples(\n    data_samples=start_box_data, bin_size=3.0, name=\"StartBox\"\n)\n\n# Left arm\nleft_arm_data = np.random.uniform(low=[10, 30], high=[45, 40], size=(500, 2))\nenv_left = Environment.from_samples(\n    data_samples=left_arm_data, bin_size=3.0, name=\"LeftArm\"\n)\n\n# Right arm\nright_arm_data = np.random.uniform(low=[55, 30], high=[90, 40], size=(500, 2))\nenv_right = Environment.from_samples(\n    data_samples=right_arm_data, bin_size=3.0, name=\"RightArm\"\n)\n\n# Center junction\njunction_data = np.random.uniform(low=[40, 28], high=[60, 35], size=(400, 2))\nenv_junction = Environment.from_samples(\n    data_samples=junction_data, bin_size=3.0, name=\"Junction\"\n)\n\nprint(\"T-Maze Compartments:\")\nfor env in [env_start, env_junction, env_left, env_right]:\n    print(f\"  {env.name:12s}: {env.n_bins} bins\")\n</pre> # Create T-maze compartments # Start box (bottom) start_box_data = np.random.uniform(low=[45, 0], high=[55, 30], size=(600, 2)) env_start = Environment.from_samples(     data_samples=start_box_data, bin_size=3.0, name=\"StartBox\" )  # Left arm left_arm_data = np.random.uniform(low=[10, 30], high=[45, 40], size=(500, 2)) env_left = Environment.from_samples(     data_samples=left_arm_data, bin_size=3.0, name=\"LeftArm\" )  # Right arm right_arm_data = np.random.uniform(low=[55, 30], high=[90, 40], size=(500, 2)) env_right = Environment.from_samples(     data_samples=right_arm_data, bin_size=3.0, name=\"RightArm\" )  # Center junction junction_data = np.random.uniform(low=[40, 28], high=[60, 35], size=(400, 2)) env_junction = Environment.from_samples(     data_samples=junction_data, bin_size=3.0, name=\"Junction\" )  print(\"T-Maze Compartments:\") for env in [env_start, env_junction, env_left, env_right]:     print(f\"  {env.name:12s}: {env.n_bins} bins\") <pre>T-Maze Compartments:\n  StartBox    : 55 bins\n  Junction    : 32 bins\n  LeftArm     : 65 bins\n  RightArm    : 65 bins\n</pre> In\u00a0[13]: Copied! <pre># Create composite T-maze\ntmaze_composite = CompositeEnvironment(\n    subenvs=[env_start, env_junction, env_left, env_right],\n    auto_bridge=True,\n    max_mnn_distance=6.0,  # Only connect nearby compartments\n)\n\nprint(\"\\nT-Maze Composite Environment:\")\nprint(f\"  Total bins: {tmaze_composite.n_bins}\")\nprint(f\"  Compartments: {len(tmaze_composite._subenvs_info)}\")\nprint(f\"  Bridges: {len(tmaze_composite._bridge_list)}\")\nprint(f\"  Total edges: {tmaze_composite.connectivity.number_of_edges()}\")\n</pre> # Create composite T-maze tmaze_composite = CompositeEnvironment(     subenvs=[env_start, env_junction, env_left, env_right],     auto_bridge=True,     max_mnn_distance=6.0,  # Only connect nearby compartments )  print(\"\\nT-Maze Composite Environment:\") print(f\"  Total bins: {tmaze_composite.n_bins}\") print(f\"  Compartments: {len(tmaze_composite._subenvs_info)}\") print(f\"  Bridges: {len(tmaze_composite._bridge_list)}\") print(f\"  Total edges: {tmaze_composite.connectivity.number_of_edges()}\") <pre>\nT-Maze Composite Environment:\n  Total bins: 217\n  Compartments: 4\n  Bridges: 28\n  Total edges: 712\n</pre> In\u00a0[14]: Copied! <pre># Visualize the T-maze with compartment labels\nfig, ax = plt.subplots(figsize=(14, 12))\n\n# Define colors for each compartment\ncompartment_colors = {\n    \"StartBox\": \"lightgreen\",\n    \"Junction\": \"lightyellow\",\n    \"LeftArm\": \"lightblue\",\n    \"RightArm\": \"lightcoral\",\n}\n\n# Plot bins colored by compartment\n# Construct bin_ranges from _subenvs_info\nbin_ranges = {}\nfor info in tmaze_composite._subenvs_info:\n    env_name = info[\"env\"].name\n    bin_ranges[env_name] = (info[\"start_idx\"], info[\"end_idx\"] + 1)\n\nfor env_name, (start_idx, end_idx) in bin_ranges.items():\n    bin_centers = tmaze_composite.bin_centers[start_idx:end_idx]\n    ax.scatter(\n        bin_centers[:, 0],\n        bin_centers[:, 1],\n        c=compartment_colors[env_name],\n        s=150,\n        alpha=0.7,\n        edgecolors=\"black\",\n        linewidth=0.5,\n        label=env_name,\n    )\n\n# Convert bridge list to set of edges for fast lookup\nbridge_edges_set = set()\nfor (i_env, i_bin), (j_env, j_bin), _ in tmaze_composite._bridge_list:\n    bin1 = tmaze_composite._subenvs_info[i_env][\"start_idx\"] + i_bin\n    bin2 = tmaze_composite._subenvs_info[j_env][\"start_idx\"] + j_bin\n    bridge_edges_set.add((min(bin1, bin2), max(bin1, bin2)))\n\n# Draw all edges\nfor edge in tmaze_composite.connectivity.edges():\n    edge_key = (min(edge[0], edge[1]), max(edge[0], edge[1]))\n    is_bridge = edge_key in bridge_edges_set\n\n    pos1 = tmaze_composite.bin_centers[edge[0]]\n    pos2 = tmaze_composite.bin_centers[edge[1]]\n\n    if is_bridge:\n        ax.plot(\n            [pos1[0], pos2[0]],\n            [pos1[1], pos2[1]],\n            \"r-\",\n            linewidth=3,\n            alpha=0.8,\n            zorder=10,\n        )\n    else:\n        ax.plot(\n            [pos1[0], pos2[0]], [pos1[1], pos2[1]], \"gray\", alpha=0.2, linewidth=0.8\n        )\n\n# Add bridge legend entry\nax.plot(\n    [],\n    [],\n    \"r-\",\n    linewidth=3,\n    alpha=0.8,\n    label=f\"Bridges ({len(tmaze_composite._bridge_list)})\",\n)\n\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(\"T-Maze Composite Environment\")\nax.legend(loc=\"upper right\")\nax.set_aspect(\"equal\")\nplt.tight_layout()\nplt.show()\n</pre> # Visualize the T-maze with compartment labels fig, ax = plt.subplots(figsize=(14, 12))  # Define colors for each compartment compartment_colors = {     \"StartBox\": \"lightgreen\",     \"Junction\": \"lightyellow\",     \"LeftArm\": \"lightblue\",     \"RightArm\": \"lightcoral\", }  # Plot bins colored by compartment # Construct bin_ranges from _subenvs_info bin_ranges = {} for info in tmaze_composite._subenvs_info:     env_name = info[\"env\"].name     bin_ranges[env_name] = (info[\"start_idx\"], info[\"end_idx\"] + 1)  for env_name, (start_idx, end_idx) in bin_ranges.items():     bin_centers = tmaze_composite.bin_centers[start_idx:end_idx]     ax.scatter(         bin_centers[:, 0],         bin_centers[:, 1],         c=compartment_colors[env_name],         s=150,         alpha=0.7,         edgecolors=\"black\",         linewidth=0.5,         label=env_name,     )  # Convert bridge list to set of edges for fast lookup bridge_edges_set = set() for (i_env, i_bin), (j_env, j_bin), _ in tmaze_composite._bridge_list:     bin1 = tmaze_composite._subenvs_info[i_env][\"start_idx\"] + i_bin     bin2 = tmaze_composite._subenvs_info[j_env][\"start_idx\"] + j_bin     bridge_edges_set.add((min(bin1, bin2), max(bin1, bin2)))  # Draw all edges for edge in tmaze_composite.connectivity.edges():     edge_key = (min(edge[0], edge[1]), max(edge[0], edge[1]))     is_bridge = edge_key in bridge_edges_set      pos1 = tmaze_composite.bin_centers[edge[0]]     pos2 = tmaze_composite.bin_centers[edge[1]]      if is_bridge:         ax.plot(             [pos1[0], pos2[0]],             [pos1[1], pos2[1]],             \"r-\",             linewidth=3,             alpha=0.8,             zorder=10,         )     else:         ax.plot(             [pos1[0], pos2[0]], [pos1[1], pos2[1]], \"gray\", alpha=0.2, linewidth=0.8         )  # Add bridge legend entry ax.plot(     [],     [],     \"r-\",     linewidth=3,     alpha=0.8,     label=f\"Bridges ({len(tmaze_composite._bridge_list)})\", )  ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(\"T-Maze Composite Environment\") ax.legend(loc=\"upper right\") ax.set_aspect(\"equal\") plt.tight_layout() plt.show() In\u00a0[15]: Copied! <pre># Find path from start box to left arm\npoint_start = np.array([50.0, 10.0])  # In start box\npoint_left_end = np.array([20.0, 35.0])  # In left arm\n\n# Map to bins\nbin_start = tmaze_composite.bin_at(point_start.reshape(1, -1))[0]\nbin_left_end = tmaze_composite.bin_at(point_left_end.reshape(1, -1))[0]\n\n# Find shortest path using networkx\npath = nx.shortest_path(tmaze_composite.connectivity, bin_start, bin_left_end)\n\nprint(\"\\nPath from Start Box to Left Arm:\")\nprint(f\"  Path length: {len(path)} bins\")\nprint(\n    f\"  Bin sequence: {path[:10]}...\" if len(path) &gt; 10 else f\"  Bin sequence: {path}\"\n)\n\n# Calculate distance\npath_distance = tmaze_composite.distance_between(point_start, point_left_end)\nprint(f\"  Geodesic distance: {path_distance:.2f} cm\")\n</pre> # Find path from start box to left arm point_start = np.array([50.0, 10.0])  # In start box point_left_end = np.array([20.0, 35.0])  # In left arm  # Map to bins bin_start = tmaze_composite.bin_at(point_start.reshape(1, -1))[0] bin_left_end = tmaze_composite.bin_at(point_left_end.reshape(1, -1))[0]  # Find shortest path using networkx path = nx.shortest_path(tmaze_composite.connectivity, bin_start, bin_left_end)  print(\"\\nPath from Start Box to Left Arm:\") print(f\"  Path length: {len(path)} bins\") print(     f\"  Bin sequence: {path[:10]}...\" if len(path) &gt; 10 else f\"  Bin sequence: {path}\" )  # Calculate distance path_distance = tmaze_composite.distance_between(point_start, point_left_end) print(f\"  Geodesic distance: {path_distance:.2f} cm\") <pre>\nPath from Start Box to Left Arm:\n  Path length: 18 bins\n  Bin sequence: [np.int64(25), 15, 5, 6, 7, 8, 9, 10, np.int64(147), 142]...\n  Geodesic distance: 50.92 cm\n</pre> In\u00a0[16]: Copied! <pre># Visualize the path\nfig, ax = plt.subplots(figsize=(14, 12))\n\n# Plot bins (faded)\nfor env_name, (start_idx, end_idx) in bin_ranges.items():\n    bin_centers = tmaze_composite.bin_centers[start_idx:end_idx]\n    ax.scatter(\n        bin_centers[:, 0],\n        bin_centers[:, 1],\n        c=compartment_colors[env_name],\n        s=100,\n        alpha=0.3,\n    )\n\n# Highlight path bins\npath_positions = tmaze_composite.bin_centers[path]\nax.scatter(\n    path_positions[:, 0],\n    path_positions[:, 1],\n    c=\"purple\",\n    s=200,\n    alpha=0.8,\n    edgecolors=\"black\",\n    linewidth=2,\n    label=\"Path bins\",\n    zorder=10,\n)\n\n# Draw path as line\nax.plot(\n    path_positions[:, 0],\n    path_positions[:, 1],\n    \"purple\",\n    linewidth=4,\n    alpha=0.6,\n    marker=\"o\",\n    markersize=8,\n    label=\"Shortest path\",\n)\n\n# Mark start and end\nax.scatter(\n    point_start[0],\n    point_start[1],\n    c=\"green\",\n    s=400,\n    marker=\"*\",\n    edgecolors=\"black\",\n    linewidth=2,\n    label=\"Start\",\n    zorder=15,\n)\nax.scatter(\n    point_left_end[0],\n    point_left_end[1],\n    c=\"red\",\n    s=400,\n    marker=\"*\",\n    edgecolors=\"black\",\n    linewidth=2,\n    label=\"End\",\n    zorder=15,\n)\n\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(f\"Shortest Path Through T-Maze ({len(path)} bins, {path_distance:.1f} cm)\")\nax.legend(loc=\"upper right\")\nax.set_aspect(\"equal\")\nplt.tight_layout()\nplt.show()\n</pre> # Visualize the path fig, ax = plt.subplots(figsize=(14, 12))  # Plot bins (faded) for env_name, (start_idx, end_idx) in bin_ranges.items():     bin_centers = tmaze_composite.bin_centers[start_idx:end_idx]     ax.scatter(         bin_centers[:, 0],         bin_centers[:, 1],         c=compartment_colors[env_name],         s=100,         alpha=0.3,     )  # Highlight path bins path_positions = tmaze_composite.bin_centers[path] ax.scatter(     path_positions[:, 0],     path_positions[:, 1],     c=\"purple\",     s=200,     alpha=0.8,     edgecolors=\"black\",     linewidth=2,     label=\"Path bins\",     zorder=10, )  # Draw path as line ax.plot(     path_positions[:, 0],     path_positions[:, 1],     \"purple\",     linewidth=4,     alpha=0.6,     marker=\"o\",     markersize=8,     label=\"Shortest path\", )  # Mark start and end ax.scatter(     point_start[0],     point_start[1],     c=\"green\",     s=400,     marker=\"*\",     edgecolors=\"black\",     linewidth=2,     label=\"Start\",     zorder=15, ) ax.scatter(     point_left_end[0],     point_left_end[1],     c=\"red\",     s=400,     marker=\"*\",     edgecolors=\"black\",     linewidth=2,     label=\"End\",     zorder=15, )  ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(f\"Shortest Path Through T-Maze ({len(path)} bins, {path_distance:.1f} cm)\") ax.legend(loc=\"upper right\") ax.set_aspect(\"equal\") plt.tight_layout() plt.show() In\u00a0[17]: Copied! <pre># Add regions for choice points\ntmaze_composite.regions.add(\n    name=\"LeftChoice\",\n    point=np.array([25.0, 35.0]),  # In left arm\n)\n\ntmaze_composite.regions.add(\n    name=\"RightChoice\",\n    point=np.array([75.0, 35.0]),  # In right arm\n)\n\ntmaze_composite.regions.add(\n    name=\"StartPoint\",\n    point=np.array([50.0, 10.0]),  # In start box\n)\n\nprint(\"\\nDefined Regions:\")\nfor name in tmaze_composite.regions.list_names():\n    region = tmaze_composite.regions[name]\n    print(f\"  {name:15s}: {region.data}\")\n</pre> # Add regions for choice points tmaze_composite.regions.add(     name=\"LeftChoice\",     point=np.array([25.0, 35.0]),  # In left arm )  tmaze_composite.regions.add(     name=\"RightChoice\",     point=np.array([75.0, 35.0]),  # In right arm )  tmaze_composite.regions.add(     name=\"StartPoint\",     point=np.array([50.0, 10.0]),  # In start box )  print(\"\\nDefined Regions:\") for name in tmaze_composite.regions.list_names():     region = tmaze_composite.regions[name]     print(f\"  {name:15s}: {region.data}\") <pre>\nDefined Regions:\n  LeftChoice     : [25. 35.]\n  RightChoice    : [75. 35.]\n  StartPoint     : [50. 10.]\n</pre> In\u00a0[18]: Copied! <pre># Calculate distances between regions\nstart_point = tmaze_composite.regions[\"StartPoint\"].data\nleft_point = tmaze_composite.regions[\"LeftChoice\"].data\nright_point = tmaze_composite.regions[\"RightChoice\"].data\n\ndist_start_left = tmaze_composite.distance_between(start_point, left_point)\ndist_start_right = tmaze_composite.distance_between(start_point, right_point)\ndist_left_right = tmaze_composite.distance_between(left_point, right_point)\n\nprint(\"\\nInter-Region Distances:\")\nprint(f\"  Start \u2192 Left:  {dist_start_left:.2f} cm\")\nprint(f\"  Start \u2192 Right: {dist_start_right:.2f} cm\")\nprint(f\"  Left \u2194 Right:  {dist_left_right:.2f} cm\")\n</pre> # Calculate distances between regions start_point = tmaze_composite.regions[\"StartPoint\"].data left_point = tmaze_composite.regions[\"LeftChoice\"].data right_point = tmaze_composite.regions[\"RightChoice\"].data  dist_start_left = tmaze_composite.distance_between(start_point, left_point) dist_start_right = tmaze_composite.distance_between(start_point, right_point) dist_left_right = tmaze_composite.distance_between(left_point, right_point)  print(\"\\nInter-Region Distances:\") print(f\"  Start \u2192 Left:  {dist_start_left:.2f} cm\") print(f\"  Start \u2192 Right: {dist_start_right:.2f} cm\") print(f\"  Left \u2194 Right:  {dist_left_right:.2f} cm\") <pre>\nInter-Region Distances:\n  Start \u2192 Left:  45.09 cm\n  Start \u2192 Right: 45.15 cm\n  Left \u2194 Right:  50.90 cm\n</pre> In\u00a0[19]: Copied! <pre># This would fail (mixing 2D and 1D environments)\n# composite_bad = CompositeEnvironment(\n#     subenvs=[env_2d, env_1d]  # Error: incompatible dimensions!\n# )\n\nprint(\"\u2713 All sub-environments must have the same n_dims\")\nprint(\"\u2713 Check env.n_dims before merging\")\n</pre> # This would fail (mixing 2D and 1D environments) # composite_bad = CompositeEnvironment( #     subenvs=[env_2d, env_1d]  # Error: incompatible dimensions! # )  print(\"\u2713 All sub-environments must have the same n_dims\") print(\"\u2713 Check env.n_dims before merging\") <pre>\u2713 All sub-environments must have the same n_dims\n\u2713 Check env.n_dims before merging\n</pre> In\u00a0[20]: Copied! <pre># If environments are far apart, they might not connect\nno_bridges_composite = CompositeEnvironment(\n    subenvs=[arena_a, arena_b, arena_c],\n    auto_bridge=True,\n    max_mnn_distance=1.0,  # Too strict!\n)\n\nprint(f\"\\nWith max_mnn_distance=1.0: {len(no_bridges_composite._bridge_list)} bridges\")\nprint(\"\u26a0 Warning: Very strict threshold may result in disconnected sub-environments\")\nprint(\n    \"\u2713 Solution: Increase threshold or use auto_bridge=True with max_mnn_distance=None\"\n)\n</pre> # If environments are far apart, they might not connect no_bridges_composite = CompositeEnvironment(     subenvs=[arena_a, arena_b, arena_c],     auto_bridge=True,     max_mnn_distance=1.0,  # Too strict! )  print(f\"\\nWith max_mnn_distance=1.0: {len(no_bridges_composite._bridge_list)} bridges\") print(\"\u26a0 Warning: Very strict threshold may result in disconnected sub-environments\") print(     \"\u2713 Solution: Increase threshold or use auto_bridge=True with max_mnn_distance=None\" ) <pre>\nWith max_mnn_distance=1.0: 0 bridges\n\u26a0 Warning: Very strict threshold may result in disconnected sub-environments\n\u2713 Solution: Increase threshold or use auto_bridge=True with max_mnn_distance=None\n</pre> In\u00a0[21]: Copied! <pre># Always verify your composite is connected as expected\nis_connected = nx.is_connected(tmaze_composite.connectivity)\nn_components = nx.number_connected_components(tmaze_composite.connectivity)\n\nprint(\"\\nConnectivity Check:\")\nprint(f\"  Graph connected: {is_connected}\")\nprint(f\"  Number of components: {n_components}\")\n\nif not is_connected:\n    print(f\"  \u26a0 Warning: Graph has {n_components} disconnected components!\")\n    print(\n        \"  Consider: Increasing max_mnn_distance or checking sub-environment positions\"\n    )\n</pre> # Always verify your composite is connected as expected is_connected = nx.is_connected(tmaze_composite.connectivity) n_components = nx.number_connected_components(tmaze_composite.connectivity)  print(\"\\nConnectivity Check:\") print(f\"  Graph connected: {is_connected}\") print(f\"  Number of components: {n_components}\")  if not is_connected:     print(f\"  \u26a0 Warning: Graph has {n_components} disconnected components!\")     print(         \"  Consider: Increasing max_mnn_distance or checking sub-environment positions\"     ) <pre>\nConnectivity Check:\n  Graph connected: True\n  Number of components: 1\n</pre> In\u00a0[\u00a0]: Copied! <pre># Get comprehensive information about the composite environment\nprint(\"=== Composite Environment Information ===\\n\")\ntmaze_composite.info()\n\n# You can also get info as a string for logging\ninfo_str = tmaze_composite.info(return_string=True)\n# print(info_str)  # Uncomment to see string output\n</pre> # Get comprehensive information about the composite environment print(\"=== Composite Environment Information ===\\n\") tmaze_composite.info()  # You can also get info as a string for logging info_str = tmaze_composite.info(return_string=True) # print(info_str)  # Uncomment to see string output In\u00a0[\u00a0]: Copied! <pre># Add regions to sub-environments - these will be accessible in composite\njunction_center = env_junction.bin_centers[len(env_junction.bin_centers) // 2]\nenv_junction.regions.add(\"junction_center\", point=junction_center.tolist())\n\nleft_goal = env_left.bin_centers[0]\nenv_left.regions.add(\"left_goal\", point=left_goal.tolist())\n\n# Recreate composite to include the regions\ntmaze_with_regions = CompositeEnvironment(\n    subenvs=[env_start, env_junction, env_left, env_right],\n    auto_bridge=True,\n    max_mnn_distance=6.0,\n)\n\nprint(\"Regions available in composite:\")\nfor region_name in tmaze_with_regions.regions:\n    print(f\"  - {region_name}\")\n\n# Query bins in a specific region\njunction_bins = tmaze_with_regions.bins_in_region(\"junction_center\")\nprint(f\"\\nBins in 'junction_center' region: {len(junction_bins)} bins\")\n\n# Get boolean mask for a region\njunction_mask = tmaze_with_regions.mask_for_region(\"junction_center\")\nprint(f\"Mask shape: {junction_mask.shape}, True count: {np.sum(junction_mask)}\")\n</pre> # Add regions to sub-environments - these will be accessible in composite junction_center = env_junction.bin_centers[len(env_junction.bin_centers) // 2] env_junction.regions.add(\"junction_center\", point=junction_center.tolist())  left_goal = env_left.bin_centers[0] env_left.regions.add(\"left_goal\", point=left_goal.tolist())  # Recreate composite to include the regions tmaze_with_regions = CompositeEnvironment(     subenvs=[env_start, env_junction, env_left, env_right],     auto_bridge=True,     max_mnn_distance=6.0, )  print(\"Regions available in composite:\") for region_name in tmaze_with_regions.regions:     print(f\"  - {region_name}\")  # Query bins in a specific region junction_bins = tmaze_with_regions.bins_in_region(\"junction_center\") print(f\"\\nBins in 'junction_center' region: {len(junction_bins)} bins\")  # Get boolean mask for a region junction_mask = tmaze_with_regions.mask_for_region(\"junction_center\") print(f\"Mask shape: {junction_mask.shape}, True count: {np.sum(junction_mask)}\") In\u00a0[\u00a0]: Copied! <pre># Import pairwise for edge iteration (more efficient than zip)\nfrom itertools import pairwise\n\n# Find path from start to right arm (crosses bridges through junction)\nsource_bin = 0  # First bin in start box\ntarget_bin = tmaze_with_regions.n_bins - 5  # Bin in right arm\n\npath = tmaze_with_regions.shortest_path(source_bin, target_bin)\n\nif path:\n    print(f\"\\nShortest path from bin {source_bin} to bin {target_bin}:\")\n    print(f\"  Path length: {len(path)} bins\")\n    print(\"  Path traverses: \", end=\"\")\n\n    # Identify which sub-environments the path crosses\n    start_n_bins = env_start.n_bins\n    junction_n_bins = env_junction.n_bins\n    left_n_bins = env_left.n_bins\n\n    in_start = any(b &lt; start_n_bins for b in path)\n    in_junction = any(start_n_bins &lt;= b &lt; start_n_bins + junction_n_bins for b in path)\n    in_left = any(\n        start_n_bins + junction_n_bins\n        &lt;= b\n        &lt; start_n_bins + junction_n_bins + left_n_bins\n        for b in path\n    )\n    in_right = any(b &gt;= start_n_bins + junction_n_bins + left_n_bins for b in path)\n\n    compartments = []\n    if in_start:\n        compartments.append(\"Start\")\n    if in_junction:\n        compartments.append(\"Junction\")\n    if in_left:\n        compartments.append(\"Left\")\n    if in_right:\n        compartments.append(\"Right\")\n\n    print(\" \u2192 \".join(compartments))\n\n    # Calculate total path distance using pairwise iteration\n    total_distance = sum(\n        tmaze_with_regions.connectivity[u][v][\"distance\"] for u, v in pairwise(path)\n    )\n    print(f\"  Total distance: {total_distance:.2f} units\")\n</pre> # Import pairwise for edge iteration (more efficient than zip) from itertools import pairwise  # Find path from start to right arm (crosses bridges through junction) source_bin = 0  # First bin in start box target_bin = tmaze_with_regions.n_bins - 5  # Bin in right arm  path = tmaze_with_regions.shortest_path(source_bin, target_bin)  if path:     print(f\"\\nShortest path from bin {source_bin} to bin {target_bin}:\")     print(f\"  Path length: {len(path)} bins\")     print(\"  Path traverses: \", end=\"\")      # Identify which sub-environments the path crosses     start_n_bins = env_start.n_bins     junction_n_bins = env_junction.n_bins     left_n_bins = env_left.n_bins      in_start = any(b &lt; start_n_bins for b in path)     in_junction = any(start_n_bins &lt;= b &lt; start_n_bins + junction_n_bins for b in path)     in_left = any(         start_n_bins + junction_n_bins         &lt;= b         &lt; start_n_bins + junction_n_bins + left_n_bins         for b in path     )     in_right = any(b &gt;= start_n_bins + junction_n_bins + left_n_bins for b in path)      compartments = []     if in_start:         compartments.append(\"Start\")     if in_junction:         compartments.append(\"Junction\")     if in_left:         compartments.append(\"Left\")     if in_right:         compartments.append(\"Right\")      print(\" \u2192 \".join(compartments))      # Calculate total path distance using pairwise iteration     total_distance = sum(         tmaze_with_regions.connectivity[u][v][\"distance\"] for u, v in pairwise(path)     )     print(f\"  Total distance: {total_distance:.2f} units\") In\u00a0[\u00a0]: Copied! <pre>import warnings\n\n# Create a composite without bridges to demonstrate warning\ndisconnected_composite = CompositeEnvironment(\n    subenvs=[arena_a, arena_b], auto_bridge=False\n)\n\n# Try to find path between disconnected sub-environments\nsource = 0  # In arena_a\ntarget = arena_a.n_bins + 5  # In arena_b\n\nwith warnings.catch_warnings(record=True) as w:\n    warnings.simplefilter(\"always\")\n    path = disconnected_composite.shortest_path(source, target)\n    if len(w) &gt; 0:\n        print(f\"\u26a0 Warning captured: {w[0].message}\")\n\nprint(f\"Path result: {path} (empty list indicates no path exists)\")\n</pre> import warnings  # Create a composite without bridges to demonstrate warning disconnected_composite = CompositeEnvironment(     subenvs=[arena_a, arena_b], auto_bridge=False )  # Try to find path between disconnected sub-environments source = 0  # In arena_a target = arena_a.n_bins + 5  # In arena_b  with warnings.catch_warnings(record=True) as w:     warnings.simplefilter(\"always\")     path = disconnected_composite.shortest_path(source, target)     if len(w) &gt; 0:         print(f\"\u26a0 Warning captured: {w[0].message}\")  print(f\"Path result: {path} (empty list indicates no path exists)\") In\u00a0[\u00a0]: Copied! <pre>import tempfile\nfrom pathlib import Path\n\n# Save composite environment to file\nwith tempfile.TemporaryDirectory() as tmpdir:\n    filepath = Path(tmpdir) / \"my_composite_env.pkl\"\n\n    # Save\n    tmaze_with_regions.save(str(filepath))\n    print(f\"Saved composite to: {filepath}\")\n    print(f\"File size: {filepath.stat().st_size / 1024:.2f} KB\")\n\n    # Load\n    loaded_composite = CompositeEnvironment.load(str(filepath))\n\n    # Verify loaded composite matches original\n    print(\"\\nVerifying loaded composite:\")\n    print(\n        f\"  n_bins: {loaded_composite.n_bins} (original: {tmaze_with_regions.n_bins})\"\n    )\n    print(\n        f\"  n_dims: {loaded_composite.n_dims} (original: {tmaze_with_regions.n_dims})\"\n    )\n    print(\n        f\"  n_sub_envs: {len(loaded_composite._subenvs_info)} (original: {len(tmaze_with_regions._subenvs_info)})\"\n    )\n    print(\n        f\"  n_bridges: {len(loaded_composite._bridge_list)} (original: {len(tmaze_with_regions._bridge_list)})\"\n    )\n    print(f\"  Regions preserved: {list(loaded_composite.regions.keys())}\")\n\n    # Test that loaded composite works\n    test_points = np.array([[5.0, 5.0]])\n    bins_loaded = loaded_composite.bin_at(test_points)\n    bins_original = tmaze_with_regions.bin_at(test_points)\n    print(f\"  bin_at() test: loaded={bins_loaded[0]}, original={bins_original[0]}\")\n\n    print(\"\\n\u2713 Save/load preserves all composite structure and functionality\")\n</pre> import tempfile from pathlib import Path  # Save composite environment to file with tempfile.TemporaryDirectory() as tmpdir:     filepath = Path(tmpdir) / \"my_composite_env.pkl\"      # Save     tmaze_with_regions.save(str(filepath))     print(f\"Saved composite to: {filepath}\")     print(f\"File size: {filepath.stat().st_size / 1024:.2f} KB\")      # Load     loaded_composite = CompositeEnvironment.load(str(filepath))      # Verify loaded composite matches original     print(\"\\nVerifying loaded composite:\")     print(         f\"  n_bins: {loaded_composite.n_bins} (original: {tmaze_with_regions.n_bins})\"     )     print(         f\"  n_dims: {loaded_composite.n_dims} (original: {tmaze_with_regions.n_dims})\"     )     print(         f\"  n_sub_envs: {len(loaded_composite._subenvs_info)} (original: {len(tmaze_with_regions._subenvs_info)})\"     )     print(         f\"  n_bridges: {len(loaded_composite._bridge_list)} (original: {len(tmaze_with_regions._bridge_list)})\"     )     print(f\"  Regions preserved: {list(loaded_composite.regions.keys())}\")      # Test that loaded composite works     test_points = np.array([[5.0, 5.0]])     bins_loaded = loaded_composite.bin_at(test_points)     bins_original = tmaze_with_regions.bin_at(test_points)     print(f\"  bin_at() test: loaded={bins_loaded[0]}, original={bins_original[0]}\")      print(\"\\n\u2713 Save/load preserves all composite structure and functionality\")"},{"location":"examples/06_composite_environments/#composite-environments-merging-multiple-spaces","title":"Composite Environments: Merging Multiple Spaces\u00b6","text":""},{"location":"examples/06_composite_environments/#learning-objectives","title":"Learning Objectives\u00b6","text":"<p>By the end of this notebook, you will be able to:</p> <ul> <li>Understand when and why to use composite environments</li> <li>Merge multiple environments into a single unified space</li> <li>Work with automatic bridge inference using mutual nearest neighbors (MNN)</li> <li>Control bridge connectivity with distance thresholds</li> <li>Analyze multi-room and multi-compartment experiments</li> <li>Query across sub-environments seamlessly</li> <li>Visualize composite structures with bridges</li> </ul> <p>Estimated time: 25-30 minutes</p>"},{"location":"examples/06_composite_environments/#what-are-composite-environments","title":"What Are Composite Environments?\u00b6","text":"<p>Many neuroscience experiments involve animals exploring multiple separate environments:</p> <ul> <li>Multi-room experiments: Animal switches between different rooms or contexts</li> <li>Track segments: Complex mazes with distinct sections (T-maze, plus-maze)</li> <li>Context switching: Same physical space with different configurations</li> <li>Multi-scale analysis: Different zoom levels or resolution in different areas</li> </ul> <p>A <code>CompositeEnvironment</code> lets you:</p> <ol> <li>Create separate <code>Environment</code> objects for each space</li> <li>Merge them into a single unified environment</li> <li>Automatically infer \"bridge\" connections between spaces</li> <li>Query and analyze across all spaces with a single API</li> </ol> <p>Key insight: The composite environment looks just like a regular <code>Environment</code> from the outside, but internally manages multiple sub-environments and their connections.</p>"},{"location":"examples/06_composite_environments/#setup","title":"Setup\u00b6","text":""},{"location":"examples/06_composite_environments/#example-1-two-room-experiment","title":"Example 1: Two-Room Experiment\u00b6","text":"<p>Let's start with a simple scenario: an animal explores two separate rooms. Each room is recorded separately, but we want to analyze neural activity across both contexts.</p>"},{"location":"examples/06_composite_environments/#create-two-separate-environments","title":"Create Two Separate Environments\u00b6","text":""},{"location":"examples/06_composite_environments/#merge-into-composite-environment","title":"Merge Into Composite Environment\u00b6","text":""},{"location":"examples/06_composite_environments/#understanding-bridges","title":"Understanding Bridges\u00b6","text":"<p>What are bridges?</p> <ul> <li>Edges connecting bins from different sub-environments</li> <li>Inferred using mutual nearest neighbors (MNN) algorithm</li> <li>Allow paths and queries to work across the entire composite space</li> </ul> <p>MNN algorithm: For each pair of sub-environments:</p> <ol> <li>Find the nearest bin in environment B for each bin in environment A</li> <li>Find the nearest bin in environment A for each bin in environment B</li> <li>Keep only the mutual nearest neighbors (A\u2192B and B\u2192A both agree)</li> <li>Create bridge edges with proper distance weights</li> </ol> <p>Let's examine the bridges:</p>"},{"location":"examples/06_composite_environments/#querying-across-sub-environments","title":"Querying Across Sub-Environments\u00b6","text":"<p>The composite environment provides the same API as a regular environment:</p>"},{"location":"examples/06_composite_environments/#example-2-controlling-bridge-connectivity","title":"Example 2: Controlling Bridge Connectivity\u00b6","text":"<p>Sometimes you want to limit which environments connect to each other. The <code>max_mnn_distance</code> parameter controls this.</p>"},{"location":"examples/06_composite_environments/#example-3-multi-compartment-maze","title":"Example 3: Multi-Compartment Maze\u00b6","text":"<p>A more realistic neuroscience example: a complex maze with distinct compartments (e.g., T-maze with start box and choice arms).</p>"},{"location":"examples/06_composite_environments/#analyzing-paths-across-compartments","title":"Analyzing Paths Across Compartments\u00b6","text":"<p>One powerful feature: finding shortest paths that traverse multiple compartments.</p>"},{"location":"examples/06_composite_environments/#working-with-regions-in-composite-environments","title":"Working with Regions in Composite Environments\u00b6","text":"<p>You can still define and use regions within composite environments:</p>"},{"location":"examples/06_composite_environments/#common-pitfalls-and-best-practices","title":"Common Pitfalls and Best Practices\u00b6","text":""},{"location":"examples/06_composite_environments/#pitfall-1-sub-environments-must-have-same-dimensionality","title":"Pitfall 1: Sub-environments must have same dimensionality\u00b6","text":""},{"location":"examples/06_composite_environments/#pitfall-2-bridge-distance-threshold-too-strict","title":"Pitfall 2: Bridge distance threshold too strict\u00b6","text":""},{"location":"examples/06_composite_environments/#best-practice-check-connectivity","title":"Best Practice: Check connectivity\u00b6","text":""},{"location":"examples/06_composite_environments/#example-4-new-compositeenvironment-methods-v010","title":"Example 4: New CompositeEnvironment Methods (v0.1.0)\u00b6","text":"<p>In v0.1.0, <code>CompositeEnvironment</code> gained full API parity with <code>Environment</code> class, including:</p> <ul> <li>Region queries: <code>bins_in_region()</code>, <code>mask_for_region()</code></li> <li>Pathfinding: <code>shortest_path()</code></li> <li>Diagnostics: <code>info()</code></li> <li>Serialization: <code>save()</code> and <code>load()</code></li> </ul>"},{"location":"examples/06_composite_environments/#diagnostic-information-with-info","title":"Diagnostic Information with <code>.info()</code>\u00b6","text":""},{"location":"examples/06_composite_environments/#region-queries-across-composite","title":"Region Queries Across Composite\u00b6","text":"<p>Region queries work seamlessly across all sub-environments in the composite.</p>"},{"location":"examples/06_composite_environments/#pathfinding-with-shortest_path","title":"Pathfinding with <code>.shortest_path()</code>\u00b6","text":"<p>Find the shortest path between any two bins in the composite, even across bridges.</p>"},{"location":"examples/06_composite_environments/#pathfinding-example-no-path-between-disconnected-components","title":"Pathfinding Example: No Path Between Disconnected Components\u00b6","text":""},{"location":"examples/06_composite_environments/#saving-and-loading-composite-environments","title":"Saving and Loading Composite Environments\u00b6","text":""},{"location":"examples/06_composite_environments/#key-takeaways","title":"Key Takeaways\u00b6","text":"<p>Congratulations! You now understand composite environments in neurospatial:</p> <ol> <li><p><code>CompositeEnvironment</code> merges multiple <code>Environment</code> instances into one unified space</p> </li> <li><p>Automatic bridge inference uses mutual nearest neighbors (MNN) to connect sub-environments</p> </li> <li><p><code>max_mnn_distance</code> parameter controls which environments connect (None = no limit)</p> </li> <li><p>Full API parity with Environment (v0.1.0):</p> <ul> <li>Spatial queries: <code>bin_at()</code>, <code>distance_between()</code>, <code>contains()</code></li> <li>Region queries: <code>bins_in_region()</code>, <code>mask_for_region()</code></li> <li>Pathfinding: <code>shortest_path()</code> (works across bridges!)</li> <li>Diagnostics: <code>info()</code> (shows composite structure and bridge stats)</li> <li>Serialization: <code>save()</code> and <code>load()</code> (persist composite environments)</li> </ul> </li> <li><p>Use cases:</p> <ul> <li>Multi-room experiments</li> <li>Complex mazes with compartments</li> <li>Context switching paradigms</li> <li>Multi-scale analysis</li> </ul> </li> <li><p>Best practices:</p> <ul> <li>Verify all sub-environments have same <code>n_dims</code></li> <li>Check connectivity after creation (<code>nx.is_connected()</code>)</li> <li>Tune <code>max_mnn_distance</code> based on your spatial scale</li> <li>Visualize bridges to verify expected connections</li> <li>Use <code>info()</code> to inspect composite structure</li> <li>Save composites to avoid re-computing bridges</li> </ul> </li> </ol>"},{"location":"examples/06_composite_environments/#next-steps","title":"Next Steps\u00b6","text":"<p>In the next notebook (07_advanced_operations.ipynb), you'll learn:</p> <ul> <li>Advanced path finding and geodesic distances</li> <li>Alignment and coordinate transformations</li> <li>Mapping probability distributions between environments</li> <li>Graph analysis and connectivity metrics</li> </ul>"},{"location":"examples/06_composite_environments/#exercises-optional","title":"Exercises (Optional)\u00b6","text":"<ol> <li>Create a plus-maze with 4 arms and analyze paths between opposite arms</li> <li>Build a composite with 5 circular arenas and find optimal <code>max_mnn_distance</code></li> <li>Calculate average bridge length for different environment configurations</li> <li>Create a composite T-maze and compute occupancy separately for each compartment</li> </ol>"},{"location":"examples/07_advanced_operations/","title":"Advanced Operations: Paths, Distances, and Alignment","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport networkx as nx\nimport numpy as np\nfrom shapely.geometry import Point, Polygon\n\nfrom neurospatial import Environment\nfrom neurospatial.alignment import (\n    get_2d_rotation_matrix,\n    map_probabilities_to_nearest_target_bin,\n)\nfrom neurospatial.transforms import Affine2D, scale_2d, translate\n\nnp.random.seed(42)\nplt.rcParams[\"figure.figsize\"] = (14, 10)\nplt.rcParams[\"font.size\"] = 11\n</pre> import matplotlib.pyplot as plt import networkx as nx import numpy as np from shapely.geometry import Point, Polygon  from neurospatial import Environment from neurospatial.alignment import (     get_2d_rotation_matrix,     map_probabilities_to_nearest_target_bin, ) from neurospatial.transforms import Affine2D, scale_2d, translate  np.random.seed(42) plt.rcParams[\"figure.figsize\"] = (14, 10) plt.rcParams[\"font.size\"] = 11 In\u00a0[2]: Copied! <pre># Create a U-shaped environment (barrier in middle)\n# Left arm\nleft_arm = np.random.uniform(low=[0, 0], high=[20, 60], size=(600, 2))\n# Bottom connector\nbottom = np.random.uniform(low=[0, 0], high=[60, 15], size=(400, 2))\n# Right arm\nright_arm = np.random.uniform(low=[40, 0], high=[60, 60], size=(600, 2))\n\nu_maze_data = np.vstack([left_arm, bottom, right_arm])\n\nenv_u = Environment.from_samples(data_samples=u_maze_data, bin_size=4.0, name=\"U_Maze\")\n\nprint(f\"U-Maze Environment: {env_u.n_bins} bins\")\n</pre> # Create a U-shaped environment (barrier in middle) # Left arm left_arm = np.random.uniform(low=[0, 0], high=[20, 60], size=(600, 2)) # Bottom connector bottom = np.random.uniform(low=[0, 0], high=[60, 15], size=(400, 2)) # Right arm right_arm = np.random.uniform(low=[40, 0], high=[60, 60], size=(600, 2))  u_maze_data = np.vstack([left_arm, bottom, right_arm])  env_u = Environment.from_samples(data_samples=u_maze_data, bin_size=4.0, name=\"U_Maze\")  print(f\"U-Maze Environment: {env_u.n_bins} bins\") <pre>U-Maze Environment: 210 bins\n</pre> In\u00a0[3]: Copied! <pre># Visualize the U-maze\nfig, ax = plt.subplots(figsize=(10, 12))\nenv_u.plot(ax=ax, show_connectivity=True)\nax.set_title(\"U-Shaped Maze\")\nax.set_aspect(\"equal\")\nplt.tight_layout()\nplt.show()\n</pre> # Visualize the U-maze fig, ax = plt.subplots(figsize=(10, 12)) env_u.plot(ax=ax, show_connectivity=True) ax.set_title(\"U-Shaped Maze\") ax.set_aspect(\"equal\") plt.tight_layout() plt.show() In\u00a0[4]: Copied! <pre># Define two points: top of left arm and top of right arm\npoint_left_top = np.array([10.0, 55.0])\npoint_right_top = np.array([50.0, 55.0])\n\n# Euclidean distance (straight line)\neuclidean_dist = np.linalg.norm(point_right_top - point_left_top)\n\n# Geodesic distance (through the environment)\ngeodesic_dist = env_u.distance_between(point_left_top, point_right_top)\n\nprint(\"Distance from left top to right top:\")\nprint(f\"  Euclidean (straight line): {euclidean_dist:.2f} cm\")\nprint(f\"  Geodesic (through maze):   {geodesic_dist:.2f} cm\")\nprint(f\"  Ratio (geodesic/euclidean): {geodesic_dist / euclidean_dist:.2f}x\")\nprint(f\"\\nThe geodesic distance is {geodesic_dist - euclidean_dist:.2f} cm longer!\")\n</pre> # Define two points: top of left arm and top of right arm point_left_top = np.array([10.0, 55.0]) point_right_top = np.array([50.0, 55.0])  # Euclidean distance (straight line) euclidean_dist = np.linalg.norm(point_right_top - point_left_top)  # Geodesic distance (through the environment) geodesic_dist = env_u.distance_between(point_left_top, point_right_top)  print(\"Distance from left top to right top:\") print(f\"  Euclidean (straight line): {euclidean_dist:.2f} cm\") print(f\"  Geodesic (through maze):   {geodesic_dist:.2f} cm\") print(f\"  Ratio (geodesic/euclidean): {geodesic_dist / euclidean_dist:.2f}x\") print(f\"\\nThe geodesic distance is {geodesic_dist - euclidean_dist:.2f} cm longer!\") <pre>Distance from left top to right top:\n  Euclidean (straight line): 40.00 cm\n  Geodesic (through maze):   110.76 cm\n  Ratio (geodesic/euclidean): 2.77x\n\nThe geodesic distance is 70.76 cm longer!\n</pre> In\u00a0[5]: Copied! <pre># Get bins for start and end points\nbin_left = env_u.bin_at(point_left_top.reshape(1, -1))[0]\nbin_right = env_u.bin_at(point_right_top.reshape(1, -1))[0]\n\n# Find shortest path\npath = env_u.shortest_path(bin_left, bin_right)\n\nprint(\"\\nShortest path:\")\nprint(f\"  Number of bins: {len(path)}\")\nprint(f\"  First 10 bins: {path[:10]}\")\n</pre> # Get bins for start and end points bin_left = env_u.bin_at(point_left_top.reshape(1, -1))[0] bin_right = env_u.bin_at(point_right_top.reshape(1, -1))[0]  # Find shortest path path = env_u.shortest_path(bin_left, bin_right)  print(\"\\nShortest path:\") print(f\"  Number of bins: {len(path)}\") print(f\"  First 10 bins: {path[:10]}\") <pre>\nShortest path:\n  Number of bins: 25\n  First 10 bins: [np.int64(46), 45, 60, 59, 58, 73, 72, 71, 70, 85]\n</pre> In\u00a0[6]: Copied! <pre># Visualize the path\nfig, ax = plt.subplots(figsize=(10, 12))\n\n# Plot all bins (faded)\nax.scatter(\n    env_u.bin_centers[:, 0], env_u.bin_centers[:, 1], c=\"lightgray\", s=100, alpha=0.3\n)\n\n# Draw edges (faded)\nfor edge in env_u.connectivity.edges():\n    pos1 = env_u.bin_centers[edge[0]]\n    pos2 = env_u.bin_centers[edge[1]]\n    ax.plot([pos1[0], pos2[0]], [pos1[1], pos2[1]], \"gray\", alpha=0.1, linewidth=0.5)\n\n# Highlight the path\npath_positions = env_u.bin_centers[path]\nax.plot(\n    path_positions[:, 0],\n    path_positions[:, 1],\n    \"blue\",\n    linewidth=4,\n    alpha=0.7,\n    marker=\"o\",\n    markersize=6,\n    label=f\"Shortest path ({geodesic_dist:.1f} cm)\",\n)\n\n# Draw straight line (Euclidean)\nax.plot(\n    [point_left_top[0], point_right_top[0]],\n    [point_left_top[1], point_right_top[1]],\n    \"r--\",\n    linewidth=3,\n    alpha=0.5,\n    label=f\"Euclidean ({euclidean_dist:.1f} cm)\",\n)\n\n# Mark start and end\nax.scatter(\n    point_left_top[0],\n    point_left_top[1],\n    c=\"green\",\n    s=400,\n    marker=\"*\",\n    edgecolors=\"black\",\n    linewidth=2,\n    label=\"Start\",\n    zorder=10,\n)\nax.scatter(\n    point_right_top[0],\n    point_right_top[1],\n    c=\"red\",\n    s=400,\n    marker=\"*\",\n    edgecolors=\"black\",\n    linewidth=2,\n    label=\"End\",\n    zorder=10,\n)\n\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(\"Geodesic vs Euclidean Distance in U-Maze\")\nax.legend(loc=\"upper right\", fontsize=10)\nax.set_aspect(\"equal\")\nplt.tight_layout()\nplt.show()\n</pre> # Visualize the path fig, ax = plt.subplots(figsize=(10, 12))  # Plot all bins (faded) ax.scatter(     env_u.bin_centers[:, 0], env_u.bin_centers[:, 1], c=\"lightgray\", s=100, alpha=0.3 )  # Draw edges (faded) for edge in env_u.connectivity.edges():     pos1 = env_u.bin_centers[edge[0]]     pos2 = env_u.bin_centers[edge[1]]     ax.plot([pos1[0], pos2[0]], [pos1[1], pos2[1]], \"gray\", alpha=0.1, linewidth=0.5)  # Highlight the path path_positions = env_u.bin_centers[path] ax.plot(     path_positions[:, 0],     path_positions[:, 1],     \"blue\",     linewidth=4,     alpha=0.7,     marker=\"o\",     markersize=6,     label=f\"Shortest path ({geodesic_dist:.1f} cm)\", )  # Draw straight line (Euclidean) ax.plot(     [point_left_top[0], point_right_top[0]],     [point_left_top[1], point_right_top[1]],     \"r--\",     linewidth=3,     alpha=0.5,     label=f\"Euclidean ({euclidean_dist:.1f} cm)\", )  # Mark start and end ax.scatter(     point_left_top[0],     point_left_top[1],     c=\"green\",     s=400,     marker=\"*\",     edgecolors=\"black\",     linewidth=2,     label=\"Start\",     zorder=10, ) ax.scatter(     point_right_top[0],     point_right_top[1],     c=\"red\",     s=400,     marker=\"*\",     edgecolors=\"black\",     linewidth=2,     label=\"End\",     zorder=10, )  ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(\"Geodesic vs Euclidean Distance in U-Maze\") ax.legend(loc=\"upper right\", fontsize=10) ax.set_aspect(\"equal\") plt.tight_layout() plt.show() <p>Key insight: The animal must travel around the barrier, making the actual distance much longer than the straight-line distance!</p> In\u00a0[7]: Copied! <pre># Calculate geodesic distances from one point to many others\nreference_point = np.array([10.0, 55.0])  # Top left\n\n# Sample test points across the environment\ntest_points = np.array(\n    [\n        [10.0, 10.0],  # Bottom left\n        [30.0, 5.0],  # Bottom middle\n        [50.0, 10.0],  # Bottom right\n        [50.0, 30.0],  # Middle right\n        [50.0, 55.0],  # Top right\n    ]\n)\n\nprint(\"\\nDistances from top-left reference point:\")\nprint(f\"{'Location':&lt;20s} {'Euclidean':&gt;12s} {'Geodesic':&gt;12s} {'Ratio':&gt;8s}\")\nprint(\"-\" * 60)\n\nfor i, test_point in enumerate(test_points):\n    euclidean = np.linalg.norm(test_point - reference_point)\n    geodesic = env_u.distance_between(reference_point, test_point)\n    ratio = geodesic / euclidean if euclidean &gt; 0 else 1.0\n\n    location = f\"Point {i} {test_point}\"\n    print(f\"{location:&lt;20s} {euclidean:&gt;10.2f} cm {geodesic:&gt;10.2f} cm {ratio:&gt;7.2f}x\")\n</pre> # Calculate geodesic distances from one point to many others reference_point = np.array([10.0, 55.0])  # Top left  # Sample test points across the environment test_points = np.array(     [         [10.0, 10.0],  # Bottom left         [30.0, 5.0],  # Bottom middle         [50.0, 10.0],  # Bottom right         [50.0, 30.0],  # Middle right         [50.0, 55.0],  # Top right     ] )  print(\"\\nDistances from top-left reference point:\") print(f\"{'Location':&lt;20s} {'Euclidean':&gt;12s} {'Geodesic':&gt;12s} {'Ratio':&gt;8s}\") print(\"-\" * 60)  for i, test_point in enumerate(test_points):     euclidean = np.linalg.norm(test_point - reference_point)     geodesic = env_u.distance_between(reference_point, test_point)     ratio = geodesic / euclidean if euclidean &gt; 0 else 1.0      location = f\"Point {i} {test_point}\"     print(f\"{location:&lt;20s} {euclidean:&gt;10.2f} cm {geodesic:&gt;10.2f} cm {ratio:&gt;7.2f}x\") <pre>\nDistances from top-left reference point:\nLocation                Euclidean     Geodesic    Ratio\n------------------------------------------------------------\nPoint 0 [10. 10.]         45.00 cm      47.95 cm    1.07x\nPoint 1 [30.  5.]         53.85 cm      60.21 cm    1.12x\nPoint 2 [50. 10.]         60.21 cm      77.82 cm    1.29x\nPoint 3 [50. 30.]         47.17 cm      82.79 cm    1.76x\nPoint 4 [50. 55.]         40.00 cm     110.76 cm    2.77x\n</pre> In\u00a0[8]: Copied! <pre># Create a simple square environment\nsquare_data = np.random.uniform(0, 40, size=(1000, 2))\nenv_original = Environment.from_samples(\n    data_samples=square_data, bin_size=5.0, name=\"Original\"\n)\n\nprint(f\"Original environment: {env_original.n_bins} bins\")\nprint(f\"Range: {env_original.dimension_ranges}\")\n</pre> # Create a simple square environment square_data = np.random.uniform(0, 40, size=(1000, 2)) env_original = Environment.from_samples(     data_samples=square_data, bin_size=5.0, name=\"Original\" )  print(f\"Original environment: {env_original.n_bins} bins\") print(f\"Range: {env_original.dimension_ranges}\") <pre>Original environment: 81 bins\nRange: ((np.float64(-2.4760824466081877), np.float64(42.45570448133162)), (np.float64(-2.4987712461847034), np.float64(42.48230813001754)))\n</pre> In\u00a0[9]: Copied! <pre># Example 1: Translation (shift by 10 cm in x, 5 cm in y)\ntranslation_transform = translate(10.0, 5.0)\ntranslated_centers = translation_transform(env_original.bin_centers)\n\nprint(\"\\nTranslation Transform:\")\nprint(f\"  Original center: {env_original.bin_centers[0]}\")\nprint(f\"  Translated center: {translated_centers[0]}\")\nprint(f\"  Shift: {translated_centers[0] - env_original.bin_centers[0]}\")\n</pre> # Example 1: Translation (shift by 10 cm in x, 5 cm in y) translation_transform = translate(10.0, 5.0) translated_centers = translation_transform(env_original.bin_centers)  print(\"\\nTranslation Transform:\") print(f\"  Original center: {env_original.bin_centers[0]}\") print(f\"  Translated center: {translated_centers[0]}\") print(f\"  Shift: {translated_centers[0] - env_original.bin_centers[0]}\") <pre>\nTranslation Transform:\n  Original center: [0.02012794 0.00017761]\n  Translated center: [10.02012794  5.00017761]\n  Shift: [10.  5.]\n</pre> In\u00a0[10]: Copied! <pre># Example 2: Rotation (45 degrees)\n# Note: There's no built-in rotate function in transforms, we use the rotation matrix\nrotation_matrix = get_2d_rotation_matrix(45.0)\nrotation_transform = Affine2D(\n    np.array(\n        [\n            [rotation_matrix[0, 0], rotation_matrix[0, 1], 0],\n            [rotation_matrix[1, 0], rotation_matrix[1, 1], 0],\n            [0, 0, 1],\n        ]\n    )\n)\nrotated_centers = rotation_transform(env_original.bin_centers)\n\nprint(\"\\nRotation Transform (45\u00b0):\")\nprint(f\"  Original: {env_original.bin_centers[0]}\")\nprint(f\"  Rotated: {rotated_centers[0]}\")\n</pre> # Example 2: Rotation (45 degrees) # Note: There's no built-in rotate function in transforms, we use the rotation matrix rotation_matrix = get_2d_rotation_matrix(45.0) rotation_transform = Affine2D(     np.array(         [             [rotation_matrix[0, 0], rotation_matrix[0, 1], 0],             [rotation_matrix[1, 0], rotation_matrix[1, 1], 0],             [0, 0, 1],         ]     ) ) rotated_centers = rotation_transform(env_original.bin_centers)  print(\"\\nRotation Transform (45\u00b0):\") print(f\"  Original: {env_original.bin_centers[0]}\") print(f\"  Rotated: {rotated_centers[0]}\") <pre>\nRotation Transform (45\u00b0):\n  Original: [0.02012794 0.00017761]\n  Rotated: [0.01410701 0.01435819]\n</pre> In\u00a0[11]: Copied! <pre># Example 3: Scaling (2x larger)\nscaling_transform = scale_2d(2.0)\nscaled_centers = scaling_transform(env_original.bin_centers)\n\nprint(\"\\nScaling Transform (2x):\")\nprint(f\"  Original: {env_original.bin_centers[0]}\")\nprint(f\"  Scaled: {scaled_centers[0]}\")\n</pre> # Example 3: Scaling (2x larger) scaling_transform = scale_2d(2.0) scaled_centers = scaling_transform(env_original.bin_centers)  print(\"\\nScaling Transform (2x):\") print(f\"  Original: {env_original.bin_centers[0]}\") print(f\"  Scaled: {scaled_centers[0]}\") <pre>\nScaling Transform (2x):\n  Original: [0.02012794 0.00017761]\n  Scaled: [0.04025588 0.00035522]\n</pre> In\u00a0[12]: Copied! <pre># Compose: First scale 2x, then rotate 30\u00b0, then translate\n# Note: Transformations are composed using the @ operator\nrotation_30 = get_2d_rotation_matrix(30.0)\nrotate_30 = Affine2D(\n    np.array(\n        [\n            [rotation_30[0, 0], rotation_30[0, 1], 0],\n            [rotation_30[1, 0], rotation_30[1, 1], 0],\n            [0, 0, 1],\n        ]\n    )\n)\ncomposite_transform = translate(20, 10) @ rotate_30 @ scale_2d(2.0)\n\n# Apply to bin centers\ntransformed_centers = composite_transform(env_original.bin_centers)\n\nprint(\"\\nComposite Transform (scale \u2192 rotate \u2192 translate):\")\nprint(f\"  Original: {env_original.bin_centers[0]}\")\nprint(f\"  Transformed: {transformed_centers[0]}\")\n</pre> # Compose: First scale 2x, then rotate 30\u00b0, then translate # Note: Transformations are composed using the @ operator rotation_30 = get_2d_rotation_matrix(30.0) rotate_30 = Affine2D(     np.array(         [             [rotation_30[0, 0], rotation_30[0, 1], 0],             [rotation_30[1, 0], rotation_30[1, 1], 0],             [0, 0, 1],         ]     ) ) composite_transform = translate(20, 10) @ rotate_30 @ scale_2d(2.0)  # Apply to bin centers transformed_centers = composite_transform(env_original.bin_centers)  print(\"\\nComposite Transform (scale \u2192 rotate \u2192 translate):\") print(f\"  Original: {env_original.bin_centers[0]}\") print(f\"  Transformed: {transformed_centers[0]}\") <pre>\nComposite Transform (scale \u2192 rotate \u2192 translate):\n  Original: [0.02012794 0.00017761]\n  Transformed: [20.034685   10.02043556]\n</pre> In\u00a0[13]: Copied! <pre># Visualize the transformations\nfig, axes = plt.subplots(2, 2, figsize=(16, 16))\naxes = axes.flatten()\n\ntransforms = [\n    (\"Original\", env_original.bin_centers),\n    (\"Translated (+10, +5)\", translated_centers),\n    (\"Rotated (45\u00b0)\", rotated_centers),\n    (\"Composite\\n(2x, 30\u00b0, +20/+10)\", transformed_centers),\n]\n\nfor ax, (title, centers) in zip(axes, transforms, strict=False):\n    ax.scatter(centers[:, 0], centers[:, 1], c=\"blue\", s=50, alpha=0.6)\n    ax.set_xlabel(\"X position (cm)\")\n    ax.set_ylabel(\"Y position (cm)\")\n    ax.set_title(title)\n    ax.set_aspect(\"equal\")\n    ax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n</pre> # Visualize the transformations fig, axes = plt.subplots(2, 2, figsize=(16, 16)) axes = axes.flatten()  transforms = [     (\"Original\", env_original.bin_centers),     (\"Translated (+10, +5)\", translated_centers),     (\"Rotated (45\u00b0)\", rotated_centers),     (\"Composite\\n(2x, 30\u00b0, +20/+10)\", transformed_centers), ]  for ax, (title, centers) in zip(axes, transforms, strict=False):     ax.scatter(centers[:, 0], centers[:, 1], c=\"blue\", s=50, alpha=0.6)     ax.set_xlabel(\"X position (cm)\")     ax.set_ylabel(\"Y position (cm)\")     ax.set_title(title)     ax.set_aspect(\"equal\")     ax.grid(True, alpha=0.3)  plt.tight_layout() plt.show() In\u00a0[14]: Copied! <pre># Apply transformation\nrotation_45 = get_2d_rotation_matrix(45.0)\nforward = Affine2D(\n    np.array(\n        [\n            [rotation_45[0, 0], rotation_45[0, 1], 0],\n            [rotation_45[1, 0], rotation_45[1, 1], 0],\n            [0, 0, 1],\n        ]\n    )\n)\nrotated = forward(env_original.bin_centers)\n\n# Undo with inverse\nbackward = forward.inverse()\nrestored = backward(rotated)\n\n# Verify they match\nmax_error = np.abs(restored - env_original.bin_centers).max()\n\nprint(\"\\nInverse Transform:\")\nprint(f\"  Original: {env_original.bin_centers[0]}\")\nprint(f\"  Rotated: {rotated[0]}\")\nprint(f\"  Restored: {restored[0]}\")\nprint(f\"  Max error: {max_error:.10f} (should be ~0)\")\n</pre> # Apply transformation rotation_45 = get_2d_rotation_matrix(45.0) forward = Affine2D(     np.array(         [             [rotation_45[0, 0], rotation_45[0, 1], 0],             [rotation_45[1, 0], rotation_45[1, 1], 0],             [0, 0, 1],         ]     ) ) rotated = forward(env_original.bin_centers)  # Undo with inverse backward = forward.inverse() restored = backward(rotated)  # Verify they match max_error = np.abs(restored - env_original.bin_centers).max()  print(\"\\nInverse Transform:\") print(f\"  Original: {env_original.bin_centers[0]}\") print(f\"  Rotated: {rotated[0]}\") print(f\"  Restored: {restored[0]}\") print(f\"  Max error: {max_error:.10f} (should be ~0)\") <pre>\nInverse Transform:\n  Original: [0.02012794 0.00017761]\n  Rotated: [0.01410701 0.01435819]\n  Restored: [0.02012794 0.00017761]\n  Max error: 0.0000000000 (should be ~0)\n</pre> In\u00a0[15]: Copied! <pre># Create two environments with different bin sizes\ncircle = Point(50, 50).buffer(25)\n\n# Fine discretization (3 cm bins)\nenv_fine = Environment.from_polygon(polygon=circle, bin_size=3.0, name=\"Fine\")\n\n# Coarse discretization (6 cm bins)\nenv_coarse = Environment.from_polygon(polygon=circle, bin_size=6.0, name=\"Coarse\")\n\nprint(f\"Fine environment: {env_fine.n_bins} bins (3 cm)\")\nprint(f\"Coarse environment: {env_coarse.n_bins} bins (6 cm)\")\n</pre> # Create two environments with different bin sizes circle = Point(50, 50).buffer(25)  # Fine discretization (3 cm bins) env_fine = Environment.from_polygon(polygon=circle, bin_size=3.0, name=\"Fine\")  # Coarse discretization (6 cm bins) env_coarse = Environment.from_polygon(polygon=circle, bin_size=6.0, name=\"Coarse\")  print(f\"Fine environment: {env_fine.n_bins} bins (3 cm)\") print(f\"Coarse environment: {env_coarse.n_bins} bins (6 cm)\") <pre>Fine environment: 225 bins (3 cm)\nCoarse environment: 69 bins (6 cm)\n</pre> In\u00a0[16]: Copied! <pre># Create a synthetic \"place field\" - Gaussian bump in the fine environment\nplace_field_center = np.array([60.0, 55.0])  # Off-center\nsigma = 8.0  # Width of place field\n\n# Calculate Gaussian firing rate at each bin\ndistances_to_center = np.linalg.norm(env_fine.bin_centers - place_field_center, axis=1)\nfiring_rates_fine = np.exp(-(distances_to_center**2) / (2 * sigma**2))\n\n# Normalize to be a probability distribution\nfiring_probs_fine = firing_rates_fine / firing_rates_fine.sum()\n\nprint(\"\\nPlace field statistics (fine):\")\nprint(f\"  Total probability: {firing_probs_fine.sum():.6f}\")\nprint(f\"  Max probability: {firing_probs_fine.max():.6f}\")\nprint(f\"  Mean probability: {firing_probs_fine.mean():.6f}\")\n</pre> # Create a synthetic \"place field\" - Gaussian bump in the fine environment place_field_center = np.array([60.0, 55.0])  # Off-center sigma = 8.0  # Width of place field  # Calculate Gaussian firing rate at each bin distances_to_center = np.linalg.norm(env_fine.bin_centers - place_field_center, axis=1) firing_rates_fine = np.exp(-(distances_to_center**2) / (2 * sigma**2))  # Normalize to be a probability distribution firing_probs_fine = firing_rates_fine / firing_rates_fine.sum()  print(\"\\nPlace field statistics (fine):\") print(f\"  Total probability: {firing_probs_fine.sum():.6f}\") print(f\"  Max probability: {firing_probs_fine.max():.6f}\") print(f\"  Mean probability: {firing_probs_fine.mean():.6f}\") <pre>\nPlace field statistics (fine):\n  Total probability: 1.000000\n  Max probability: 0.022762\n  Mean probability: 0.004444\n</pre> In\u00a0[17]: Copied! <pre># Visualize the place field on fine grid\nfig, ax = plt.subplots(figsize=(10, 10))\n\nscatter = ax.scatter(\n    env_fine.bin_centers[:, 0],\n    env_fine.bin_centers[:, 1],\n    c=firing_probs_fine,\n    s=200,\n    cmap=\"hot\",\n    vmin=0,\n    vmax=firing_probs_fine.max(),\n)\n\nax.scatter(\n    place_field_center[0],\n    place_field_center[1],\n    c=\"blue\",\n    s=400,\n    marker=\"*\",\n    edgecolors=\"white\",\n    linewidth=2,\n    label=\"Field center\",\n)\n\nplt.colorbar(scatter, ax=ax, label=\"Firing probability\")\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(\"Place Field (Fine Grid, 3 cm bins)\")\nax.set_aspect(\"equal\")\nax.legend()\nplt.tight_layout()\nplt.show()\n</pre> # Visualize the place field on fine grid fig, ax = plt.subplots(figsize=(10, 10))  scatter = ax.scatter(     env_fine.bin_centers[:, 0],     env_fine.bin_centers[:, 1],     c=firing_probs_fine,     s=200,     cmap=\"hot\",     vmin=0,     vmax=firing_probs_fine.max(), )  ax.scatter(     place_field_center[0],     place_field_center[1],     c=\"blue\",     s=400,     marker=\"*\",     edgecolors=\"white\",     linewidth=2,     label=\"Field center\", )  plt.colorbar(scatter, ax=ax, label=\"Firing probability\") ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(\"Place Field (Fine Grid, 3 cm bins)\") ax.set_aspect(\"equal\") ax.legend() plt.tight_layout() plt.show() In\u00a0[18]: Copied! <pre># Map the probabilities to the coarse grid\nfiring_probs_coarse = map_probabilities_to_nearest_target_bin(\n    source_env=env_fine,\n    target_env=env_coarse,\n    source_probs=firing_probs_fine,\n    mode=\"nearest\",  # Map each source bin to nearest target bin\n)\n\nprint(\"\\nPlace field statistics (coarse):\")\nprint(f\"  Total probability: {firing_probs_coarse.sum():.6f}\")\nprint(f\"  Max probability: {firing_probs_coarse.max():.6f}\")\nprint(f\"  Mean probability: {firing_probs_coarse.mean():.6f}\")\n</pre> # Map the probabilities to the coarse grid firing_probs_coarse = map_probabilities_to_nearest_target_bin(     source_env=env_fine,     target_env=env_coarse,     source_probs=firing_probs_fine,     mode=\"nearest\",  # Map each source bin to nearest target bin )  print(\"\\nPlace field statistics (coarse):\") print(f\"  Total probability: {firing_probs_coarse.sum():.6f}\") print(f\"  Max probability: {firing_probs_coarse.max():.6f}\") print(f\"  Mean probability: {firing_probs_coarse.mean():.6f}\") <pre>\nPlace field statistics (coarse):\n  Total probability: 1.000000\n  Max probability: 0.089230\n  Mean probability: 0.014493\n</pre> In\u00a0[19]: Copied! <pre># Compare fine and coarse\nfig, axes = plt.subplots(1, 2, figsize=(18, 8))\n\n# Fine grid\nscatter1 = axes[0].scatter(\n    env_fine.bin_centers[:, 0],\n    env_fine.bin_centers[:, 1],\n    c=firing_probs_fine,\n    s=150,\n    cmap=\"hot\",\n    vmin=0,\n    vmax=firing_probs_fine.max(),\n)\naxes[0].set_title(f\"Fine Grid ({env_fine.n_bins} bins, 3 cm)\")\naxes[0].set_xlabel(\"X position (cm)\")\naxes[0].set_ylabel(\"Y position (cm)\")\naxes[0].set_aspect(\"equal\")\nplt.colorbar(scatter1, ax=axes[0], label=\"Probability\")\n\n# Coarse grid\nscatter2 = axes[1].scatter(\n    env_coarse.bin_centers[:, 0],\n    env_coarse.bin_centers[:, 1],\n    c=firing_probs_coarse,\n    s=300,\n    cmap=\"hot\",\n    vmin=0,\n    vmax=firing_probs_fine.max(),  # Use same scale\n)\naxes[1].set_title(f\"Coarse Grid ({env_coarse.n_bins} bins, 6 cm)\")\naxes[1].set_xlabel(\"X position (cm)\")\naxes[1].set_ylabel(\"Y position (cm)\")\naxes[1].set_aspect(\"equal\")\nplt.colorbar(scatter2, ax=axes[1], label=\"Probability\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Compare fine and coarse fig, axes = plt.subplots(1, 2, figsize=(18, 8))  # Fine grid scatter1 = axes[0].scatter(     env_fine.bin_centers[:, 0],     env_fine.bin_centers[:, 1],     c=firing_probs_fine,     s=150,     cmap=\"hot\",     vmin=0,     vmax=firing_probs_fine.max(), ) axes[0].set_title(f\"Fine Grid ({env_fine.n_bins} bins, 3 cm)\") axes[0].set_xlabel(\"X position (cm)\") axes[0].set_ylabel(\"Y position (cm)\") axes[0].set_aspect(\"equal\") plt.colorbar(scatter1, ax=axes[0], label=\"Probability\")  # Coarse grid scatter2 = axes[1].scatter(     env_coarse.bin_centers[:, 0],     env_coarse.bin_centers[:, 1],     c=firing_probs_coarse,     s=300,     cmap=\"hot\",     vmin=0,     vmax=firing_probs_fine.max(),  # Use same scale ) axes[1].set_title(f\"Coarse Grid ({env_coarse.n_bins} bins, 6 cm)\") axes[1].set_xlabel(\"X position (cm)\") axes[1].set_ylabel(\"Y position (cm)\") axes[1].set_aspect(\"equal\") plt.colorbar(scatter2, ax=axes[1], label=\"Probability\")  plt.tight_layout() plt.show() <p>Note: The probability is preserved (sums to ~1.0), but distributed over fewer, larger bins in the coarse grid.</p> In\u00a0[20]: Copied! <pre># Create rotated version of the fine environment\n# Simulate camera rotation between sessions\nrotation_angle = 45.0  # degrees\n\n# Apply rotation to bin centers to create \"Session 2\" data\nrotation_matrix = get_2d_rotation_matrix(rotation_angle)\nrotation = Affine2D(\n    np.array(\n        [\n            [rotation_matrix[0, 0], rotation_matrix[0, 1], 0],\n            [rotation_matrix[1, 0], rotation_matrix[1, 1], 0],\n            [0, 0, 1],\n        ]\n    )\n)\nrotated_centers = rotation(env_fine.bin_centers)\n\n# Create environment from rotated bin centers\n# (In practice, you'd have new data from Session 2)\nenv_rotated = Environment.from_samples(\n    data_samples=rotated_centers, bin_size=3.0, name=\"Session2_Rotated\"\n)\n\nprint(f\"\\nRotated environment: {env_rotated.n_bins} bins\")\n</pre> # Create rotated version of the fine environment # Simulate camera rotation between sessions rotation_angle = 45.0  # degrees  # Apply rotation to bin centers to create \"Session 2\" data rotation_matrix = get_2d_rotation_matrix(rotation_angle) rotation = Affine2D(     np.array(         [             [rotation_matrix[0, 0], rotation_matrix[0, 1], 0],             [rotation_matrix[1, 0], rotation_matrix[1, 1], 0],             [0, 0, 1],         ]     ) ) rotated_centers = rotation(env_fine.bin_centers)  # Create environment from rotated bin centers # (In practice, you'd have new data from Session 2) env_rotated = Environment.from_samples(     data_samples=rotated_centers, bin_size=3.0, name=\"Session2_Rotated\" )  print(f\"\\nRotated environment: {env_rotated.n_bins} bins\") <pre>\nRotated environment: 188 bins\n</pre> In\u00a0[21]: Copied! <pre># Map place field from Session 1 to Session 2 coordinates\n# Transform Session 1 bin centers to Session 2 coordinates using the rotation transform\ntransformed_bin_centers = rotation(env_fine.bin_centers)\n\n# Now map probabilities\n# (This is more complex - we're showing the concept)\nprint(\"\\nConcept: Place field mapping across rotated sessions\")\nprint(\"  Session 1 (original): Place field centered at\", place_field_center)\nprint(\"  Session 2 (45\u00b0 rotation): Would need to transform center and remap\")\nprint(\"\\nThis is useful for analyzing place field stability across contexts!\")\n</pre> # Map place field from Session 1 to Session 2 coordinates # Transform Session 1 bin centers to Session 2 coordinates using the rotation transform transformed_bin_centers = rotation(env_fine.bin_centers)  # Now map probabilities # (This is more complex - we're showing the concept) print(\"\\nConcept: Place field mapping across rotated sessions\") print(\"  Session 1 (original): Place field centered at\", place_field_center) print(\"  Session 2 (45\u00b0 rotation): Would need to transform center and remap\") print(\"\\nThis is useful for analyzing place field stability across contexts!\") <pre>\nConcept: Place field mapping across rotated sessions\n  Session 1 (original): Place field centered at [60. 55.]\n  Session 2 (45\u00b0 rotation): Would need to transform center and remap\n\nThis is useful for analyzing place field stability across contexts!\n</pre> In\u00a0[22]: Copied! <pre># Create a complex environment for graph analysis\npolygon_coords = [\n    (0, 0),\n    (50, 0),\n    (50, 20),\n    (30, 20),\n    (30, 40),\n    (50, 40),\n    (50, 60),\n    (0, 60),\n    (0, 40),\n    (20, 40),\n    (20, 20),\n    (0, 20),\n]\ncomplex_polygon = Polygon(polygon_coords)\n\nenv_complex = Environment.from_polygon(\n    polygon=complex_polygon, bin_size=4.0, name=\"ComplexMaze\"\n)\n\nprint(f\"Complex maze: {env_complex.n_bins} bins\")\nprint(f\"Edges: {env_complex.connectivity.number_of_edges()}\")\n</pre> # Create a complex environment for graph analysis polygon_coords = [     (0, 0),     (50, 0),     (50, 20),     (30, 20),     (30, 40),     (50, 40),     (50, 60),     (0, 60),     (0, 40),     (20, 40),     (20, 20),     (0, 20), ] complex_polygon = Polygon(polygon_coords)  env_complex = Environment.from_polygon(     polygon=complex_polygon, bin_size=4.0, name=\"ComplexMaze\" )  print(f\"Complex maze: {env_complex.n_bins} bins\") print(f\"Edges: {env_complex.connectivity.number_of_edges()}\") <pre>Complex maze: 145 bins\nEdges: 472\n</pre> In\u00a0[23]: Copied! <pre># Graph metrics\nprint(\"\\nGraph Metrics:\")\nprint(f\"  Number of nodes: {env_complex.connectivity.number_of_nodes()}\")\nprint(f\"  Number of edges: {env_complex.connectivity.number_of_edges()}\")\nprint(f\"  Is connected: {nx.is_connected(env_complex.connectivity)}\")\nprint(\n    f\"  Average degree: {sum(dict(env_complex.connectivity.degree()).values()) / env_complex.n_bins:.2f}\"\n)\n</pre> # Graph metrics print(\"\\nGraph Metrics:\") print(f\"  Number of nodes: {env_complex.connectivity.number_of_nodes()}\") print(f\"  Number of edges: {env_complex.connectivity.number_of_edges()}\") print(f\"  Is connected: {nx.is_connected(env_complex.connectivity)}\") print(     f\"  Average degree: {sum(dict(env_complex.connectivity.degree()).values()) / env_complex.n_bins:.2f}\" ) <pre>\nGraph Metrics:\n  Number of nodes: 145\n  Number of edges: 472\n  Is connected: True\n  Average degree: 6.51\n</pre> In\u00a0[24]: Copied! <pre># Find boundary nodes (bins on the edge of the environment)\n# These have fewer neighbors than interior bins\ndegree_dict = dict(env_complex.connectivity.degree())\ndegrees = np.array([degree_dict[i] for i in range(env_complex.n_bins)])\n\n# In a regular grid, interior nodes have 8 neighbors (with diagonal)\n# Boundary nodes have fewer\nis_boundary = degrees &lt; degrees.max()\nn_boundary = is_boundary.sum()\n\nprint(\"\\nBoundary Analysis:\")\nprint(f\"  Max degree (interior): {degrees.max()}\")\nprint(f\"  Boundary bins: {n_boundary} ({100 * n_boundary / env_complex.n_bins:.1f}%)\")\nprint(f\"  Interior bins: {env_complex.n_bins - n_boundary}\")\n</pre> # Find boundary nodes (bins on the edge of the environment) # These have fewer neighbors than interior bins degree_dict = dict(env_complex.connectivity.degree()) degrees = np.array([degree_dict[i] for i in range(env_complex.n_bins)])  # In a regular grid, interior nodes have 8 neighbors (with diagonal) # Boundary nodes have fewer is_boundary = degrees &lt; degrees.max() n_boundary = is_boundary.sum()  print(\"\\nBoundary Analysis:\") print(f\"  Max degree (interior): {degrees.max()}\") print(f\"  Boundary bins: {n_boundary} ({100 * n_boundary / env_complex.n_bins:.1f}%)\") print(f\"  Interior bins: {env_complex.n_bins - n_boundary}\") <pre>\nBoundary Analysis:\n  Max degree (interior): 8\n  Boundary bins: 72 (49.7%)\n  Interior bins: 73\n</pre> In\u00a0[25]: Copied! <pre># Visualize boundary vs interior\nfig, ax = plt.subplots(figsize=(12, 14))\n\n# Color by degree (number of neighbors)\nscatter = ax.scatter(\n    env_complex.bin_centers[:, 0],\n    env_complex.bin_centers[:, 1],\n    c=degrees,\n    s=200,\n    cmap=\"RdYlBu\",\n    edgecolors=\"black\",\n    linewidth=0.5,\n)\n\nplt.colorbar(scatter, ax=ax, label=\"Number of neighbors (degree)\")\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(\"Bin Connectivity (degree)\\nBlue = boundary, Red = interior\")\nax.set_aspect(\"equal\")\nplt.tight_layout()\nplt.show()\n</pre> # Visualize boundary vs interior fig, ax = plt.subplots(figsize=(12, 14))  # Color by degree (number of neighbors) scatter = ax.scatter(     env_complex.bin_centers[:, 0],     env_complex.bin_centers[:, 1],     c=degrees,     s=200,     cmap=\"RdYlBu\",     edgecolors=\"black\",     linewidth=0.5, )  plt.colorbar(scatter, ax=ax, label=\"Number of neighbors (degree)\") ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(\"Bin Connectivity (degree)\\nBlue = boundary, Red = interior\") ax.set_aspect(\"equal\") plt.tight_layout() plt.show() In\u00a0[26]: Copied! <pre># Calculate betweenness centrality\n# (measures how often a node appears on shortest paths)\nbetweenness = nx.betweenness_centrality(env_complex.connectivity, weight=\"distance\")\nbetweenness_array = np.array([betweenness[i] for i in range(env_complex.n_bins)])\n\n# Find most central bins\ntop_5_indices = np.argsort(betweenness_array)[-5:]\n\nprint(\"\\nTop 5 Most Central Bins (betweenness):\")\nfor i, idx in enumerate(top_5_indices[::-1]):\n    pos = env_complex.bin_centers[idx]\n    centrality = betweenness_array[idx]\n    print(f\"  {i + 1}. Bin {idx} at {pos}: centrality={centrality:.4f}\")\n</pre> # Calculate betweenness centrality # (measures how often a node appears on shortest paths) betweenness = nx.betweenness_centrality(env_complex.connectivity, weight=\"distance\") betweenness_array = np.array([betweenness[i] for i in range(env_complex.n_bins)])  # Find most central bins top_5_indices = np.argsort(betweenness_array)[-5:]  print(\"\\nTop 5 Most Central Bins (betweenness):\") for i, idx in enumerate(top_5_indices[::-1]):     pos = env_complex.bin_centers[idx]     centrality = betweenness_array[idx]     print(f\"  {i + 1}. Bin {idx} at {pos}: centrality={centrality:.4f}\") <pre>\nTop 5 Most Central Bins (betweenness):\n  1. Bin 55 at [21.15384615 22.        ]: centrality=0.2115\n  2. Bin 59 at [21.15384615 38.        ]: centrality=0.2115\n  3. Bin 89 at [28.84615385 38.        ]: centrality=0.2103\n  4. Bin 85 at [28.84615385 22.        ]: centrality=0.2103\n  5. Bin 58 at [21.15384615 34.        ]: centrality=0.1772\n</pre> In\u00a0[27]: Copied! <pre># Visualize centrality\nfig, ax = plt.subplots(figsize=(12, 14))\n\nscatter = ax.scatter(\n    env_complex.bin_centers[:, 0],\n    env_complex.bin_centers[:, 1],\n    c=betweenness_array,\n    s=200,\n    cmap=\"YlOrRd\",\n    edgecolors=\"black\",\n    linewidth=0.5,\n)\n\n# Highlight top central bins\nax.scatter(\n    env_complex.bin_centers[top_5_indices, 0],\n    env_complex.bin_centers[top_5_indices, 1],\n    s=400,\n    facecolors=\"none\",\n    edgecolors=\"blue\",\n    linewidth=3,\n    label=\"Top 5 central\",\n)\n\nplt.colorbar(scatter, ax=ax, label=\"Betweenness centrality\")\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(\"Betweenness Centrality\\n(High = appears on many shortest paths)\")\nax.legend()\nax.set_aspect(\"equal\")\nplt.tight_layout()\nplt.show()\n</pre> # Visualize centrality fig, ax = plt.subplots(figsize=(12, 14))  scatter = ax.scatter(     env_complex.bin_centers[:, 0],     env_complex.bin_centers[:, 1],     c=betweenness_array,     s=200,     cmap=\"YlOrRd\",     edgecolors=\"black\",     linewidth=0.5, )  # Highlight top central bins ax.scatter(     env_complex.bin_centers[top_5_indices, 0],     env_complex.bin_centers[top_5_indices, 1],     s=400,     facecolors=\"none\",     edgecolors=\"blue\",     linewidth=3,     label=\"Top 5 central\", )  plt.colorbar(scatter, ax=ax, label=\"Betweenness centrality\") ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(\"Betweenness Centrality\\n(High = appears on many shortest paths)\") ax.legend() ax.set_aspect(\"equal\") plt.tight_layout() plt.show() <p>Interpretation: High centrality bins are \"bottlenecks\" - the animal must pass through them to travel between many locations. These might correspond to junctions in mazes or doorways in multi-room environments.</p> In\u00a0[28]: Copied! <pre># When mapping probabilities, they should sum to 1.0\n# If they don't, normalize them first!\n\nfiring_rates = np.random.rand(env_fine.n_bins)  # Raw firing rates\nprint(f\"Raw firing rates sum: {firing_rates.sum():.4f}\")\n\n# Normalize\nfiring_probs_normalized = firing_rates / firing_rates.sum()\nprint(f\"Normalized probabilities sum: {firing_probs_normalized.sum():.4f}\")\n\nprint(\"\\n\u2713 Always normalize to probabilities before mapping!\")\n</pre> # When mapping probabilities, they should sum to 1.0 # If they don't, normalize them first!  firing_rates = np.random.rand(env_fine.n_bins)  # Raw firing rates print(f\"Raw firing rates sum: {firing_rates.sum():.4f}\")  # Normalize firing_probs_normalized = firing_rates / firing_rates.sum() print(f\"Normalized probabilities sum: {firing_probs_normalized.sum():.4f}\")  print(\"\\n\u2713 Always normalize to probabilities before mapping!\") <pre>Raw firing rates sum: 112.9080\nNormalized probabilities sum: 1.0000\n\n\u2713 Always normalize to probabilities before mapping!\n</pre> In\u00a0[29]: Copied! <pre># Transforms are applied RIGHT TO LEFT\ntest_point = np.array([[10.0, 10.0]])\n\n# Scale then translate\ntransform1 = translate(10, 10) @ scale_2d(2.0)\nresult1 = transform1(test_point)\n\n# Translate then scale (different!)\ntransform2 = scale_2d(2.0) @ translate(10, 10)\nresult2 = transform2(test_point)\n\nprint(\"Transform order matters:\")\nprint(f\"  Original: {test_point[0]}\")\nprint(f\"  Scale \u2192 Translate: {result1[0]}\")\nprint(f\"  Translate \u2192 Scale: {result2[0]}\")\nprint(\"\\n\u2713 Be explicit about order: compose left-to-right, applies right-to-left\")\n</pre> # Transforms are applied RIGHT TO LEFT test_point = np.array([[10.0, 10.0]])  # Scale then translate transform1 = translate(10, 10) @ scale_2d(2.0) result1 = transform1(test_point)  # Translate then scale (different!) transform2 = scale_2d(2.0) @ translate(10, 10) result2 = transform2(test_point)  print(\"Transform order matters:\") print(f\"  Original: {test_point[0]}\") print(f\"  Scale \u2192 Translate: {result1[0]}\") print(f\"  Translate \u2192 Scale: {result2[0]}\") print(\"\\n\u2713 Be explicit about order: compose left-to-right, applies right-to-left\") <pre>Transform order matters:\n  Original: [10. 10.]\n  Scale \u2192 Translate: [30. 30.]\n  Translate \u2192 Scale: [40. 40.]\n\n\u2713 Be explicit about order: compose left-to-right, applies right-to-left\n</pre> In\u00a0[30]: Copied! <pre>print(\"\\n\u2713 Always plot original and transformed coordinates to verify\")\nprint(\"\u2713 Check that inverse transforms restore original data\")\nprint(\"\u2713 Use test points with known expected results\")\n</pre> print(\"\\n\u2713 Always plot original and transformed coordinates to verify\") print(\"\u2713 Check that inverse transforms restore original data\") print(\"\u2713 Use test points with known expected results\") <pre>\n\u2713 Always plot original and transformed coordinates to verify\n\u2713 Check that inverse transforms restore original data\n\u2713 Use test points with known expected results\n</pre>"},{"location":"examples/07_advanced_operations/#advanced-operations-paths-distances-and-alignment","title":"Advanced Operations: Paths, Distances, and Alignment\u00b6","text":""},{"location":"examples/07_advanced_operations/#learning-objectives","title":"Learning Objectives\u00b6","text":"<p>By the end of this notebook, you will be able to:</p> <ul> <li>Calculate shortest paths through complex environments</li> <li>Understand geodesic vs Euclidean distances</li> <li>Use coordinate transformations (rotation, scaling, translation)</li> <li>Map probability distributions between different environments</li> <li>Align environments with different coordinate systems</li> <li>Apply spatial transforms to analyze remapping and context changes</li> <li>Perform graph-based spatial analysis</li> </ul> <p>Estimated time: 30-35 minutes</p>"},{"location":"examples/07_advanced_operations/#conceptual-introduction","title":"Conceptual Introduction\u00b6","text":"<p>In real neuroscience experiments, you often need to:</p> <ol> <li>Measure distances - How far did the animal travel? What's the distance between place fields?</li> <li>Find paths - What route did the animal take? What's the shortest path between locations?</li> <li>Align environments - Compare data from different sessions where the camera position shifted</li> <li>Map distributions - Transfer place fields between slightly different discretizations</li> </ol> <p>The <code>neurospatial</code> package provides powerful tools for all of these operations!</p>"},{"location":"examples/07_advanced_operations/#setup","title":"Setup\u00b6","text":""},{"location":"examples/07_advanced_operations/#part-1-shortest-paths-and-geodesic-distances","title":"Part 1: Shortest Paths and Geodesic Distances\u00b6","text":""},{"location":"examples/07_advanced_operations/#understanding-distance-metrics","title":"Understanding Distance Metrics\u00b6","text":"<p>Euclidean distance: Straight-line distance (\"as the crow flies\")</p> <p>Geodesic distance: Distance along the shortest path through the environment</p> <p>These can differ significantly in complex environments with barriers or non-Euclidean layouts!</p>"},{"location":"examples/07_advanced_operations/#comparing-euclidean-vs-geodesic-distance","title":"Comparing Euclidean vs Geodesic Distance\u00b6","text":""},{"location":"examples/07_advanced_operations/#visualizing-the-shortest-path","title":"Visualizing the Shortest Path\u00b6","text":""},{"location":"examples/07_advanced_operations/#analyzing-multiple-paths","title":"Analyzing Multiple Paths\u00b6","text":""},{"location":"examples/07_advanced_operations/#part-2-coordinate-transformations","title":"Part 2: Coordinate Transformations\u00b6","text":"<p>Real experiments often have coordinate system issues:</p> <ul> <li>Camera rotated between sessions</li> <li>Different zoom levels (scaling)</li> <li>Arena positioned differently (translation)</li> </ul> <p>The <code>transforms</code> module provides composable 2D transformations!</p>"},{"location":"examples/07_advanced_operations/#basic-transformations","title":"Basic Transformations\u00b6","text":""},{"location":"examples/07_advanced_operations/#composing-transformations","title":"Composing Transformations\u00b6","text":"<p>The power of <code>Affine2D</code> is that you can combine transformations using the <code>@</code> operator:</p>"},{"location":"examples/07_advanced_operations/#inverse-transformations","title":"Inverse Transformations\u00b6","text":"<p>Every transformation has an inverse that undoes it:</p>"},{"location":"examples/07_advanced_operations/#part-3-mapping-probability-distributions","title":"Part 3: Mapping Probability Distributions\u00b6","text":"<p>A common neuroscience task: you have a place field (neural firing rate map) in one discretization, and you need to map it to another discretization.</p> <p>Use cases:</p> <ul> <li>Compare place fields across sessions with slightly different bin sizes</li> <li>Align data from rotated/shifted environments</li> <li>Map predictions from one resolution to another</li> </ul>"},{"location":"examples/07_advanced_operations/#example-mapping-between-different-bin-sizes","title":"Example: Mapping Between Different Bin Sizes\u00b6","text":""},{"location":"examples/07_advanced_operations/#example-mapping-between-rotated-environments","title":"Example: Mapping Between Rotated Environments\u00b6","text":""},{"location":"examples/07_advanced_operations/#part-4-graph-analysis","title":"Part 4: Graph Analysis\u00b6","text":"<p>Since environments are based on NetworkX graphs, you can use graph analysis tools!</p>"},{"location":"examples/07_advanced_operations/#centrality-measures","title":"Centrality Measures\u00b6","text":"<p>Graph centrality can identify \"important\" locations in an environment:</p>"},{"location":"examples/07_advanced_operations/#common-pitfalls-and-best-practices","title":"Common Pitfalls and Best Practices\u00b6","text":""},{"location":"examples/07_advanced_operations/#pitfall-1-forgetting-to-normalize-probabilities","title":"Pitfall 1: Forgetting to normalize probabilities\u00b6","text":""},{"location":"examples/07_advanced_operations/#pitfall-2-transform-order-matters","title":"Pitfall 2: Transform order matters!\u00b6","text":""},{"location":"examples/07_advanced_operations/#best-practice-verify-transformations-visually","title":"Best Practice: Verify transformations visually\u00b6","text":""},{"location":"examples/07_advanced_operations/#key-takeaways","title":"Key Takeaways\u00b6","text":"<p>Congratulations! You've mastered advanced neurospatial operations:</p> <ol> <li><p>Shortest paths find routes through complex environments</p> <ul> <li>Use <code>shortest_path(bin1, bin2)</code> for bin sequences</li> <li>Returns list of bin indices along the path</li> </ul> </li> <li><p>Geodesic distance measures actual travel distance along connectivity graph</p> <ul> <li>Use <code>distance_between(point1, point2)</code></li> <li>Can differ significantly from Euclidean distance in complex spaces</li> </ul> </li> <li><p>Coordinate transformations handle rotations, scaling, translation</p> <ul> <li>Use <code>Affine2D</code> class for transformations</li> <li>Compose transformations: <code>translate(10, 5) @ rotate_transform @ scale_2d(2)</code></li> <li>Every transform has <code>.inverse()</code> to undo it</li> </ul> </li> <li><p>Probability mapping transfers distributions between environments</p> <ul> <li>Use <code>map_probabilities_to_nearest_target_bin()</code></li> <li>Preserves total probability while changing discretization</li> <li>Useful for comparing place fields across sessions</li> </ul> </li> <li><p>Graph analysis reveals environment structure</p> <ul> <li>Degree centrality: number of neighbors</li> <li>Betweenness centrality: bottlenecks and junctions</li> <li>Use NetworkX functions on <code>env.connectivity</code></li> </ul> </li> </ol>"},{"location":"examples/07_advanced_operations/#next-steps","title":"Next Steps\u00b6","text":"<p>In the final notebook (08_complete_workflow.ipynb), you'll see:</p> <ul> <li>Complete end-to-end neuroscience analysis pipeline</li> <li>Raw tracking data \u2192 place fields \u2192 occupancy normalization</li> <li>Multi-region analysis and comparisons</li> <li>Integration of all concepts from previous notebooks</li> <li>Real-world best practices and workflows</li> </ul>"},{"location":"examples/07_advanced_operations/#exercises-optional","title":"Exercises (Optional)\u00b6","text":"<ol> <li>Create a figure-8 maze and calculate geodesic distances between all junction points</li> <li>Design a transformation that rotates 90\u00b0 around a specific point (not origin)</li> <li>Map a place field from a hexagonal to a regular grid layout</li> <li>Find the bin with highest betweenness centrality in a T-maze and explain why</li> <li>Create two rotated versions of an environment and verify probability mapping preserves total mass</li> </ol>"},{"location":"examples/08_complete_workflow/","title":"Complete Workflow: From Raw Data to Publication-Ready Analysis","text":"In\u00a0[1]: Copied! <pre>import warnings\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.gridspec import GridSpec\nfrom scipy.stats import pearsonr\n\nfrom neurospatial import Environment\n\nnp.random.seed(42)\nwarnings.filterwarnings(\"ignore\")  # Suppress minor warnings for cleaner output\n\nplt.rcParams[\"figure.figsize\"] = (16, 12)\nplt.rcParams[\"font.size\"] = 11\nplt.rcParams[\"axes.labelsize\"] = 12\nplt.rcParams[\"axes.titlesize\"] = 14\n</pre> import warnings  import matplotlib.pyplot as plt import numpy as np from matplotlib.gridspec import GridSpec from scipy.stats import pearsonr  from neurospatial import Environment  np.random.seed(42) warnings.filterwarnings(\"ignore\")  # Suppress minor warnings for cleaner output  plt.rcParams[\"figure.figsize\"] = (16, 12) plt.rcParams[\"font.size\"] = 11 plt.rcParams[\"axes.labelsize\"] = 12 plt.rcParams[\"axes.titlesize\"] = 14 In\u00a0[2]: Copied! <pre>def generate_plus_maze_trajectory(n_samples=36000, sampling_rate=30.0):\n    \"\"\"\n    Generate realistic plus maze exploration trajectory.\n\n    Parameters\n    ----------\n    n_samples : int\n        Number of position samples (default 36000 = 20 min at 30 Hz).\n    sampling_rate : float\n        Sampling rate in Hz.\n\n    Returns\n    -------\n    trajectory : ndarray, shape (n_samples, 2)\n        X, Y positions in cm.\n    timestamps : ndarray, shape (n_samples,)\n        Time in seconds.\n    \"\"\"\n    # Plus maze dimensions (in cm)\n\n    # Define arm centers\n    arm_centers = {\n        \"north\": (50, 75),\n        \"south\": (50, 25),\n        \"east\": (75, 50),\n        \"west\": (25, 50),\n        \"center\": (50, 50),\n    }\n\n    trajectory = np.zeros((n_samples, 2))\n    trajectory[0] = arm_centers[\"center\"]\n\n    current_arm = \"center\"\n    time_in_arm = 0\n\n    for i in range(1, n_samples):\n        # Randomly switch arms at center\n        if (\n            current_arm == \"center\" and time_in_arm &gt; 30 and np.random.rand() &lt; 0.1\n        ):  # Stay at least 1 sec, 10% chance to switch\n            current_arm = np.random.choice([\"north\", \"south\", \"east\", \"west\"])\n            time_in_arm = 0\n        elif (\n            current_arm != \"center\" and time_in_arm &gt; 150 and np.random.rand() &lt; 0.15\n        ):  # Stay at least 5 sec, 15% chance to return\n            current_arm = \"center\"\n            time_in_arm = 0\n\n        # Move toward current target\n        target = arm_centers[current_arm]\n        direction = np.array(target) - trajectory[i - 1]\n        distance = np.linalg.norm(direction)\n\n        if distance &gt; 1.0:\n            direction = direction / distance\n            step = direction * np.random.uniform(0.5, 2.5)  # Variable speed\n        else:\n            step = np.random.randn(2) * 0.5  # Small random movements when at target\n\n        trajectory[i] = trajectory[i - 1] + step\n\n        # Keep within bounds\n        trajectory[i] = np.clip(trajectory[i], 15, 85)\n\n        time_in_arm += 1\n\n    timestamps = np.arange(n_samples) / sampling_rate\n\n    return trajectory, timestamps\n\n\n# Generate trajectory\nposition_data, timestamps = generate_plus_maze_trajectory()\n\nprint(\"Position Tracking Data:\")\nprint(f\"  Duration: {timestamps[-1]:.1f} seconds ({timestamps[-1] / 60:.1f} minutes)\")\nprint(f\"  Samples: {len(timestamps)}\")\nprint(\"  Sampling rate: 30 Hz\")\nprint(\n    f\"  X range: [{position_data[:, 0].min():.1f}, {position_data[:, 0].max():.1f}] cm\"\n)\nprint(\n    f\"  Y range: [{position_data[:, 1].min():.1f}, {position_data[:, 1].max():.1f}] cm\"\n)\n</pre> def generate_plus_maze_trajectory(n_samples=36000, sampling_rate=30.0):     \"\"\"     Generate realistic plus maze exploration trajectory.      Parameters     ----------     n_samples : int         Number of position samples (default 36000 = 20 min at 30 Hz).     sampling_rate : float         Sampling rate in Hz.      Returns     -------     trajectory : ndarray, shape (n_samples, 2)         X, Y positions in cm.     timestamps : ndarray, shape (n_samples,)         Time in seconds.     \"\"\"     # Plus maze dimensions (in cm)      # Define arm centers     arm_centers = {         \"north\": (50, 75),         \"south\": (50, 25),         \"east\": (75, 50),         \"west\": (25, 50),         \"center\": (50, 50),     }      trajectory = np.zeros((n_samples, 2))     trajectory[0] = arm_centers[\"center\"]      current_arm = \"center\"     time_in_arm = 0      for i in range(1, n_samples):         # Randomly switch arms at center         if (             current_arm == \"center\" and time_in_arm &gt; 30 and np.random.rand() &lt; 0.1         ):  # Stay at least 1 sec, 10% chance to switch             current_arm = np.random.choice([\"north\", \"south\", \"east\", \"west\"])             time_in_arm = 0         elif (             current_arm != \"center\" and time_in_arm &gt; 150 and np.random.rand() &lt; 0.15         ):  # Stay at least 5 sec, 15% chance to return             current_arm = \"center\"             time_in_arm = 0          # Move toward current target         target = arm_centers[current_arm]         direction = np.array(target) - trajectory[i - 1]         distance = np.linalg.norm(direction)          if distance &gt; 1.0:             direction = direction / distance             step = direction * np.random.uniform(0.5, 2.5)  # Variable speed         else:             step = np.random.randn(2) * 0.5  # Small random movements when at target          trajectory[i] = trajectory[i - 1] + step          # Keep within bounds         trajectory[i] = np.clip(trajectory[i], 15, 85)          time_in_arm += 1      timestamps = np.arange(n_samples) / sampling_rate      return trajectory, timestamps   # Generate trajectory position_data, timestamps = generate_plus_maze_trajectory()  print(\"Position Tracking Data:\") print(f\"  Duration: {timestamps[-1]:.1f} seconds ({timestamps[-1] / 60:.1f} minutes)\") print(f\"  Samples: {len(timestamps)}\") print(\"  Sampling rate: 30 Hz\") print(     f\"  X range: [{position_data[:, 0].min():.1f}, {position_data[:, 0].max():.1f}] cm\" ) print(     f\"  Y range: [{position_data[:, 1].min():.1f}, {position_data[:, 1].max():.1f}] cm\" ) <pre>Position Tracking Data:\n  Duration: 1200.0 seconds (20.0 minutes)\n  Samples: 36000\n  Sampling rate: 30 Hz\n  X range: [22.5, 77.5] cm\n  Y range: [22.1, 77.3] cm\n</pre> In\u00a0[3]: Copied! <pre># Visualize trajectory\nfig, axes = plt.subplots(1, 2, figsize=(18, 8))\n\n# Full trajectory colored by time\nscatter = axes[0].scatter(\n    position_data[:, 0],\n    position_data[:, 1],\n    c=timestamps,\n    s=1,\n    alpha=0.3,\n    cmap=\"viridis\",\n)\naxes[0].plot(\n    position_data[0, 0], position_data[0, 1], \"go\", markersize=10, label=\"Start\"\n)\naxes[0].plot(\n    position_data[-1, 0], position_data[-1, 1], \"ro\", markersize=10, label=\"End\"\n)\naxes[0].set_xlabel(\"X position (cm)\")\naxes[0].set_ylabel(\"Y position (cm)\")\naxes[0].set_title(\"Full Trajectory (20 minutes)\")\naxes[0].set_aspect(\"equal\")\naxes[0].legend()\nplt.colorbar(scatter, ax=axes[0], label=\"Time (s)\")\n\n# Time series\naxes[1].plot(\n    timestamps, position_data[:, 0], \"b-\", alpha=0.7, linewidth=0.5, label=\"X position\"\n)\naxes[1].plot(\n    timestamps, position_data[:, 1], \"r-\", alpha=0.7, linewidth=0.5, label=\"Y position\"\n)\naxes[1].set_xlabel(\"Time (s)\")\naxes[1].set_ylabel(\"Position (cm)\")\naxes[1].set_title(\"Position Over Time\")\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n</pre> # Visualize trajectory fig, axes = plt.subplots(1, 2, figsize=(18, 8))  # Full trajectory colored by time scatter = axes[0].scatter(     position_data[:, 0],     position_data[:, 1],     c=timestamps,     s=1,     alpha=0.3,     cmap=\"viridis\", ) axes[0].plot(     position_data[0, 0], position_data[0, 1], \"go\", markersize=10, label=\"Start\" ) axes[0].plot(     position_data[-1, 0], position_data[-1, 1], \"ro\", markersize=10, label=\"End\" ) axes[0].set_xlabel(\"X position (cm)\") axes[0].set_ylabel(\"Y position (cm)\") axes[0].set_title(\"Full Trajectory (20 minutes)\") axes[0].set_aspect(\"equal\") axes[0].legend() plt.colorbar(scatter, ax=axes[0], label=\"Time (s)\")  # Time series axes[1].plot(     timestamps, position_data[:, 0], \"b-\", alpha=0.7, linewidth=0.5, label=\"X position\" ) axes[1].plot(     timestamps, position_data[:, 1], \"r-\", alpha=0.7, linewidth=0.5, label=\"Y position\" ) axes[1].set_xlabel(\"Time (s)\") axes[1].set_ylabel(\"Position (cm)\") axes[1].set_title(\"Position Over Time\") axes[1].legend() axes[1].grid(True, alpha=0.3)  plt.tight_layout() plt.show() In\u00a0[4]: Copied! <pre>def generate_place_cell_spikes(position_data, timestamps, n_neurons=20):\n    \"\"\"\n    Generate realistic place cell spike times.\n\n    Parameters\n    ----------\n    position_data : ndarray, shape (n_samples, 2)\n        Position trajectory.\n    timestamps : ndarray, shape (n_samples,)\n        Time for each position sample.\n    n_neurons : int\n        Number of neurons to simulate.\n\n    Returns\n    -------\n    spike_times : dict\n        Mapping from neuron_id to array of spike times.\n    place_field_centers : dict\n        Mapping from neuron_id to (x, y) place field center.\n    \"\"\"\n    spike_times = {}\n    place_field_centers = {}\n\n    # Define regions for place fields\n    regions = [\n        (50, 75, \"north\"),  # North arm\n        (50, 25, \"south\"),  # South arm\n        (75, 50, \"east\"),  # East arm\n        (25, 50, \"west\"),  # West arm\n        (50, 50, \"center\"),  # Center\n    ]\n\n    for neuron_id in range(n_neurons):\n        # Randomly assign place field\n        if neuron_id &lt; 15:  # 15 place cells\n            # Choose region\n            region = regions[neuron_id % len(regions)]\n            # Add some variability\n            center_x = region[0] + np.random.randn() * 5\n            center_y = region[1] + np.random.randn() * 5\n            place_field_centers[neuron_id] = (center_x, center_y)\n\n            # Field width\n            field_width = np.random.uniform(8, 15)\n\n            # Peak firing rate\n            peak_rate = np.random.uniform(8, 20)  # Hz\n\n            # Calculate firing rate at each position\n            distances = np.sqrt(\n                (position_data[:, 0] - center_x) ** 2\n                + (position_data[:, 1] - center_y) ** 2\n            )\n            firing_rates = peak_rate * np.exp(-(distances**2) / (2 * field_width**2))\n\n        else:  # 5 non-spatial cells (control)\n            place_field_centers[neuron_id] = None\n            firing_rates = np.ones(len(timestamps)) * np.random.uniform(\n                1, 3\n            )  # Low baseline\n\n        # Generate spikes from firing rates (inhomogeneous Poisson process)\n        dt = np.diff(timestamps).mean()  # Time step\n        spike_probs = firing_rates * dt  # Probability of spike in each time bin\n        spike_occurred = np.random.rand(len(timestamps)) &lt; spike_probs\n        spike_times[neuron_id] = timestamps[spike_occurred]\n\n    return spike_times, place_field_centers\n\n\n# Generate spikes\nspike_times, place_field_centers = generate_place_cell_spikes(position_data, timestamps)\n\nprint(\"\\nNeural Activity Data:\")\nprint(f\"  Number of neurons: {len(spike_times)}\")\nprint(\"  Place cells: 15\")\nprint(\"  Non-spatial cells: 5\")\nprint(\"\\nSpike counts:\")\nfor neuron_id in range(5):  # Show first 5\n    n_spikes = len(spike_times[neuron_id])\n    mean_rate = n_spikes / timestamps[-1]\n    field_info = (\n        \"\"\n        if place_field_centers[neuron_id] is None\n        else f\" (field at {place_field_centers[neuron_id]})\"\n    )\n    print(f\"  Neuron {neuron_id}: {n_spikes} spikes, {mean_rate:.2f} Hz{field_info}\")\n</pre> def generate_place_cell_spikes(position_data, timestamps, n_neurons=20):     \"\"\"     Generate realistic place cell spike times.      Parameters     ----------     position_data : ndarray, shape (n_samples, 2)         Position trajectory.     timestamps : ndarray, shape (n_samples,)         Time for each position sample.     n_neurons : int         Number of neurons to simulate.      Returns     -------     spike_times : dict         Mapping from neuron_id to array of spike times.     place_field_centers : dict         Mapping from neuron_id to (x, y) place field center.     \"\"\"     spike_times = {}     place_field_centers = {}      # Define regions for place fields     regions = [         (50, 75, \"north\"),  # North arm         (50, 25, \"south\"),  # South arm         (75, 50, \"east\"),  # East arm         (25, 50, \"west\"),  # West arm         (50, 50, \"center\"),  # Center     ]      for neuron_id in range(n_neurons):         # Randomly assign place field         if neuron_id &lt; 15:  # 15 place cells             # Choose region             region = regions[neuron_id % len(regions)]             # Add some variability             center_x = region[0] + np.random.randn() * 5             center_y = region[1] + np.random.randn() * 5             place_field_centers[neuron_id] = (center_x, center_y)              # Field width             field_width = np.random.uniform(8, 15)              # Peak firing rate             peak_rate = np.random.uniform(8, 20)  # Hz              # Calculate firing rate at each position             distances = np.sqrt(                 (position_data[:, 0] - center_x) ** 2                 + (position_data[:, 1] - center_y) ** 2             )             firing_rates = peak_rate * np.exp(-(distances**2) / (2 * field_width**2))          else:  # 5 non-spatial cells (control)             place_field_centers[neuron_id] = None             firing_rates = np.ones(len(timestamps)) * np.random.uniform(                 1, 3             )  # Low baseline          # Generate spikes from firing rates (inhomogeneous Poisson process)         dt = np.diff(timestamps).mean()  # Time step         spike_probs = firing_rates * dt  # Probability of spike in each time bin         spike_occurred = np.random.rand(len(timestamps)) &lt; spike_probs         spike_times[neuron_id] = timestamps[spike_occurred]      return spike_times, place_field_centers   # Generate spikes spike_times, place_field_centers = generate_place_cell_spikes(position_data, timestamps)  print(\"\\nNeural Activity Data:\") print(f\"  Number of neurons: {len(spike_times)}\") print(\"  Place cells: 15\") print(\"  Non-spatial cells: 5\") print(\"\\nSpike counts:\") for neuron_id in range(5):  # Show first 5     n_spikes = len(spike_times[neuron_id])     mean_rate = n_spikes / timestamps[-1]     field_info = (         \"\"         if place_field_centers[neuron_id] is None         else f\" (field at {place_field_centers[neuron_id]})\"     )     print(f\"  Neuron {neuron_id}: {n_spikes} spikes, {mean_rate:.2f} Hz{field_info}\") <pre>\nNeural Activity Data:\n  Number of neurons: 20\n  Place cells: 15\n  Non-spatial cells: 5\n\nSpike counts:\n  Neuron 0: 2550 spikes, 2.13 Hz (field at (52.905933068908794, 78.54288066686532))\n  Neuron 1: 2386 spikes, 1.99 Hz (field at (44.61819029954033, 20.16027818946123))\n  Neuron 2: 3614 spikes, 3.01 Hz (field at (80.18829096380401, 45.11910589089495))\n  Neuron 3: 2546 spikes, 2.12 Hz (field at (25.183272204238953, 39.80059298300367))\n  Neuron 4: 4132 spikes, 3.44 Hz (field at (47.51480131280007, 44.34407854469787))\n</pre> In\u00a0[5]: Copied! <pre># Create environment from position data\nenv = Environment.from_samples(\n    data_samples=position_data,\n    bin_size=3.0,  # 3 cm bins - good resolution for rodent place fields\n    connect_diagonal_neighbors=True,\n    infer_active_bins=True,\n    bin_count_threshold=5,  # Require at least 5 samples per bin\n    name=\"PlusMaze\",\n)\n\nprint(\"\\nSpatial Environment:\")\nprint(env.info())\n</pre> # Create environment from position data env = Environment.from_samples(     data_samples=position_data,     bin_size=3.0,  # 3 cm bins - good resolution for rodent place fields     connect_diagonal_neighbors=True,     infer_active_bins=True,     bin_count_threshold=5,  # Require at least 5 samples per bin     name=\"PlusMaze\", )  print(\"\\nSpatial Environment:\") print(env.info()) <pre>\nSpatial Environment:\nEnvironment Information\n=======================\n\nName: PlusMaze\nLayout Type: RegularGrid\nDimensions: 2\nNumber of Bins: 76\n\nSpatial Extent:\n  Dimension 0: [21.04, 79.03] (range: 57.99)\n  Dimension 1: [20.59, 78.80] (range: 58.21)\n\nBin Sizes:\n  Dimension 0: 2.90\n  Dimension 1: 2.91\n\nRegions: None\n\n</pre> In\u00a0[6]: Copied! <pre># Visualize the discretized environment\nfig, ax = plt.subplots(figsize=(10, 10))\nenv.plot(ax=ax, show_connectivity=True)\nax.set_title(f\"Plus Maze Environment ({env.n_bins} bins, 3 cm resolution)\")\nax.set_aspect(\"equal\")\nplt.tight_layout()\nplt.show()\n</pre> # Visualize the discretized environment fig, ax = plt.subplots(figsize=(10, 10)) env.plot(ax=ax, show_connectivity=True) ax.set_title(f\"Plus Maze Environment ({env.n_bins} bins, 3 cm resolution)\") ax.set_aspect(\"equal\") plt.tight_layout() plt.show() In\u00a0[7]: Copied! <pre># Add regions for each arm and center\nregions_to_add = {\n    \"north_arm\": (50, 75),\n    \"south_arm\": (50, 25),\n    \"east_arm\": (75, 50),\n    \"west_arm\": (25, 50),\n    \"center\": (50, 50),\n    \"north_reward\": (50, 85),  # End of north arm\n    \"south_reward\": (50, 15),  # End of south arm\n}\n\nfor name, point in regions_to_add.items():\n    env.regions.add(name=name, point=np.array(point))\n\nprint(\"Defined Regions:\")\nfor name in env.regions:\n    region = env.regions[name]\n    print(f\"  {name:15s}: {region.data}\")\n</pre> # Add regions for each arm and center regions_to_add = {     \"north_arm\": (50, 75),     \"south_arm\": (50, 25),     \"east_arm\": (75, 50),     \"west_arm\": (25, 50),     \"center\": (50, 50),     \"north_reward\": (50, 85),  # End of north arm     \"south_reward\": (50, 15),  # End of south arm }  for name, point in regions_to_add.items():     env.regions.add(name=name, point=np.array(point))  print(\"Defined Regions:\") for name in env.regions:     region = env.regions[name]     print(f\"  {name:15s}: {region.data}\") <pre>Defined Regions:\n  north_arm      : [50. 75.]\n  south_arm      : [50. 25.]\n  east_arm       : [75. 50.]\n  west_arm       : [25. 50.]\n  center         : [50. 50.]\n  north_reward   : [50. 85.]\n  south_reward   : [50. 15.]\n</pre> In\u00a0[8]: Copied! <pre># Map positions to bins\nbin_indices = env.bin_at(position_data)\n\n# Count samples per bin (occupancy in number of samples)\noccupancy_samples = np.bincount(bin_indices[bin_indices &gt;= 0], minlength=env.n_bins)\n\n# Convert to time (seconds)\nsampling_rate = 30.0  # Hz\noccupancy_time = occupancy_samples / sampling_rate\n\nprint(\"\\nOccupancy Statistics:\")\nprint(f\"  Total time: {occupancy_time.sum():.1f} seconds\")\nprint(f\"  Mean time per bin: {occupancy_time[occupancy_time &gt; 0].mean():.2f} seconds\")\nprint(f\"  Max time in any bin: {occupancy_time.max():.2f} seconds\")\nprint(f\"  Bins with &gt;1 sec: {(occupancy_time &gt; 1).sum()} / {env.n_bins}\")\n</pre> # Map positions to bins bin_indices = env.bin_at(position_data)  # Count samples per bin (occupancy in number of samples) occupancy_samples = np.bincount(bin_indices[bin_indices &gt;= 0], minlength=env.n_bins)  # Convert to time (seconds) sampling_rate = 30.0  # Hz occupancy_time = occupancy_samples / sampling_rate  print(\"\\nOccupancy Statistics:\") print(f\"  Total time: {occupancy_time.sum():.1f} seconds\") print(f\"  Mean time per bin: {occupancy_time[occupancy_time &gt; 0].mean():.2f} seconds\") print(f\"  Max time in any bin: {occupancy_time.max():.2f} seconds\") print(f\"  Bins with &gt;1 sec: {(occupancy_time &gt; 1).sum()} / {env.n_bins}\") <pre>\nOccupancy Statistics:\n  Total time: 1200.0 seconds\n  Mean time per bin: 15.79 seconds\n  Max time in any bin: 166.23 seconds\n  Bins with &gt;1 sec: 64 / 76\n</pre> In\u00a0[9]: Copied! <pre># Visualize occupancy\nfig, ax = plt.subplots(figsize=(10, 10))\n\nscatter = ax.scatter(\n    env.bin_centers[:, 0],\n    env.bin_centers[:, 1],\n    c=occupancy_time,\n    s=200,\n    cmap=\"YlOrRd\",\n    vmin=0,\n    edgecolors=\"black\",\n    linewidth=0.5,\n)\n\nplt.colorbar(scatter, ax=ax, label=\"Occupancy (seconds)\")\nax.set_xlabel(\"X position (cm)\")\nax.set_ylabel(\"Y position (cm)\")\nax.set_title(\"Occupancy Map\")\nax.set_aspect(\"equal\")\nplt.tight_layout()\nplt.show()\n</pre> # Visualize occupancy fig, ax = plt.subplots(figsize=(10, 10))  scatter = ax.scatter(     env.bin_centers[:, 0],     env.bin_centers[:, 1],     c=occupancy_time,     s=200,     cmap=\"YlOrRd\",     vmin=0,     edgecolors=\"black\",     linewidth=0.5, )  plt.colorbar(scatter, ax=ax, label=\"Occupancy (seconds)\") ax.set_xlabel(\"X position (cm)\") ax.set_ylabel(\"Y position (cm)\") ax.set_title(\"Occupancy Map\") ax.set_aspect(\"equal\") plt.tight_layout() plt.show() In\u00a0[10]: Copied! <pre>def compute_place_field(\n    spike_times,\n    position_data,\n    bin_indices,\n    timestamps,\n    n_bins,\n    occupancy_time,\n    smooth_sigma=1.0,\n):\n    \"\"\"\n    Compute occupancy-normalized firing rate map.\n\n    Parameters\n    ----------\n    spike_times : ndarray\n        Spike times for one neuron.\n    position_data : ndarray, shape (n_samples, 2)\n        Position trajectory.\n    bin_indices : ndarray, shape (n_samples,)\n        Bin index for each position sample.\n    timestamps : ndarray, shape (n_samples,)\n        Time for each position sample.\n    n_bins : int\n        Total number of bins.\n    occupancy_time : ndarray, shape (n_bins,)\n        Time spent in each bin (seconds).\n    smooth_sigma : float\n        Gaussian smoothing parameter.\n\n    Returns\n    -------\n    firing_rate : ndarray, shape (n_bins,)\n        Firing rate in Hz for each bin.\n    spike_count : ndarray, shape (n_bins,)\n        Number of spikes in each bin.\n    \"\"\"\n    # Find which bin the animal was in for each spike\n    spike_bin_indices = np.zeros(len(spike_times), dtype=int)\n    for i, spike_time in enumerate(spike_times):\n        # Find closest timestamp\n        idx = np.argmin(np.abs(timestamps - spike_time))\n        spike_bin_indices[i] = bin_indices[idx]\n\n    # Count spikes per bin\n    spike_count = np.bincount(\n        spike_bin_indices[spike_bin_indices &gt;= 0], minlength=n_bins\n    ).astype(float)\n\n    # Compute firing rate (spikes / time)\n    firing_rate = np.zeros(n_bins)\n    valid_bins = occupancy_time &gt; 0.1  # Only bins with &gt;100ms occupancy\n    firing_rate[valid_bins] = spike_count[valid_bins] / occupancy_time[valid_bins]\n\n    return firing_rate, spike_count\n\n\n# Compute place fields for all neurons\nplace_fields = {}\nspike_counts = {}\n\nprint(\"Computing place fields...\")\nfor neuron_id in range(len(spike_times)):\n    firing_rate, spike_count = compute_place_field(\n        spike_times=spike_times[neuron_id],\n        position_data=position_data,\n        bin_indices=bin_indices,\n        timestamps=timestamps,\n        n_bins=env.n_bins,\n        occupancy_time=occupancy_time,\n    )\n    place_fields[neuron_id] = firing_rate\n    spike_counts[neuron_id] = spike_count\n\nprint(f\"\\nComputed place fields for {len(place_fields)} neurons\")\nprint(\"\\nSample statistics (first 5 neurons):\")\nfor neuron_id in range(5):\n    mean_rate = place_fields[neuron_id][place_fields[neuron_id] &gt; 0].mean()\n    peak_rate = place_fields[neuron_id].max()\n    print(f\"  Neuron {neuron_id}: mean={mean_rate:.2f} Hz, peak={peak_rate:.2f} Hz\")\n</pre> def compute_place_field(     spike_times,     position_data,     bin_indices,     timestamps,     n_bins,     occupancy_time,     smooth_sigma=1.0, ):     \"\"\"     Compute occupancy-normalized firing rate map.      Parameters     ----------     spike_times : ndarray         Spike times for one neuron.     position_data : ndarray, shape (n_samples, 2)         Position trajectory.     bin_indices : ndarray, shape (n_samples,)         Bin index for each position sample.     timestamps : ndarray, shape (n_samples,)         Time for each position sample.     n_bins : int         Total number of bins.     occupancy_time : ndarray, shape (n_bins,)         Time spent in each bin (seconds).     smooth_sigma : float         Gaussian smoothing parameter.      Returns     -------     firing_rate : ndarray, shape (n_bins,)         Firing rate in Hz for each bin.     spike_count : ndarray, shape (n_bins,)         Number of spikes in each bin.     \"\"\"     # Find which bin the animal was in for each spike     spike_bin_indices = np.zeros(len(spike_times), dtype=int)     for i, spike_time in enumerate(spike_times):         # Find closest timestamp         idx = np.argmin(np.abs(timestamps - spike_time))         spike_bin_indices[i] = bin_indices[idx]      # Count spikes per bin     spike_count = np.bincount(         spike_bin_indices[spike_bin_indices &gt;= 0], minlength=n_bins     ).astype(float)      # Compute firing rate (spikes / time)     firing_rate = np.zeros(n_bins)     valid_bins = occupancy_time &gt; 0.1  # Only bins with &gt;100ms occupancy     firing_rate[valid_bins] = spike_count[valid_bins] / occupancy_time[valid_bins]      return firing_rate, spike_count   # Compute place fields for all neurons place_fields = {} spike_counts = {}  print(\"Computing place fields...\") for neuron_id in range(len(spike_times)):     firing_rate, spike_count = compute_place_field(         spike_times=spike_times[neuron_id],         position_data=position_data,         bin_indices=bin_indices,         timestamps=timestamps,         n_bins=env.n_bins,         occupancy_time=occupancy_time,     )     place_fields[neuron_id] = firing_rate     spike_counts[neuron_id] = spike_count  print(f\"\\nComputed place fields for {len(place_fields)} neurons\") print(\"\\nSample statistics (first 5 neurons):\") for neuron_id in range(5):     mean_rate = place_fields[neuron_id][place_fields[neuron_id] &gt; 0].mean()     peak_rate = place_fields[neuron_id].max()     print(f\"  Neuron {neuron_id}: mean={mean_rate:.2f} Hz, peak={peak_rate:.2f} Hz\") <pre>Computing place fields...\n\nComputed place fields for 20 neurons\n\nSample statistics (first 5 neurons):\n  Neuron 0: mean=3.39 Hz, peak=13.55 Hz\n  Neuron 1: mean=2.69 Hz, peak=10.43 Hz\n  Neuron 2: mean=3.38 Hz, peak=15.87 Hz\n  Neuron 3: mean=2.43 Hz, peak=8.16 Hz\n  Neuron 4: mean=4.93 Hz, peak=13.45 Hz\n</pre> In\u00a0[11]: Copied! <pre># Plot place fields for first 12 neurons\nfig = plt.figure(figsize=(20, 15))\ngs = GridSpec(3, 4, figure=fig, hspace=0.3, wspace=0.3)\n\nfor idx in range(12):\n    ax = fig.add_subplot(gs[idx // 4, idx % 4])\n\n    firing_rate = place_fields[idx]\n\n    scatter = ax.scatter(\n        env.bin_centers[:, 0],\n        env.bin_centers[:, 1],\n        c=firing_rate,\n        s=150,\n        cmap=\"hot\",\n        vmin=0,\n        vmax=firing_rate.max() if firing_rate.max() &gt; 0 else 1,\n        edgecolors=\"gray\",\n        linewidth=0.3,\n    )\n\n    # Mark true place field center if it exists\n    if place_field_centers[idx] is not None:\n        ax.plot(\n            place_field_centers[idx][0],\n            place_field_centers[idx][1],\n            \"c*\",\n            markersize=15,\n            markeredgecolor=\"white\",\n            markeredgewidth=1.5,\n        )\n\n    ax.set_xlabel(\"X (cm)\", fontsize=9)\n    ax.set_ylabel(\"Y (cm)\", fontsize=9)\n    ax.set_title(f\"Neuron {idx} (peak: {firing_rate.max():.1f} Hz)\", fontsize=10)\n    ax.set_aspect(\"equal\")\n    plt.colorbar(scatter, ax=ax, label=\"Rate (Hz)\")\n\nplt.suptitle(\"Place Fields (Firing Rate Maps)\", fontsize=16, y=0.995)\nplt.show()\n</pre> # Plot place fields for first 12 neurons fig = plt.figure(figsize=(20, 15)) gs = GridSpec(3, 4, figure=fig, hspace=0.3, wspace=0.3)  for idx in range(12):     ax = fig.add_subplot(gs[idx // 4, idx % 4])      firing_rate = place_fields[idx]      scatter = ax.scatter(         env.bin_centers[:, 0],         env.bin_centers[:, 1],         c=firing_rate,         s=150,         cmap=\"hot\",         vmin=0,         vmax=firing_rate.max() if firing_rate.max() &gt; 0 else 1,         edgecolors=\"gray\",         linewidth=0.3,     )      # Mark true place field center if it exists     if place_field_centers[idx] is not None:         ax.plot(             place_field_centers[idx][0],             place_field_centers[idx][1],             \"c*\",             markersize=15,             markeredgecolor=\"white\",             markeredgewidth=1.5,         )      ax.set_xlabel(\"X (cm)\", fontsize=9)     ax.set_ylabel(\"Y (cm)\", fontsize=9)     ax.set_title(f\"Neuron {idx} (peak: {firing_rate.max():.1f} Hz)\", fontsize=10)     ax.set_aspect(\"equal\")     plt.colorbar(scatter, ax=ax, label=\"Rate (Hz)\")  plt.suptitle(\"Place Fields (Firing Rate Maps)\", fontsize=16, y=0.995) plt.show() In\u00a0[12]: Copied! <pre>def compute_spatial_information(firing_rate, occupancy_time):\n    \"\"\"\n    Compute spatial information in bits per spike.\n\n    Skaggs et al. (1993) metric:\n    I = \u03a3 p(x) * (r(x) / r_mean) * log2(r(x) / r_mean)\n\n    Parameters\n    ----------\n    firing_rate : ndarray, shape (n_bins,)\n        Firing rate in each bin (Hz).\n    occupancy_time : ndarray, shape (n_bins,)\n        Time spent in each bin (seconds).\n\n    Returns\n    -------\n    spatial_info : float\n        Spatial information in bits per spike.\n    \"\"\"\n    # Occupancy probability\n    total_time = occupancy_time.sum()\n    p_x = occupancy_time / total_time\n\n    # Mean firing rate\n    r_mean = np.sum(firing_rate * p_x)\n\n    if r_mean == 0:\n        return 0.0\n\n    # Spatial information\n    spatial_info = 0.0\n    for i in range(len(firing_rate)):\n        if p_x[i] &gt; 0 and firing_rate[i] &gt; 0:\n            spatial_info += (\n                p_x[i] * (firing_rate[i] / r_mean) * np.log2(firing_rate[i] / r_mean)\n            )\n\n    return spatial_info\n\n\n# Compute spatial information for all neurons\nspatial_information = {}\nfor neuron_id in range(len(spike_times)):\n    spatial_info = compute_spatial_information(\n        firing_rate=place_fields[neuron_id], occupancy_time=occupancy_time\n    )\n    spatial_information[neuron_id] = spatial_info\n\n# Sort by spatial information\nsorted_neurons = sorted(spatial_information.items(), key=lambda x: x[1], reverse=True)\n\nprint(\"\\nSpatial Information (bits/spike):\")\nprint(f\"{'Neuron':&lt;10s} {'Info':&gt;10s} {'Type':&gt;15s} {'Peak Rate':&gt;12s}\")\nprint(\"-\" * 50)\nfor neuron_id, info in sorted_neurons[:10]:  # Top 10\n    cell_type = (\n        \"Place cell\" if place_field_centers[neuron_id] is not None else \"Non-spatial\"\n    )\n    peak_rate = place_fields[neuron_id].max()\n    print(f\"{neuron_id:&lt;10d} {info:&gt;10.3f} {cell_type:&gt;15s} {peak_rate:&gt;10.2f} Hz\")\n</pre> def compute_spatial_information(firing_rate, occupancy_time):     \"\"\"     Compute spatial information in bits per spike.      Skaggs et al. (1993) metric:     I = \u03a3 p(x) * (r(x) / r_mean) * log2(r(x) / r_mean)      Parameters     ----------     firing_rate : ndarray, shape (n_bins,)         Firing rate in each bin (Hz).     occupancy_time : ndarray, shape (n_bins,)         Time spent in each bin (seconds).      Returns     -------     spatial_info : float         Spatial information in bits per spike.     \"\"\"     # Occupancy probability     total_time = occupancy_time.sum()     p_x = occupancy_time / total_time      # Mean firing rate     r_mean = np.sum(firing_rate * p_x)      if r_mean == 0:         return 0.0      # Spatial information     spatial_info = 0.0     for i in range(len(firing_rate)):         if p_x[i] &gt; 0 and firing_rate[i] &gt; 0:             spatial_info += (                 p_x[i] * (firing_rate[i] / r_mean) * np.log2(firing_rate[i] / r_mean)             )      return spatial_info   # Compute spatial information for all neurons spatial_information = {} for neuron_id in range(len(spike_times)):     spatial_info = compute_spatial_information(         firing_rate=place_fields[neuron_id], occupancy_time=occupancy_time     )     spatial_information[neuron_id] = spatial_info  # Sort by spatial information sorted_neurons = sorted(spatial_information.items(), key=lambda x: x[1], reverse=True)  print(\"\\nSpatial Information (bits/spike):\") print(f\"{'Neuron':&lt;10s} {'Info':&gt;10s} {'Type':&gt;15s} {'Peak Rate':&gt;12s}\") print(\"-\" * 50) for neuron_id, info in sorted_neurons[:10]:  # Top 10     cell_type = (         \"Place cell\" if place_field_centers[neuron_id] is not None else \"Non-spatial\"     )     peak_rate = place_fields[neuron_id].max()     print(f\"{neuron_id:&lt;10d} {info:&gt;10.3f} {cell_type:&gt;15s} {peak_rate:&gt;10.2f} Hz\") <pre>\nSpatial Information (bits/spike):\nNeuron           Info            Type    Peak Rate\n--------------------------------------------------\n5               2.567      Place cell      14.45 Hz\n7               2.197      Place cell       8.02 Hz\n0               2.141      Place cell      13.55 Hz\n10              2.140      Place cell      16.44 Hz\n13              2.109      Place cell      12.22 Hz\n8               2.091      Place cell       9.69 Hz\n12              1.868      Place cell      16.88 Hz\n11              1.802      Place cell       8.62 Hz\n1               1.790      Place cell      10.43 Hz\n2               1.776      Place cell      15.87 Hz\n</pre> In\u00a0[13]: Copied! <pre># Classify place cells using threshold\nplace_cell_threshold = 0.5  # bits/spike (common threshold)\n\nplace_cell_ids = [\n    nid for nid, info in spatial_information.items() if info &gt; place_cell_threshold\n]\nnon_spatial_ids = [\n    nid for nid, info in spatial_information.items() if info &lt;= place_cell_threshold\n]\n\nprint(f\"\\nPlace Cell Classification (threshold = {place_cell_threshold} bits/spike):\")\nprint(f\"  Place cells: {len(place_cell_ids)} / {len(spike_times)}\")\nprint(f\"  Non-spatial: {len(non_spatial_ids)} / {len(spike_times)}\")\n\n# Compare with ground truth\ntrue_place_cells = list(range(15))  # We know first 15 are place cells\ntrue_positives = len(set(place_cell_ids) &amp; set(true_place_cells))\nfalse_positives = len(set(place_cell_ids) - set(true_place_cells))\nfalse_negatives = len(set(true_place_cells) - set(place_cell_ids))\n\nprecision = true_positives / len(place_cell_ids) if place_cell_ids else 0\nrecall = true_positives / len(true_place_cells)\n\nprint(\"\\nDetection Performance (vs ground truth):\")\nprint(f\"  True positives: {true_positives}\")\nprint(f\"  False positives: {false_positives}\")\nprint(f\"  False negatives: {false_negatives}\")\nprint(f\"  Precision: {precision:.2%}\")\nprint(f\"  Recall: {recall:.2%}\")\n</pre> # Classify place cells using threshold place_cell_threshold = 0.5  # bits/spike (common threshold)  place_cell_ids = [     nid for nid, info in spatial_information.items() if info &gt; place_cell_threshold ] non_spatial_ids = [     nid for nid, info in spatial_information.items() if info &lt;= place_cell_threshold ]  print(f\"\\nPlace Cell Classification (threshold = {place_cell_threshold} bits/spike):\") print(f\"  Place cells: {len(place_cell_ids)} / {len(spike_times)}\") print(f\"  Non-spatial: {len(non_spatial_ids)} / {len(spike_times)}\")  # Compare with ground truth true_place_cells = list(range(15))  # We know first 15 are place cells true_positives = len(set(place_cell_ids) &amp; set(true_place_cells)) false_positives = len(set(place_cell_ids) - set(true_place_cells)) false_negatives = len(set(true_place_cells) - set(place_cell_ids))  precision = true_positives / len(place_cell_ids) if place_cell_ids else 0 recall = true_positives / len(true_place_cells)  print(\"\\nDetection Performance (vs ground truth):\") print(f\"  True positives: {true_positives}\") print(f\"  False positives: {false_positives}\") print(f\"  False negatives: {false_negatives}\") print(f\"  Precision: {precision:.2%}\") print(f\"  Recall: {recall:.2%}\") <pre>\nPlace Cell Classification (threshold = 0.5 bits/spike):\n  Place cells: 13 / 20\n  Non-spatial: 7 / 20\n\nDetection Performance (vs ground truth):\n  True positives: 13\n  False positives: 0\n  False negatives: 2\n  Precision: 100.00%\n  Recall: 86.67%\n</pre> In\u00a0[14]: Copied! <pre># Visualize spatial information distribution\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Histogram\ninfo_values = list(spatial_information.values())\naxes[0].hist(info_values, bins=20, alpha=0.7, edgecolor=\"black\")\naxes[0].axvline(\n    place_cell_threshold, color=\"red\", linestyle=\"--\", linewidth=2, label=\"Threshold\"\n)\naxes[0].set_xlabel(\"Spatial Information (bits/spike)\")\naxes[0].set_ylabel(\"Count\")\naxes[0].set_title(\"Distribution of Spatial Information\")\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Scatter: spatial info vs peak rate\npeak_rates = [place_fields[nid].max() for nid in range(len(spike_times))]\ncolors = [\"red\" if nid in place_cell_ids else \"blue\" for nid in range(len(spike_times))]\naxes[1].scatter(\n    peak_rates,\n    info_values,\n    c=colors,\n    s=100,\n    alpha=0.6,\n    edgecolors=\"black\",\n    linewidth=0.5,\n)\naxes[1].axhline(\n    place_cell_threshold, color=\"red\", linestyle=\"--\", linewidth=2, alpha=0.5\n)\naxes[1].set_xlabel(\"Peak Firing Rate (Hz)\")\naxes[1].set_ylabel(\"Spatial Information (bits/spike)\")\naxes[1].set_title(\"Spatial Information vs Peak Rate\")\naxes[1].grid(True, alpha=0.3)\naxes[1].legend([\"Threshold\", \"Place cells\", \"Non-spatial\"], loc=\"upper right\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Visualize spatial information distribution fig, axes = plt.subplots(1, 2, figsize=(16, 6))  # Histogram info_values = list(spatial_information.values()) axes[0].hist(info_values, bins=20, alpha=0.7, edgecolor=\"black\") axes[0].axvline(     place_cell_threshold, color=\"red\", linestyle=\"--\", linewidth=2, label=\"Threshold\" ) axes[0].set_xlabel(\"Spatial Information (bits/spike)\") axes[0].set_ylabel(\"Count\") axes[0].set_title(\"Distribution of Spatial Information\") axes[0].legend() axes[0].grid(True, alpha=0.3)  # Scatter: spatial info vs peak rate peak_rates = [place_fields[nid].max() for nid in range(len(spike_times))] colors = [\"red\" if nid in place_cell_ids else \"blue\" for nid in range(len(spike_times))] axes[1].scatter(     peak_rates,     info_values,     c=colors,     s=100,     alpha=0.6,     edgecolors=\"black\",     linewidth=0.5, ) axes[1].axhline(     place_cell_threshold, color=\"red\", linestyle=\"--\", linewidth=2, alpha=0.5 ) axes[1].set_xlabel(\"Peak Firing Rate (Hz)\") axes[1].set_ylabel(\"Spatial Information (bits/spike)\") axes[1].set_title(\"Spatial Information vs Peak Rate\") axes[1].grid(True, alpha=0.3) axes[1].legend([\"Threshold\", \"Place cells\", \"Non-spatial\"], loc=\"upper right\")  plt.tight_layout() plt.show() In\u00a0[15]: Copied! <pre>def compute_region_firing_rates(\n    spike_times, bin_indices, timestamps, env, region_names\n):\n    \"\"\"\n    Compute mean firing rate in each region for each neuron.\n\n    Parameters\n    ----------\n    spike_times : dict\n        Spike times for all neurons.\n    bin_indices : ndarray\n        Bin index for each timestamp.\n    timestamps : ndarray\n        Time for each position sample.\n    env : Environment\n        Spatial environment.\n    region_names : list of str\n        Names of regions to analyze.\n\n    Returns\n    -------\n    region_rates : dict\n        Nested dict: {neuron_id: {region_name: firing_rate}}.\n    \"\"\"\n    region_rates = {nid: {} for nid in spike_times}\n\n    for region_name in region_names:\n        # Find bins in this region (within 10 cm of region point)\n        region_point = env.regions[region_name].data\n        distances_to_region = np.linalg.norm(env.bin_centers - region_point, axis=1)\n        region_bin_mask = distances_to_region &lt; 10.0  # Within 10 cm\n        region_bins = np.where(region_bin_mask)[0]\n\n        # Find times when animal was in this region\n        in_region = np.isin(bin_indices, region_bins)\n        region_duration = in_region.sum() / 30.0  # seconds\n\n        if region_duration &lt; 1.0:  # Skip if less than 1 second\n            for nid in spike_times:\n                region_rates[nid][region_name] = np.nan\n            continue\n\n        # Count spikes in region for each neuron\n        for nid, spikes in spike_times.items():\n            # Find which spikes occurred in region\n            spike_in_region = np.zeros(len(spikes), dtype=bool)\n            for i, spike_time in enumerate(spikes):\n                idx = np.argmin(np.abs(timestamps - spike_time))\n                spike_in_region[i] = in_region[idx]\n\n            n_spikes = spike_in_region.sum()\n            region_rates[nid][region_name] = n_spikes / region_duration\n\n    return region_rates\n\n\n# Compute firing rates in each arm\narm_names = [\"north_arm\", \"south_arm\", \"east_arm\", \"west_arm\", \"center\"]\nregion_rates = compute_region_firing_rates(\n    spike_times=spike_times,\n    bin_indices=bin_indices,\n    timestamps=timestamps,\n    env=env,\n    region_names=arm_names,\n)\n\nprint(\"\\nRegion-Specific Firing Rates:\")\nprint(f\"\\n{'Neuron':&lt;10s}\", end=\"\")\nfor region_name in arm_names:\n    print(f\"{region_name:&gt;12s}\", end=\"\")\nprint()\nprint(\"-\" * 70)\n\nfor neuron_id in range(5):  # Show first 5\n    print(f\"{neuron_id:&lt;10d}\", end=\"\")\n    for region_name in arm_names:\n        rate = region_rates[neuron_id][region_name]\n        if np.isnan(rate):\n            print(f\"{'N/A':&gt;12s}\", end=\"\")\n        else:\n            print(f\"{rate:&gt;10.2f} Hz\", end=\"\")\n    print()\n</pre> def compute_region_firing_rates(     spike_times, bin_indices, timestamps, env, region_names ):     \"\"\"     Compute mean firing rate in each region for each neuron.      Parameters     ----------     spike_times : dict         Spike times for all neurons.     bin_indices : ndarray         Bin index for each timestamp.     timestamps : ndarray         Time for each position sample.     env : Environment         Spatial environment.     region_names : list of str         Names of regions to analyze.      Returns     -------     region_rates : dict         Nested dict: {neuron_id: {region_name: firing_rate}}.     \"\"\"     region_rates = {nid: {} for nid in spike_times}      for region_name in region_names:         # Find bins in this region (within 10 cm of region point)         region_point = env.regions[region_name].data         distances_to_region = np.linalg.norm(env.bin_centers - region_point, axis=1)         region_bin_mask = distances_to_region &lt; 10.0  # Within 10 cm         region_bins = np.where(region_bin_mask)[0]          # Find times when animal was in this region         in_region = np.isin(bin_indices, region_bins)         region_duration = in_region.sum() / 30.0  # seconds          if region_duration &lt; 1.0:  # Skip if less than 1 second             for nid in spike_times:                 region_rates[nid][region_name] = np.nan             continue          # Count spikes in region for each neuron         for nid, spikes in spike_times.items():             # Find which spikes occurred in region             spike_in_region = np.zeros(len(spikes), dtype=bool)             for i, spike_time in enumerate(spikes):                 idx = np.argmin(np.abs(timestamps - spike_time))                 spike_in_region[i] = in_region[idx]              n_spikes = spike_in_region.sum()             region_rates[nid][region_name] = n_spikes / region_duration      return region_rates   # Compute firing rates in each arm arm_names = [\"north_arm\", \"south_arm\", \"east_arm\", \"west_arm\", \"center\"] region_rates = compute_region_firing_rates(     spike_times=spike_times,     bin_indices=bin_indices,     timestamps=timestamps,     env=env,     region_names=arm_names, )  print(\"\\nRegion-Specific Firing Rates:\") print(f\"\\n{'Neuron':&lt;10s}\", end=\"\") for region_name in arm_names:     print(f\"{region_name:&gt;12s}\", end=\"\") print() print(\"-\" * 70)  for neuron_id in range(5):  # Show first 5     print(f\"{neuron_id:&lt;10d}\", end=\"\")     for region_name in arm_names:         rate = region_rates[neuron_id][region_name]         if np.isnan(rate):             print(f\"{'N/A':&gt;12s}\", end=\"\")         else:             print(f\"{rate:&gt;10.2f} Hz\", end=\"\")     print() <pre>\nRegion-Specific Firing Rates:\n\nNeuron       north_arm   south_arm    east_arm    west_arm      center\n----------------------------------------------------------------------\n0              12.13 Hz      0.00 Hz      0.12 Hz      0.03 Hz      0.77 Hz\n1               0.00 Hz      9.45 Hz      0.08 Hz      0.26 Hz      0.67 Hz\n2               0.04 Hz      0.23 Hz     12.60 Hz      0.00 Hz      0.70 Hz\n3               0.04 Hz      0.68 Hz      0.01 Hz      7.83 Hz      1.09 Hz\n4               1.05 Hz      3.79 Hz      1.48 Hz      2.71 Hz      7.78 Hz\n</pre> In\u00a0[16]: Copied! <pre># Visualize region selectivity for place cells\nfig, axes = plt.subplots(2, 3, figsize=(18, 12))\naxes = axes.flatten()\n\n# Show first 6 place cells\nfor idx, neuron_id in enumerate(sorted_neurons[:6]):\n    neuron_id = neuron_id[0]  # Extract ID from tuple\n\n    rates = [region_rates[neuron_id][name] for name in arm_names]\n    rates = [0 if np.isnan(r) else r for r in rates]  # Replace NaN with 0\n\n    axes[idx].bar(\n        range(len(arm_names)), rates, color=\"steelblue\", edgecolor=\"black\", alpha=0.7\n    )\n    axes[idx].set_xticks(range(len(arm_names)))\n    axes[idx].set_xticklabels(\n        [name.replace(\"_\", \"\\n\") for name in arm_names], fontsize=9\n    )\n    axes[idx].set_ylabel(\"Firing Rate (Hz)\")\n    axes[idx].set_title(\n        f\"Neuron {neuron_id} (SI={spatial_information[neuron_id]:.2f} bits/spike)\"\n    )\n    axes[idx].grid(True, alpha=0.3, axis=\"y\")\n\nplt.suptitle(\"Region-Specific Firing Rates (Top 6 Place Cells)\", fontsize=14)\nplt.tight_layout()\nplt.show()\n</pre> # Visualize region selectivity for place cells fig, axes = plt.subplots(2, 3, figsize=(18, 12)) axes = axes.flatten()  # Show first 6 place cells for idx, neuron_id in enumerate(sorted_neurons[:6]):     neuron_id = neuron_id[0]  # Extract ID from tuple      rates = [region_rates[neuron_id][name] for name in arm_names]     rates = [0 if np.isnan(r) else r for r in rates]  # Replace NaN with 0      axes[idx].bar(         range(len(arm_names)), rates, color=\"steelblue\", edgecolor=\"black\", alpha=0.7     )     axes[idx].set_xticks(range(len(arm_names)))     axes[idx].set_xticklabels(         [name.replace(\"_\", \"\\n\") for name in arm_names], fontsize=9     )     axes[idx].set_ylabel(\"Firing Rate (Hz)\")     axes[idx].set_title(         f\"Neuron {neuron_id} (SI={spatial_information[neuron_id]:.2f} bits/spike)\"     )     axes[idx].grid(True, alpha=0.3, axis=\"y\")  plt.suptitle(\"Region-Specific Firing Rates (Top 6 Place Cells)\", fontsize=14) plt.tight_layout() plt.show() In\u00a0[17]: Copied! <pre># Create population rate matrix (neurons \u00d7 bins)\nn_place_cells = len(place_cell_ids)\npopulation_matrix = np.zeros((n_place_cells, env.n_bins))\n\nfor i, neuron_id in enumerate(place_cell_ids):\n    population_matrix[i, :] = place_fields[neuron_id]\n\nprint(f\"\\nPopulation Matrix Shape: {population_matrix.shape}\")\nprint(f\"  Neurons: {n_place_cells}\")\nprint(f\"  Bins: {env.n_bins}\")\n</pre> # Create population rate matrix (neurons \u00d7 bins) n_place_cells = len(place_cell_ids) population_matrix = np.zeros((n_place_cells, env.n_bins))  for i, neuron_id in enumerate(place_cell_ids):     population_matrix[i, :] = place_fields[neuron_id]  print(f\"\\nPopulation Matrix Shape: {population_matrix.shape}\") print(f\"  Neurons: {n_place_cells}\") print(f\"  Bins: {env.n_bins}\") <pre>\nPopulation Matrix Shape: (13, 76)\n  Neurons: 13\n  Bins: 76\n</pre> In\u00a0[18]: Copied! <pre># Visualize population activity as heatmap\nfig, ax = plt.subplots(figsize=(16, 8))\n\n# Sort neurons by peak location\npeak_bins = [place_fields[nid].argmax() for nid in place_cell_ids]\nsort_order = np.argsort(peak_bins)\n\n# Normalize each neuron's activity to [0, 1]\npopulation_normalized = population_matrix.copy()\nfor i in range(n_place_cells):\n    max_rate = population_normalized[i, :].max()\n    if max_rate &gt; 0:\n        population_normalized[i, :] /= max_rate\n\nim = ax.imshow(\n    population_normalized[sort_order, :],\n    aspect=\"auto\",\n    cmap=\"hot\",\n    interpolation=\"nearest\",\n)\n\nax.set_xlabel(\"Spatial Bin\")\nax.set_ylabel(\"Neuron (sorted by peak location)\")\nax.set_title(\"Population Activity (Normalized Firing Rates)\")\nplt.colorbar(im, ax=ax, label=\"Normalized Rate\")\nplt.tight_layout()\nplt.show()\n</pre> # Visualize population activity as heatmap fig, ax = plt.subplots(figsize=(16, 8))  # Sort neurons by peak location peak_bins = [place_fields[nid].argmax() for nid in place_cell_ids] sort_order = np.argsort(peak_bins)  # Normalize each neuron's activity to [0, 1] population_normalized = population_matrix.copy() for i in range(n_place_cells):     max_rate = population_normalized[i, :].max()     if max_rate &gt; 0:         population_normalized[i, :] /= max_rate  im = ax.imshow(     population_normalized[sort_order, :],     aspect=\"auto\",     cmap=\"hot\",     interpolation=\"nearest\", )  ax.set_xlabel(\"Spatial Bin\") ax.set_ylabel(\"Neuron (sorted by peak location)\") ax.set_title(\"Population Activity (Normalized Firing Rates)\") plt.colorbar(im, ax=ax, label=\"Normalized Rate\") plt.tight_layout() plt.show() In\u00a0[19]: Copied! <pre># Compute correlation matrix between all pairs of bins\n# (how similar is the population code at different locations?)\nn_bins = env.n_bins\ncorrelation_matrix = np.zeros((n_bins, n_bins))\n\nfor i in range(n_bins):\n    for j in range(i, n_bins):\n        # Population vectors at bins i and j\n        vec_i = population_matrix[:, i]\n        vec_j = population_matrix[:, j]\n\n        # Compute correlation (if both have activity)\n        if vec_i.sum() &gt; 0 and vec_j.sum() &gt; 0:\n            corr, _ = pearsonr(vec_i, vec_j)\n            correlation_matrix[i, j] = corr\n            correlation_matrix[j, i] = corr\n        else:\n            correlation_matrix[i, j] = 0\n            correlation_matrix[j, i] = 0\n\nprint(f\"Population Vector Correlation Matrix: {correlation_matrix.shape}\")\nprint(f\"Mean correlation: {correlation_matrix[correlation_matrix &gt; 0].mean():.3f}\")\nprint(f\"Max correlation: {correlation_matrix.max():.3f}\")\n</pre> # Compute correlation matrix between all pairs of bins # (how similar is the population code at different locations?) n_bins = env.n_bins correlation_matrix = np.zeros((n_bins, n_bins))  for i in range(n_bins):     for j in range(i, n_bins):         # Population vectors at bins i and j         vec_i = population_matrix[:, i]         vec_j = population_matrix[:, j]          # Compute correlation (if both have activity)         if vec_i.sum() &gt; 0 and vec_j.sum() &gt; 0:             corr, _ = pearsonr(vec_i, vec_j)             correlation_matrix[i, j] = corr             correlation_matrix[j, i] = corr         else:             correlation_matrix[i, j] = 0             correlation_matrix[j, i] = 0  print(f\"Population Vector Correlation Matrix: {correlation_matrix.shape}\") print(f\"Mean correlation: {correlation_matrix[correlation_matrix &gt; 0].mean():.3f}\") print(f\"Max correlation: {correlation_matrix.max():.3f}\") <pre>Population Vector Correlation Matrix: (76, 76)\nMean correlation: 0.568\nMax correlation: 1.000\n</pre> In\u00a0[20]: Copied! <pre># Visualize correlation as a function of spatial distance\n# Do nearby locations have more similar population codes?\nspatial_distances = []\ncorrelations = []\n\nfor i in range(n_bins):\n    for j in range(i + 1, n_bins):\n        # Spatial distance\n        dist = np.linalg.norm(env.bin_centers[i] - env.bin_centers[j])\n        corr = correlation_matrix[i, j]\n\n        if corr &gt; 0:  # Only valid correlations\n            spatial_distances.append(dist)\n            correlations.append(corr)\n\nspatial_distances = np.array(spatial_distances)\ncorrelations = np.array(correlations)\n\n# Plot\nfig, ax = plt.subplots(figsize=(12, 8))\n\n# Scatter with transparency\nax.scatter(spatial_distances, correlations, s=1, alpha=0.1, c=\"blue\")\n\n# Binned average\nbins = np.arange(0, spatial_distances.max(), 5)\nbin_indices = np.digitize(spatial_distances, bins)\nbinned_corr = [correlations[bin_indices == i].mean() for i in range(1, len(bins))]\nbin_centers = bins[:-1] + np.diff(bins) / 2\nax.plot(bin_centers, binned_corr, \"r-\", linewidth=3, label=\"Binned average\")\n\nax.set_xlabel(\"Spatial Distance (cm)\")\nax.set_ylabel(\"Population Vector Correlation\")\nax.set_title(\"Population Code Similarity vs Spatial Distance\")\nax.legend()\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nInterpretation: Higher correlation at short distances means nearby\")\nprint(\"locations have similar population activity patterns (smooth representation).\")\n</pre> # Visualize correlation as a function of spatial distance # Do nearby locations have more similar population codes? spatial_distances = [] correlations = []  for i in range(n_bins):     for j in range(i + 1, n_bins):         # Spatial distance         dist = np.linalg.norm(env.bin_centers[i] - env.bin_centers[j])         corr = correlation_matrix[i, j]          if corr &gt; 0:  # Only valid correlations             spatial_distances.append(dist)             correlations.append(corr)  spatial_distances = np.array(spatial_distances) correlations = np.array(correlations)  # Plot fig, ax = plt.subplots(figsize=(12, 8))  # Scatter with transparency ax.scatter(spatial_distances, correlations, s=1, alpha=0.1, c=\"blue\")  # Binned average bins = np.arange(0, spatial_distances.max(), 5) bin_indices = np.digitize(spatial_distances, bins) binned_corr = [correlations[bin_indices == i].mean() for i in range(1, len(bins))] bin_centers = bins[:-1] + np.diff(bins) / 2 ax.plot(bin_centers, binned_corr, \"r-\", linewidth=3, label=\"Binned average\")  ax.set_xlabel(\"Spatial Distance (cm)\") ax.set_ylabel(\"Population Vector Correlation\") ax.set_title(\"Population Code Similarity vs Spatial Distance\") ax.legend() ax.grid(True, alpha=0.3) plt.tight_layout() plt.show()  print(\"\\nInterpretation: Higher correlation at short distances means nearby\") print(\"locations have similar population activity patterns (smooth representation).\") <pre>\nInterpretation: Higher correlation at short distances means nearby\nlocations have similar population activity patterns (smooth representation).\n</pre> In\u00a0[21]: Copied! <pre># Create multi-panel summary figure\nfig = plt.figure(figsize=(20, 16))\ngs = GridSpec(3, 3, figure=fig, hspace=0.35, wspace=0.35)\n\n# Panel A: Trajectory with occupancy\nax_a = fig.add_subplot(gs[0, 0])\nscatter_a = ax_a.scatter(\n    env.bin_centers[:, 0],\n    env.bin_centers[:, 1],\n    c=occupancy_time,\n    s=150,\n    cmap=\"YlOrRd\",\n    edgecolors=\"black\",\n    linewidth=0.3,\n)\nax_a.set_xlabel(\"X position (cm)\")\nax_a.set_ylabel(\"Y position (cm)\")\nax_a.set_title(\"A. Occupancy Map\", fontweight=\"bold\")\nax_a.set_aspect(\"equal\")\nplt.colorbar(scatter_a, ax=ax_a, label=\"Time (s)\")\n\n# Panel B: Example place cell\nax_b = fig.add_subplot(gs[0, 1])\nbest_neuron = sorted_neurons[0][0]\nscatter_b = ax_b.scatter(\n    env.bin_centers[:, 0],\n    env.bin_centers[:, 1],\n    c=place_fields[best_neuron],\n    s=150,\n    cmap=\"hot\",\n    edgecolors=\"black\",\n    linewidth=0.3,\n)\nax_b.set_xlabel(\"X position (cm)\")\nax_b.set_ylabel(\"Y position (cm)\")\nax_b.set_title(f\"B. Example Place Cell (Neuron {best_neuron})\", fontweight=\"bold\")\nax_b.set_aspect(\"equal\")\nplt.colorbar(scatter_b, ax=ax_b, label=\"Rate (Hz)\")\n\n# Panel C: Spatial information distribution\nax_c = fig.add_subplot(gs[0, 2])\ninfo_values = list(spatial_information.values())\nax_c.hist(info_values, bins=15, alpha=0.7, edgecolor=\"black\", color=\"steelblue\")\nax_c.axvline(\n    place_cell_threshold, color=\"red\", linestyle=\"--\", linewidth=2, label=\"Threshold\"\n)\nax_c.set_xlabel(\"Spatial Information (bits/spike)\")\nax_c.set_ylabel(\"Number of Neurons\")\nax_c.set_title(\"C. Spatial Selectivity\", fontweight=\"bold\")\nax_c.legend()\nax_c.grid(True, alpha=0.3, axis=\"y\")\n\n# Panel D: Population heatmap\nax_d = fig.add_subplot(gs[1, :])\nim_d = ax_d.imshow(\n    population_normalized[sort_order, :],\n    aspect=\"auto\",\n    cmap=\"hot\",\n    interpolation=\"nearest\",\n)\nax_d.set_xlabel(\"Spatial Bin\")\nax_d.set_ylabel(\"Neuron (sorted)\")\nax_d.set_title(\"D. Population Activity\", fontweight=\"bold\")\nplt.colorbar(im_d, ax=ax_d, label=\"Normalized Rate\")\n\n# Panel E: Region selectivity for top neurons\nax_e = fig.add_subplot(gs[2, 0])\nneuron_to_plot = sorted_neurons[0][0]\nrates = [region_rates[neuron_to_plot][name] for name in arm_names]\nrates = [0 if np.isnan(r) else r for r in rates]\nax_e.bar(range(len(arm_names)), rates, color=\"steelblue\", edgecolor=\"black\", alpha=0.7)\nax_e.set_xticks(range(len(arm_names)))\nax_e.set_xticklabels([name.replace(\"_\", \"\\n\") for name in arm_names], fontsize=9)\nax_e.set_ylabel(\"Firing Rate (Hz)\")\nax_e.set_title(f\"E. Region Selectivity (Neuron {neuron_to_plot})\", fontweight=\"bold\")\nax_e.grid(True, alpha=0.3, axis=\"y\")\n\n# Panel F: Population correlation vs distance\nax_f = fig.add_subplot(gs[2, 1])\nax_f.scatter(spatial_distances, correlations, s=1, alpha=0.1, c=\"blue\")\nax_f.plot(bin_centers, binned_corr, \"r-\", linewidth=3, label=\"Mean\")\nax_f.set_xlabel(\"Spatial Distance (cm)\")\nax_f.set_ylabel(\"Correlation\")\nax_f.set_title(\"F. Population Code Similarity\", fontweight=\"bold\")\nax_f.legend()\nax_f.grid(True, alpha=0.3)\n\n# Panel G: Summary statistics\nax_g = fig.add_subplot(gs[2, 2])\nax_g.axis(\"off\")\nsummary_text = f\"\"\"\nSUMMARY STATISTICS\n\nRecording:\n  Duration: {timestamps[-1] / 60:.1f} min\n  Position samples: {len(timestamps):,}\n\nEnvironment:\n  Bin size: 3.0 cm\n  Active bins: {env.n_bins}\n\nNeural Activity:\n  Neurons recorded: {len(spike_times)}\n  Place cells: {len(place_cell_ids)}\n  Non-spatial: {len(non_spatial_ids)}\n\nSpatial Information:\n  Mean: {np.mean(info_values):.3f} bits/spike\n  Max: {np.max(info_values):.3f} bits/spike\n\nDetection Performance:\n  Precision: {precision:.1%}\n  Recall: {recall:.1%}\n\"\"\"\nax_g.text(\n    0.1,\n    0.5,\n    summary_text,\n    fontsize=11,\n    family=\"monospace\",\n    verticalalignment=\"center\",\n    bbox={\"boxstyle\": \"round\", \"facecolor\": \"wheat\", \"alpha\": 0.3},\n)\nax_g.set_title(\"G. Summary\", fontweight=\"bold\")\n\nplt.suptitle(\n    \"Complete Spatial Analysis: Plus Maze Place Cell Recording\",\n    fontsize=18,\n    fontweight=\"bold\",\n    y=0.995,\n)\nplt.savefig(\"/tmp/place_cell_analysis.png\", dpi=150, bbox_inches=\"tight\")\nplt.show()\n\nprint(\"\\nFigure saved to /tmp/place_cell_analysis.png\")\n</pre> # Create multi-panel summary figure fig = plt.figure(figsize=(20, 16)) gs = GridSpec(3, 3, figure=fig, hspace=0.35, wspace=0.35)  # Panel A: Trajectory with occupancy ax_a = fig.add_subplot(gs[0, 0]) scatter_a = ax_a.scatter(     env.bin_centers[:, 0],     env.bin_centers[:, 1],     c=occupancy_time,     s=150,     cmap=\"YlOrRd\",     edgecolors=\"black\",     linewidth=0.3, ) ax_a.set_xlabel(\"X position (cm)\") ax_a.set_ylabel(\"Y position (cm)\") ax_a.set_title(\"A. Occupancy Map\", fontweight=\"bold\") ax_a.set_aspect(\"equal\") plt.colorbar(scatter_a, ax=ax_a, label=\"Time (s)\")  # Panel B: Example place cell ax_b = fig.add_subplot(gs[0, 1]) best_neuron = sorted_neurons[0][0] scatter_b = ax_b.scatter(     env.bin_centers[:, 0],     env.bin_centers[:, 1],     c=place_fields[best_neuron],     s=150,     cmap=\"hot\",     edgecolors=\"black\",     linewidth=0.3, ) ax_b.set_xlabel(\"X position (cm)\") ax_b.set_ylabel(\"Y position (cm)\") ax_b.set_title(f\"B. Example Place Cell (Neuron {best_neuron})\", fontweight=\"bold\") ax_b.set_aspect(\"equal\") plt.colorbar(scatter_b, ax=ax_b, label=\"Rate (Hz)\")  # Panel C: Spatial information distribution ax_c = fig.add_subplot(gs[0, 2]) info_values = list(spatial_information.values()) ax_c.hist(info_values, bins=15, alpha=0.7, edgecolor=\"black\", color=\"steelblue\") ax_c.axvline(     place_cell_threshold, color=\"red\", linestyle=\"--\", linewidth=2, label=\"Threshold\" ) ax_c.set_xlabel(\"Spatial Information (bits/spike)\") ax_c.set_ylabel(\"Number of Neurons\") ax_c.set_title(\"C. Spatial Selectivity\", fontweight=\"bold\") ax_c.legend() ax_c.grid(True, alpha=0.3, axis=\"y\")  # Panel D: Population heatmap ax_d = fig.add_subplot(gs[1, :]) im_d = ax_d.imshow(     population_normalized[sort_order, :],     aspect=\"auto\",     cmap=\"hot\",     interpolation=\"nearest\", ) ax_d.set_xlabel(\"Spatial Bin\") ax_d.set_ylabel(\"Neuron (sorted)\") ax_d.set_title(\"D. Population Activity\", fontweight=\"bold\") plt.colorbar(im_d, ax=ax_d, label=\"Normalized Rate\")  # Panel E: Region selectivity for top neurons ax_e = fig.add_subplot(gs[2, 0]) neuron_to_plot = sorted_neurons[0][0] rates = [region_rates[neuron_to_plot][name] for name in arm_names] rates = [0 if np.isnan(r) else r for r in rates] ax_e.bar(range(len(arm_names)), rates, color=\"steelblue\", edgecolor=\"black\", alpha=0.7) ax_e.set_xticks(range(len(arm_names))) ax_e.set_xticklabels([name.replace(\"_\", \"\\n\") for name in arm_names], fontsize=9) ax_e.set_ylabel(\"Firing Rate (Hz)\") ax_e.set_title(f\"E. Region Selectivity (Neuron {neuron_to_plot})\", fontweight=\"bold\") ax_e.grid(True, alpha=0.3, axis=\"y\")  # Panel F: Population correlation vs distance ax_f = fig.add_subplot(gs[2, 1]) ax_f.scatter(spatial_distances, correlations, s=1, alpha=0.1, c=\"blue\") ax_f.plot(bin_centers, binned_corr, \"r-\", linewidth=3, label=\"Mean\") ax_f.set_xlabel(\"Spatial Distance (cm)\") ax_f.set_ylabel(\"Correlation\") ax_f.set_title(\"F. Population Code Similarity\", fontweight=\"bold\") ax_f.legend() ax_f.grid(True, alpha=0.3)  # Panel G: Summary statistics ax_g = fig.add_subplot(gs[2, 2]) ax_g.axis(\"off\") summary_text = f\"\"\" SUMMARY STATISTICS  Recording:   Duration: {timestamps[-1] / 60:.1f} min   Position samples: {len(timestamps):,}  Environment:   Bin size: 3.0 cm   Active bins: {env.n_bins}  Neural Activity:   Neurons recorded: {len(spike_times)}   Place cells: {len(place_cell_ids)}   Non-spatial: {len(non_spatial_ids)}  Spatial Information:   Mean: {np.mean(info_values):.3f} bits/spike   Max: {np.max(info_values):.3f} bits/spike  Detection Performance:   Precision: {precision:.1%}   Recall: {recall:.1%} \"\"\" ax_g.text(     0.1,     0.5,     summary_text,     fontsize=11,     family=\"monospace\",     verticalalignment=\"center\",     bbox={\"boxstyle\": \"round\", \"facecolor\": \"wheat\", \"alpha\": 0.3}, ) ax_g.set_title(\"G. Summary\", fontweight=\"bold\")  plt.suptitle(     \"Complete Spatial Analysis: Plus Maze Place Cell Recording\",     fontsize=18,     fontweight=\"bold\",     y=0.995, ) plt.savefig(\"/tmp/place_cell_analysis.png\", dpi=150, bbox_inches=\"tight\") plt.show()  print(\"\\nFigure saved to /tmp/place_cell_analysis.png\") <pre>\nFigure saved to /tmp/place_cell_analysis.png\n</pre>"},{"location":"examples/08_complete_workflow/#complete-workflow-from-raw-data-to-publication-ready-analysis","title":"Complete Workflow: From Raw Data to Publication-Ready Analysis\u00b6","text":""},{"location":"examples/08_complete_workflow/#learning-objectives","title":"Learning Objectives\u00b6","text":"<p>By the end of this notebook, you will be able to:</p> <ul> <li>Process raw position tracking data from start to finish</li> <li>Compute occupancy-normalized place fields (spatial firing rate maps)</li> <li>Analyze neural activity across multiple regions of interest</li> <li>Detect and characterize spatial tuning (place cells, grid cells)</li> <li>Compare neural representations across different maze compartments</li> <li>Create publication-quality visualizations</li> <li>Apply best practices for reproducible spatial analysis</li> </ul> <p>Estimated time: 40-50 minutes</p> <p>This notebook integrates concepts from all previous notebooks into a complete real-world analysis pipeline.</p>"},{"location":"examples/08_complete_workflow/#experimental-scenario","title":"Experimental Scenario\u00b6","text":"<p>Setup: You've recorded neural activity (hippocampal place cells) from a rat exploring a plus maze. The maze has:</p> <ul> <li>4 arms (North, South, East, West)</li> <li>A central junction</li> <li>Two reward locations (North and South arms)</li> </ul> <p>Data:</p> <ul> <li>Position tracking at 30 Hz</li> <li>Spike times from 20 simultaneously recorded neurons</li> <li>20 minute recording session</li> </ul> <p>Goal: Identify place cells, characterize their firing fields, and analyze spatial selectivity.</p>"},{"location":"examples/08_complete_workflow/#setup-and-imports","title":"Setup and Imports\u00b6","text":""},{"location":"examples/08_complete_workflow/#step-1-generate-synthetic-experimental-data","title":"Step 1: Generate Synthetic Experimental Data\u00b6","text":"<p>We'll simulate realistic tracking and neural data to demonstrate the workflow.</p>"},{"location":"examples/08_complete_workflow/#11-simulate-position-tracking","title":"1.1 Simulate Position Tracking\u00b6","text":""},{"location":"examples/08_complete_workflow/#12-simulate-neural-activity-place-cells","title":"1.2 Simulate Neural Activity (Place Cells)\u00b6","text":""},{"location":"examples/08_complete_workflow/#step-2-create-spatial-environment","title":"Step 2: Create Spatial Environment\u00b6","text":"<p>Now we discretize the continuous position data into spatial bins.</p>"},{"location":"examples/08_complete_workflow/#21-define-regions-of-interest","title":"2.1 Define Regions of Interest\u00b6","text":""},{"location":"examples/08_complete_workflow/#step-3-compute-occupancy","title":"Step 3: Compute Occupancy\u00b6","text":"<p>Occupancy tells us how much time the animal spent in each bin. This is crucial for normalizing neural activity.</p>"},{"location":"examples/08_complete_workflow/#step-4-compute-place-fields-firing-rate-maps","title":"Step 4: Compute Place Fields (Firing Rate Maps)\u00b6","text":"<p>For each neuron, we'll compute:</p> <ol> <li>Spike count per bin</li> <li>Occupancy-normalized firing rate (spikes/second)</li> <li>Smoothed firing rate map</li> </ol>"},{"location":"examples/08_complete_workflow/#41-visualize-place-fields","title":"4.1 Visualize Place Fields\u00b6","text":""},{"location":"examples/08_complete_workflow/#step-5-spatial-information-and-place-cell-detection","title":"Step 5: Spatial Information and Place Cell Detection\u00b6","text":"<p>We'll compute spatial information (bits/spike) to quantify how well each neuron encodes spatial location.</p>"},{"location":"examples/08_complete_workflow/#step-6-multi-region-analysis","title":"Step 6: Multi-Region Analysis\u00b6","text":"<p>Analyze how neurons respond differently in different maze compartments.</p>"},{"location":"examples/08_complete_workflow/#step-7-population-analysis","title":"Step 7: Population Analysis\u00b6","text":"<p>Analyze the entire population of place cells to understand ensemble coding.</p>"},{"location":"examples/08_complete_workflow/#71-compute-population-vector-correlations","title":"7.1 Compute Population Vector Correlations\u00b6","text":"<p>How similar is the population activity pattern in different locations?</p>"},{"location":"examples/08_complete_workflow/#step-8-publication-quality-summary-figure","title":"Step 8: Publication-Quality Summary Figure\u00b6","text":"<p>Create a comprehensive figure summarizing the analysis.</p>"},{"location":"examples/08_complete_workflow/#best-practices-and-recommendations","title":"Best Practices and Recommendations\u00b6","text":"<p>Based on this complete workflow, here are key best practices:</p>"},{"location":"examples/08_complete_workflow/#1-data-quality","title":"1. Data Quality\u00b6","text":"<ul> <li>Always check position tracking quality: Remove periods with missing data or tracking errors</li> <li>Verify sampling rate: Ensure consistent timing for spike-position alignment</li> <li>Filter outliers: Remove impossible positions or velocities</li> </ul>"},{"location":"examples/08_complete_workflow/#2-spatial-discretization","title":"2. Spatial Discretization\u00b6","text":"<ul> <li>Choose appropriate bin_size: 2-5 cm for rodents, scale with arena size</li> <li>Balance resolution vs statistics: Smaller bins = better resolution but fewer samples per bin</li> <li>Use infer_active_bins: Automatically filter unvisited areas</li> <li>Set bin_count_threshold: Require minimum occupancy (e.g., 5-10 samples)</li> </ul>"},{"location":"examples/08_complete_workflow/#3-firing-rate-calculation","title":"3. Firing Rate Calculation\u00b6","text":"<ul> <li>Always normalize by occupancy: Use spikes/time, not raw spike counts</li> <li>Filter low-occupancy bins: Exclude bins with &lt;100ms occupancy</li> <li>Consider smoothing: Gaussian smoothing can reduce noise but may blur fine details</li> <li>Report both raw and smoothed: Show both for transparency</li> </ul>"},{"location":"examples/08_complete_workflow/#4-place-cell-classification","title":"4. Place Cell Classification\u00b6","text":"<ul> <li>Use multiple metrics: Spatial information, peak rate, field size</li> <li>Compare to shuffled controls: Ensure selectivity isn't by chance</li> <li>Report thresholds clearly: Document criteria for classification</li> <li>Validate visually: Always inspect firing rate maps</li> </ul>"},{"location":"examples/08_complete_workflow/#5-population-analysis","title":"5. Population Analysis\u00b6","text":"<ul> <li>Normalize before comparing: Scale firing rates to [0, 1] or z-scores</li> <li>Account for sampling bias: Some locations may be over-represented</li> <li>Use cross-validation: Test decoding on held-out data</li> </ul>"},{"location":"examples/08_complete_workflow/#6-reproducibility","title":"6. Reproducibility\u00b6","text":"<ul> <li>Document parameters: Save all analysis parameters (bin_size, thresholds, etc.)</li> <li>Version control: Track code and parameter changes</li> <li>Save intermediate results: Don't recompute expensive analyses</li> <li>Create analysis scripts: Automate from raw data to figures</li> </ul>"},{"location":"examples/08_complete_workflow/#7-visualization","title":"7. Visualization\u00b6","text":"<ul> <li>Use appropriate colormaps: 'hot' for firing rates, 'viridis' for continuous data</li> <li>Include scale bars and units: Always label axes with units</li> <li>Show sample sizes: Report n for all statistics</li> <li>Create summary figures: Multi-panel figures for comprehensive view</li> </ul>"},{"location":"examples/08_complete_workflow/#key-takeaways","title":"Key Takeaways\u00b6","text":"<p>Congratulations! You've completed a full spatial neuroscience analysis pipeline:</p> <ol> <li><p>Raw data processing: Position tracking and spike times \u2192 spatial bins</p> </li> <li><p>Environment creation: Use <code>Environment.from_samples()</code> with appropriate parameters</p> </li> <li><p>Occupancy computation: Essential for normalizing neural activity</p> </li> <li><p>Place field calculation: Occupancy-normalized firing rate maps</p> </li> <li><p>Spatial information: Quantitative metric for spatial selectivity</p> </li> <li><p>Place cell detection: Classify neurons by spatial tuning</p> </li> <li><p>Multi-region analysis: Compare activity across maze compartments</p> </li> <li><p>Population coding: Ensemble-level spatial representation</p> </li> <li><p>Publication figures: Create comprehensive, clear visualizations</p> </li> </ol> <p>This workflow is directly applicable to your own data! Simply replace the synthetic data with your actual tracking and spike data.</p>"},{"location":"examples/08_complete_workflow/#extensions-and-next-steps","title":"Extensions and Next Steps\u00b6","text":"<p>To extend this analysis, consider:</p> <ol> <li>Temporal analysis: How do place fields change over time? (stability, remapping)</li> <li>Decoding: Predict position from population activity (Bayesian decoding)</li> <li>Trajectory analysis: Analyze paths, running speed effects</li> <li>Grid cells: Detect hexagonal firing patterns (autocorrelation)</li> <li>Theta sequences: Time-compressed replay within theta cycles</li> <li>Multi-session alignment: Compare place fields across days</li> <li>State-dependent activity: Different firing in different behavioral states</li> </ol>"},{"location":"examples/08_complete_workflow/#additional-resources","title":"Additional Resources\u00b6","text":"<ul> <li>neurospatial documentation: Full API reference and examples</li> <li>Previous notebooks: Review specific topics (layouts, regions, transforms)</li> <li>Scientific papers:<ul> <li>O'Keefe &amp; Dostrovsky (1971) - Original place cell discovery</li> <li>Skaggs et al. (1993) - Spatial information metric</li> <li>Wilson &amp; McNaughton (1993) - Population coding</li> </ul> </li> </ul> <p>Thank you for completing this tutorial series!</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Welcome to neurospatial! This section will help you get up and running quickly.</p>"},{"location":"getting-started/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Installation: How to install neurospatial and its dependencies</li> <li>Quickstart: A 5-minute introduction with working examples</li> <li>Core Concepts: Understanding bins, connectivity graphs, and layout engines</li> </ul>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>neurospatial requires:</p> <ul> <li>Python 3.10 or higher</li> <li>Basic familiarity with NumPy and array operations</li> <li>Understanding of spatial coordinates (e.g., x, y positions)</li> </ul>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<p>After completing the getting started guide, explore:</p> <ul> <li>User Guide: Deep dives into specific features</li> <li>API Reference: Complete API documentation</li> <li>Examples: Real-world use cases and notebooks</li> </ul>"},{"location":"getting-started/core-concepts/","title":"Core Concepts","text":"<p>Understanding these core concepts will help you use neurospatial effectively.</p>"},{"location":"getting-started/core-concepts/#spatial-discretization","title":"Spatial Discretization","text":"<p>neurospatial converts continuous spatial coordinates into discrete bins (also called nodes or spatial bins). This discretization is essential for:</p> <ul> <li>Computing spatial statistics (occupancy, firing rates, etc.)</li> <li>Representing spatial relationships in a graph structure</li> <li>Performing efficient spatial queries</li> <li>Reducing computational complexity</li> </ul>"},{"location":"getting-started/core-concepts/#example-continuous-to-discrete","title":"Example: Continuous to Discrete","text":"<pre><code>import numpy as np\nfrom neurospatial import Environment\n\n# Continuous coordinates (cm)\ncontinuous_position = np.array([[10.5, 12.3]])\n\n# Create discretized environment\nenv = Environment.from_samples(\n    data_samples=continuous_position,\n    bin_size=2.0  # 2 cm bins\n)\n\n# Map to discrete bin index\nbin_index = env.bin_at(continuous_position)[0]\nprint(f\"Continuous position {continuous_position[0]} \u2192 Bin {bin_index}\")\n\n# Get bin center (representative coordinate)\nbin_center = env.bin_centers[bin_index]\nprint(f\"Bin {bin_index} center: {bin_center}\")\n</code></pre>"},{"location":"getting-started/core-concepts/#bins-and-active-bins","title":"Bins and Active Bins","text":""},{"location":"getting-started/core-concepts/#bins","title":"Bins","text":"<p>A bin is a discrete spatial unit with:</p> <ul> <li>A unique integer index</li> <li>A center coordinate in N-dimensional space</li> <li>Optional size/extent information</li> <li>Connectivity to neighboring bins</li> </ul>"},{"location":"getting-started/core-concepts/#active-vs-inactive-bins","title":"Active vs Inactive Bins","text":"<p>Active bins are bins considered part of the environment. Inactive bins are excluded (e.g., walls, obstacles, or unvisited regions).</p> <pre><code># All bins are active by default\nenv = Environment.from_samples(data, bin_size=2.0)\nprint(f\"All bins active: {env.n_bins}\")\n\n# Automatically infer active bins from data\nenv_auto = Environment.from_samples(\n    data,\n    bin_size=2.0,\n    infer_active_bins=True,  # Only bins with data\n    bin_count_threshold=1    # Minimum samples per bin\n)\nprint(f\"Auto-detected active bins: {env_auto.n_bins}\")\n</code></pre>"},{"location":"getting-started/core-concepts/#why-activeinactive-matters","title":"Why Active/Inactive Matters","text":"<p>In neuroscience, you often want to exclude:</p> <ul> <li>Areas the animal didn't visit</li> <li>Physical barriers (walls, obstacles)</li> <li>Regions outside the experimental arena</li> </ul> <p>This prevents:</p> <ul> <li>Dividing by zero in firing rate calculations</li> <li>Including irrelevant bins in statistics</li> <li>Wasting computation on empty space</li> </ul>"},{"location":"getting-started/core-concepts/#connectivity-graphs","title":"Connectivity Graphs","text":"<p>Every environment includes a connectivity graph (NetworkX <code>Graph</code>) that defines spatial relationships between bins.</p>"},{"location":"getting-started/core-concepts/#graph-structure","title":"Graph Structure","text":"<ul> <li>Nodes: Represent bins (indexed 0, 1, 2, ...)</li> <li>Edges: Connect neighboring bins</li> <li>Attributes: Store spatial metadata</li> </ul> <pre><code># Access the connectivity graph\nG = env.connectivity\n\nprint(f\"Number of nodes: {G.number_of_nodes()}\")\nprint(f\"Number of edges: {G.number_of_edges()}\")\n\n# Node attributes (mandatory)\nnode_0_attrs = G.nodes[0]\nprint(f\"Node 0 position: {node_0_attrs['pos']}\")\nprint(f\"Node 0 grid index: {node_0_attrs['original_grid_nd_index']}\")\n\n# Edge attributes (mandatory)\nedge_attrs = G.edges[0, 1]\nprint(f\"Edge (0,1) distance: {edge_attrs['distance']}\")\nprint(f\"Edge (0,1) vector: {edge_attrs['vector']}\")\n</code></pre>"},{"location":"getting-started/core-concepts/#mandatory-graph-metadata","title":"Mandatory Graph Metadata","text":"<p>neurospatial enforces mandatory attributes for correctness:</p> <p>Node attributes:</p> <ul> <li><code>'pos'</code>: Tuple of N-D coordinates</li> <li><code>'source_grid_flat_index'</code>: Flat index in original grid</li> <li><code>'original_grid_nd_index'</code>: N-D grid index tuple</li> </ul> <p>Edge attributes:</p> <ul> <li><code>'distance'</code>: Euclidean distance between bin centers</li> <li><code>'vector'</code>: Displacement vector (as tuple)</li> <li><code>'edge_id'</code>: Unique integer edge identifier</li> <li><code>'angle_2d'</code>: Angle in 2D (optional, for 2D layouts)</li> </ul> <p>These attributes enable spatial queries like shortest paths, distance calculations, and neighbor finding.</p>"},{"location":"getting-started/core-concepts/#why-graphs","title":"Why Graphs?","text":"<p>Graphs provide:</p> <ol> <li>Flexible topology: Handle complex shapes, holes, and disconnected regions</li> <li>Efficient queries: NetworkX algorithms for paths, distances, neighborhoods</li> <li>Manifold distances: Geodesic distances that respect environment boundaries</li> <li>Extensibility: Add custom node/edge attributes for your analysis</li> </ol>"},{"location":"getting-started/core-concepts/#layout-engines","title":"Layout Engines","text":"<p>Layout engines define how continuous space is discretized into bins. They implement the <code>LayoutEngine</code> protocol.</p>"},{"location":"getting-started/core-concepts/#available-layout-engines","title":"Available Layout Engines","text":"Engine Description Use Case <code>RegularGridLayout</code> Rectangular/cuboid grids Standard spatial binning <code>HexagonalLayout</code> Hexagonal tessellation Uniform neighbor distances <code>GraphLayout</code> 1D linearized tracks Maze/track experiments <code>MaskedGridLayout</code> Grid with active mask Arbitrary active regions <code>ImageMaskLayout</code> Binary image masking Image-based boundaries <code>ShapelyPolygonLayout</code> Polygon-bounded grid Circular/custom arenas <code>TriangularMeshLayout</code> Triangular tessellation Alternative to grids"},{"location":"getting-started/core-concepts/#automatic-selection","title":"Automatic Selection","text":"<p>Factory methods automatically choose the appropriate engine:</p> <pre><code># Regular grid (automatic)\nenv_grid = Environment.from_samples(data, bin_size=2.0)\n\n# Hexagonal (explicit)\nenv_hex = Environment.from_samples(\n    data, bin_size=2.0, layout_type=\"hexagonal\"\n)\n\n# Polygon-bounded (automatic)\nenv_poly = Environment.from_polygon(polygon, bin_size=2.0)\n\n# 1D linearized (automatic)\nenv_1d = Environment.from_graph(graph, edge_order, bin_size=2.0)\n</code></pre>"},{"location":"getting-started/core-concepts/#protocol-based-design","title":"Protocol-Based Design","text":"<p>Layout engines implement a protocol (not inheritance):</p> <pre><code># Layout engines must provide:\n# - bin_centers: NDArray of shape (n_bins, n_dims)\n# - connectivity: nx.Graph with mandatory attributes\n# - dimension_ranges: List of (min, max) tuples\n# - is_1d: bool (True for linearized layouts)\n# - build(): Method to construct the layout\n# - point_to_bin_index(): Map points to bins\n# - bin_sizes(): Compute bin sizes\n# - plot(): Visualize the layout\n</code></pre> <p>This design allows:</p> <ul> <li>Custom layout engines without modifying core code</li> <li>Type checking with protocols</li> <li>Maximum flexibility</li> </ul>"},{"location":"getting-started/core-concepts/#1d-vs-n-d-environments","title":"1D vs N-D Environments","text":""},{"location":"getting-started/core-concepts/#n-d-environments-grids","title":"N-D Environments (Grids)","text":"<p>Most environments are N-dimensional (typically 2D or 3D):</p> <ul> <li>Use grid-based layouts</li> <li>Spatial queries in original coordinate space</li> <li>Multiple neighbors per bin (4-8 in 2D, 6-26 in 3D)</li> </ul> <pre><code># 2D environment\nenv_2d = Environment.from_samples(data_2d, bin_size=2.0)\nprint(f\"Dimensionality: {env_2d.n_dims}D\")\nprint(f\"Is 1D: {env_2d.is_1d}\")  # False\n\n# Spatial queries use 2D coordinates\npoint_2d = np.array([[10.0, 15.0]])\nbin_idx = env_2d.bin_at(point_2d)[0]\n</code></pre>"},{"location":"getting-started/core-concepts/#1d-environments-linearized-tracks","title":"1D Environments (Linearized Tracks)","text":"<p>1D linearized environments represent tracks/mazes as a single dimension:</p> <ul> <li>Use <code>GraphLayout</code> engine</li> <li>Linearize complex 2D/3D geometries into 1D</li> <li>Essential for track-based experiments (T-maze, plus maze, etc.)</li> </ul> <pre><code>import networkx as nx\n\n# Define track structure\ngraph = nx.Graph()\ngraph.add_node(0, pos=(0.0, 0.0))\ngraph.add_node(1, pos=(10.0, 0.0))\ngraph.add_node(2, pos=(20.0, 0.0))\ngraph.add_edge(0, 1, edge_id=0, distance=10.0)\ngraph.add_edge(1, 2, edge_id=1, distance=10.0)\n\n# Create 1D environment\nenv_1d = Environment.from_graph(\n    graph=graph,\n    edge_order=[(0, 1), (1, 2)],\n    bin_size=2.0\n)\n\nprint(f\"Is 1D: {env_1d.is_1d}\")  # True\n\n# Convert 2D position to 1D linear coordinate\nposition_2d = np.array([[15.0, 0.0]])\nposition_1d = env_1d.to_linear(position_2d)\nprint(f\"2D position {position_2d[0]} \u2192 1D position {position_1d[0]:.2f}\")\n\n# Convert back\nposition_2d_reconstructed = env_1d.linear_to_nd(position_1d)\n</code></pre> <p>When to use 1D:</p> <ul> <li>Track-based experiments (mazes, linear tracks)</li> <li>Analyzing sequences along specific paths</li> <li>Decoding position in 1D space</li> <li>Reducing dimensionality for analysis</li> </ul>"},{"location":"getting-started/core-concepts/#regions-of-interest-rois","title":"Regions of Interest (ROIs)","text":"<p>Regions are named spatial areas within an environment:</p> <ul> <li>Immutable <code>Region</code> objects (point or polygon)</li> <li>Managed by <code>Regions</code> container (dict-like)</li> <li>JSON serialization support</li> </ul> <pre><code>from shapely.geometry import Point, Polygon\n\n# Add point region\nenv.regions.add(\"StartLocation\", point=(0.0, 0.0))\n\n# Add polygon region (buffered point = circle)\nreward_zone = Point(10.0, 10.0).buffer(5.0)\nenv.regions.add(\"RewardZone\", polygon=reward_zone)\n\n# Add polygon region (custom shape)\ncorners = [(0, 0), (10, 0), (10, 10), (0, 10)]\ncustom_zone = Polygon(corners)\nenv.regions.add(\"CustomZone\", polygon=custom_zone)\n\n# Access regions\nprint(env.regions.list_names())  # ['StartLocation', 'RewardZone', 'CustomZone']\nprint(env.regions[\"RewardZone\"].type)  # 'polygon'\n\n# Region operations\narea = env.regions.area(\"RewardZone\")\ncenter = env.regions.region_center(\"RewardZone\")\n\n# Regions are immutable - use update to modify\nenv.regions.update_region(\"StartLocation\", point=(5.0, 5.0))\n</code></pre>"},{"location":"getting-started/core-concepts/#the-fitted-state-pattern","title":"The Fitted State Pattern","text":"<p><code>Environment</code> uses a fitted state pattern to ensure proper initialization:</p> <pre><code># Factory methods automatically fit the environment\nenv = Environment.from_samples(data, bin_size=2.0)\nprint(env._is_fitted)  # True\n\n# Can now call spatial query methods\nbin_idx = env.bin_at(point)  # Works\n\n# Don't use bare constructor (not fitted)\n# env_bad = Environment()  # Not fitted\n# env_bad.bin_at(point)  # RuntimeError!\n</code></pre> <p>Methods requiring a fitted environment use the <code>@check_fitted</code> decorator to prevent errors.</p>"},{"location":"getting-started/core-concepts/#factory-methods-vs-constructor","title":"Factory Methods vs Constructor","text":"<p>Always use factory methods, not the bare constructor:</p> Factory Method Purpose <code>Environment.from_samples()</code> Create from data points <code>Environment.from_graph()</code> Create 1D linearized track <code>Environment.from_polygon()</code> Grid bounded by polygon <code>Environment.from_mask()</code> Pre-defined N-D boolean mask <code>Environment.from_image()</code> Binary image mask <code>Environment.from_layout()</code> Direct layout specification <p>Factory methods ensure:</p> <ul> <li>Proper initialization and fitting</li> <li>Correct layout engine selection</li> <li>Validation of parameters</li> <li>Sensible defaults</li> </ul>"},{"location":"getting-started/core-concepts/#summary","title":"Summary","text":"<p>Key takeaways:</p> <ol> <li>Discretization: Continuous space \u2192 discrete bins</li> <li>Active bins: Only include relevant spatial regions</li> <li>Connectivity graphs: Define spatial relationships with mandatory metadata</li> <li>Layout engines: Protocol-based, swappable discretization strategies</li> <li>1D vs N-D: Different query methods for linearized vs grid environments</li> <li>Regions: Named, immutable ROIs within environments</li> <li>Factory methods: Always use these, not bare constructor</li> </ol>"},{"location":"getting-started/core-concepts/#next-steps","title":"Next Steps","text":"<ul> <li>User Guide: Detailed feature guides</li> <li>API Reference: Complete API documentation</li> <li>Examples: Real-world use cases</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide covers how to install neurospatial for different use cases.</p>"},{"location":"getting-started/installation/#standard-installation","title":"Standard Installation","text":"<p>Install neurospatial from PyPI using pip:</p> <pre><code>pip install neurospatial\n</code></pre> <p>This installs neurospatial with all required dependencies for core functionality.</p>"},{"location":"getting-started/installation/#development-installation","title":"Development Installation","text":"<p>If you want to contribute to neurospatial or run the latest development version:</p> <pre><code># Clone the repository\ngit clone https://github.com/edeno/neurospatial.git\ncd neurospatial\n\n# Install with uv (recommended)\nuv sync --extra dev\n\n# Or with pip\npip install -e \".[dev]\"\n</code></pre> <p>The <code>dev</code> extra includes testing, linting, and development tools:</p> <ul> <li>pytest (testing framework)</li> <li>pytest-cov (test coverage)</li> <li>ruff (linting and formatting)</li> <li>pre-commit (git hooks)</li> <li>mypy (type checking)</li> </ul>"},{"location":"getting-started/installation/#documentation-building","title":"Documentation Building","text":"<p>To build the documentation locally:</p> <pre><code># Install with documentation dependencies\nuv sync --extra docs\n\n# Sync example notebooks\nuv run python docs/sync_notebooks.py\n\n# Serve documentation locally\nuv run mkdocs serve\n</code></pre> <p>Then open http://127.0.0.1:8000 in your browser.</p>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":""},{"location":"getting-started/installation/#opencv-support","title":"OpenCV Support","text":"<p>For advanced image-based masking features:</p> <pre><code>pip install neurospatial[opencv]\n</code></pre>"},{"location":"getting-started/installation/#verifying-installation","title":"Verifying Installation","text":"<p>Verify your installation by importing neurospatial:</p> <pre><code>import neurospatial\nprint(neurospatial.__version__)\n</code></pre> <p>Or run a quick test:</p> <pre><code>from neurospatial import Environment\nimport numpy as np\n\n# Create a simple environment\ndata = np.random.uniform(0, 100, (50, 2))\nenv = Environment.from_samples(data, bin_size=10.0)\nprint(f\"Created environment with {env.n_bins} bins\")\n</code></pre>"},{"location":"getting-started/installation/#tested-dependency-versions","title":"Tested Dependency Versions","text":"<p>neurospatial v0.1.0 has been tested with:</p> Package Tested Version Python 3.13.5 numpy 2.3.4 pandas 2.3.3 matplotlib 3.10.7 networkx 3.5 scipy 1.16.3 scikit-learn 1.7.2 shapely 2.1.2 track-linearization 2.4.0 <p>These versions represent the tested configuration, but neurospatial likely works with a range of versions for each dependency.</p>"},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":"<ul> <li>OS: Linux, macOS, or Windows</li> <li>Python: 3.10 or higher</li> <li>Memory: Recommended 4GB+ for typical use cases</li> <li>Disk: ~100MB for installation</li> </ul>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#import-errors","title":"Import Errors","text":"<p>If you encounter <code>ModuleNotFoundError</code>:</p> <pre><code># Ensure you're in the correct environment\nwhich python  # Should point to your virtual environment\n\n# Reinstall neurospatial\npip install --force-reinstall neurospatial\n</code></pre>"},{"location":"getting-started/installation/#using-uv","title":"Using uv","text":"<p>This project uses uv for package management. If you're developing:</p> <ul> <li>Always use <code>uv run</code> to execute commands (e.g., <code>uv run pytest</code>)</li> <li>Never use bare <code>python</code>, <code>pip</code>, or <code>pytest</code> commands</li> </ul>"},{"location":"getting-started/installation/#dependency-conflicts","title":"Dependency Conflicts","text":"<p>If you have dependency conflicts:</p> <pre><code># Create a fresh virtual environment\npython -m venv neurospatial-env\nsource neurospatial-env/bin/activate  # On Windows: neurospatial-env\\Scripts\\activate\n\n# Install neurospatial\npip install neurospatial\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Once installed, proceed to the Quickstart guide to create your first environment.</p>"},{"location":"getting-started/quickstart/","title":"Quickstart","text":"<p>This guide provides a quick introduction to neurospatial's main features. You'll learn how to create environments, query spatial bins, and define regions of interest.</p>"},{"location":"getting-started/quickstart/#basic-environment-creation","title":"Basic Environment Creation","text":"<p>The most common use case is creating an environment from spatial data samples:</p> <pre><code>import numpy as np\nfrom neurospatial import Environment\n\n# Simulate position tracking data (x, y coordinates in cm)\n# Shape: (n_timepoints, 2)\nposition_data = np.array([\n    [10.0, 10.0],\n    [12.0, 11.0],\n    [15.0, 15.0],\n    [18.0, 12.0],\n    [20.0, 10.0],\n    [22.0, 15.0],\n    [25.0, 20.0],\n    # ... more positions\n])\n\n# Create environment with 2 cm bins\nenv = Environment.from_samples(\n    data_samples=position_data,\n    bin_size=2.0,  # Required parameter\n    name=\"OpenField\"\n)\n\n# Inspect the environment\nprint(f\"Environment: {env.name}\")\nprint(f\"Number of bins: {env.n_bins}\")\nprint(f\"Dimensions: {env.n_dims}D\")\nprint(f\"Spatial extent: {env.dimension_ranges}\")\n</code></pre>"},{"location":"getting-started/quickstart/#spatial-queries","title":"Spatial Queries","text":"<p>Once you have an environment, you can perform various spatial queries:</p> <pre><code># Map a point to its bin index\npoint = np.array([[15.0, 15.0]])\nbin_idx = env.bin_at(point)[0]\nprint(f\"Point {point[0]} is in bin {bin_idx}\")\n\n# Get bin center coordinates\ncenter = env.bin_centers[bin_idx]\nprint(f\"Bin {bin_idx} center: {center}\")\n\n# Check if a point is in the environment\nis_inside = env.contains(point)[0]\nprint(f\"Point is inside environment: {is_inside}\")\n\n# Find neighbors of a bin\nneighbors = env.neighbors(bin_idx)\nprint(f\"Bin {bin_idx} has {len(neighbors)} neighbors: {neighbors}\")\n\n# Calculate distance between bins\nbin_a, bin_b = 0, 10\ndistance = env.distance_between(bin_a, bin_b)\nprint(f\"Distance between bins {bin_a} and {bin_b}: {distance:.2f}\")\n\n# Find shortest path\npath = env.shortest_path(bin_a, bin_b)\nprint(f\"Shortest path: {path}\")\n</code></pre>"},{"location":"getting-started/quickstart/#computing-occupancy","title":"Computing Occupancy","text":"<p>A common neuroscience workflow is computing time spent in each bin:</p> <pre><code># Assign all positions to bins\nbin_indices = env.bin_at(position_data)\n\n# Compute occupancy histogram\noccupancy, _ = np.histogram(\n    bin_indices,\n    bins=np.arange(env.n_bins + 1)\n)\n\nprint(f\"Time in bin 0: {occupancy[0]} samples\")\nprint(f\"Total occupied bins: {np.sum(occupancy &gt; 0)}\")\n</code></pre>"},{"location":"getting-started/quickstart/#defining-regions-of-interest","title":"Defining Regions of Interest","text":"<p>You can define named regions (ROIs) within your environment:</p> <pre><code>from shapely.geometry import Point\n\n# Add a circular reward zone (5 cm radius)\nreward_polygon = Point(15.0, 15.0).buffer(5.0)\nenv.regions.add(\"RewardZone\", polygon=reward_polygon)\n\n# Add a point marker for start location\nenv.regions.add(\"StartLocation\", point=(10.0, 10.0))\n\n# Query regions\nprint(f\"Number of regions: {len(env.regions)}\")\nprint(f\"Region names: {env.regions.list_names()}\")\n\n# Get region statistics\narea = env.regions.area(\"RewardZone\")\ncenter = env.regions.region_center(\"RewardZone\")\nprint(f\"Reward zone area: {area:.2f} cm\u00b2\")\nprint(f\"Reward zone center: {center}\")\n</code></pre>"},{"location":"getting-started/quickstart/#visualizing-the-environment","title":"Visualizing the Environment","text":"<p>Visualize your environment with matplotlib:</p> <pre><code>import matplotlib.pyplot as plt\n\n# Create figure\nfig, ax = plt.subplots(figsize=(8, 8))\n\n# Plot the environment\nenv.plot(ax=ax)\n\n# Overlay trajectory\nax.plot(\n    position_data[:, 0],\n    position_data[:, 1],\n    'r-', alpha=0.5, linewidth=1,\n    label='Trajectory'\n)\n\nax.set_title(env.name)\nax.legend()\nplt.show()\n</code></pre>"},{"location":"getting-started/quickstart/#automatic-active-bin-detection","title":"Automatic Active Bin Detection","text":"<p>For sparse data, you can automatically detect active regions:</p> <pre><code># Create environment with automatic active bin detection\nenv_auto = Environment.from_samples(\n    data_samples=position_data,\n    bin_size=2.0,\n    infer_active_bins=True,  # Enable automatic detection\n    bin_count_threshold=1,   # Minimum samples per bin\n    dilate=True,             # Expand active region\n    fill_holes=True,         # Fill gaps\n    name=\"OpenField_Auto\"\n)\n\nprint(f\"Active bins: {env_auto.n_bins}\")\n</code></pre>"},{"location":"getting-started/quickstart/#creating-masked-environments","title":"Creating Masked Environments","text":"<p>Create environments bounded by polygons:</p> <pre><code>from shapely.geometry import Polygon\n\n# Define a circular arena (40 cm radius)\ntheta = np.linspace(0, 2*np.pi, 100)\nboundary = np.column_stack([\n    40 * np.cos(theta),\n    40 * np.sin(theta)\n])\npolygon = Polygon(boundary)\n\n# Create environment bounded by polygon\nenv_circle = Environment.from_polygon(\n    polygon=polygon,\n    bin_size=2.5,\n    name=\"CircularArena\"\n)\n\nprint(f\"Circular arena bins: {env_circle.n_bins}\")\n</code></pre>"},{"location":"getting-started/quickstart/#working-with-different-layout-types","title":"Working with Different Layout Types","text":"<p>neurospatial supports multiple layout engines:</p> <pre><code># Hexagonal layout (more uniform neighbor distances)\nenv_hex = Environment.from_samples(\n    data_samples=position_data,\n    bin_size=2.0,\n    layout_type=\"hexagonal\",\n    name=\"HexEnvironment\"\n)\n\n# Triangular mesh\nenv_tri = Environment.from_samples(\n    data_samples=position_data,\n    bin_size=2.0,\n    layout_type=\"triangular\",\n    name=\"TriEnvironment\"\n)\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<p>Now that you understand the basics, explore:</p> <ul> <li>Core Concepts: Deeper understanding of bins, graphs, and layout engines</li> <li>User Guide: Detailed guides for specific features</li> <li>API Reference: Complete API documentation</li> <li>Examples: Real-world use cases with Jupyter notebooks</li> </ul>"},{"location":"getting-started/quickstart/#common-patterns","title":"Common Patterns","text":""},{"location":"getting-started/quickstart/#pattern-1-spatial-firing-rate-map","title":"Pattern 1: Spatial Firing Rate Map","text":"<pre><code># Compute spike counts per bin\nspike_bin_indices = env.bin_at(spike_positions)\nspike_counts, _ = np.histogram(\n    spike_bin_indices,\n    bins=np.arange(env.n_bins + 1)\n)\n\n# Compute occupancy\nposition_bin_indices = env.bin_at(position_data)\noccupancy, _ = np.histogram(\n    position_bin_indices,\n    bins=np.arange(env.n_bins + 1)\n)\n\n# Calculate firing rate (spikes/sec, assuming 30 Hz sampling)\nsampling_rate = 30.0  # Hz\ntime_per_bin = occupancy / sampling_rate\nfiring_rate = np.divide(\n    spike_counts,\n    time_per_bin,\n    where=time_per_bin &gt; 0\n)\n</code></pre>"},{"location":"getting-started/quickstart/#pattern-2-distance-to-target","title":"Pattern 2: Distance to Target","text":"<pre><code># Find bin containing target location\ntarget = np.array([[20.0, 20.0]])\ntarget_bin = env.bin_at(target)[0]\n\n# Calculate distance from every bin to target\ndistances = np.array([\n    env.distance_between(bin_idx, target_bin)\n    for bin_idx in range(env.n_bins)\n])\n\nprint(f\"Mean distance to target: {np.mean(distances):.2f} cm\")\n</code></pre>"},{"location":"getting-started/quickstart/#pattern-3-region-occupancy","title":"Pattern 3: Region Occupancy","text":"<pre><code># Define multiple zones\nzones = {\n    \"Zone1\": Point(10.0, 10.0).buffer(5.0),\n    \"Zone2\": Point(25.0, 25.0).buffer(5.0),\n}\n\nfor name, polygon in zones.items():\n    env.regions.add(name, polygon=polygon)\n\n# Compute time in each zone\nfor name in zones.keys():\n    # Get bins in this region\n    region_bins = []\n    for bin_idx in range(env.n_bins):\n        bin_point = Point(env.bin_centers[bin_idx])\n        if env.regions[name].polygon.contains(bin_point):\n            region_bins.append(bin_idx)\n\n    # Count samples\n    time_in_region = np.sum(np.isin(position_bin_indices, region_bins))\n    print(f\"Time in {name}: {time_in_region} samples\")\n</code></pre>"},{"location":"user-guide/","title":"User Guide","text":"<p>This guide provides detailed explanations of neurospatial's features and workflows.</p>"},{"location":"user-guide/#contents","title":"Contents","text":"<ul> <li>Environments: Creating and working with Environment objects</li> <li>Layout Engines: Understanding different discretization strategies</li> <li>Regions: Defining and managing regions of interest</li> <li>Composite Environments: Merging multiple environments</li> <li>Alignment &amp; Transforms: Transforming spatial representations</li> </ul>"},{"location":"user-guide/#who-this-guide-is-for","title":"Who This Guide Is For","text":"<p>This guide is for users who:</p> <ul> <li>Have completed the Quickstart</li> <li>Want to understand specific features in depth</li> <li>Need to solve complex spatial analysis problems</li> <li>Want to customize neurospatial for their use case</li> </ul>"},{"location":"user-guide/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Getting Started section</li> <li>Familiarity with NumPy arrays and basic Python</li> <li>Understanding of spatial coordinates</li> </ul>"},{"location":"user-guide/#navigation","title":"Navigation","text":"<p>Each page covers a specific feature area with:</p> <ul> <li>Conceptual explanations</li> <li>Code examples</li> <li>Common patterns and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"user-guide/#quick-links","title":"Quick Links","text":"<p>Common Tasks:</p> <ul> <li>Creating different environment types</li> <li>Choosing the right layout engine</li> <li>Defining regions</li> <li>Combining multiple environments</li> <li>Aligning spatial maps</li> </ul>"},{"location":"user-guide/#see-also","title":"See Also","text":"<ul> <li>API Reference: Detailed API documentation</li> <li>Examples: Real-world use cases</li> <li>Getting Started: Beginner tutorials</li> </ul>"},{"location":"user-guide/alignment/","title":"Alignment &amp; Transforms","text":"<p>neurospatial provides tools for transforming and aligning spatial representations between environments.</p>"},{"location":"user-guide/alignment/#affine-transformations","title":"Affine Transformations","text":"<pre><code>from neurospatial.transforms import Affine2D\n\n# Create transformation\ntransform = Affine2D()\ntransform.rotate(np.pi/4)  # 45 degrees\ntransform.translate(10, 20)\ntransform.scale(1.5, 1.5)\n\n# Apply to points\ntransformed_points = transform.transform(points)\n</code></pre>"},{"location":"user-guide/alignment/#probability-alignment","title":"Probability Alignment","text":"<p>Map probability distributions between environments:</p> <pre><code>from neurospatial.alignment import map_probabilities_to_nearest_target_bin\n\n# Align distributions from source to target environment\naligned_probs = map_probabilities_to_nearest_target_bin(\n    source_env=env1,\n    target_env=env2,\n    source_probabilities=probs1\n)\n</code></pre> <p>See the API Reference for complete documentation.</p>"},{"location":"user-guide/composite-environments/","title":"Composite Environments","text":"<p><code>CompositeEnvironment</code> allows you to merge multiple environments with automatic bridge inference.</p>"},{"location":"user-guide/composite-environments/#basic-usage","title":"Basic Usage","text":"<pre><code>from neurospatial import Environment\nfrom neurospatial.composite import CompositeEnvironment\n\n# Create multiple environments\nenv1 = Environment.from_samples(data1, bin_size=2.0, name=\"Arena1\")\nenv2 = Environment.from_samples(data2, bin_size=2.0, name=\"Arena2\")\n\n# Merge environments\ncomposite = CompositeEnvironment(\n    environments=[env1, env2],\n    names=[\"Arena1\", \"Arena2\"]\n)\n</code></pre>"},{"location":"user-guide/composite-environments/#automatic-bridge-inference","title":"Automatic Bridge Inference","text":"<p>CompositeEnvironment automatically infers connections (bridges) between environments based on mutual nearest neighbors.</p> <p>See the API Reference for complete documentation.</p>"},{"location":"user-guide/environments/","title":"Environments","text":"<p>The <code>Environment</code> class is the main interface for working with discretized spatial environments in neurospatial.</p>"},{"location":"user-guide/environments/#overview","title":"Overview","text":"<p>An <code>Environment</code> wraps a layout engine and provides:</p> <ul> <li>Spatial queries (point-to-bin mapping, neighbors, paths, distances)</li> <li>Region management (named ROIs)</li> <li>Visualization capabilities</li> <li>Serialization support</li> </ul>"},{"location":"user-guide/environments/#factory-methods","title":"Factory Methods","text":"<p>Always create environments using factory methods, not the bare constructor:</p>"},{"location":"user-guide/environments/#from_samples","title":"from_samples()","text":"<p>Create an environment from data samples (most common):</p> <pre><code>import numpy as np\nfrom neurospatial import Environment\n\n# Position data (n_samples, n_dims)\ndata = np.random.uniform(0, 100, (1000, 2))\n\nenv = Environment.from_samples(\n    data_samples=data,\n    bin_size=5.0,\n    name=\"MyEnvironment\"\n)\n</code></pre> <p>Parameters:</p> <ul> <li><code>data_samples</code>: Array of shape (n_samples, n_dims)</li> <li><code>bin_size</code>: Size of bins (required)</li> <li><code>infer_active_bins</code>: Automatically detect active regions (default: False)</li> <li><code>bin_count_threshold</code>: Minimum samples per active bin</li> <li><code>layout_type</code>: \"regular\", \"hexagonal\", or \"triangular\"</li> <li><code>dilate</code>, <code>fill_holes</code>, <code>close</code>: Morphological operations</li> </ul> <p>See API Reference for complete parameter documentation.</p>"},{"location":"user-guide/environments/#from_polygon","title":"from_polygon()","text":"<p>Create an environment bounded by a Shapely polygon:</p> <pre><code>from shapely.geometry import Polygon\n\n# Circular arena\ntheta = np.linspace(0, 2*np.pi, 100)\nboundary = np.column_stack([50*np.cos(theta), 50*np.sin(theta)])\npolygon = Polygon(boundary)\n\nenv = Environment.from_polygon(\n    polygon=polygon,\n    bin_size=2.5,\n    name=\"CircularArena\"\n)\n</code></pre>"},{"location":"user-guide/environments/#from_graph","title":"from_graph()","text":"<p>Create a 1D linearized track environment:</p> <pre><code>import networkx as nx\n\n# Define track topology\ngraph = nx.Graph()\ngraph.add_node(0, pos=(0.0, 0.0))\ngraph.add_node(1, pos=(50.0, 0.0))\ngraph.add_edge(0, 1, edge_id=0, distance=50.0)\n\nenv = Environment.from_graph(\n    graph=graph,\n    edge_order=[(0, 1)],\n    bin_size=2.0,\n    name=\"LinearTrack\"\n)\n</code></pre>"},{"location":"user-guide/environments/#from_mask","title":"from_mask()","text":"<p>Create from a pre-defined N-D boolean mask:</p> <pre><code># Create custom mask\nmask = np.zeros((50, 50), dtype=bool)\nmask[10:40, 10:40] = True  # Active region\n\nenv = Environment.from_mask(\n    mask=mask,\n    bin_size=2.0,\n    dimension_ranges=[(0, 100), (0, 100)],\n    name=\"MaskedEnvironment\"\n)\n</code></pre>"},{"location":"user-guide/environments/#from_image","title":"from_image()","text":"<p>Create from a binary image file:</p> <pre><code>env = Environment.from_image(\n    image_path=\"arena_mask.png\",\n    bin_size=2.0,\n    dimension_ranges=[(0, 100), (0, 100)],\n    name=\"ImageEnvironment\"\n)\n</code></pre>"},{"location":"user-guide/environments/#spatial-queries","title":"Spatial Queries","text":""},{"location":"user-guide/environments/#bin_at","title":"bin_at()","text":"<p>Map points to bin indices:</p> <pre><code>points = np.array([\n    [10.0, 20.0],\n    [30.0, 40.0],\n    [50.0, 60.0]\n])\n\nbin_indices = env.bin_at(points)\n# Returns: array of bin indices\n</code></pre>"},{"location":"user-guide/environments/#contains","title":"contains()","text":"<p>Check if points are within the environment:</p> <pre><code>is_inside = env.contains(points)\n# Returns: boolean array\n</code></pre>"},{"location":"user-guide/environments/#neighbors","title":"neighbors()","text":"<p>Get neighboring bins:</p> <pre><code>neighbors = env.neighbors(bin_index=42)\n# Returns: list of neighbor bin indices\n</code></pre>"},{"location":"user-guide/environments/#distance_between","title":"distance_between()","text":"<p>Calculate distance between bins:</p> <pre><code>distance = env.distance_between(bin_a=10, bin_b=20)\n# Returns: float distance\n</code></pre>"},{"location":"user-guide/environments/#shortest_path","title":"shortest_path()","text":"<p>Find shortest path between bins:</p> <pre><code>path = env.shortest_path(start_bin=0, end_bin=50)\n# Returns: list of bin indices forming path\n</code></pre>"},{"location":"user-guide/environments/#properties","title":"Properties","text":"<p>Access environment properties:</p> <pre><code># Basic properties\nprint(env.n_bins)           # Number of bins\nprint(env.n_dims)           # Number of dimensions\nprint(env.is_1d)            # True for linearized environments\nprint(env.name)             # Environment name\n\n# Spatial information\nprint(env.bin_centers)      # Array of shape (n_bins, n_dims)\nprint(env.dimension_ranges) # List of (min, max) tuples\nprint(env.connectivity)     # NetworkX graph\n\n# Layout-specific (if available)\nif hasattr(env.layout, 'grid_shape'):\n    print(env.layout.grid_shape)\n</code></pre>"},{"location":"user-guide/environments/#1d-environments","title":"1D Environments","text":"<p>Linearized track environments have additional methods:</p> <pre><code># Check if environment is 1D\nif env.is_1d:\n    # Convert N-D coordinates to 1D\n    linear_position = env.to_linear(nd_position)\n\n    # Convert 1D back to N-D\n    nd_position = env.linear_to_nd(linear_position)\n</code></pre>"},{"location":"user-guide/environments/#visualization","title":"Visualization","text":"<p>Plot the environment:</p> <pre><code>import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(8, 8))\nenv.plot(ax=ax)\nplt.show()\n</code></pre>"},{"location":"user-guide/environments/#common-patterns","title":"Common Patterns","text":""},{"location":"user-guide/environments/#pattern-occupancy-map","title":"Pattern: Occupancy Map","text":"<pre><code># Assign positions to bins\nposition_data = load_tracking_data()  # (n_timepoints, 2)\nbin_indices = env.bin_at(position_data)\n\n# Compute occupancy\noccupancy, _ = np.histogram(\n    bin_indices,\n    bins=np.arange(env.n_bins + 1)\n)\n\n# Visualize\nfig, ax = plt.subplots()\nenv.plot(ax=ax)\n# Overlay occupancy heatmap...\n</code></pre>"},{"location":"user-guide/environments/#pattern-spatial-smoothing","title":"Pattern: Spatial Smoothing","text":"<pre><code># Smooth data using neighbor relationships\ndef spatial_smooth(values, env, sigma=1.0):\n    smoothed = np.zeros_like(values)\n    for bin_idx in range(env.n_bins):\n        neighbors = env.neighbors(bin_idx)\n        neighbor_values = values[neighbors]\n        smoothed[bin_idx] = np.mean(neighbor_values)\n    return smoothed\n</code></pre>"},{"location":"user-guide/environments/#see-also","title":"See Also","text":"<ul> <li>Layout Engines: Understanding discretization strategies</li> <li>Regions: Defining ROIs within environments</li> <li>API Reference: Complete API documentation</li> </ul>"},{"location":"user-guide/layout-engines/","title":"Layout Engines","text":"<p>Layout engines define how continuous space is discretized into bins. This page helps you choose the right engine for your analysis.</p>"},{"location":"user-guide/layout-engines/#quick-decision-guide","title":"Quick Decision Guide","text":"<p>Most common scenarios:</p> <ol> <li>Standard open field experiment \u2192 Use <code>Environment.from_samples()</code> (defaults to RegularGridLayout)</li> <li>Circular arena \u2192 Use <code>Environment.from_polygon()</code> (ShapelyPolygonLayout)</li> <li>T-maze or track \u2192 Use <code>Environment.from_graph()</code> (GraphLayout)</li> <li>Need uniform neighbor distances \u2192 Use <code>layout_type=\"hexagonal\"</code> (HexagonalLayout)</li> </ol>"},{"location":"user-guide/layout-engines/#available-engines","title":"Available Engines","text":""},{"location":"user-guide/layout-engines/#regulargridlayout","title":"RegularGridLayout","text":"<p>Standard rectangular/cuboid grids - fastest and most common.</p> <p>When to use: Default choice for rectangular environments Performance: \u2b50\u2b50\u2b50\u2b50\u2b50 (fastest) Memory: \u2b50\u2b50\u2b50\u2b50\u2b50 (most efficient) Setup complexity: \u2b50\u2b50\u2b50\u2b50\u2b50 (easiest)</p> <pre><code>env = Environment.from_samples(positions, bin_size=2.5)\n# or explicitly:\nenv = Environment.from_samples(positions, bin_size=2.5, layout_type=\"regular\")\n</code></pre>"},{"location":"user-guide/layout-engines/#hexagonallayout","title":"HexagonalLayout","text":"<p>Hexagonal tessellation with uniform neighbor distances.</p> <p>When to use: When analyzing directional patterns or need isotropic representation Performance: \u2b50\u2b50\u2b50\u2b50 (very fast) Memory: \u2b50\u2b50\u2b50\u2b50 (efficient, ~15% more bins) Setup complexity: \u2b50\u2b50\u2b50\u2b50 (easy)</p> <pre><code>env = Environment.from_samples(positions, bin_size=2.5, layout_type=\"hexagonal\")\n</code></pre> <p>Trade-off: All 6 neighbors equidistant, but requires 15% more bins for same coverage.</p>"},{"location":"user-guide/layout-engines/#graphlayout","title":"GraphLayout","text":"<p>1D linearized track for mazes and structured environments.</p> <p>When to use: T-maze, plus maze, linear track experiments Performance: \u2b50\u2b50 (slower lookups) Memory: \u2b50\u2b50 (higher usage) Setup complexity: \u2b50\u2b50 (requires graph definition)</p> <pre><code>import networkx as nx\n\nG = nx.Graph()\nG.add_node(0, pos=(0, 0))\nG.add_node(1, pos=(50, 0))\nG.add_edge(0, 1, edge_id=0, distance=50.0)\n\nenv = Environment.from_graph(G, edge_order=[(0, 1)], bin_size=2.0)\n</code></pre> <p>Key feature: Converts 2D positions to 1D linear coordinates with <code>env.to_linear()</code></p>"},{"location":"user-guide/layout-engines/#maskedgridlayout","title":"MaskedGridLayout","text":"<p>Grid with active/inactive regions - automatically used when <code>infer_active_bins=True</code>.</p> <p>When to use: Sparse data, need to exclude walls/unvisited areas Performance: \u2b50\u2b50\u2b50\u2b50 (fast) Memory: \u2b50\u2b50\u2b50\u2b50\u2b50 (very efficient for sparse environments) Setup complexity: \u2b50\u2b50\u2b50 (automatic with parameter tuning)</p> <pre><code>env = Environment.from_samples(\n    positions,\n    bin_size=2.5,\n    infer_active_bins=True,\n    dilate=True,\n    fill_holes=True\n)\n</code></pre>"},{"location":"user-guide/layout-engines/#shapelypolygonlayout","title":"ShapelyPolygonLayout","text":"<p>Grid bounded by polygon for geometric arenas.</p> <p>When to use: Circular, elliptical, or custom-shaped arenas Performance: \u2b50\u2b50\u2b50 (moderate) Memory: \u2b50\u2b50\u2b50\u2b50 (efficient) Setup complexity: \u2b50\u2b50\u2b50 (need polygon definition)</p> <pre><code>from shapely.geometry import Point\nimport numpy as np\n\n# Circular arena\ntheta = np.linspace(0, 2*np.pi, 100)\nboundary = np.column_stack([50*np.cos(theta), 50*np.sin(theta)])\nfrom shapely.geometry import Polygon\narena = Polygon(boundary)\n\nenv = Environment.from_polygon(arena, bin_size=2.5)\n</code></pre>"},{"location":"user-guide/layout-engines/#triangularmeshlayout","title":"TriangularMeshLayout","text":"<p>Triangular tessellation - alternative grid structure.</p> <p>When to use: Alternative to hexagonal, specific geometric needs Performance: \u2b50\u2b50\u2b50 (moderate) Memory: \u2b50\u2b50\u2b50\u2b50 (efficient) Setup complexity: \u2b50\u2b50\u2b50\u2b50 (easy)</p> <pre><code>env = Environment.from_samples(positions, bin_size=2.5, layout_type=\"triangular\")\n</code></pre>"},{"location":"user-guide/layout-engines/#imagemasklayout","title":"ImageMaskLayout","text":"<p>Binary image-based boundaries from video analysis.</p> <p>When to use: Extracting arena from video frames Performance: \u2b50\u2b50\u2b50 (moderate) Memory: \u2b50\u2b50\u2b50 (moderate) Setup complexity: \u2b50\u2b50 (requires image preprocessing)</p> <pre><code>env = Environment.from_image(\n    image_path=\"arena_mask.png\",\n    bin_size=2.5,\n    dimension_ranges=[(0, 100), (0, 100)]\n)\n</code></pre>"},{"location":"user-guide/layout-engines/#performance-comparison","title":"Performance Comparison","text":"<p>Benchmark: 100x100 cm arena, 2.5 cm bins, 10,000 position lookups</p> Engine Setup (ms) Lookups/sec Memory (MB) Bins Regular 5 1,000,000 0.5 1,600 Hexagonal 8 900,000 0.6 1,840 Masked 15 800,000 0.3 ~1,100 Polygon 50 600,000 0.6 ~1,250 Triangular 10 700,000 0.6 ~1,700 Graph 100 100,000 1.0 50 nodes <p>Practical impact: For typical experiments (10k-100k positions), all engines complete in &lt;1 second. Choose based on spatial structure needs, not performance.</p>"},{"location":"user-guide/layout-engines/#choosing-bin-size","title":"Choosing Bin Size","text":"<p>Bin size has more impact than engine choice for most analyses.</p>"},{"location":"user-guide/layout-engines/#guidelines-by-arena-size","title":"Guidelines by Arena Size","text":"<p>Rat (100x100 cm arena): - Coarse: 5-10 cm \u2192 100-400 bins - Standard: 2-5 cm \u2192 400-2,500 bins - Fine: 1-2 cm \u2192 2,500-10,000 bins</p> <p>Mouse (40x40 cm arena): - Coarse: 2-4 cm \u2192 100-400 bins - Standard: 1-2 cm \u2192 400-1,600 bins - Fine: 0.5-1 cm \u2192 1,600-6,400 bins</p>"},{"location":"user-guide/layout-engines/#rule-of-thumb","title":"Rule of Thumb","text":"<p>Target 10-100 samples per bin for stable statistics:</p> <pre><code># Estimate good bin_size\nn_samples = len(positions)\narena_area = 100 * 100  # cm\u00b2\ntarget_samples_per_bin = 50\n\ntarget_bins = n_samples / target_samples_per_bin\nbin_size = np.sqrt(arena_area / target_bins)\n</code></pre>"},{"location":"user-guide/layout-engines/#decision-tree","title":"Decision Tree","text":"<pre><code>What's your environment?\n\u2502\n\u251c\u2500 Rectangular/square arena\n\u2502  \u251c\u2500 Need direction-independent analysis? \u2192 Hexagonal\n\u2502  \u2514\u2500 Standard analysis \u2192 Regular (default)\n\u2502\n\u251c\u2500 Circular/elliptical arena \u2192 Polygon\n\u2502\n\u251c\u2500 Track/maze with branches \u2192 Graph\n\u2502\n\u2514\u2500 Sparse data with walls/obstacles\n   \u251c\u2500 Have binary image \u2192 ImageMask\n   \u251c\u2500 Have polygon boundary \u2192 Polygon\n   \u2514\u2500 Just position data \u2192 Masked (infer_active_bins=True)\n</code></pre>"},{"location":"user-guide/layout-engines/#common-patterns","title":"Common Patterns","text":""},{"location":"user-guide/layout-engines/#pattern-1-let-neurospatial-choose","title":"Pattern 1: Let neurospatial choose","text":"<pre><code># Simplest - neurospatial picks appropriate engine\nenv = Environment.from_samples(positions, bin_size=2.5)\n</code></pre>"},{"location":"user-guide/layout-engines/#pattern-2-explicit-control","title":"Pattern 2: Explicit control","text":"<pre><code># Choose specific engine when you know what you need\nenv = Environment.from_samples(\n    positions,\n    bin_size=2.5,\n    layout_type=\"hexagonal\"  # Override default\n)\n</code></pre>"},{"location":"user-guide/layout-engines/#pattern-3-complex-boundaries","title":"Pattern 3: Complex boundaries","text":"<pre><code># Use factory method for specific geometry\nenv = Environment.from_polygon(polygon, bin_size=2.5)\n# or\nenv = Environment.from_image(image_path, bin_size=2.5, dimension_ranges=[(0,100), (0,100)])\n</code></pre>"},{"location":"user-guide/layout-engines/#summary","title":"Summary","text":"<p>For most users: - Start with <code>Environment.from_samples()</code> and default settings - Adjust <code>bin_size</code> based on your data density - Only change engine if you have specific geometric or analytical needs</p> <p>Key factors: 1. Environment shape (rectangular vs. circular vs. track) 2. Data density (affects bin size, not engine) 3. Analysis needs (directional uniformity, 1D linearization)</p>"},{"location":"user-guide/layout-engines/#see-also","title":"See Also","text":"<ul> <li>Environments Guide: Using different factory methods</li> <li>Examples: Visual comparisons</li> <li>API Reference</li> </ul>"},{"location":"user-guide/regions/","title":"Regions","text":"<p>Regions allow you to define and manage named spatial areas (ROIs) within your environment.</p>"},{"location":"user-guide/regions/#creating-regions","title":"Creating Regions","text":"<pre><code>from shapely.geometry import Point, Polygon\n\n# Point region\nenv.regions.add(\"StartLocation\", point=(0.0, 0.0))\n\n# Polygon region (circular)\nreward_zone = Point(10.0, 10.0).buffer(5.0)\nenv.regions.add(\"RewardZone\", polygon=reward_zone)\n\n# Polygon region (custom)\ncorners = [(0, 0), (10, 0), (10, 10), (0, 10)]\ncustom = Polygon(corners)\nenv.regions.add(\"CustomZone\", polygon=custom)\n</code></pre>"},{"location":"user-guide/regions/#managing-regions","title":"Managing Regions","text":"<pre><code># List regions\nnames = env.regions.list_names()\n\n# Access region\nregion = env.regions[\"RewardZone\"]\n\n# Remove region\ndel env.regions[\"RewardZone\"]\n# or\nenv.regions.remove(\"RewardZone\")\n\n# Update region (creates new immutable instance)\nenv.regions.update_region(\"StartLocation\", point=(5.0, 5.0))\n</code></pre>"},{"location":"user-guide/regions/#region-operations","title":"Region Operations","text":"<pre><code># Compute area\narea = env.regions.area(\"RewardZone\")\n\n# Get center\ncenter = env.regions.region_center(\"RewardZone\")\n\n# Buffer region\nbuffered = env.regions.buffer(\"RewardZone\", distance=2.0)\n</code></pre> <p>See the API Reference for complete documentation.</p>"},{"location":"user-guide/workflows/","title":"Complete Workflows","text":"<p>This page demonstrates end-to-end analysis workflows that integrate multiple neurospatial features.</p>"},{"location":"user-guide/workflows/#workflow-1-place-field-analysis","title":"Workflow 1: Place Field Analysis","text":"<p>A complete workflow for analyzing spatial firing patterns of neurons during navigation.</p>"},{"location":"user-guide/workflows/#overview","title":"Overview","text":"<p>Goal: Compute spatial firing rate maps from position tracking and spike data</p> <p>Steps: Load data \u2192 Create environment \u2192 Compute occupancy \u2192 Process spikes \u2192 Calculate firing rates \u2192 Visualize</p>"},{"location":"user-guide/workflows/#complete-example","title":"Complete Example","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom neurospatial import Environment\n\n# Step 1: Load experimental data\n# Position data: (n_timepoints, 2) array of x, y coordinates in cm\n# Spike times: timestamps when neuron fired\nposition_data = load_position_data()  # Your data loading function\nspike_times = load_spike_times()      # Your spike loading function\nsampling_rate = 30.0  # Hz\n\n# Step 2: Create environment with appropriate parameters\nenv = Environment.from_samples(\n    data_samples=position_data,\n    bin_size=2.5,  # 2.5 cm bins for 100x100 cm arena\n    infer_active_bins=True,\n    bin_count_threshold=5,  # Require at least 5 samples per bin\n    dilate=True,  # Expand active region slightly\n    fill_holes=True,  # Fill interior gaps\n    name=\"OpenFieldSession1\"\n)\n\nprint(f\"Created environment with {env.n_bins} active bins\")\nprint(f\"Spatial extent: {env.dimension_ranges}\")\n\n# Step 3: Compute occupancy (time spent in each bin)\nposition_bin_indices = env.bin_at(position_data)\noccupancy_counts, _ = np.histogram(\n    position_bin_indices,\n    bins=np.arange(env.n_bins + 1)\n)\noccupancy_time = occupancy_counts / sampling_rate  # Convert to seconds\n\n# Sanity check\ntotal_time = len(position_data) / sampling_rate\nprint(f\"Total session time: {total_time:.1f} seconds\")\nprint(f\"Time accounted for: {occupancy_time.sum():.1f} seconds\")\nassert np.isclose(occupancy_time.sum(), total_time, rtol=0.01)\n\n# Step 4: Map spikes to bins\n# Find position at each spike time (requires interpolation in real data)\nspike_positions = interpolate_position(position_data, spike_times)\nspike_bin_indices = env.bin_at(spike_positions)\n\n# Count spikes per bin\nspike_counts, _ = np.histogram(\n    spike_bin_indices,\n    bins=np.arange(env.n_bins + 1)\n)\n\n# Step 5: Calculate firing rate map\n# Only compute firing rate for bins with sufficient occupancy\nmin_occupancy = 0.1  # seconds\nfiring_rate = np.full(env.n_bins, np.nan)\nvalid_bins = occupancy_time &gt;= min_occupancy\n\nfiring_rate[valid_bins] = (\n    spike_counts[valid_bins] / occupancy_time[valid_bins]\n)\n\nprint(f\"Peak firing rate: {np.nanmax(firing_rate):.2f} Hz\")\nprint(f\"Mean firing rate: {np.nanmean(firing_rate):.2f} Hz\")\nprint(f\"Bins with valid firing rate: {np.sum(valid_bins)}/{env.n_bins}\")\n\n# Step 6: Smooth firing rate map (optional)\nfrom scipy.ndimage import gaussian_filter\n\n# Reshape to 2D grid for smoothing\nif hasattr(env.layout, 'grid_shape'):\n    grid_shape = env.layout.grid_shape\n    active_mask = env.layout.active_mask\n\n    # Create full grid with NaN for inactive bins\n    firing_rate_grid = np.full(grid_shape, np.nan)\n    firing_rate_grid[active_mask] = firing_rate\n\n    # Smooth (only affects active regions)\n    smoothed_grid = gaussian_filter(\n        np.nan_to_num(firing_rate_grid),\n        sigma=1.0\n    )\n    firing_rate_smoothed = smoothed_grid[active_mask]\nelse:\n    firing_rate_smoothed = firing_rate  # Can't smooth non-grid layouts\n\n# Step 7: Visualize results\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# Plot 1: Trajectory with environment\nax1 = axes[0]\nenv.plot(ax=ax1)\nax1.plot(position_data[:, 0], position_data[:, 1],\n         'r-', alpha=0.3, linewidth=0.5)\nax1.set_title('Trajectory')\n\n# Plot 2: Occupancy map\nax2 = axes[1]\nscatter = ax2.scatter(\n    env.bin_centers[:, 0],\n    env.bin_centers[:, 1],\n    c=occupancy_time,\n    s=50,\n    cmap='viridis'\n)\nplt.colorbar(scatter, ax=ax2, label='Time (s)')\nax2.set_title('Occupancy')\nax2.set_xlabel('X (cm)')\nax2.set_ylabel('Y (cm)')\n\n# Plot 3: Firing rate map\nax3 = axes[2]\nscatter = ax3.scatter(\n    env.bin_centers[:, 0],\n    env.bin_centers[:, 1],\n    c=firing_rate_smoothed,\n    s=50,\n    cmap='hot',\n    vmin=0\n)\nplt.colorbar(scatter, ax=ax3, label='Firing Rate (Hz)')\nax3.set_title('Place Field')\nax3.set_xlabel('X (cm)')\nax3.set_ylabel('Y (cm)')\n\nplt.tight_layout()\nplt.savefig('place_field_analysis.png', dpi=300)\nplt.show()\n\n# Step 8: Export results\nresults = {\n    'environment': env,\n    'occupancy_time': occupancy_time,\n    'spike_counts': spike_counts,\n    'firing_rate': firing_rate,\n    'firing_rate_smoothed': firing_rate_smoothed,\n    'bin_centers': env.bin_centers,\n}\n\n# Save for later analysis\nnp.savez('place_field_results.npz', **results)\n</code></pre>"},{"location":"user-guide/workflows/#key-considerations","title":"Key Considerations","text":"<p>Bin Size Selection: - Too large: Lose spatial resolution - Too small: Insufficient occupancy, noisy firing rates - Rule of thumb: 2-5 cm for rat open field (100x100 cm arena)</p> <p>Occupancy Threshold: - Exclude bins with low occupancy to avoid division by zero - Typical: 0.1-1.0 seconds minimum - Trade-off: Coverage vs. reliability</p> <p>Smoothing: - Reduces noise but blurs fine spatial structure - Gaussian filter with sigma=1-2 bins is typical - Consider not smoothing if bin size already large</p>"},{"location":"user-guide/workflows/#workflow-2-region-based-analysis","title":"Workflow 2: Region-Based Analysis","text":"<p>Analyzing behavior across experimentally-defined spatial zones.</p>"},{"location":"user-guide/workflows/#overview_1","title":"Overview","text":"<p>Goal: Compare neural activity and behavior across different regions of the environment</p> <p>Steps: Define regions \u2192 Compute metrics per region \u2192 Statistical comparison</p>"},{"location":"user-guide/workflows/#complete-example_1","title":"Complete Example","text":"<pre><code>from neurospatial import Environment\nfrom shapely.geometry import Point\nimport numpy as np\n\n# Create environment from position data\nenv = Environment.from_samples(position_data, bin_size=3.0)\n\n# Define experimental regions\n# Center zone (15 cm radius circle)\ncenter_point = Point(50.0, 50.0)  # Arena center\nenv.regions.add(\"Center\", polygon=center_point.buffer(15.0))\n\n# Corner zones (10x10 cm squares)\ncorners = {\n    \"TopLeft\": [(0, 90), (10, 90), (10, 100), (0, 100)],\n    \"TopRight\": [(90, 90), (100, 90), (100, 100), (90, 100)],\n    \"BottomLeft\": [(0, 0), (10, 0), (10, 10), (0, 10)],\n    \"BottomRight\": [(90, 0), (100, 0), (100, 10), (90, 10)],\n}\n\nfor name, coords in corners.items():\n    from shapely.geometry import Polygon\n    env.regions.add(name, polygon=Polygon(coords))\n\n# Find which bins belong to each region\nregion_bins = {}\nfor region_name in env.regions.list_names():\n    region_polygon = env.regions[region_name].polygon\n    bins_in_region = []\n\n    for bin_idx in range(env.n_bins):\n        bin_point = Point(env.bin_centers[bin_idx])\n        if region_polygon.contains(bin_point):\n            bins_in_region.append(bin_idx)\n\n    region_bins[region_name] = np.array(bins_in_region)\n    print(f\"{region_name}: {len(bins_in_region)} bins\")\n\n# Compute occupancy per region\nposition_bins = env.bin_at(position_data)\nsampling_rate = 30.0  # Hz\n\nregion_occupancy = {}\nfor region_name, bins in region_bins.items():\n    time_in_region = np.sum(np.isin(position_bins, bins)) / sampling_rate\n    region_occupancy[region_name] = time_in_region\n    print(f\"Time in {region_name}: {time_in_region:.2f} seconds\")\n\n# Compute firing rate per region\nspike_positions = interpolate_position(position_data, spike_times)\nspike_bins = env.bin_at(spike_positions)\n\nregion_firing_rates = {}\nfor region_name, bins in region_bins.items():\n    spikes_in_region = np.sum(np.isin(spike_bins, bins))\n    time_in_region = region_occupancy[region_name]\n\n    if time_in_region &gt; 0.5:  # Require 0.5s minimum\n        firing_rate = spikes_in_region / time_in_region\n        region_firing_rates[region_name] = firing_rate\n    else:\n        region_firing_rates[region_name] = np.nan\n\n    print(f\"{region_name} firing rate: {firing_rate:.2f} Hz\")\n\n# Statistical comparison\n# Example: Is firing rate higher in center vs. corners?\ncenter_rate = region_firing_rates[\"Center\"]\ncorner_rates = [region_firing_rates[name] for name in corners.keys()]\ncorner_rates = [r for r in corner_rates if not np.isnan(r)]\n\nprint(f\"\\nCenter: {center_rate:.2f} Hz\")\nprint(f\"Corners: {np.mean(corner_rates):.2f} \u00b1 {np.std(corner_rates):.2f} Hz\")\n\n# Visualize regions\nfig, ax = plt.subplots(figsize=(8, 8))\nenv.plot(ax=ax)\n\n# Color-code regions\ncolors = plt.cm.Set3(np.linspace(0, 1, len(env.regions)))\nfor idx, region_name in enumerate(env.regions.list_names()):\n    region = env.regions[region_name]\n    if region.polygon:\n        x, y = region.polygon.exterior.xy\n        ax.fill(x, y, alpha=0.3, color=colors[idx], label=region_name)\n\nax.legend()\nax.set_title('Experimental Regions')\nplt.show()\n</code></pre>"},{"location":"user-guide/workflows/#workflow-3-multi-session-alignment","title":"Workflow 3: Multi-Session Alignment","text":"<p>Comparing environments across recording sessions.</p>"},{"location":"user-guide/workflows/#overview_2","title":"Overview","text":"<p>Goal: Align spatial representations from different sessions to track stability</p> <p>Steps: Create environments for each session \u2192 Align using transforms \u2192 Compare firing patterns</p>"},{"location":"user-guide/workflows/#complete-example_2","title":"Complete Example","text":"<pre><code>from neurospatial import Environment\nfrom neurospatial.alignment import map_probabilities_to_nearest_target_bin\nimport numpy as np\n\n# Session 1 (reference)\nenv1 = Environment.from_samples(\n    session1_position,\n    bin_size=2.5,\n    name=\"Session1\"\n)\nfiring_rate1 = compute_firing_rate(env1, session1_position, session1_spikes)\n\n# Session 2 (may have slight camera shift or animal positioning differences)\nenv2 = Environment.from_samples(\n    session2_position,\n    bin_size=2.5,\n    name=\"Session2\"\n)\nfiring_rate2 = compute_firing_rate(env2, session2_position, session2_spikes)\n\n# Align session 2 to session 1 coordinate frame\nfiring_rate2_aligned = map_probabilities_to_nearest_target_bin(\n    source_env=env2,\n    target_env=env1,\n    source_probabilities=firing_rate2\n)\n\n# Compute spatial correlation\nvalid_bins = ~np.isnan(firing_rate1) &amp; ~np.isnan(firing_rate2_aligned)\ncorrelation = np.corrcoef(\n    firing_rate1[valid_bins],\n    firing_rate2_aligned[valid_bins]\n)[0, 1]\n\nprint(f\"Spatial correlation: {correlation:.3f}\")\n\n# Visualize comparison\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# Session 1\naxes[0].scatter(env1.bin_centers[:, 0], env1.bin_centers[:, 1],\n                c=firing_rate1, s=50, cmap='hot')\naxes[0].set_title('Session 1')\n\n# Session 2 (aligned)\naxes[1].scatter(env1.bin_centers[:, 0], env1.bin_centers[:, 1],\n                c=firing_rate2_aligned, s=50, cmap='hot')\naxes[1].set_title('Session 2 (aligned)')\n\n# Difference\ndifference = firing_rate2_aligned - firing_rate1\naxes[2].scatter(env1.bin_centers[:, 0], env1.bin_centers[:, 1],\n                c=difference, s=50, cmap='RdBu_r',\n                vmin=-np.nanmax(np.abs(difference)),\n                vmax=np.nanmax(np.abs(difference)))\naxes[2].set_title(f'Difference (r={correlation:.3f})')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user-guide/workflows/#workflow-4-track-linearization","title":"Workflow 4: Track Linearization","text":"<p>Analyzing maze experiments with branching structures.</p>"},{"location":"user-guide/workflows/#overview_3","title":"Overview","text":"<p>Goal: Convert 2D maze positions to 1D linearized coordinates for sequential analysis</p> <p>Steps: Define track graph \u2192 Create 1D environment \u2192 Map positions \u2192 Analyze</p> <p>See the complete example in examples/05_track_linearization.ipynb.</p>"},{"location":"user-guide/workflows/#common-patterns","title":"Common Patterns","text":""},{"location":"user-guide/workflows/#pattern-handling-edge-cases","title":"Pattern: Handling Edge Cases","text":"<pre><code># Always check for valid bins\nbin_indices = env.bin_at(positions)\nvalid = bin_indices != -1  # -1 indicates point outside environment\n\n# Use only valid data\nvalid_positions = positions[valid]\nvalid_bins = bin_indices[valid]\n\n# Or handle invalid gracefully\nfiring_rate = np.full(env.n_bins, np.nan)\nvalid_occupancy = occupancy_time &gt; min_threshold\nfiring_rate[valid_occupancy] = spike_counts[valid_occupancy] / occupancy_time[valid_occupancy]\n</code></pre>"},{"location":"user-guide/workflows/#pattern-batch-processing","title":"Pattern: Batch Processing","text":"<pre><code># Process multiple neurons efficiently\nneurons = load_all_neurons()\nfiring_rate_maps = []\n\nfor neuron_id, spike_times in neurons.items():\n    spike_positions = interpolate_position(position_data, spike_times)\n    spike_bins = env.bin_at(spike_positions)\n    spike_counts, _ = np.histogram(spike_bins, bins=np.arange(env.n_bins + 1))\n\n    firing_rate = spike_counts / occupancy_time\n    firing_rate[occupancy_time &lt; min_occupancy] = np.nan\n\n    firing_rate_maps.append(firing_rate)\n\nfiring_rate_maps = np.array(firing_rate_maps)  # Shape: (n_neurons, n_bins)\n</code></pre>"},{"location":"user-guide/workflows/#pattern-progressive-refinement","title":"Pattern: Progressive Refinement","text":"<pre><code># Start with coarse binning for quick overview\nenv_coarse = Environment.from_samples(positions, bin_size=10.0)\n# ... analyze ...\n\n# Refine in regions of interest\nenv_fine = Environment.from_samples(\n    positions,\n    bin_size=2.0,\n    infer_active_bins=True,\n    dilate=True\n)\n# ... detailed analysis ...\n</code></pre>"},{"location":"user-guide/workflows/#see-also","title":"See Also","text":"<ul> <li>Environment API: Complete method documentation</li> <li>Regions Guide: Working with ROIs</li> <li>Example Notebooks: Interactive tutorials</li> </ul>"}]}