{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Animation Overlays (v0.4.0)\n",
    "\n",
    "This notebook demonstrates the new overlay system for visualizing animal behavior alongside spatial fields:\n",
    "\n",
    "1. **Position Overlays** - Trajectories with decaying trails\n",
    "2. **Bodypart Overlays** - Pose tracking with skeleton rendering\n",
    "3. **Head Direction Overlays** - Orientation arrows\n",
    "4. **Multi-Animal Support** - Track multiple animals simultaneously\n",
    "5. **Regions** - Highlight spatial regions of interest\n",
    "6. **Temporal Alignment** - Sync overlays at different sampling rates\n",
    "7. **Backend Comparison** - Same data across all backends\n",
    "\n",
    "**Estimated time**: 20-25 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- Overlay trajectories on animated spatial fields\n",
    "- Visualize pose tracking data with skeletons\n",
    "- Display head direction as dynamic arrows\n",
    "- Track multiple animals in the same animation\n",
    "- Highlight regions of interest with transparency\n",
    "- Align overlays at different sampling rates using `frame_times`\n",
    "- Choose the right backend for overlay visualization\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "**Optional dependencies** (install as needed):\n",
    "\n",
    "```bash\n",
    "# For Napari backend (recommended for overlays)\n",
    "pip install 'napari[all]>=0.4.18'\n",
    "\n",
    "# For video export\n",
    "# macOS: brew install ffmpeg\n",
    "# Ubuntu: sudo apt install ffmpeg\n",
    "```\n",
    "\n",
    "**Note**: HTML backend supports position and region overlays only (no pose or head direction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from neurospatial import (\n",
    "    BodypartOverlay,\n",
    "    Environment,\n",
    "    HeadDirectionOverlay,\n",
    "    PositionOverlay,\n",
    ")\n",
    "from neurospatial.animation.backends.video_backend import check_ffmpeg_available\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Output directory\n",
    "output_dir = Path.cwd()\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup: Create Environment and Simulate Data\n",
    "\n",
    "We'll create a circular arena and simulate:\n",
    "- A place field that tracks with the animal\n",
    "- Animal trajectory exploring the arena\n",
    "- Head direction as the animal moves\n",
    "- Pose data (nose, body center, tail base) for skeleton visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_env",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating circular arena environment...\")\n",
    "\n",
    "# Circular arena (50 cm radius)\n",
    "center = Point(50, 50)\n",
    "radius = 50.0\n",
    "circle = center.buffer(radius)\n",
    "\n",
    "env = Environment.from_polygon(polygon=circle, bin_size=2.5, name=\"CircularArena\")\n",
    "env.units = \"cm\"\n",
    "env.frame = \"open_field\"\n",
    "\n",
    "# Add region of interest (reward zone in upper-right quadrant)\n",
    "reward_zone = Point(65, 65)\n",
    "env.regions.add(\"reward\", point=reward_zone)\n",
    "\n",
    "print(f\"Environment: {env.n_bins} bins, {env.n_dims}D\")\n",
    "print(f\"Regions: {list(env.regions.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simulate_trajectory",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSimulating animal trajectory...\")\n",
    "\n",
    "n_frames = 50  # 50 time points\n",
    "t = np.linspace(0, 4 * np.pi, n_frames)  # 2 revolutions\n",
    "\n",
    "# Spiral trajectory from center outward\n",
    "r = np.linspace(5, 40, n_frames)  # Radius increases\n",
    "theta = t + np.random.randn(n_frames) * 0.1  # Angle with noise\n",
    "\n",
    "# Convert to Cartesian (center at 50, 50)\n",
    "trajectory = np.column_stack([50 + r * np.cos(theta), 50 + r * np.sin(theta)])\n",
    "\n",
    "# Head direction (tangent to spiral)\n",
    "head_angles = theta + np.pi / 2  # Perpendicular to radius\n",
    "\n",
    "print(f\"Trajectory: {n_frames} frames\")\n",
    "print(f\"  Position range: [{trajectory.min():.1f}, {trajectory.max():.1f}] cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simulate_pose",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSimulating pose data (nose, body, tail)...\")\n",
    "\n",
    "# Pose: 3 keypoints with skeleton\n",
    "body_length = 10.0  # cm\n",
    "\n",
    "# Nose: ahead of body center\n",
    "nose_offset = body_length * 0.5\n",
    "nose_x = trajectory[:, 0] + nose_offset * np.cos(head_angles)\n",
    "nose_y = trajectory[:, 1] + nose_offset * np.sin(head_angles)\n",
    "\n",
    "# Body center: trajectory position\n",
    "body_x = trajectory[:, 0]\n",
    "body_y = trajectory[:, 1]\n",
    "\n",
    "# Tail: behind body center\n",
    "tail_offset = body_length * 0.5\n",
    "tail_x = trajectory[:, 0] - tail_offset * np.cos(head_angles)\n",
    "tail_y = trajectory[:, 1] - tail_offset * np.sin(head_angles)\n",
    "\n",
    "# Pose dictionary\n",
    "pose_data = {\n",
    "    \"nose\": np.column_stack([nose_x, nose_y]),\n",
    "    \"body\": np.column_stack([body_x, body_y]),\n",
    "    \"tail\": np.column_stack([tail_x, tail_y]),\n",
    "}\n",
    "\n",
    "# Skeleton: connections between keypoints\n",
    "skeleton = [(\"tail\", \"body\"), (\"body\", \"nose\")]\n",
    "\n",
    "print(\"Pose: 3 keypoints (nose, body, tail)\")\n",
    "print(f\"Skeleton: {len(skeleton)} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simulate_fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSimulating place field that tracks with animal...\")\n",
    "\n",
    "# Place field centered on animal position at each frame\n",
    "fields = []\n",
    "for i in range(n_frames):\n",
    "    # Find bin closest to animal position\n",
    "    pos = trajectory[i : i + 1]  # Shape (1, 2)\n",
    "    center_bin = env.bin_at(pos)[0]\n",
    "\n",
    "    # Gaussian field around animal\n",
    "    distances = env.distance_to([center_bin])\n",
    "    sigma = 12.0  # cm\n",
    "    field = np.exp(-(distances**2) / (2 * sigma**2))\n",
    "\n",
    "    # Add noise\n",
    "    field = field + np.random.randn(env.n_bins) * 0.1\n",
    "    field = np.maximum(field, 0)\n",
    "\n",
    "    fields.append(field)\n",
    "\n",
    "fields = np.array(fields)\n",
    "print(f\"Fields: {fields.shape} (frames x bins)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex1",
   "metadata": {},
   "source": [
    "## Example 1: Position Overlay with Trail\n",
    "\n",
    "Overlay the animal's trajectory on the animated field with a decaying trail showing recent positions.\n",
    "\n",
    "**Key features**:\n",
    "- `trail_length=10` shows last 10 frames\n",
    "- Trail fades from current (opaque) to past (transparent)\n",
    "- Current position rendered as a marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex1_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create position overlay with trail\n",
    "position_overlay = PositionOverlay(\n",
    "    data=trajectory,\n",
    "    color=\"red\",\n",
    "    size=12.0,\n",
    "    trail_length=10,  # Show last 10 frames as trail\n",
    ")\n",
    "\n",
    "print(\"Example 1: Position Overlay with Trail\")\n",
    "print(f\"  Trajectory: {trajectory.shape[0]} frames\")\n",
    "print(\"  Trail length: 10 frames (decaying alpha)\")\n",
    "print(\"  Color: red, Size: 12.0\")\n",
    "\n",
    "try:\n",
    "    import napari\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    print(\"\\nLaunching Napari viewer...\")\n",
    "    viewer = env.animate_fields(\n",
    "        fields,\n",
    "        overlays=[position_overlay],\n",
    "        backend=\"napari\",\n",
    "        fps=10,\n",
    "        title=\"Position Overlay with Trail\",\n",
    "    )\n",
    "\n",
    "    print(\"\u2713 Napari viewer opened\")\n",
    "    print(\"  Watch the red trail follow the animal\")\n",
    "\n",
    "    if get_ipython() is None:\n",
    "        napari.run()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\u2297 Napari not available. Install with: pip install 'napari[all]>=0.4.18'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex2",
   "metadata": {},
   "source": [
    "## Example 2: Pose Tracking with Skeleton\n",
    "\n",
    "Overlay full pose data (nose, body, tail) with skeleton connecting the keypoints.\n",
    "\n",
    "**Key features**:\n",
    "- `data` is a dict mapping bodypart names to trajectories\n",
    "- `skeleton` defines edges between bodyparts\n",
    "- `colors` can customize per-bodypart colors\n",
    "- Skeleton rendered with specified color and width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex2_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bodypart overlay with skeleton\n",
    "bodypart_overlay = BodypartOverlay(\n",
    "    data=pose_data,\n",
    "    skeleton=skeleton,\n",
    "    colors={\"nose\": \"yellow\", \"body\": \"red\", \"tail\": \"blue\"},\n",
    "    skeleton_color=\"white\",\n",
    "    skeleton_width=2.0,\n",
    ")\n",
    "\n",
    "print(\"Example 2: Pose Tracking with Skeleton\")\n",
    "print(f\"  Bodyparts: {list(pose_data.keys())}\")\n",
    "print(f\"  Skeleton edges: {skeleton}\")\n",
    "print(\"  Colors: nose=yellow, body=red, tail=blue\")\n",
    "\n",
    "try:\n",
    "    import napari\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    print(\"\\nLaunching Napari viewer...\")\n",
    "    viewer = env.animate_fields(\n",
    "        fields,\n",
    "        overlays=[bodypart_overlay],\n",
    "        backend=\"napari\",\n",
    "        fps=10,\n",
    "        title=\"Pose Tracking with Skeleton\",\n",
    "    )\n",
    "\n",
    "    print(\"\u2713 Napari viewer opened\")\n",
    "    print(\"  Watch the skeleton follow the animal pose\")\n",
    "\n",
    "    if get_ipython() is None:\n",
    "        napari.run()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\u2297 Napari not available. Install with: pip install 'napari[all]>=0.4.18'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex3",
   "metadata": {},
   "source": [
    "## Example 3: Head Direction Visualization\n",
    "\n",
    "Overlay head direction as dynamic arrows pointing in the direction of travel.\n",
    "\n",
    "**Key features**:\n",
    "- `data` can be angles (radians) or unit vectors\n",
    "- Arrows rendered with specified color and length\n",
    "- Arrow origin is at the animal's position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex3_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create head direction overlay (angles in radians)\n",
    "head_direction_overlay = HeadDirectionOverlay(\n",
    "    data=head_angles,\n",
    "    color=\"yellow\",\n",
    "    length=15.0,  # Arrow length in cm\n",
    ")\n",
    "\n",
    "print(\"Example 3: Head Direction Visualization\")\n",
    "print(f\"  Head angles: {head_angles.shape[0]} frames\")\n",
    "print(\"  Arrow color: yellow, Length: 15.0 cm\")\n",
    "\n",
    "try:\n",
    "    import napari\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    print(\"\\nLaunching Napari viewer...\")\n",
    "\n",
    "    # Combine position + head direction overlays\n",
    "    viewer = env.animate_fields(\n",
    "        fields,\n",
    "        overlays=[position_overlay, head_direction_overlay],\n",
    "        backend=\"napari\",\n",
    "        fps=10,\n",
    "        title=\"Position + Head Direction\",\n",
    "    )\n",
    "\n",
    "    print(\"\u2713 Napari viewer opened\")\n",
    "    print(\"  Watch the yellow arrow show heading direction\")\n",
    "\n",
    "    if get_ipython() is None:\n",
    "        napari.run()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\u2297 Napari not available. Install with: pip install 'napari[all]>=0.4.18'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex4",
   "metadata": {},
   "source": [
    "## Example 4: Multi-Animal Tracking\n",
    "\n",
    "Track multiple animals simultaneously by providing multiple overlay instances.\n",
    "\n",
    "**Key features**:\n",
    "- Pass a list of overlays for each animal\n",
    "- Each overlay automatically gets a suffix (e.g., \"Position_1\", \"Position_2\")\n",
    "- All animals rendered in the same animation with different colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex4_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example 4: Multi-Animal Tracking\")\n",
    "print(\"\\nSimulating second animal...\")\n",
    "\n",
    "# Second animal with offset trajectory\n",
    "trajectory_2 = trajectory + np.array([10, -10])  # Offset spatially\n",
    "trajectory_2 = np.clip(trajectory_2, 5, 95)  # Keep in bounds\n",
    "\n",
    "# Create overlays for both animals\n",
    "animal1_overlay = PositionOverlay(\n",
    "    data=trajectory, color=\"red\", size=12.0, trail_length=8\n",
    ")\n",
    "\n",
    "animal2_overlay = PositionOverlay(\n",
    "    data=trajectory_2, color=\"blue\", size=12.0, trail_length=8\n",
    ")\n",
    "\n",
    "print(\"  Animal 1: red\")\n",
    "print(\"  Animal 2: blue (offset trajectory)\")\n",
    "\n",
    "try:\n",
    "    import napari\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    print(\"\\nLaunching Napari viewer...\")\n",
    "    viewer = env.animate_fields(\n",
    "        fields,\n",
    "        overlays=[animal1_overlay, animal2_overlay],  # Multiple overlays\n",
    "        backend=\"napari\",\n",
    "        fps=10,\n",
    "        title=\"Multi-Animal Tracking\",\n",
    "    )\n",
    "\n",
    "    print(\"\u2713 Napari viewer opened\")\n",
    "    print(\"  Watch both animals explore simultaneously\")\n",
    "\n",
    "    if get_ipython() is None:\n",
    "        napari.run()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\u2297 Napari not available. Install with: pip install 'napari[all]>=0.4.18'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex5",
   "metadata": {},
   "source": [
    "## Example 5: Regions Overlay with Spatial Fields\n",
    "\n",
    "Highlight spatial regions of interest (e.g., reward zones) alongside overlays.\n",
    "\n",
    "**Key features**:\n",
    "- `show_regions=True` displays all defined regions\n",
    "- `show_regions=[\"reward\"]` displays specific regions only\n",
    "- `region_alpha=0.3` controls transparency\n",
    "- Regions rendered as colored polygons/points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex5_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example 5: Regions Overlay\")\n",
    "print(f\"  Showing region: {list(env.regions.keys())}\")\n",
    "print(\"  Region alpha: 0.3 (30% transparent)\")\n",
    "\n",
    "try:\n",
    "    import napari\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    print(\"\\nLaunching Napari viewer...\")\n",
    "    viewer = env.animate_fields(\n",
    "        fields,\n",
    "        overlays=[position_overlay],\n",
    "        show_regions=True,  # Show all regions\n",
    "        region_alpha=0.3,  # 30% transparent\n",
    "        backend=\"napari\",\n",
    "        fps=10,\n",
    "        title=\"Position + Reward Region\",\n",
    "    )\n",
    "\n",
    "    print(\"\u2713 Napari viewer opened\")\n",
    "    print(\"  Watch the animal approach the reward region\")\n",
    "\n",
    "    if get_ipython() is None:\n",
    "        napari.run()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\u2297 Napari not available. Install with: pip install 'napari[all]>=0.4.18'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex6",
   "metadata": {},
   "source": [
    "## Example 6: Mixed-Rate Temporal Alignment\n",
    "\n",
    "Align overlays sampled at different rates using temporal timestamps.\n",
    "\n",
    "**Key features**:\n",
    "- Overlay `times` parameter specifies timestamps for each frame\n",
    "- `frame_times` parameter specifies field frame timestamps\n",
    "- Linear interpolation automatically aligns overlay to field frames\n",
    "- Works even when overlay and fields have different sampling rates\n",
    "\n",
    "**Example**: Position tracked at 120 Hz, fields computed at 10 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex6_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example 6: Mixed-Rate Temporal Alignment\")\n",
    "print(\"\\nSimulating high-frequency position tracking...\")\n",
    "\n",
    "# High-frequency position tracking (120 Hz)\n",
    "duration = 5.0  # seconds\n",
    "fps_high = 120  # Hz\n",
    "n_samples_high = int(duration * fps_high)  # 600 samples\n",
    "\n",
    "# Generate high-frequency trajectory\n",
    "t_high = np.linspace(0, duration, n_samples_high)\n",
    "theta_high = t_high * 2 * np.pi + np.random.randn(n_samples_high) * 0.05\n",
    "r_high = 20 + 15 * np.sin(t_high * 3)\n",
    "\n",
    "trajectory_high_freq = np.column_stack(\n",
    "    [50 + r_high * np.cos(theta_high), 50 + r_high * np.sin(theta_high)]\n",
    ")\n",
    "timestamps_high = t_high\n",
    "\n",
    "print(f\"  Position tracking: {n_samples_high} samples at {fps_high} Hz\")\n",
    "\n",
    "# Low-frequency fields (10 Hz)\n",
    "fps_low = 10  # Hz\n",
    "n_frames_low = int(duration * fps_low)  # 50 frames\n",
    "frame_times = np.linspace(0, duration, n_frames_low)\n",
    "\n",
    "print(f\"  Field computation: {n_frames_low} frames at {fps_low} Hz\")\n",
    "\n",
    "# Compute fields at low frequency\n",
    "fields_low_freq = []\n",
    "for t in frame_times:\n",
    "    # Find closest high-freq position\n",
    "    idx = np.argmin(np.abs(timestamps_high - t))\n",
    "    pos = trajectory_high_freq[idx : idx + 1]\n",
    "    center_bin = env.bin_at(pos)[0]\n",
    "\n",
    "    distances = env.distance_to([center_bin])\n",
    "    field = np.exp(-(distances**2) / (2 * 12.0**2))\n",
    "    field = field + np.random.randn(env.n_bins) * 0.1\n",
    "    field = np.maximum(field, 0)\n",
    "    fields_low_freq.append(field)\n",
    "\n",
    "fields_low_freq = np.array(fields_low_freq)\n",
    "\n",
    "# Create overlay with timestamps\n",
    "position_overlay_timed = PositionOverlay(\n",
    "    data=trajectory_high_freq,\n",
    "    times=timestamps_high,  # 120 Hz timestamps\n",
    "    color=\"red\",\n",
    "    size=10.0,\n",
    "    trail_length=15,\n",
    ")\n",
    "\n",
    "print(\"\\n\u2713 Overlay will be interpolated to match field frame times\")\n",
    "print(\"  (Linear interpolation: 120 Hz \u2192 10 Hz)\")\n",
    "\n",
    "try:\n",
    "    import napari\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    print(\"\\nLaunching Napari viewer...\")\n",
    "    viewer = env.animate_fields(\n",
    "        fields_low_freq,\n",
    "        overlays=[position_overlay_timed],\n",
    "        frame_times=frame_times,  # Explicit field timestamps\n",
    "        backend=\"napari\",\n",
    "        fps=10,\n",
    "        title=\"Mixed-Rate Alignment (120 Hz \u2192 10 Hz)\",\n",
    "    )\n",
    "\n",
    "    print(\"\u2713 Napari viewer opened\")\n",
    "    print(\"  Position automatically aligned to field frames\")\n",
    "\n",
    "    if get_ipython() is None:\n",
    "        napari.run()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\u2297 Napari not available. Install with: pip install 'napari[all]>=0.4.18'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex7",
   "metadata": {},
   "source": [
    "## Example 7: Backend Comparison\n",
    "\n",
    "Compare overlay rendering across all backends with the same data.\n",
    "\n",
    "**Backend capabilities**:\n",
    "\n",
    "| Backend | Position | Bodypart | HeadDirection | Regions |\n",
    "|---------|----------|----------|---------------|--------|\n",
    "| Napari  | \u2713 | \u2713 | \u2713 | \u2713 |\n",
    "| Video   | \u2713 | \u2713 | \u2713 | \u2713 |\n",
    "| HTML    | \u2713 | \u2717 | \u2717 | \u2713 |\n",
    "| Widget  | \u2713 | \u2713 | \u2713 | \u2713 |\n",
    "\n",
    "**Note**: HTML backend warns when given unsupported overlay types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex7_napari",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example 7a: Napari Backend (Full Support)\")\n",
    "\n",
    "try:\n",
    "    import napari\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    # All overlay types supported\n",
    "    viewer = env.animate_fields(\n",
    "        fields,\n",
    "        overlays=[position_overlay, bodypart_overlay, head_direction_overlay],\n",
    "        show_regions=True,\n",
    "        backend=\"napari\",\n",
    "        fps=10,\n",
    "        title=\"Napari: All Overlays\",\n",
    "    )\n",
    "\n",
    "    print(\"\u2713 Napari: Position + Pose + Head Direction + Regions\")\n",
    "\n",
    "    if get_ipython() is None:\n",
    "        napari.run()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\u2297 Napari not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex7_video",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example 7b: Video Backend (Full Support)\")\n",
    "\n",
    "if check_ffmpeg_available():\n",
    "    # All overlay types supported\n",
    "    output_path = env.animate_fields(\n",
    "        fields,\n",
    "        overlays=[position_overlay, bodypart_overlay, head_direction_overlay],\n",
    "        show_regions=True,\n",
    "        backend=\"video\",\n",
    "        save_path=output_dir / \"17_all_overlays.mp4\",\n",
    "        fps=10,\n",
    "        n_workers=4,\n",
    "    )\n",
    "    print(f\"\u2713 Video: Saved to {output_path}\")\n",
    "else:\n",
    "    print(\"\u2297 ffmpeg not available for video export\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex7_html",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example 7c: HTML Backend (Position + Regions Only)\")\n",
    "print(\"  WARNING: HTML backend does NOT support bodypart or head direction overlays\")\n",
    "print(\"  (Warnings will be emitted if provided)\\n\")\n",
    "\n",
    "# HTML: Only position and regions supported\n",
    "html_path = env.animate_fields(\n",
    "    fields,\n",
    "    overlays=[position_overlay],  # Only position overlay\n",
    "    show_regions=True,\n",
    "    backend=\"html\",\n",
    "    save_path=output_dir / \"17_position_only.html\",\n",
    "    fps=10,\n",
    ")\n",
    "\n",
    "print(f\"\u2713 HTML: Saved to {html_path}\")\n",
    "print(\"  (Position + Regions rendered; pose/head direction not supported)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex7_widget",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example 7d: Widget Backend (Full Support)\")\n",
    "\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    if get_ipython() is not None:\n",
    "        # All overlay types supported\n",
    "        widget = env.animate_fields(\n",
    "            fields,\n",
    "            overlays=[position_overlay, bodypart_overlay, head_direction_overlay],\n",
    "            show_regions=True,\n",
    "            backend=\"widget\",\n",
    "            fps=10,\n",
    "        )\n",
    "        print(\"\u2713 Widget: Position + Pose + Head Direction + Regions\")\n",
    "    else:\n",
    "        print(\"\u2297 Not in Jupyter notebook\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\u2297 IPython/ipywidgets not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "takeaways",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Overlay Types\n",
    "\n",
    "1. **PositionOverlay**: Trajectories with decaying trails\n",
    "   - `data`: (n_frames, n_dims) array\n",
    "   - `trail_length`: Number of past frames to show\n",
    "   - `color`, `size`: Marker appearance\n",
    "\n",
    "2. **BodypartOverlay**: Pose tracking with skeletons\n",
    "   - `data`: Dict mapping bodypart names to (n_frames, n_dims) arrays\n",
    "   - `skeleton`: List of (bodypart1, bodypart2) edge tuples\n",
    "   - `colors`: Per-bodypart colors\n",
    "   - `skeleton_color`, `skeleton_width`: Skeleton appearance\n",
    "\n",
    "3. **HeadDirectionOverlay**: Orientation arrows\n",
    "   - `data`: (n_frames,) angles in radians OR (n_frames, n_dims) unit vectors\n",
    "   - `color`, `length`: Arrow appearance\n",
    "\n",
    "### Temporal Alignment\n",
    "\n",
    "- Add `times` parameter to overlay for timestamps\n",
    "- Add `frame_times` parameter to `animate_fields()` for field timestamps\n",
    "- Linear interpolation automatically aligns overlay to field frames\n",
    "- Works even when overlay and fields have different sampling rates\n",
    "\n",
    "### Backend Capabilities\n",
    "\n",
    "- **Napari**: Full support (all overlay types + regions)\n",
    "- **Video**: Full support (all overlay types + regions)\n",
    "- **HTML**: Partial support (position + regions only, warns for others)\n",
    "- **Widget**: Full support (all overlay types + regions)\n",
    "\n",
    "### Multi-Animal Support\n",
    "\n",
    "- Pass multiple overlay instances in a list\n",
    "- Each overlay automatically gets a suffix (e.g., \"Position_1\", \"Position_2\")\n",
    "- Use different colors to distinguish animals\n",
    "\n",
    "### Common Patterns\n",
    "\n",
    "```python\n",
    "# Simple trajectory overlay\n",
    "from neurospatial import PositionOverlay\n",
    "overlay = PositionOverlay(data=trajectory, color=\"red\", trail_length=10)\n",
    "env.animate_fields(fields, overlays=[overlay], backend=\"napari\")\n",
    "\n",
    "# Pose with skeleton\n",
    "from neurospatial import BodypartOverlay\n",
    "overlay = BodypartOverlay(\n",
    "    data={\"nose\": nose_traj, \"body\": body_traj, \"tail\": tail_traj},\n",
    "    skeleton=[(\"tail\", \"body\"), (\"body\", \"nose\")],\n",
    "    skeleton_color=\"white\"\n",
    ")\n",
    "env.animate_fields(fields, overlays=[overlay], backend=\"napari\")\n",
    "\n",
    "# Mixed-rate alignment\n",
    "overlay = PositionOverlay(data=trajectory_120hz, times=times_120hz)\n",
    "env.animate_fields(\n",
    "    fields_10hz,\n",
    "    overlays=[overlay],\n",
    "    frame_times=times_10hz,  # Automatic interpolation\n",
    "    backend=\"napari\"\n",
    ")\n",
    "\n",
    "# Multi-animal\n",
    "env.animate_fields(\n",
    "    fields,\n",
    "    overlays=[overlay_animal1, overlay_animal2],\n",
    "    backend=\"napari\"\n",
    ")\n",
    "\n",
    "# Show regions\n",
    "env.animate_fields(\n",
    "    fields,\n",
    "    overlays=[overlay],\n",
    "    show_regions=True,\n",
    "    region_alpha=0.3,\n",
    "    backend=\"napari\"\n",
    ")\n",
    "```\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "- **Video export**: Use `n_workers > 1` for parallel rendering\n",
    "- **Large datasets**: Use Napari for exploration, subsample for video\n",
    "- **HTML file size**: Limit frames (default max 500) or use video backend\n",
    "- **Parallel rendering**: Call `env.clear_cache()` before video export with `n_workers > 1`\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Apply overlays to your own behavioral tracking data\n",
    "- Combine multiple overlay types for rich visualizations\n",
    "- Export publication-quality videos with overlays\n",
    "- Use temporal alignment for multi-modal data (tracking + neural recordings)\n",
    "\n",
    "For more details, see:\n",
    "- `docs/animation_overlays.md` - Complete overlay documentation\n",
    "- `examples/16_field_animation.ipynb` - Animation backends without overlays"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
