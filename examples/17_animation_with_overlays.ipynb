{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Animation Overlays\n",
    "\n",
    "This notebook demonstrates the new overlay system for visualizing animal behavior alongside spatial fields:\n",
    "\n",
    "1. **Position Overlays** - Trajectories with decaying trails\n",
    "2. **Bodypart Overlays** - Pose tracking with skeleton rendering\n",
    "3. **Head Direction Overlays** - Orientation arrows\n",
    "4. **Multi-Animal Support** - Track multiple animals simultaneously\n",
    "5. **Regions** - Highlight spatial regions of interest\n",
    "6. **Temporal Alignment** - Sync overlays at different sampling rates\n",
    "7. **Backend Comparison** - Same data across all backends\n",
    "\n",
    "**Estimated time**: 20-25 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- Overlay trajectories on animated spatial fields\n",
    "- Visualize pose tracking data with skeletons\n",
    "- Display head direction as dynamic arrows\n",
    "- Track multiple animals in the same animation\n",
    "- Highlight regions of interest with transparency\n",
    "- Align overlays at different sampling rates using `frame_times`\n",
    "- Choose the right backend for overlay visualization\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "**Optional dependencies** (install as needed):\n",
    "\n",
    "```bash\n",
    "# For Napari backend (recommended for overlays)\n",
    "pip install 'napari[all]>=0.4.18'\n",
    "\n",
    "# For video export\n",
    "# macOS: brew install ffmpeg\n",
    "# Ubuntu: sudo apt install ffmpeg\n",
    "```\n",
    "\n",
    "**Note**: HTML backend supports position and region overlays only (no pose or head direction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:15:55.865523Z",
     "iopub.status.busy": "2025-12-05T21:15:55.865148Z",
     "iopub.status.idle": "2025-12-05T21:15:57.745988Z",
     "shell.execute_reply": "2025-12-05T21:15:57.745652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: /Users/edeno/Documents/GitHub/neurospatial/examples\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from neurospatial import (\n",
    "    BodypartOverlay,\n",
    "    Environment,\n",
    "    HeadDirectionOverlay,\n",
    "    PositionOverlay,\n",
    ")\n",
    "from neurospatial.animation import Skeleton\n",
    "from neurospatial.animation.backends.video_backend import check_ffmpeg_available\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Output directory\n",
    "output_dir = Path.cwd()\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup: Create Environment and Simulate Data\n",
    "\n",
    "We'll create a circular arena and simulate:\n",
    "- A place field that tracks with the animal\n",
    "- Animal trajectory exploring the arena\n",
    "- Head direction as the animal moves\n",
    "- Pose data (nose, body center, tail base) for skeleton visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "setup_env",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:15:57.747786Z",
     "iopub.status.busy": "2025-12-05T21:15:57.747561Z",
     "iopub.status.idle": "2025-12-05T21:15:57.814124Z",
     "shell.execute_reply": "2025-12-05T21:15:57.813807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating circular arena environment...\n",
      "Environment: 1264 bins, 2D\n",
      "Regions: ['reward']\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating circular arena environment...\")\n",
    "\n",
    "# Circular arena (50 cm radius)\n",
    "center = Point(50, 50)\n",
    "radius = 50.0\n",
    "circle = center.buffer(radius)\n",
    "\n",
    "env = Environment.from_polygon(polygon=circle, bin_size=2.5, name=\"CircularArena\")\n",
    "env.units = \"cm\"\n",
    "env.frame = \"open_field\"\n",
    "\n",
    "# Add region of interest (reward zone in upper-right quadrant)\n",
    "reward_zone = Point(65, 65)\n",
    "env.regions.add(\"reward\", point=reward_zone)\n",
    "\n",
    "print(f\"Environment: {env.n_bins} bins, {env.n_dims}D\")\n",
    "print(f\"Regions: {list(env.regions.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "simulate_trajectory",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:15:57.815767Z",
     "iopub.status.busy": "2025-12-05T21:15:57.815653Z",
     "iopub.status.idle": "2025-12-05T21:15:57.818639Z",
     "shell.execute_reply": "2025-12-05T21:15:57.818264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating animal trajectory...\n",
      "Trajectory: 50 frames\n",
      "  Position range: [13.9, 89.4] cm\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSimulating animal trajectory...\")\n",
    "\n",
    "n_frames = 50  # 50 time points\n",
    "t = np.linspace(0, 4 * np.pi, n_frames)  # 2 revolutions\n",
    "\n",
    "# Spiral trajectory from center outward\n",
    "r = np.linspace(5, 40, n_frames)  # Radius increases\n",
    "theta = t + np.random.randn(n_frames) * 0.1  # Angle with noise\n",
    "\n",
    "# Convert to Cartesian (center at 50, 50)\n",
    "trajectory = np.column_stack([50 + r * np.cos(theta), 50 + r * np.sin(theta)])\n",
    "\n",
    "# Head direction (tangent to spiral)\n",
    "head_angles = theta + np.pi / 2  # Perpendicular to radius\n",
    "\n",
    "print(f\"Trajectory: {n_frames} frames\")\n",
    "print(f\"  Position range: [{trajectory.min():.1f}, {trajectory.max():.1f}] cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "simulate_pose",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:15:57.820169Z",
     "iopub.status.busy": "2025-12-05T21:15:57.820036Z",
     "iopub.status.idle": "2025-12-05T21:15:57.823079Z",
     "shell.execute_reply": "2025-12-05T21:15:57.822798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating pose data (nose, body, tail)...\n",
      "Pose: 3 keypoints (nose, body, tail)\n",
      "Skeleton: 2 edges\n",
      "  Node colors and edge styling defined in Skeleton object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSimulating pose data (nose, body, tail)...\")\n",
    "\n",
    "# Pose: 3 keypoints with skeleton\n",
    "body_length = 10.0  # cm\n",
    "\n",
    "# Nose: ahead of body center\n",
    "nose_offset = body_length * 0.5\n",
    "nose_x = trajectory[:, 0] + nose_offset * np.cos(head_angles)\n",
    "nose_y = trajectory[:, 1] + nose_offset * np.sin(head_angles)\n",
    "\n",
    "# Body center: trajectory position\n",
    "body_x = trajectory[:, 0]\n",
    "body_y = trajectory[:, 1]\n",
    "\n",
    "# Tail: behind body center\n",
    "tail_offset = body_length * 0.5\n",
    "tail_x = trajectory[:, 0] - tail_offset * np.cos(head_angles)\n",
    "tail_y = trajectory[:, 1] - tail_offset * np.sin(head_angles)\n",
    "\n",
    "# Pose dictionary\n",
    "pose_data = {\n",
    "    \"nose\": np.column_stack([nose_x, nose_y]),\n",
    "    \"body\": np.column_stack([body_x, body_y]),\n",
    "    \"tail\": np.column_stack([tail_x, tail_y]),\n",
    "}\n",
    "\n",
    "# Skeleton: defines bodypart nodes and edge connections\n",
    "skeleton = Skeleton(\n",
    "    name=\"mouse_simple\",\n",
    "    nodes=(\"nose\", \"body\", \"tail\"),\n",
    "    edges=((\"tail\", \"body\"), (\"body\", \"nose\")),\n",
    "    edge_color=\"white\",\n",
    "    edge_width=2.0,\n",
    ")\n",
    "\n",
    "print(\"Pose: 3 keypoints (nose, body, tail)\")\n",
    "print(f\"Skeleton: {skeleton.n_edges} edges\")\n",
    "print(\"  Node colors and edge styling defined in Skeleton object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "simulate_fields",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:15:57.824598Z",
     "iopub.status.busy": "2025-12-05T21:15:57.824499Z",
     "iopub.status.idle": "2025-12-05T21:15:57.949833Z",
     "shell.execute_reply": "2025-12-05T21:15:57.949397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating place field that tracks with animal...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields: (50, 1264) (frames x bins)\n",
      "Frame times: 0.00s to 4.90s (10 Hz)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSimulating place field that tracks with animal...\")\n",
    "\n",
    "# Place field centered on animal position at each frame\n",
    "fields = []\n",
    "for i in range(n_frames):\n",
    "    # Find bin closest to animal position\n",
    "    pos = trajectory[i : i + 1]  # Shape (1, 2)\n",
    "    center_bin = env.bin_at(pos)[0]\n",
    "\n",
    "    # Gaussian field around animal\n",
    "    distances = env.distance_to([center_bin])\n",
    "    sigma = 12.0  # cm\n",
    "    field = np.exp(-(distances**2) / (2 * sigma**2))\n",
    "\n",
    "    # Add noise\n",
    "    field = field + np.random.randn(env.n_bins) * 0.1\n",
    "    field = np.maximum(field, 0)\n",
    "\n",
    "    fields.append(field)\n",
    "\n",
    "fields = np.array(fields)\n",
    "print(f\"Fields: {fields.shape} (frames x bins)\")\n",
    "\n",
    "# Create frame_times (required for animate_fields)\n",
    "# Using 10 Hz frame rate (100ms per frame)\n",
    "frame_times = np.arange(n_frames) / 10.0  # seconds\n",
    "print(f\"Frame times: {frame_times[0]:.2f}s to {frame_times[-1]:.2f}s (10 Hz)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex1",
   "metadata": {},
   "source": [
    "## Example 1: Position Overlay with Trail\n",
    "\n",
    "Overlay the animal's trajectory on the animated field with a decaying trail showing recent positions.\n",
    "\n",
    "**Key features**:\n",
    "- `trail_length=10` shows last 10 frames\n",
    "- Trail fades from current (opaque) to past (transparent)\n",
    "- Current position rendered as a marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ex1_code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:15:57.951438Z",
     "iopub.status.busy": "2025-12-05T21:15:57.951317Z",
     "iopub.status.idle": "2025-12-05T21:16:00.823080Z",
     "shell.execute_reply": "2025-12-05T21:16:00.822698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: Position Overlay with Trail\n",
      "  Trajectory: 50 frames\n",
      "  Trail length: 10 frames (decaying alpha)\n",
      "  Color: red, Size: 12.0\n",
      "\n",
      "Launching Napari viewer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edeno/Documents/GitHub/neurospatial/src/neurospatial/animation/core.py:436: UserWarning: render_napari received unknown keyword arguments that will be ignored: bitrate, codec, colorbar_label, contrast_limits, dpi, dry_run, image_format, max_html_frames, n_workers, overlay_trajectory, show_colorbar. These may be parameters intended for other backends.\n",
      "  return render_napari(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Napari viewer opened\n",
      "  Watch the red trail follow the animal\n"
     ]
    }
   ],
   "source": [
    "# Create position overlay with trail\n",
    "position_overlay = PositionOverlay(\n",
    "    data=trajectory,\n",
    "    color=\"red\",\n",
    "    size=12.0,\n",
    "    trail_length=10,  # Show last 10 frames as trail\n",
    ")\n",
    "\n",
    "print(\"Example 1: Position Overlay with Trail\")\n",
    "print(f\"  Trajectory: {trajectory.shape[0]} frames\")\n",
    "print(\"  Trail length: 10 frames (decaying alpha)\")\n",
    "print(\"  Color: red, Size: 12.0\")\n",
    "\n",
    "try:\n",
    "    import napari\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    print(\"\\nLaunching Napari viewer...\")\n",
    "    viewer = env.animate_fields(\n",
    "        fields,\n",
    "        overlays=[position_overlay],\n",
    "        frame_times=frame_times,\n",
    "        backend=\"napari\",\n",
    "        fps=10,\n",
    "        title=\"Position Overlay with Trail\",\n",
    "    )\n",
    "\n",
    "    print(\"✓ Napari viewer opened\")\n",
    "    print(\"  Watch the red trail follow the animal\")\n",
    "\n",
    "    if get_ipython() is None:\n",
    "        napari.run()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"⊗ Napari not available. Install with: pip install 'napari[all]>=0.4.18'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex2",
   "metadata": {},
   "source": [
    "## Example 2: Pose Tracking with Skeleton\n",
    "\n",
    "Overlay full pose data (nose, body, tail) with skeleton connecting the keypoints.\n",
    "\n",
    "**Key features**:\n",
    "- `data` is a dict mapping bodypart names to trajectories\n",
    "- `skeleton` defines edges between bodyparts\n",
    "- `colors` can customize per-bodypart colors\n",
    "- Skeleton rendered with specified color and width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ex2_code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:16:00.824937Z",
     "iopub.status.busy": "2025-12-05T21:16:00.824811Z",
     "iopub.status.idle": "2025-12-05T21:16:01.334550Z",
     "shell.execute_reply": "2025-12-05T21:16:01.334231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 2: Pose Tracking with Skeleton\n",
      "  Bodyparts: ['nose', 'body', 'tail']\n",
      "  Skeleton edges: (('body', 'tail'), ('body', 'nose'))\n",
      "  Skeleton styling: edge_color=white, edge_width=2.0\n",
      "  Node colors: nose=yellow, body=red, tail=blue\n",
      "\n",
      "Launching Napari viewer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edeno/Documents/GitHub/neurospatial/src/neurospatial/animation/core.py:436: UserWarning: render_napari received unknown keyword arguments that will be ignored: bitrate, codec, colorbar_label, contrast_limits, dpi, dry_run, image_format, max_html_frames, n_workers, overlay_trajectory, show_colorbar. These may be parameters intended for other backends.\n",
      "  return render_napari(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Napari viewer opened\n",
      "  Watch the skeleton follow the animal pose\n"
     ]
    }
   ],
   "source": [
    "# Create bodypart overlay with skeleton\n",
    "# Note: Skeleton styling (edge_color, edge_width) comes from the Skeleton object\n",
    "bodypart_overlay = BodypartOverlay(\n",
    "    data=pose_data,\n",
    "    skeleton=skeleton,  # Skeleton object with nodes, edges, and styling\n",
    "    colors={\"nose\": \"yellow\", \"body\": \"red\", \"tail\": \"blue\"},\n",
    ")\n",
    "\n",
    "print(\"Example 2: Pose Tracking with Skeleton\")\n",
    "print(f\"  Bodyparts: {list(pose_data.keys())}\")\n",
    "print(f\"  Skeleton edges: {skeleton.edges}\")\n",
    "print(\n",
    "    f\"  Skeleton styling: edge_color={skeleton.edge_color}, edge_width={skeleton.edge_width}\"\n",
    ")\n",
    "print(\"  Node colors: nose=yellow, body=red, tail=blue\")\n",
    "\n",
    "try:\n",
    "    import napari\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    print(\"\\nLaunching Napari viewer...\")\n",
    "    viewer = env.animate_fields(\n",
    "        fields,\n",
    "        overlays=[bodypart_overlay],\n",
    "        frame_times=frame_times,\n",
    "        backend=\"napari\",\n",
    "        fps=10,\n",
    "        title=\"Pose Tracking with Skeleton\",\n",
    "    )\n",
    "\n",
    "    print(\"✓ Napari viewer opened\")\n",
    "    print(\"  Watch the skeleton follow the animal pose\")\n",
    "\n",
    "    if get_ipython() is None:\n",
    "        napari.run()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"⊗ Napari not available. Install with: pip install 'napari[all]>=0.4.18'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex3",
   "metadata": {},
   "source": [
    "## Example 3: Head Direction Visualization\n",
    "\n",
    "Overlay head direction as dynamic arrows pointing in the direction of travel.\n",
    "\n",
    "**Key features**:\n",
    "- `data` can be angles (radians) or unit vectors\n",
    "- Arrows rendered with specified color and length\n",
    "- Arrow origin is at the animal's position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ex3_code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:16:01.530756Z",
     "iopub.status.busy": "2025-12-05T21:16:01.530560Z",
     "iopub.status.idle": "2025-12-05T21:16:02.107949Z",
     "shell.execute_reply": "2025-12-05T21:16:02.107653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 3: Head Direction Visualization\n",
      "  Head angles: 50 frames\n",
      "  Arrow color: yellow, Length: 15.0 cm\n",
      "\n",
      "Launching Napari viewer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edeno/Documents/GitHub/neurospatial/src/neurospatial/animation/core.py:436: UserWarning: render_napari received unknown keyword arguments that will be ignored: bitrate, codec, colorbar_label, contrast_limits, dpi, dry_run, image_format, max_html_frames, n_workers, overlay_trajectory, show_colorbar. These may be parameters intended for other backends.\n",
      "  return render_napari(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Napari viewer opened\n",
      "  Watch the yellow arrow show heading direction\n"
     ]
    }
   ],
   "source": [
    "# Create head direction overlay (angles in radians)\n",
    "head_direction_overlay = HeadDirectionOverlay(\n",
    "    data=head_angles,\n",
    "    color=\"yellow\",\n",
    "    length=15.0,  # Arrow length in cm\n",
    ")\n",
    "\n",
    "print(\"Example 3: Head Direction Visualization\")\n",
    "print(f\"  Head angles: {head_angles.shape[0]} frames\")\n",
    "print(\"  Arrow color: yellow, Length: 15.0 cm\")\n",
    "\n",
    "try:\n",
    "    import napari\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    print(\"\\nLaunching Napari viewer...\")\n",
    "\n",
    "    # Combine position + head direction overlays\n",
    "    viewer = env.animate_fields(\n",
    "        fields,\n",
    "        overlays=[position_overlay, head_direction_overlay],\n",
    "        frame_times=frame_times,\n",
    "        backend=\"napari\",\n",
    "        fps=10,\n",
    "        title=\"Position + Head Direction\",\n",
    "    )\n",
    "\n",
    "    print(\"✓ Napari viewer opened\")\n",
    "    print(\"  Watch the yellow arrow show heading direction\")\n",
    "\n",
    "    if get_ipython() is None:\n",
    "        napari.run()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"⊗ Napari not available. Install with: pip install 'napari[all]>=0.4.18'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex4",
   "metadata": {},
   "source": [
    "## Example 4: Multi-Animal Tracking\n",
    "\n",
    "Track multiple animals simultaneously by providing multiple overlay instances.\n",
    "\n",
    "**Key features**:\n",
    "- Pass a list of overlays for each animal\n",
    "- Each overlay automatically gets a suffix (e.g., \"Position_1\", \"Position_2\")\n",
    "- All animals rendered in the same animation with different colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ex4_code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:16:02.292279Z",
     "iopub.status.busy": "2025-12-05T21:16:02.292119Z",
     "iopub.status.idle": "2025-12-05T21:16:03.141294Z",
     "shell.execute_reply": "2025-12-05T21:16:03.140983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 4: Multi-Animal Tracking\n",
      "\n",
      "Simulating second animal...\n",
      "  Animal 1: red\n",
      "  Animal 2: blue (offset trajectory)\n",
      "\n",
      "Launching Napari viewer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edeno/Documents/GitHub/neurospatial/src/neurospatial/animation/core.py:436: UserWarning: render_napari received unknown keyword arguments that will be ignored: bitrate, codec, colorbar_label, contrast_limits, dpi, dry_run, image_format, max_html_frames, n_workers, overlay_trajectory, show_colorbar. These may be parameters intended for other backends.\n",
      "  return render_napari(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Napari viewer opened\n",
      "  Watch both animals explore simultaneously\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 4: Multi-Animal Tracking\")\n",
    "print(\"\\nSimulating second animal...\")\n",
    "\n",
    "# Second animal with offset trajectory\n",
    "trajectory_2 = trajectory + np.array([10, -10])  # Offset spatially\n",
    "trajectory_2 = np.clip(trajectory_2, 5, 95)  # Keep in bounds\n",
    "\n",
    "# Create overlays for both animals\n",
    "animal1_overlay = PositionOverlay(\n",
    "    data=trajectory, color=\"red\", size=12.0, trail_length=8\n",
    ")\n",
    "\n",
    "animal2_overlay = PositionOverlay(\n",
    "    data=trajectory_2, color=\"blue\", size=12.0, trail_length=8\n",
    ")\n",
    "\n",
    "print(\"  Animal 1: red\")\n",
    "print(\"  Animal 2: blue (offset trajectory)\")\n",
    "\n",
    "try:\n",
    "    import napari\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    print(\"\\nLaunching Napari viewer...\")\n",
    "    viewer = env.animate_fields(\n",
    "        fields,\n",
    "        overlays=[animal1_overlay, animal2_overlay],  # Multiple overlays\n",
    "        frame_times=frame_times,\n",
    "        backend=\"napari\",\n",
    "        fps=10,\n",
    "        title=\"Multi-Animal Tracking\",\n",
    "    )\n",
    "\n",
    "    print(\"✓ Napari viewer opened\")\n",
    "    print(\"  Watch both animals explore simultaneously\")\n",
    "\n",
    "    if get_ipython() is None:\n",
    "        napari.run()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"⊗ Napari not available. Install with: pip install 'napari[all]>=0.4.18'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex5",
   "metadata": {},
   "source": [
    "## Example 5: Regions Overlay with Spatial Fields\n",
    "\n",
    "Highlight spatial regions of interest (e.g., reward zones) alongside overlays.\n",
    "\n",
    "**Key features**:\n",
    "- `show_regions=True` displays all defined regions\n",
    "- `show_regions=[\"reward\"]` displays specific regions only\n",
    "- `region_alpha=0.3` controls transparency\n",
    "- Regions rendered as colored polygons/points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ex5_code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:16:03.380671Z",
     "iopub.status.busy": "2025-12-05T21:16:03.380505Z",
     "iopub.status.idle": "2025-12-05T21:16:04.245523Z",
     "shell.execute_reply": "2025-12-05T21:16:04.245167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 5: Regions Overlay\n",
      "  Showing region: ['reward']\n",
      "  Region alpha: 0.3 (30% transparent)\n",
      "\n",
      "Launching Napari viewer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edeno/Documents/GitHub/neurospatial/src/neurospatial/animation/core.py:436: UserWarning: render_napari received unknown keyword arguments that will be ignored: bitrate, codec, colorbar_label, contrast_limits, dpi, dry_run, image_format, max_html_frames, n_workers, overlay_trajectory, show_colorbar. These may be parameters intended for other backends.\n",
      "  return render_napari(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Napari viewer opened\n",
      "  Watch the animal approach the reward region\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 5: Regions Overlay\")\n",
    "print(f\"  Showing region: {list(env.regions.keys())}\")\n",
    "print(\"  Region alpha: 0.3 (30% transparent)\")\n",
    "\n",
    "try:\n",
    "    import napari\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    print(\"\\nLaunching Napari viewer...\")\n",
    "    viewer = env.animate_fields(\n",
    "        fields,\n",
    "        overlays=[position_overlay],\n",
    "        show_regions=True,  # Show all regions\n",
    "        region_alpha=0.3,  # 30% transparent\n",
    "        frame_times=frame_times,\n",
    "        backend=\"napari\",\n",
    "        fps=10,\n",
    "        title=\"Position + Reward Region\",\n",
    "    )\n",
    "\n",
    "    print(\"✓ Napari viewer opened\")\n",
    "    print(\"  Watch the animal approach the reward region\")\n",
    "\n",
    "    if get_ipython() is None:\n",
    "        napari.run()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"⊗ Napari not available. Install with: pip install 'napari[all]>=0.4.18'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex6",
   "metadata": {},
   "source": [
    "## Example 6: Mixed-Rate Temporal Alignment\n",
    "\n",
    "Align overlays sampled at different rates using temporal timestamps.\n",
    "\n",
    "**Key features**:\n",
    "- Overlay `times` parameter specifies timestamps for each frame\n",
    "- `frame_times` parameter specifies field frame timestamps\n",
    "- Linear interpolation automatically aligns overlay to field frames\n",
    "- Works even when overlay and fields have different sampling rates\n",
    "\n",
    "**Example**: Position tracked at 120 Hz, fields computed at 10 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ex6_code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:16:04.413970Z",
     "iopub.status.busy": "2025-12-05T21:16:04.413814Z",
     "iopub.status.idle": "2025-12-05T21:16:05.152057Z",
     "shell.execute_reply": "2025-12-05T21:16:05.151560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 6: Mixed-Rate Temporal Alignment\n",
      "\n",
      "Simulating high-frequency position tracking...\n",
      "  Position tracking: 600 samples at 120 Hz\n",
      "  Field computation: 50 frames at 10 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Overlay will be interpolated to match field frame times\n",
      "  (Linear interpolation: 120 Hz → 10 Hz)\n",
      "\n",
      "Launching Napari viewer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edeno/Documents/GitHub/neurospatial/src/neurospatial/animation/core.py:436: UserWarning: render_napari received unknown keyword arguments that will be ignored: bitrate, codec, colorbar_label, contrast_limits, dpi, dry_run, image_format, max_html_frames, n_workers, overlay_trajectory, show_colorbar. These may be parameters intended for other backends.\n",
      "  return render_napari(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Napari viewer opened\n",
      "  Position automatically aligned to field frames\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 6: Mixed-Rate Temporal Alignment\")\n",
    "print(\"\\nSimulating high-frequency position tracking...\")\n",
    "\n",
    "# High-frequency position tracking (120 Hz)\n",
    "duration = 5.0  # seconds\n",
    "fps_high = 120  # Hz\n",
    "n_samples_high = int(duration * fps_high)  # 600 samples\n",
    "\n",
    "# Generate high-frequency trajectory\n",
    "t_high = np.linspace(0, duration, n_samples_high)\n",
    "theta_high = t_high * 2 * np.pi + np.random.randn(n_samples_high) * 0.05\n",
    "r_high = 20 + 15 * np.sin(t_high * 3)\n",
    "\n",
    "trajectory_high_freq = np.column_stack(\n",
    "    [50 + r_high * np.cos(theta_high), 50 + r_high * np.sin(theta_high)]\n",
    ")\n",
    "timestamps_high = t_high\n",
    "\n",
    "print(f\"  Position tracking: {n_samples_high} samples at {fps_high} Hz\")\n",
    "\n",
    "# Low-frequency fields (10 Hz)\n",
    "fps_low = 10  # Hz\n",
    "n_frames_low = int(duration * fps_low)  # 50 frames\n",
    "frame_times = np.linspace(0, duration, n_frames_low)\n",
    "\n",
    "print(f\"  Field computation: {n_frames_low} frames at {fps_low} Hz\")\n",
    "\n",
    "# Compute fields at low frequency\n",
    "fields_low_freq = []\n",
    "for t in frame_times:\n",
    "    # Find closest high-freq position\n",
    "    idx = np.argmin(np.abs(timestamps_high - t))\n",
    "    pos = trajectory_high_freq[idx : idx + 1]\n",
    "    center_bin = env.bin_at(pos)[0]\n",
    "\n",
    "    distances = env.distance_to([center_bin])\n",
    "    field = np.exp(-(distances**2) / (2 * 12.0**2))\n",
    "    field = field + np.random.randn(env.n_bins) * 0.1\n",
    "    field = np.maximum(field, 0)\n",
    "    fields_low_freq.append(field)\n",
    "\n",
    "fields_low_freq = np.array(fields_low_freq)\n",
    "\n",
    "# Create overlay with timestamps\n",
    "position_overlay_timed = PositionOverlay(\n",
    "    data=trajectory_high_freq,\n",
    "    times=timestamps_high,  # 120 Hz timestamps\n",
    "    color=\"red\",\n",
    "    size=10.0,\n",
    "    trail_length=15,\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Overlay will be interpolated to match field frame times\")\n",
    "print(\"  (Linear interpolation: 120 Hz → 10 Hz)\")\n",
    "\n",
    "try:\n",
    "    import napari\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    print(\"\\nLaunching Napari viewer...\")\n",
    "    viewer = env.animate_fields(\n",
    "        fields_low_freq,\n",
    "        overlays=[position_overlay_timed],\n",
    "        frame_times=frame_times,  # Explicit field timestamps\n",
    "        backend=\"napari\",\n",
    "        fps=10,\n",
    "        title=\"Mixed-Rate Alignment (120 Hz → 10 Hz)\",\n",
    "    )\n",
    "\n",
    "    print(\"✓ Napari viewer opened\")\n",
    "    print(\"  Position automatically aligned to field frames\")\n",
    "\n",
    "    if get_ipython() is None:\n",
    "        napari.run()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"⊗ Napari not available. Install with: pip install 'napari[all]>=0.4.18'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex7",
   "metadata": {},
   "source": [
    "## Example 7: Backend Comparison\n",
    "\n",
    "Compare overlay rendering across all backends with the same data.\n",
    "\n",
    "**Backend capabilities**:\n",
    "\n",
    "| Backend | Position | Bodypart | HeadDirection | Regions |\n",
    "|---------|----------|----------|---------------|--------|\n",
    "| Napari  | ✓ | ✓ | ✓ | ✓ |\n",
    "| Video   | ✓ | ✓ | ✓ | ✓ |\n",
    "| HTML    | ✓ | ✗ | ✗ | ✓ |\n",
    "| Widget  | ✓ | ✓ | ✓ | ✓ |\n",
    "\n",
    "**Note**: HTML backend warns when given unsupported overlay types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ex7_napari",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:16:05.297384Z",
     "iopub.status.busy": "2025-12-05T21:16:05.297213Z",
     "iopub.status.idle": "2025-12-05T21:16:06.515765Z",
     "shell.execute_reply": "2025-12-05T21:16:06.515422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 7a: Napari Backend (Full Support)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edeno/Documents/GitHub/neurospatial/src/neurospatial/animation/core.py:436: UserWarning: render_napari received unknown keyword arguments that will be ignored: bitrate, codec, colorbar_label, contrast_limits, dpi, dry_run, image_format, max_html_frames, n_workers, overlay_trajectory, show_colorbar. These may be parameters intended for other backends.\n",
      "  return render_napari(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Napari: Position + Pose + Head Direction + Regions\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 7a: Napari Backend (Full Support)\")\n",
    "\n",
    "try:\n",
    "    import napari\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    # All overlay types supported\n",
    "    viewer = env.animate_fields(\n",
    "        fields,\n",
    "        overlays=[position_overlay, bodypart_overlay, head_direction_overlay],\n",
    "        show_regions=True,\n",
    "        frame_times=frame_times,\n",
    "        backend=\"napari\",\n",
    "        fps=10,\n",
    "        title=\"Napari: All Overlays\",\n",
    "    )\n",
    "\n",
    "    print(\"✓ Napari: Position + Pose + Head Direction + Regions\")\n",
    "\n",
    "    if get_ipython() is None:\n",
    "        napari.run()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"⊗ Napari not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ex7_video",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:16:06.801925Z",
     "iopub.status.busy": "2025-12-05T21:16:06.801758Z",
     "iopub.status.idle": "2025-12-05T21:16:12.947561Z",
     "shell.execute_reply": "2025-12-05T21:16:12.946948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 7b: Video Backend (Full Support)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering 50 frames using 4 workers...\n",
      "Estimated time: ~6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Workers:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Workers:  25%|██▌       | 1/4 [00:03<00:11,  3.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Workers: 100%|██████████| 4/4 [00:03<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding video...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Video saved to /Users/edeno/Documents/GitHub/neurospatial/examples/17_all_overlays.mp4\n",
      "✓ Video: Saved to /Users/edeno/Documents/GitHub/neurospatial/examples/17_all_overlays.mp4\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 7b: Video Backend (Full Support)\")\n",
    "\n",
    "if check_ffmpeg_available():\n",
    "    # All overlay types supported\n",
    "    output_path = env.animate_fields(\n",
    "        fields,\n",
    "        overlays=[position_overlay, bodypart_overlay, head_direction_overlay],\n",
    "        show_regions=True,\n",
    "        frame_times=frame_times,\n",
    "        backend=\"video\",\n",
    "        save_path=output_dir / \"17_all_overlays.mp4\",\n",
    "        fps=10,\n",
    "        n_workers=4,\n",
    "    )\n",
    "    print(f\"✓ Video: Saved to {output_path}\")\n",
    "else:\n",
    "    print(\"⊗ ffmpeg not available for video export\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ex7_html",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:16:12.993229Z",
     "iopub.status.busy": "2025-12-05T21:16:12.992942Z",
     "iopub.status.idle": "2025-12-05T21:16:14.433613Z",
     "shell.execute_reply": "2025-12-05T21:16:14.433064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 7c: HTML Backend (Position + Regions Only)\n",
      "  WARNING: HTML backend does NOT support bodypart or head direction overlays\n",
      "  (Warnings will be emitted if provided)\n",
      "\n",
      "Rendering 50 frames to PNG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Encoding frames:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Encoding frames:   6%|▌         | 3/50 [00:00<00:01, 28.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Encoding frames:  14%|█▍        | 7/50 [00:00<00:01, 32.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Encoding frames:  22%|██▏       | 11/50 [00:00<00:01, 33.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Encoding frames:  30%|███       | 15/50 [00:00<00:01, 34.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Encoding frames:  38%|███▊      | 19/50 [00:00<00:00, 34.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Encoding frames:  46%|████▌     | 23/50 [00:00<00:00, 35.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Encoding frames:  54%|█████▍    | 27/50 [00:00<00:00, 35.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Encoding frames:  62%|██████▏   | 31/50 [00:00<00:00, 36.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Encoding frames:  70%|███████   | 35/50 [00:00<00:00, 36.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Encoding frames:  78%|███████▊  | 39/50 [00:01<00:00, 35.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Encoding frames:  86%|████████▌ | 43/50 [00:01<00:00, 35.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Encoding frames:  94%|█████████▍| 47/50 [00:01<00:00, 35.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Encoding frames: 100%|██████████| 50/50 [00:01<00:00, 35.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ HTML saved to /Users/edeno/Documents/GitHub/neurospatial/examples/17_position_only.html (1.6 MB)\n",
      "✓ HTML: Saved to /Users/edeno/Documents/GitHub/neurospatial/examples/17_position_only.html\n",
      "  (Position + Regions rendered; pose/head direction not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 7c: HTML Backend (Position + Regions Only)\")\n",
    "print(\"  WARNING: HTML backend does NOT support bodypart or head direction overlays\")\n",
    "print(\"  (Warnings will be emitted if provided)\\n\")\n",
    "\n",
    "# HTML: Only position and regions supported\n",
    "html_path = env.animate_fields(\n",
    "    fields,\n",
    "    overlays=[position_overlay],  # Only position overlay\n",
    "    show_regions=True,\n",
    "    frame_times=frame_times,\n",
    "    backend=\"html\",\n",
    "    save_path=output_dir / \"17_position_only.html\",\n",
    "    fps=10,\n",
    ")\n",
    "\n",
    "print(f\"✓ HTML: Saved to {html_path}\")\n",
    "print(\"  (Position + Regions rendered; pose/head direction not supported)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ex7_widget",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:16:14.471803Z",
     "iopub.status.busy": "2025-12-05T21:16:14.471614Z",
     "iopub.status.idle": "2025-12-05T21:16:15.789763Z",
     "shell.execute_reply": "2025-12-05T21:16:15.789486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 7d: Widget Backend (Full Support)\n",
      "Pre-rendering 50 frames for widget...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c787100f057146df8aa31ecfc7f28791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Play(value=0, interval=111, max=49), IntSlider(value=0, description='Frame:', ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Widget: Position + Pose + Head Direction + Regions\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 7d: Widget Backend (Full Support)\")\n",
    "\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    if get_ipython() is not None:\n",
    "        # All overlay types supported\n",
    "        widget = env.animate_fields(\n",
    "            fields,\n",
    "            overlays=[position_overlay, bodypart_overlay, head_direction_overlay],\n",
    "            show_regions=True,\n",
    "            frame_times=frame_times,\n",
    "            backend=\"widget\",\n",
    "            fps=10,\n",
    "        )\n",
    "        print(\"✓ Widget: Position + Pose + Head Direction + Regions\")\n",
    "    else:\n",
    "        print(\"⊗ Not in Jupyter notebook\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"⊗ IPython/ipywidgets not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "takeaways",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Overlay Types\n",
    "\n",
    "1. **PositionOverlay**: Trajectories with decaying trails\n",
    "   - `data`: (n_frames, n_dims) array\n",
    "   - `trail_length`: Number of past frames to show\n",
    "   - `color`, `size`: Marker appearance\n",
    "\n",
    "2. **BodypartOverlay**: Pose tracking with skeletons\n",
    "   - `data`: Dict mapping bodypart names to (n_frames, n_dims) arrays\n",
    "   - `skeleton`: Skeleton object defining nodes, edges, and styling\n",
    "   - `colors`: Per-bodypart colors (or use skeleton.node_colors)\n",
    "\n",
    "3. **HeadDirectionOverlay**: Orientation arrows\n",
    "   - `data`: (n_frames,) angles in radians OR (n_frames, n_dims) unit vectors\n",
    "   - `color`, `length`: Arrow appearance\n",
    "\n",
    "### Temporal Alignment\n",
    "\n",
    "- Add `times` parameter to overlay for timestamps\n",
    "- Add `frame_times` parameter to `animate_fields()` for field timestamps\n",
    "- Linear interpolation automatically aligns overlay to field frames\n",
    "- Works even when overlay and fields have different sampling rates\n",
    "\n",
    "### Backend Capabilities\n",
    "\n",
    "- **Napari**: Full support (all overlay types + regions)\n",
    "- **Video**: Full support (all overlay types + regions)\n",
    "- **HTML**: Partial support (position + regions only, warns for others)\n",
    "- **Widget**: Full support (all overlay types + regions)\n",
    "\n",
    "### Multi-Animal Support\n",
    "\n",
    "- Pass multiple overlay instances in a list\n",
    "- Each overlay automatically gets a suffix (e.g., \"Position_1\", \"Position_2\")\n",
    "- Use different colors to distinguish animals\n",
    "\n",
    "### Common Patterns\n",
    "\n",
    "```python\n",
    "# Simple trajectory overlay\n",
    "from neurospatial import PositionOverlay\n",
    "overlay = PositionOverlay(data=trajectory, color=\"red\", trail_length=10)\n",
    "env.animate_fields(fields, overlays=[overlay], backend=\"napari\")\n",
    "\n",
    "# Pose with skeleton\n",
    "from neurospatial import BodypartOverlay\n",
    "from neurospatial.animation import Skeleton\n",
    "skeleton = Skeleton(\n",
    "    name=\"mouse\",\n",
    "    nodes=(\"nose\", \"body\", \"tail\"),\n",
    "    edges=((\"tail\", \"body\"), (\"body\", \"nose\")),\n",
    "    edge_color=\"white\",\n",
    "    edge_width=2.0,\n",
    ")\n",
    "overlay = BodypartOverlay(\n",
    "    data={\"nose\": nose_traj, \"body\": body_traj, \"tail\": tail_traj},\n",
    "    skeleton=skeleton,\n",
    ")\n",
    "env.animate_fields(fields, overlays=[overlay], backend=\"napari\")\n",
    "\n",
    "# Mixed-rate alignment\n",
    "overlay = PositionOverlay(data=trajectory_120hz, times=times_120hz)\n",
    "env.animate_fields(\n",
    "    fields_10hz,\n",
    "    overlays=[overlay],\n",
    "    frame_times=times_10hz,  # Automatic interpolation\n",
    "    backend=\"napari\"\n",
    ")\n",
    "\n",
    "# Multi-animal\n",
    "env.animate_fields(\n",
    "    fields,\n",
    "    overlays=[overlay_animal1, overlay_animal2],\n",
    "    backend=\"napari\"\n",
    ")\n",
    "\n",
    "# Show regions\n",
    "env.animate_fields(\n",
    "    fields,\n",
    "    overlays=[overlay],\n",
    "    show_regions=True,\n",
    "    region_alpha=0.3,\n",
    "    backend=\"napari\"\n",
    ")\n",
    "```\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "- **Video export**: Use `n_workers > 1` for parallel rendering\n",
    "- **Large datasets**: Use Napari for exploration, subsample for video\n",
    "- **HTML file size**: Limit frames (default max 500) or use video backend\n",
    "- **Parallel rendering**: Call `env.clear_cache()` before video export with `n_workers > 1`\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Apply overlays to your own behavioral tracking data\n",
    "- Combine multiple overlay types for rich visualizations\n",
    "- Export publication-quality videos with overlays\n",
    "- Use temporal alignment for multi-modal data (tracking + neural recordings)\n",
    "\n",
    "For more details, see:\n",
    "- `docs/animation_overlays.md` - Complete overlay documentation\n",
    "- `examples/16_field_animation.ipynb` - Animation backends without overlays"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "neurospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0bd368a6e4374f3398b39e81851bcdae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LinkModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "LinkModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": null,
       "source": [
        "IPY_MODEL_8896bf42df9c44c688e55416cbdc2b81",
        "value"
       ],
       "target": [
        "IPY_MODEL_599f3350d3dc450694bc43524849ebbd",
        "value"
       ]
      }
     },
     "11d67cf26056481a9c72af911ec12741": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "380436a925a64e92941a436dee904f16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "599f3350d3dc450694bc43524849ebbd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "IntSliderModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "IntSliderModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "IntSliderView",
       "behavior": "drag-tap",
       "continuous_update": true,
       "description": "Frame:",
       "description_allow_html": false,
       "disabled": false,
       "layout": "IPY_MODEL_83f912c655184e38952f4e38bb198626",
       "max": 49,
       "min": 0,
       "orientation": "horizontal",
       "readout": true,
       "readout_format": "d",
       "step": 1,
       "style": "IPY_MODEL_751770e7964143a1a5aaa4dd04508740",
       "tabbable": null,
       "tooltip": null,
       "value": 0
      }
     },
     "751770e7964143a1a5aaa4dd04508740": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "SliderStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "SliderStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "description_width": "",
       "handle_color": null
      }
     },
     "79bc33c899654d34a7719ea128c3b08c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d3a303e90fb4434af969919298e085f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80598426d72a47ae83740af6896dfe80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7d3a303e90fb4434af969919298e085f",
       "placeholder": "​",
       "style": "IPY_MODEL_c75cbee5d640473d848803d012c3167d",
       "tabbable": null,
       "tooltip": null,
       "value": "<h3 style='text-align: center; margin: 0;'>Frame 1</h3>"
      }
     },
     "83f912c655184e38952f4e38bb198626": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8896bf42df9c44c688e55416cbdc2b81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "PlayModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "PlayModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "PlayView",
       "description": "",
       "description_allow_html": false,
       "disabled": false,
       "interval": 111,
       "layout": "IPY_MODEL_f4cc2002a60b42d4ad4a57e7dc3ed416",
       "max": 49,
       "min": 0,
       "playing": false,
       "repeat": false,
       "show_repeat": true,
       "step": 1,
       "style": "IPY_MODEL_e28540643978486d9e7e97d78014801f",
       "tabbable": null,
       "tooltip": null,
       "value": 0
      }
     },
     "a8140bcf84e0465fbaa0d3e3b372f8fe": {
      "buffers": [
       {
        "data": "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",
        "encoding": "base64",
        "path": [
         "value"
        ]
       }
      ],
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ImageModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ImageModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ImageView",
       "format": "png",
       "height": "",
       "layout": "IPY_MODEL_11d67cf26056481a9c72af911ec12741",
       "tabbable": null,
       "tooltip": null,
       "width": "800"
      }
     },
     "c75cbee5d640473d848803d012c3167d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c787100f057146df8aa31ecfc7f28791": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fb5a4e65aca24c57bc7e4527d5a2e0b5",
        "IPY_MODEL_80598426d72a47ae83740af6896dfe80",
        "IPY_MODEL_a8140bcf84e0465fbaa0d3e3b372f8fe"
       ],
       "layout": "IPY_MODEL_380436a925a64e92941a436dee904f16",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e28540643978486d9e7e97d78014801f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f4cc2002a60b42d4ad4a57e7dc3ed416": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fb5a4e65aca24c57bc7e4527d5a2e0b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8896bf42df9c44c688e55416cbdc2b81",
        "IPY_MODEL_599f3350d3dc450694bc43524849ebbd"
       ],
       "layout": "IPY_MODEL_79bc33c899654d34a7719ea128c3b08c",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
